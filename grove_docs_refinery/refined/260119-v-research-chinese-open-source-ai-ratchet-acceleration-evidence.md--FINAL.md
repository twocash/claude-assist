---
author: Jim Calhoun
date: '2026-01-19'
domain: research
last_synced: '2026-01-20T14:38:44.943675'
local_file: 260119-v-research-chinese-open-source-ai-ratchet-acceleration-evidence.md--FINAL.md
notion_id: 2ed780a78eef8169a2f5cffe14572617
notion_url: https://www.notion.so/Chinese-Open-Source-AI-Ratchet-Acceleration-Evidence-2ed780a78eef8169a2f5cffe14572617
status: final
title: 'Chinese Open-Source AI: Ratchet Acceleration Evidence'
type: vision
---

# Chinese Open-Source AI: Ratchet Acceleration Evidence

*Research Brief | December 2025*
**Abstract**
Chinese AI laboratories have emerged as an unexpected acceleration mechanism for local AI capability diffusion. Between December 2024 and July 2025, DeepSeek-V3 and Moonshot's Kimi K2 achieved GPT-4-class performance at 5% of historical training costs ($5-6M vs. $100M+) while releasing full model weights under permissive open-source licenses. This pattern introduces a parallel propagation channel that compresses the Ratchet thesis's projected 21-month frontier-to-local lag, making frontier-adjacent capabilities immediately available for consumer deployment. The trend is driven by competitive dynamics in China's AI ecosystem, training efficiency breakthroughs (FP8 mixed precision, mixture-of-experts architectures), and hardware constraints that paradoxically incentivize optimization. For Grove's hybrid architecture, this acceleration improves the technical risk profile by raising the local capability floor faster than baseline projections, potentially enabling more cognitive operations to remain local at launch while reducing cloud subsidy requirements during the efficiency-enlightenment loop period.
**Classification:** Strategic Intelligence for Grove Architecture Planning
Jim Calhoun
The-Grove.ai
Copyright 2025
