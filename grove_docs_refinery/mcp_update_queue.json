[
  {
    "notion_id": "2ee780a78eef816b8f91fe1014800b50",
    "filename": "260100-s-arch-bedrock-information-architecture.md--FINAL.md",
    "tables_count": 12,
    "converted_content": "\n# Bedrock Information Architecture\n\n**Version:** 1.0\n**Date:** January 2026\n**Status:** Canonical Reference\n\n---\n\n## Purpose\n\nThis document defines the information architecture for the Bedrock workspaceâ€”the knowledge curation layer of Grove's exploration infrastructure. It establishes the conceptual model, navigation structure, and design primitives that govern how humans interact with knowledge lifecycle management.\n\nThe goal is **self-evident software**: interfaces so aligned with natural mental models that they require no manual.\n\n---\n\n## The Grove Metaphor\n\nGrove's entire architecture builds on a horticultural metaphor that maps directly to knowledge work:\n\n<table header-row=\"true\">\n\t<tr>\n\t\t<td>Metaphor</td>\n\t\t<td>System Concept</td>\n\t\t<td>What It Means</td>\n\t</tr>\n\t<tr>\n\t\t<td>**Grove**</td>\n\t\t<td>The exploration infrastructure</td>\n\t\t<td>A living system where knowledge grows</td>\n\t</tr>\n\t<tr>\n\t\t<td>**Trellis**</td>\n\t\t<td>The architecture standard</td>\n\t\t<td>Structure that enables growth without constraining it</td>\n\t</tr>\n\t<tr>\n\t\t<td>**Sprout**</td>\n\t\t<td>Atomic research unit</td>\n\t\t<td>A planted question that grows into understanding</td>\n\t</tr>\n\t<tr>\n\t\t<td>**Nursery**</td>\n\t\t<td>Immature knowledge space</td>\n\t\t<td>Where sprouts are cultivated before maturity</td>\n\t</tr>\n\t<tr>\n\t\t<td>**Garden**</td>\n\t\t<td>Mature knowledge corpus</td>\n\t\t<td>Validated knowledge that feeds exploration</td>\n\t</tr>\n\t<tr>\n\t\t<td>**Lens**</td>\n\t\t<td>Perspective</td>\n\t\t<td>A way of seeing that shapes what's noticed</td>\n\t</tr>\n\t<tr>\n\t\t<td>**Experience**</td>\n\t\t<td>Configured delivery</td>\n\t\t<td>How exploration feels to the Observer</td>\n\t</tr>\n</table>\n\nThis metaphor is not decorationâ€”it is **architecture**. Every interface decision tests against it: *\"Would a gardener understand this?\"*\n\n---\n\n## The Knowledge Lifecycle\n\nKnowledge in Grove follows a natural lifecycle from intent to integration:\n\n```\n    SPARK                    SPROUT                   GROWING\n      â”‚                        â”‚                         â”‚\n      â”‚  \"I want to           â”‚  Planted in            â”‚  Research agents\n      â”‚   understand X\"        â”‚  the system            â”‚  cultivating\n      â”‚                        â”‚                         â”‚\n      â–¼                        â–¼                         â–¼\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\nâ”‚  Intent  â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¶â”‚  Nursery â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¶â”‚  Nursery â”‚\nâ”‚ declared â”‚            â”‚ (planted)â”‚              â”‚ (growing)â”‚\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n                                                        â”‚\n                                                        â–¼\n                        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n                        â”‚  Garden  â”‚â—€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚  Review  â”‚\n                        â”‚ (mature) â”‚   accepted   â”‚  (ready) â”‚\n                        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n                              â”‚\n                              â–¼\n                    Feeds agent responses\n                    in /explore\n```\n\n### Lifecycle States\n\n<table header-row=\"true\">\n\t<tr>\n\t\t<td>State</td>\n\t\t<td>Location</td>\n\t\t<td>Description</td>\n\t\t<td>Observer Experience</td>\n\t</tr>\n\t<tr>\n\t\t<td>**Planted**</td>\n\t\t<td>Nursery</td>\n\t\t<td>Sprout created, queued for research</td>\n\t\t<td>\"I asked a question\"</td>\n\t</tr>\n\t<tr>\n\t\t<td>**Growing**</td>\n\t\t<td>Nursery</td>\n\t\t<td>Agents actively researching</td>\n\t\t<td>\"Research in progress\"</td>\n\t</tr>\n\t<tr>\n\t\t<td>**Ready**</td>\n\t\t<td>Nursery</td>\n\t\t<td>Research complete, awaiting review</td>\n\t\t<td>\"Ready for me to review\"</td>\n\t</tr>\n\t<tr>\n\t\t<td>**Mature**</td>\n\t\t<td>Garden</td>\n\t\t<td>Accepted into corpus</td>\n\t\t<td>\"Part of the knowledge base\"</td>\n\t</tr>\n\t<tr>\n\t\t<td>**Archived**</td>\n\t\t<td>Garden (archived)</td>\n\t\t<td>Deprecated but preserved</td>\n\t\t<td>\"Historical reference\"</td>\n\t</tr>\n</table>\n\n### The Maturity Test\n\n> **A sprout graduates to the Garden when it can feed exploration.**\n\nThis single criterion determines placement: Can this knowledge enhance agent responses? If yes, it belongs in the Garden. If not yet, it remains in the Nursery.\n\n---\n\n## The Visibility Model\n\nAccess to Bedrock features follows progressive disclosure based on role:\n\n```\n                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n                    â”‚              EXPERIENCE                 â”‚\n                    â”‚        (configured delivery)            â”‚\n                    â”‚                                         â”‚\n                    â”‚  System prompt Â· Thesis Â· Architect     â”‚\n                    â”‚  config Â· Quality gates                 â”‚\n                    â”‚                                         â”‚\n                    â”‚            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”                  â”‚\n                    â”‚            â”‚  Admin  â”‚                  â”‚\n                    â”‚            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                  â”‚\n                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n                                      â”‚\n                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n                    â”‚         LENSES  Â·  PROMPTS              â”‚\n                    â”‚        (cultivation tools)              â”‚\n                    â”‚                                         â”‚\n                    â”‚  Perspectives Â· Templates Â· Patterns    â”‚\n                    â”‚                                         â”‚\n                    â”‚         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                â”‚\n                    â”‚         â”‚  Cultivator  â”‚                â”‚\n                    â”‚         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                â”‚\n                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n                                      â”‚\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\nâ”‚                NURSERY  Â·  GARDEN                           â”‚\nâ”‚              (knowledge lifecycle)                          â”‚\nâ”‚                                                             â”‚\nâ”‚  Sprouts in progress Â· Mature corpus Â· Research status      â”‚\nâ”‚                                                             â”‚\nâ”‚                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                             â”‚\nâ”‚                    â”‚ Everyone â”‚                             â”‚\nâ”‚                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                             â”‚\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n```\n\n### Role Definitions\n\n<table header-row=\"true\">\n\t<tr>\n\t\t<td>Role</td>\n\t\t<td>Can See</td>\n\t\t<td>Can Do</td>\n\t</tr>\n\t<tr>\n\t\t<td>**Explorer**</td>\n\t\t<td>Nursery, Garden</td>\n\t\t<td>Plant sprouts, review results, explore corpus</td>\n\t</tr>\n\t<tr>\n\t\t<td>**Cultivator**</td>\n\t\t<td>+ Lenses, Prompts</td>\n\t\t<td>Configure perspectives, create templates</td>\n\t</tr>\n\t<tr>\n\t\t<td>**Admin**</td>\n\t\t<td>+ Experience</td>\n\t\t<td>Configure system prompt, thesis, architect settings</td>\n\t</tr>\n</table>\n\n### The Progressive Disclosure Principle\n\n> **Show less, reveal more.**\n\nObservers see only what they can act on. Complexity emerges with capability, not by default. An explorer never seesâ€”or faces confusion fromâ€”admin controls.\n\n---\n\n## The Navigation Structure\n\n### Bedrock Workspace Navigation\n\n```\n/bedrock\nâ”‚\nâ”œâ”€â”€ Dashboard                    â† Overview & health\nâ”‚   â””â”€â”€ Activity feed, system status, quick actions\nâ”‚\nâ”œâ”€â”€ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  (Knowledge Lifecycle)\nâ”‚\nâ”œâ”€â”€ Nursery                      â† Sprouts in cultivation\nâ”‚   â””â”€â”€ Planted, growing, ready for review\nâ”‚   â””â”€â”€ Filter by status, age, research type\nâ”‚   â””â”€â”€ Actions: review, promote to Garden, archive\nâ”‚\nâ”œâ”€â”€ Garden                       â† Mature corpus\nâ”‚   â””â”€â”€ RAG vectors + graduated sprout outputs\nâ”‚   â””â”€â”€ Search, browse, inspect provenance\nâ”‚   â””â”€â”€ Actions: archive, view usage, trace lineage\nâ”‚\nâ”œâ”€â”€ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  (Cultivation Tools)\nâ”‚\nâ”œâ”€â”€ Lenses                       â† Perspectives\nâ”‚   â””â”€â”€ Persona configurations\nâ”‚   â””â”€â”€ How agents \"see\" on behalf of Observers\nâ”‚\nâ”œâ”€â”€ Prompts                      â† Templates\nâ”‚   â””â”€â”€ Interaction patterns\nâ”‚   â””â”€â”€ Starting points for exploration\nâ”‚\nâ”œâ”€â”€ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  (Delivery Configuration)\nâ”‚\nâ””â”€â”€ Experience                   â† THE experience\n    â””â”€â”€ System prompt (identity, voice, structure)\n    â””â”€â”€ Thesis (what this grove investigates)\n    â””â”€â”€ Sprout Architect config (inference, quality gates)\n    â””â”€â”€ Singleton: one active configuration, versioned\n```\n\n### Navigation Groupings\n\n<table header-row=\"true\">\n\t<tr>\n\t\t<td>Group</td>\n\t\t<td>Purpose</td>\n\t\t<td>Contains</td>\n\t</tr>\n\t<tr>\n\t\t<td>**Knowledge Lifecycle**</td>\n\t\t<td>Where things are by maturity</td>\n\t\t<td>Nursery, Garden</td>\n\t</tr>\n\t<tr>\n\t\t<td>**Cultivation Tools**</td>\n\t\t<td>How you shape knowledge</td>\n\t\t<td>Lenses, Prompts</td>\n\t</tr>\n\t<tr>\n\t\t<td>**Delivery Configuration**</td>\n\t\t<td>What gets experienced</td>\n\t\t<td>Experience</td>\n\t</tr>\n</table>\n\n### URL Structure\n\n```\n/bedrock                    â†’ Dashboard\n/bedrock/nursery            â†’ Sprouts in cultivation\n/bedrock/garden             â†’ Mature corpus\n/bedrock/lenses             â†’ Lens management\n/bedrock/prompts            â†’ Prompt templates\n/bedrock/experience         â†’ Experience configuration\n```\n\n---\n\n## The /explore Inspector\n\nWhen exploring in `/explore`, Observers see their research activity via an inspector panel:\n\n### The Nursery Badge\n\nA persistent indicator showing active research:\n\n```\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\nâ”‚  ğŸŒ± 3                           â”‚  â† Badge: 3 sprouts growing\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚  Expanded view:                 â”‚\nâ”‚                                 â”‚\nâ”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚\nâ”‚  â”‚ ğŸŒ± Witness timeline...    â”‚  â”‚  â† Growing\nâ”‚  â”‚    â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘ 45%         â”‚  â”‚\nâ”‚  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤  â”‚\nâ”‚  â”‚ âœ“ Email chain analysis    â”‚  â”‚  â† Ready for review\nâ”‚  â”‚    Ready Â· Tap to review  â”‚  â”‚\nâ”‚  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤  â”‚\nâ”‚  â”‚ ğŸŒ± Deposition conflicts   â”‚  â”‚  â† Growing\nâ”‚  â”‚    â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘ 72%       â”‚  â”‚\nâ”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚\nâ”‚                                 â”‚\nâ”‚  View all in Nursery â†’          â”‚  â† Deep link to /bedrock/nursery\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n```\n\n### Scope Distinction\n\n<table header-row=\"true\">\n\t<tr>\n\t\t<td>Context</td>\n\t\t<td>What's Shown</td>\n\t\t<td>Scope</td>\n\t</tr>\n\t<tr>\n\t\t<td>/explore inspector</td>\n\t\t<td>My Nursery</td>\n\t\t<td>Session or user-scoped</td>\n\t</tr>\n\t<tr>\n\t\t<td>/bedrock/nursery</td>\n\t\t<td>The Nursery</td>\n\t\t<td>Grove-scoped (all sprouts)</td>\n\t</tr>\n</table>\n\nSame concept, different scope. The metaphor holds at both levels.\n\n---\n\n## Design Primitives\n\nThese patterns repeat throughout Grove's architecture:\n\n### 1. Lifecycle State\n\nThings move through defined states toward maturity.\n\n```\nImmature â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¶ Mature\n   â”‚                                â”‚\n   â”‚  (cultivation, review,         â”‚\n   â”‚   validation)                  â”‚\n   â”‚                                â”‚\n   â–¼                                â–¼\nNursery                          Garden\nDraft                            Active\nPending                          Published\n```\n\n**Application:** Sprouts, system prompts, lensesâ€”all follow this pattern.\n\n### 2. Singleton vs Instance\n\nSome things are unique per grove; others are collections.\n\n<table header-row=\"true\">\n\t<tr>\n\t\t<td>Pattern</td>\n\t\t<td>Cardinality</td>\n\t\t<td>Examples</td>\n\t</tr>\n\t<tr>\n\t\t<td>**Singleton**</td>\n\t\t<td>One active per grove</td>\n\t\t<td>Experience (system prompt), Grove Settings</td>\n\t</tr>\n\t<tr>\n\t\t<td>**Instance**</td>\n\t\t<td>Many per grove</td>\n\t\t<td>Sprouts, Lenses, Prompts, Journeys</td>\n\t</tr>\n</table>\n\n**Singleton Rules:**\n- One active at a time\n- Multiple versions exist (history)\n- Activating new version archives previous\n- Global `is_active` flag\n\n**Instance Rules:**\n- Many can be active simultaneously\n- Each instance can have versions\n- `is_active` scoped to instance, not global\n\n### 3. Progressive Disclosure\n\nComplexity reveals with capability.\n\n```\nConsumer â”€â”€â”€â”€â”€â”€â–¶ Cultivator â”€â”€â”€â”€â”€â”€â–¶ Architect\n    â”‚                â”‚                  â”‚\n    â”‚  (sees less)   â”‚  (sees more)     â”‚  (sees all)\n    â”‚                â”‚                  â”‚\n    â–¼                â–¼                  â–¼\nExplore          + Shape            + Configure\n```\n\n**Application:** Navigation items, feature visibility, action availability.\n\n### 4. Spatial Logic\n\nThings have a *place* based on their nature.\n\n<table header-row=\"true\">\n\t<tr>\n\t\t<td>Nature</td>\n\t\t<td>Place</td>\n\t\t<td>Examples</td>\n\t</tr>\n\t<tr>\n\t\t<td>**States**</td>\n\t\t<td>Lifecycle locations</td>\n\t\t<td>Nursery, Garden</td>\n\t</tr>\n\t<tr>\n\t\t<td>**Tools**</td>\n\t\t<td>Workbenches</td>\n\t\t<td>Lenses, Prompts</td>\n\t</tr>\n\t<tr>\n\t\t<td>**Configuration**</td>\n\t\t<td>Control rooms</td>\n\t\t<td>Experience</td>\n\t</tr>\n</table>\n\nUsers navigate *to* places, not *through* menus.\n\n### 5. Provenance as Infrastructure\n\nEverything tracks its origin.\n\n```typescript\ninterface Provenance {\n  createdBy: Actor;          // Who/what created this\n  createdAt: Timestamp;      // When\n  createdFrom?: Reference;   // What it came from\n  createdWith?: Context;     // What lens/journey/state\n}\n```\n\n**The Rule:** A fact without a root is a weed.\n\n---\n\n## The Experience Singleton\n\nThe **Experience** console configures THE experience of exploration. It is singularâ€”one active configuration per grove.\n\n### What Experience Contains\n\n<table header-row=\"true\">\n\t<tr>\n\t\t<td>Component</td>\n\t\t<td>Purpose</td>\n\t\t<td>Versioned?</td>\n\t</tr>\n\t<tr>\n\t\t<td>**System Prompt**</td>\n\t\t<td>Identity, voice, structure, knowledge, boundaries</td>\n\t\t<td>Yes</td>\n\t</tr>\n\t<tr>\n\t\t<td>**Thesis**</td>\n\t\t<td>What this grove investigates</td>\n\t\t<td>Yes</td>\n\t</tr>\n\t<tr>\n\t\t<td>**Sprout Architect Config**</td>\n\t\t<td>Inference rules, quality gates, spawn limits</td>\n\t\t<td>Yes</td>\n\t</tr>\n\t<tr>\n\t\t<td>**Response Behaviors**</td>\n\t\t<td>Mode (architect/librarian/contemplative), closing style</td>\n\t\t<td>Yes</td>\n\t</tr>\n</table>\n\n### Experience vs Experiences\n\n<table header-row=\"true\">\n\t<tr>\n\t\t<td>Concept</td>\n\t\t<td>Meaning</td>\n\t</tr>\n\t<tr>\n\t\t<td>**Experience** (singular)</td>\n\t\t<td>THE configured delivery of exploration</td>\n\t</tr>\n\t<tr>\n\t\t<td>~~Experiences~~ (plural)</td>\n\t\t<td>âŒ Incorrectâ€”implies multiple active configs</td>\n\t</tr>\n</table>\n\nThere is one experience. It can be versioned. Only one version is active.\n\n### Version Management\n\n```\nExperience\nâ”œâ”€â”€ v1 (archived)\nâ”œâ”€â”€ v2 (archived)\nâ”œâ”€â”€ v3 (ACTIVE) â† Current experience\nâ””â”€â”€ v4 (draft)  â† Work in progress\n```\n\nActivating v4 archives v3. Only one active at a time.\n\n---\n\n## Metaphor Glossary\n\nFor consistency across all Grove interfaces and documentation:\n\n<table header-row=\"true\">\n\t<tr>\n\t\t<td>Term</td>\n\t\t<td>Definition</td>\n\t\t<td>Anti-pattern</td>\n\t</tr>\n\t<tr>\n\t\t<td>**Grove**</td>\n\t\t<td>The exploration infrastructure; a tenant/organization's space</td>\n\t\t<td>\"Workspace,\" \"Account\"</td>\n\t</tr>\n\t<tr>\n\t\t<td>**Trellis**</td>\n\t\t<td>The architectural standard Grove implements</td>\n\t\t<td>\"Framework,\" \"Platform\"</td>\n\t</tr>\n\t<tr>\n\t\t<td>**Sprout**</td>\n\t\t<td>An atomic unit of research intent</td>\n\t\t<td>\"Query,\" \"Request,\" \"Task\"</td>\n\t</tr>\n\t<tr>\n\t\t<td>**Nursery**</td>\n\t\t<td>Where immature sprouts are cultivated</td>\n\t\t<td>\"Queue,\" \"Pipeline,\" \"Inbox\"</td>\n\t</tr>\n\t<tr>\n\t\t<td>**Garden**</td>\n\t\t<td>The mature knowledge corpus</td>\n\t\t<td>\"Database,\" \"Repository,\" \"Store\"</td>\n\t</tr>\n\t<tr>\n\t\t<td>**Lens**</td>\n\t\t<td>A configured perspective</td>\n\t\t<td>\"Persona,\" \"Role,\" \"Mode\"</td>\n\t</tr>\n\t<tr>\n\t\t<td>**Experience**</td>\n\t\t<td>The configured delivery of exploration</td>\n\t\t<td>\"Settings,\" \"Configuration\"</td>\n\t</tr>\n\t<tr>\n\t\t<td>**Cultivator**</td>\n\t\t<td>A user who shapes knowledge</td>\n\t\t<td>\"Editor,\" \"Curator\"</td>\n\t</tr>\n\t<tr>\n\t\t<td>**Spark**</td>\n\t\t<td>The initial intent before it becomes a sprout</td>\n\t\t<td>\"Input,\" \"Prompt\"</td>\n\t</tr>\n\t<tr>\n\t\t<td>**Harvest**</td>\n\t\t<td>The act of reviewing/accepting research</td>\n\t\t<td>\"Review,\" \"Approval\"</td>\n\t</tr>\n</table>\n\n### Usage Examples\n\n**Correct:**\n- \"Your sprout is growing in the nursery\"\n- \"This insight has matured to the garden\"\n- \"Configure the experience for this grove\"\n\n**Incorrect:**\n- \"Your query is in the processing queue\"\n- \"This data has been added to the database\"\n- \"Update the settings for this workspace\"\n\n---\n\n## Migration from Current State\n\nThe current Bedrock implementation uses different terminology:\n\n<table header-row=\"true\">\n\t<tr>\n\t\t<td>Current</td>\n\t\t<td>Proposed</td>\n\t\t<td>Migration Notes</td>\n\t</tr>\n\t<tr>\n\t\t<td>Pipeline</td>\n\t\t<td>**Garden**</td>\n\t\t<td>Rename route, update nav, preserve functionality</td>\n\t</tr>\n\t<tr>\n\t\t<td>Garden (sprouts)</td>\n\t\t<td>**Nursery**</td>\n\t\t<td>Rename route, update nav, reframe purpose</td>\n\t</tr>\n\t<tr>\n\t\t<td>Experiences (plural)</td>\n\t\t<td>**Experience** (singular)</td>\n\t\t<td>Rename route, update nav, enforce singleton</td>\n\t</tr>\n\t<tr>\n\t\t<td>Dashboard</td>\n\t\t<td>Dashboard</td>\n\t\t<td>Keep as-is</td>\n\t</tr>\n\t<tr>\n\t\t<td>Lenses</td>\n\t\t<td>Lenses</td>\n\t\t<td>Keep as-is</td>\n\t</tr>\n\t<tr>\n\t\t<td>Prompts</td>\n\t\t<td>Prompts</td>\n\t\t<td>Keep as-is</td>\n\t</tr>\n</table>\n\n### Route Changes\n\n```\nCurrent                    Proposed\nâ”€â”€â”€â”€â”€â”€â”€                    â”€â”€â”€â”€â”€â”€â”€â”€\n/bedrock/pipeline    â†’     /bedrock/garden\n/bedrock/garden      â†’     /bedrock/nursery\n/bedrock/experiences â†’     /bedrock/experience\n```\n\n### Component Renames\n\n```\nCurrent                    Proposed\nâ”€â”€â”€â”€â”€â”€â”€                    â”€â”€â”€â”€â”€â”€â”€â”€\nPipelineMonitor.tsx  â†’     GardenConsole.tsx\nGardenConsole.tsx    â†’     NurseryConsole.tsx\nExperiencesConsole/  â†’     ExperienceConsole/\n```\n\n---\n\n## Validation Checklist\n\nBefore implementing any Bedrock interface, verify:\n\n- [ ] **Metaphor coherence:** Would a gardener understand this term?\n- [ ] **Lifecycle clarity:** Is the maturity state obvious?\n- [ ] **Role appropriateness:** Does visibility match capability?\n- [ ] **Singleton/Instance correctness:** Is cardinality correct?\n- [ ] **Spatial logic:** Is this a place, tool, or configuration?\n- [ ] **Provenance present:** Can users trace origins?\n- [ ] **Progressive disclosure:** Is complexity earned, not imposed?\n\n---\n\n## The Art\n\nWhat makes this architecture elegant:\n\n1. **Metaphor coherence** â€” Every term reinforces the same mental model\n2. **Self-evidence** â€” Interfaces explain themselves through naming\n3. **Natural hierarchy** â€” Lifecycle â†’ Tools â†’ Configuration feels inevitable\n4. **Scalable simplicity** â€” The same patterns work at every level\n5. **Human-centered language** â€” No jargon, no tech-speak, no acronyms\n\n> *The best interface is one that disappears. Observers should feel like they're tending a garden, not operating software.*\n\n---\n\n## Provenance\n\n<table header-row=\"true\">\n\t<tr>\n\t\t<td>Field</td>\n\t\t<td>Value</td>\n\t</tr>\n\t<tr>\n\t\t<td>**Author**</td>\n\t\t<td>Jim Calhoun / Claude</td>\n\t</tr>\n\t<tr>\n\t\t<td>**Created**</td>\n\t\t<td>2026-01-10</td>\n\t</tr>\n\t<tr>\n\t\t<td>**Context**</td>\n\t\t<td>Bedrock IA refinement session</td>\n\t</tr>\n\t<tr>\n\t\t<td>**Methodology**</td>\n\t\t<td>Collaborative design dialogue</td>\n\t</tr>\n\t<tr>\n\t\t<td>**Status**</td>\n\t\t<td>Canonical reference for Bedrock development</td>\n\t</tr>\n</table>\n\n---\n\n*This document is the source of truth for Bedrock information architecture. All implementation should reference it. Updates require explicit versioning.*"
  },
  {
    "notion_id": "2ee780a78eef8128b8adef7764ebbcf1",
    "filename": "251224-s-pattern-console-extraction-vs-rewrite.md--FINAL.md",
    "tables_count": 7,
    "converted_content": "\n# Foundation Console Deep Dive: Extraction vs Rewrite Analysis\n\n**Date:** December 24, 2024\n\n**Purpose:** Inform Foundation Sprint Spec for Kinetic Architecture migration\n\n**Status:** Analysis Complete â€” Ready for Sprint Planning\n\n---\n\n## Executive Summary\n\nThe current Foundation console architecture achieves **80% feature completeness** but lacks **architectural consistency**. NarrativeArchitect demonstrates the target three-panel inspector pattern successfully, while other consoles (KnowledgeVault, HealthDashboard, EngagementBridge) use different layouts. The path to Kinetic Architecture requires:\n\n1. **Extract** working patterns from NarrativeArchitect into reusable primitives\n2. **Unify** schema types under DEXObject base interface\n3. **Refactor** NarrativeArchitect to consume from DEXRegistry\n4. **Migrate** other consoles to unified pattern\n\n---\n\n## Current Architecture Analysis\n\n### Working Three-Panel Layout\n\n```\nFoundationWorkspace.tsx\nâ”œâ”€â”€ FoundationHeader (48px fixed)\nâ””â”€â”€ ThreeColumnLayout\n    â”œâ”€â”€ FoundationNav (220px) â€” Sidebar navigation\n    â”œâ”€â”€ <Outlet> â†’ Console content (flex-1)\n    â””â”€â”€ FoundationInspector (340px, conditional)\n```\n\n**What Works:**\n\n- `ThreeColumnLayout` renders three columns properly\n- `FoundationUIContext` manages inspector state globally\n- `FoundationInspector` routes to correct inspector by mode type\n- `JourneyInspector` and `NodeInspector` are fully implemented\n- Click â†’ openInspector() â†’ Panel opens pattern functions correctly\n\n---\n\n## Component Inventory\n\n### Shared Primitives (src/shared/)\n\n<table header-row=\"true\">\n\t<tr>\n\t\t<td>Component</td>\n\t\t<td>Lines</td>\n\t\t<td>Status</td>\n\t\t<td>Reusable</td>\n\t</tr>\n\t<tr>\n\t\t<td>`ThreeColumnLayout`</td>\n\t\t<td>68</td>\n\t\t<td>âœ… Working</td>\n\t\t<td>Yes â€” Core layout</td>\n\t</tr>\n\t<tr>\n\t\t<td>`InspectorPanel`</td>\n\t\t<td>99</td>\n\t\t<td>âœ… Working</td>\n\t\t<td>Yes â€” Inspector wrapper</td>\n\t</tr>\n\t<tr>\n\t\t<td>`InspectorSection`</td>\n\t\t<td>15</td>\n\t\t<td>âœ… Working</td>\n\t\t<td>Yes â€” Section primitive</td>\n\t</tr>\n\t<tr>\n\t\t<td>`InspectorDivider`</td>\n\t\t<td>3</td>\n\t\t<td>âœ… Working</td>\n\t\t<td>Yes â€” Divider</td>\n\t</tr>\n\t<tr>\n\t\t<td>`CollectionHeader`</td>\n\t\t<td>106</td>\n\t\t<td>âœ… Working</td>\n\t\t<td>Yes â€” Search/filter bar</td>\n\t</tr>\n\t<tr>\n\t\t<td>`SearchInput`</td>\n\t\t<td>~40</td>\n\t\t<td>âœ… Working</td>\n\t\t<td>Yes</td>\n\t</tr>\n\t<tr>\n\t\t<td>`FilterButton`</td>\n\t\t<td>~60</td>\n\t\t<td>âœ… Working</td>\n\t\t<td>Yes</td>\n\t</tr>\n\t<tr>\n\t\t<td>`SortButton`</td>\n\t\t<td>~50</td>\n\t\t<td>âœ… Working</td>\n\t\t<td>Yes</td>\n\t</tr>\n\t<tr>\n\t\t<td>`EmptyState`</td>\n\t\t<td>~40</td>\n\t\t<td>âœ… Working</td>\n\t\t<td>Yes</td>\n\t</tr>\n\t<tr>\n\t\t<td>`LoadingSpinner`</td>\n\t\t<td>~30</td>\n\t\t<td>âœ… Working</td>\n\t\t<td>Yes</td>\n\t</tr>\n\t<tr>\n\t\t<td>`StatusBadge`</td>\n\t\t<td>~25</td>\n\t\t<td>âœ… Working</td>\n\t\t<td>Yes</td>\n\t</tr>\n</table>\n\n### Foundation Components (src/foundation/components/)\n\n<table header-row=\"true\">\n\t<tr>\n\t\t<td>Component</td>\n\t\t<td>Lines</td>\n\t\t<td>Status</td>\n\t\t<td>Action</td>\n\t</tr>\n\t<tr>\n\t\t<td>`DataPanel`</td>\n\t\t<td>59</td>\n\t\t<td>âœ… Working</td>\n\t\t<td>Keep â€” Generic panel wrapper</td>\n\t</tr>\n\t<tr>\n\t\t<td>`MetricCard`</td>\n\t\t<td>76</td>\n\t\t<td>âœ… Working</td>\n\t\t<td>Keep â€” Rename to StatCard</td>\n\t</tr>\n\t<tr>\n\t\t<td>`GlowButton`</td>\n\t\t<td>114</td>\n\t\t<td>âœ… Working</td>\n\t\t<td>Keep â€” Button primitive</td>\n\t</tr>\n</table>\n\n### Console-Specific Components (Inline in NarrativeArchitect)\n\n<table header-row=\"true\">\n\t<tr>\n\t\t<td>Component</td>\n\t\t<td>Lines</td>\n\t\t<td>Status</td>\n\t\t<td>Action</td>\n\t</tr>\n\t<tr>\n\t\t<td>`ViewToggle`</td>\n\t\t<td>~50</td>\n\t\t<td>Inline</td>\n\t\t<td>**EXTRACT** â†’ Generic toggle</td>\n\t</tr>\n\t<tr>\n\t\t<td>`JourneyList`</td>\n\t\t<td>~45</td>\n\t\t<td>Inline</td>\n\t\t<td>**EXTRACT** â†’ ObjectList</td>\n\t</tr>\n\t<tr>\n\t\t<td>`PersonaList`</td>\n\t\t<td>~35</td>\n\t\t<td>Inline</td>\n\t\t<td>**EXTRACT** â†’ ObjectList</td>\n\t</tr>\n\t<tr>\n\t\t<td>`NodeGrid`</td>\n\t\t<td>~60</td>\n\t\t<td>Inline</td>\n\t\t<td>**EXTRACT** â†’ CollectionGrid</td>\n\t</tr>\n\t<tr>\n\t\t<td>`CardGrid`</td>\n\t\t<td>~45</td>\n\t\t<td>Inline</td>\n\t\t<td>**EXTRACT** â†’ CollectionGrid</td>\n\t</tr>\n</table>\n\n### Inspectors (src/foundation/inspectors/)\n\n<table header-row=\"true\">\n\t<tr>\n\t\t<td>Inspector</td>\n\t\t<td>Lines</td>\n\t\t<td>Status</td>\n\t\t<td>Action</td>\n\t</tr>\n\t<tr>\n\t\t<td>`JourneyInspector`</td>\n\t\t<td>167</td>\n\t\t<td>âœ… Complete</td>\n\t\t<td>Reference implementation</td>\n\t</tr>\n\t<tr>\n\t\t<td>`NodeInspector`</td>\n\t\t<td>192</td>\n\t\t<td>âœ… Complete</td>\n\t\t<td>Reference implementation</td>\n\t</tr>\n\t<tr>\n\t\t<td>`SproutReviewInspector`</td>\n\t\t<td>215</td>\n\t\t<td>âœ… Complete</td>\n\t\t<td>Reference implementation</td>\n\t</tr>\n\t<tr>\n\t\t<td>`PersonaInspector`</td>\n\t\t<td>â€”</td>\n\t\t<td>Placeholder</td>\n\t\t<td>Implement</td>\n\t</tr>\n\t<tr>\n\t\t<td>`CardInspector`</td>\n\t\t<td>â€”</td>\n\t\t<td>Placeholder</td>\n\t\t<td>Implement</td>\n\t</tr>\n</table>\n\n---\n\n## Data Layer Analysis\n\n### Current Schema Types (narratives-schema.ts)\n\n```tsx\n// V2.1 Types (Journey-based)\ninterface Journey {\n  id: string;\n  title: string;\n  description: string;\n  status: 'draft' | 'active' | 'archived';\n  version?: number;\n  entryNodeId?: string;\n  estimatedMinutes?: number;\n  linkedHubId?: string;\n  createdAt?: string;\n  updatedAt?: string;\n}\n\ninterface JourneyNode {\n  id: string;\n  label: string;\n  query: string;\n  journeyId: string;\n  sequenceOrder?: number;\n  primaryNext?: string;\n  alternateNext?: string[];\n  hubId?: string;\n  sectionId?: string;\n  contextSnippet?: string;\n}\n\ninterface TopicHub {\n  id: string;\n  title: string;\n  tags: string[];\n  priority: number;\n  enabled: boolean;\n  primarySource: string;\n  supportingSources: string[];\n  expertFraming: string;\n  keyPoints: string[];\n  createdAt?: string;\n  updatedAt?: string;\n}\n\n// V2.0 Types (Card-based)\ninterface Persona { ... }\ninterface Card { ... }\n```\n\n### Gap Analysis: Current Types vs DEXObject\n\n**Missing from Current Types:**\n\n- `proposedBy: 'human' | 'agent'` â€” Agent proposal tracking\n- `approvedBy?: string` â€” Human approval tracking\n- `telemetryScore?: number` â€” Usage/effectiveness metrics\n- `evolutionHistory?: VersionEntry[]` â€” Change tracking\n\n**Current Types Map to DEX:**\n\n<table header-row=\"true\">\n\t<tr>\n\t\t<td>Current Type</td>\n\t\t<td>DEX Type</td>\n\t\t<td>Notes</td>\n\t</tr>\n\t<tr>\n\t\t<td>`Journey`</td>\n\t\t<td>`DEXJourney`</td>\n\t\t<td>Add kinetic fields</td>\n\t</tr>\n\t<tr>\n\t\t<td>`JourneyNode`</td>\n\t\t<td>`DEXNode`</td>\n\t\t<td>Add kinetic fields</td>\n\t</tr>\n\t<tr>\n\t\t<td>`TopicHub`</td>\n\t\t<td>`DEXHub`</td>\n\t\t<td>Add kinetic fields</td>\n\t</tr>\n\t<tr>\n\t\t<td>`Persona`</td>\n\t\t<td>`DEXLens`</td>\n\t\t<td>Rename for clarity</td>\n\t</tr>\n\t<tr>\n\t\t<td>`Card`</td>\n\t\t<td>`DEXCard`</td>\n\t\t<td>Legacy, keep for V2.0</td>\n\t</tr>\n</table>\n\n---\n\n## Hook Analysis\n\n### useNarrativeSchema (337 lines)\n\n**Current Responsibilities:**\n\n1. Load schema from `/api/narrative`\n2. Handle V1 â†’ V2 migration\n3. Provide derived data (allJourneys, allNodes, allCards)\n4. Filter functions (getFilteredCards, getFilteredJourneys, getFilteredNodes)\n5. Selectors (getJourney, getNode, getCard, getPersona)\n6. Save to `/api/admin/narrative`\n7. CRUD operations (updateCard, deleteCard, createCard)\n\n**Refactor Strategy:**\n\n```\nuseNarrativeSchema (current monolith)\n    â†“ Split into:\nuseDEXRegistry (generic object store)\nâ”œâ”€â”€ register(type, objects)\nâ”œâ”€â”€ get(type, id)\nâ”œâ”€â”€ update(type, id, updates)\nâ”œâ”€â”€ delete(type, id)\nâ”œâ”€â”€ filter(type, predicate)\nâ””â”€â”€ subscribe(type, callback)\n\nuseDEXJourneys (domain hook)\nâ”œâ”€â”€ journeys: DEXJourney[]\nâ”œâ”€â”€ getJourney(id)\nâ””â”€â”€ filterJourneys(query)\n\nuseDEXNodes (domain hook)\nâ”œâ”€â”€ nodes: DEXNode[]\nâ”œâ”€â”€ getNode(id)\nâ””â”€â”€ filterNodes(journeyId, query)\n\nuseDEXSync (persistence hook)\nâ”œâ”€â”€ save()\nâ”œâ”€â”€ loading, saving, status\nâ””â”€â”€ GitHub sync status\n```\n\n---\n\n## Console Comparison Matrix\n\n<table header-row=\"true\">\n\t<tr>\n\t\t<td>Feature</td>\n\t\t<td>NarrativeArchitect</td>\n\t\t<td>KnowledgeVault</td>\n\t\t<td>HealthDashboard</td>\n\t\t<td>EngagementBridge</td>\n\t\t<td>SproutQueue</td>\n\t</tr>\n\t<tr>\n\t\t<td>Uses ThreeColumnLayout</td>\n\t\t<td>âœ… (via Outlet)</td>\n\t\t<td>âŒ</td>\n\t\t<td>âŒ</td>\n\t\t<td>âŒ</td>\n\t\t<td>âœ… (via Outlet)</td>\n\t</tr>\n\t<tr>\n\t\t<td>Uses FoundationUIContext</td>\n\t\t<td>âœ…</td>\n\t\t<td>âŒ</td>\n\t\t<td>âŒ</td>\n\t\t<td>âŒ</td>\n\t\t<td>âœ…</td>\n\t</tr>\n\t<tr>\n\t\t<td>Has Inspector</td>\n\t\t<td>âœ…</td>\n\t\t<td>âŒ</td>\n\t\t<td>âŒ</td>\n\t\t<td>âŒ</td>\n\t\t<td>âœ…</td>\n\t</tr>\n\t<tr>\n\t\t<td>Uses DataPanel</td>\n\t\t<td>âœ…</td>\n\t\t<td>âœ…</td>\n\t\t<td>âœ…</td>\n\t\t<td>âœ…</td>\n\t\t<td>âŒ</td>\n\t</tr>\n\t<tr>\n\t\t<td>Uses MetricCard</td>\n\t\t<td>âœ…</td>\n\t\t<td>âœ…</td>\n\t\t<td>âœ…</td>\n\t\t<td>âœ…</td>\n\t\t<td>âœ…</td>\n\t</tr>\n\t<tr>\n\t\t<td>Uses GlowButton</td>\n\t\t<td>âœ…</td>\n\t\t<td>âœ…</td>\n\t\t<td>âœ…</td>\n\t\t<td>âœ…</td>\n\t\t<td>âŒ</td>\n\t</tr>\n\t<tr>\n\t\t<td>Uses CollectionHeader</td>\n\t\t<td>âœ…</td>\n\t\t<td>âŒ</td>\n\t\t<td>âŒ</td>\n\t\t<td>âŒ</td>\n\t\t<td>âœ…</td>\n\t</tr>\n\t<tr>\n\t\t<td>Has Tab navigation</td>\n\t\t<td>âŒ (ViewToggle)</td>\n\t\t<td>âŒ</td>\n\t\t<td>âœ… (internal)</td>\n\t\t<td>âœ… (internal)</td>\n\t\t<td>âœ… (filter tabs)</td>\n\t</tr>\n\t<tr>\n\t\t<td>Lines</td>\n\t\t<td>571</td>\n\t\t<td>223</td>\n\t\t<td>540</td>\n\t\t<td>333</td>\n\t\t<td>146</td>\n\t</tr>\n</table>\n\n---\n\n## Extraction Plan\n\n### Phase 1: Extract Component Grammar (No Breaking Changes)\n\n**From NarrativeArchitect, extract:**\n\n1. **ViewToggle â†’ SegmentedControl**\n\n```tsx\ninterface SegmentedControlProps<T extends string> {\n  options: { id: T; label: string; icon?: string }[];\n  value: T;\n  onChange: (value: T) => void;\n}\n```\n\n2. **JourneyList + PersonaList â†’ ObjectList**\n\n```tsx\ninterface ObjectListProps<T> {\n  items: T[];\n  selectedId: string | null;\n  activeInspectorId: string | null;\n  onSelect: (id: string) => void;\n  renderItem: (item: T) => { label: string; count?: number; status?: 'active' | 'inactive' };\n  emptyMessage?: string;\n}\n```\n\n3. **NodeGrid + CardGrid â†’ ObjectGrid**\n\n```tsx\ninterface ObjectGridProps<T> {\n  items: T[];\n  activeInspectorId: string | null;\n  searchQuery: string;\n  onSelect: (id: string) => void;\n  renderCard: (item: T) => { title: string; subtitle: string; badges: Badge[] };\n  emptyMessage?: string;\n  columns?: 2 | 3 | 4;\n}\n```\n\n### Phase 2: Create DEXObject Type System\n\n```tsx\n// src/core/schema/dex.ts\n\n/** Base interface for all DEX-compliant objects */\nexport interface DEXObject {\n  id: string;\n  type: DEXObjectType;\n  label: string;\n  description?: string;\n  icon?: string;\n  color?: string;\n  status: 'draft' | 'active' | 'archived';\n  \n  // Versioning\n  version: number;\n  createdAt: string;\n  updatedAt: string;\n  \n  // Kinetic metadata\n  proposedBy?: 'human' | 'agent';\n  approvedBy?: string;\n  telemetryScore?: number;\n  evolutionHistory?: DEXVersionEntry[];\n}\n\nexport type DEXObjectType = 'lens' | 'journey' | 'node' | 'hub' | 'card' | 'sprout';\n\n/** Extended types */\nexport interface DEXJourney extends DEXObject {\n  type: 'journey';\n  entryNodeId?: string;\n  estimatedMinutes?: number;\n  linkedHubId?: string;\n}\n\nexport interface DEXNode extends DEXObject {\n  type: 'node';\n  query: string;\n  journeyId: string;\n  sequenceOrder?: number;\n  primaryNext?: string;\n  alternateNext?: string[];\n  hubId?: string;\n  sectionId?: string;\n  contextSnippet?: string;\n}\n\nexport interface DEXHub extends DEXObject {\n  type: 'hub';\n  tags: string[];\n  priority: number;\n  enabled: boolean;\n  primarySource: string;\n  supportingSources: string[];\n  expertFraming: string;\n  keyPoints: string[];\n}\n\nexport interface DEXLens extends DEXObject {\n  type: 'lens';\n  enabled: boolean;\n  toneGuidance: string;\n  narrativeStyle: string;\n  arcEmphasis: Record<string, number>;\n  openingPhase: string;\n  defaultThreadLength: number;\n  entryPoints: string[];\n  suggestedThread: string[];\n}\n```\n\n### Phase 3: Create DEXRegistry\n\n```tsx\n// src/core/registry/DEXRegistry.ts\n\nexport interface DEXRegistry {\n  // Read operations\n  get<T extends DEXObject>(type: DEXObjectType, id: string): T | null;\n  getAll<T extends DEXObject>(type: DEXObjectType): T[];\n  filter<T extends DEXObject>(type: DEXObjectType, predicate: (item: T) => boolean): T[];\n  \n  // Write operations\n  register<T extends DEXObject>(type: DEXObjectType, objects: Record<string, T>): void;\n  update<T extends DEXObject>(type: DEXObjectType, id: string, updates: Partial<T>): void;\n  delete(type: DEXObjectType, id: string): void;\n  create<T extends DEXObject>(type: DEXObjectType, object: Omit<T, 'id' | 'version' | 'createdAt' | 'updatedAt'>): string;\n  \n  // Subscriptions\n  subscribe(type: DEXObjectType, callback: (objects: DEXObject[]) => void): () => void;\n  \n  // Persistence\n  hydrate(schema: NarrativeSchemaV2): void;\n  dehydrate(): NarrativeSchemaV2;\n}\n```\n\n---\n\n## Migration Path\n\n### Sprint 1: Extract & Unify (This Sprint)\n\n**Deliverables:**\n\n1. Extract `SegmentedControl`, `ObjectList`, `ObjectGrid` from NarrativeArchitect\n2. Create `DEXObject` type system in `src/core/schema/dex.ts`\n3. Create `useDEXRegistry` hook (React context-based)\n4. Refactor `useNarrativeSchema` to use DEXRegistry internally\n5. NarrativeArchitect continues working (no breaking changes)\n\n**Success Criteria:**\n\n- All existing tests pass\n- NarrativeArchitect looks and works identically\n- New components are documented in shared/\n- DEXObject types export from @core/schema\n\n### Sprint 2: Migrate Consoles\n\n- Refactor SproutQueue to use ObjectGrid\n- Add inspector to KnowledgeVault\n- Unify tab patterns across consoles\n\n### Sprint 3: Agent Proposal Pipeline\n\n- Add proposal queue to DEXRegistry\n- Implement agent â†’ proposal â†’ human approval flow\n- Add telemetry scoring hooks\n\n---\n\n## Risk Assessment\n\n<table header-row=\"true\">\n\t<tr>\n\t\t<td>Risk</td>\n\t\t<td>Likelihood</td>\n\t\t<td>Impact</td>\n\t\t<td>Mitigation</td>\n\t</tr>\n\t<tr>\n\t\t<td>Breaking existing tests</td>\n\t\t<td>Medium</td>\n\t\t<td>High</td>\n\t\t<td>Run tests continuously during refactor</td>\n\t</tr>\n\t<tr>\n\t\t<td>Schema migration errors</td>\n\t\t<td>Low</td>\n\t\t<td>High</td>\n\t\t<td>Add validation layer, keep V2.0 compatibility</td>\n\t</tr>\n\t<tr>\n\t\t<td>Performance regression</td>\n\t\t<td>Low</td>\n\t\t<td>Medium</td>\n\t\t<td>Benchmark before/after</td>\n\t</tr>\n\t<tr>\n\t\t<td>Over-abstraction</td>\n\t\t<td>Medium</td>\n\t\t<td>Medium</td>\n\t\t<td>Start minimal, add features as needed</td>\n\t</tr>\n</table>\n\n---\n\n## Appendix: File Inventory\n\n**Files to Modify:**\n\n- `src/foundation/consoles/NarrativeArchitect.tsx` (571 lines)\n- `src/foundation/hooks/useNarrativeSchema.ts` (337 lines)\n- `data/narratives-schema.ts` (596 lines)\n\n**Files to Create:**\n\n- `src/core/schema/dex.ts` â€” DEXObject type system\n- `src/core/registry/DEXRegistry.ts` â€” Central object store\n- `src/core/registry/useDEXRegistry.ts` â€” React hook\n- `src/shared/SegmentedControl.tsx` â€” View toggle\n- `src/shared/ObjectList.tsx` â€” Generic list\n- `src/shared/ObjectGrid.tsx` â€” Generic grid\n\n**Files Unchanged:**\n\n- All inspector components (already well-structured)\n- ThreeColumnLayout, InspectorPanel (working as-is)\n- DataPanel, MetricCard, GlowButton (keep as-is)\n\n---\n\n## Next Step\n\nThis analysis provides clear scope for the Foundation Sprint Spec:\n\n1. **Extract component grammar** â€” 3 new shared components\n2. **Create DEX types** â€” New schema file\n3. **Create DEXRegistry** â€” Central store pattern\n4. **Refactor useNarrativeSchema** â€” Internal change, API stable\n5. **Update NarrativeArchitect** â€” Use new components\n\nEstimated effort: **2-3 focused sessions** with Claude Code."
  },
  {
    "notion_id": "2ee780a78eef81c3bf38fe145dd84b82",
    "filename": "251200-s-spec-research-agent-product-vision.md--FINAL.md",
    "tables_count": 6,
    "converted_content": "\n# Grove Research Agent: Product Vision & Plan\n\n**Document Type:** Product Vision & Roadmap  \n**Author:** Jim Calhoun, Grove AI Foundation  \n**Created:** December 28, 2025  \n**Status:** Draft for Review  \n\n---\n\n## Executive Summary\n\nThe Research Agent transforms Grove from a knowledge *retrieval* system into a knowledge *growth* system. Observers commission deep research on any topic, receive structured analysis with citations, and add validated findings directly to their personal knowledge base.\n\n**The core insight:** Research isn't a featureâ€”it's infrastructure for how intelligence compounds in Grove. Every research request yields new Sprouts that make future exploration smarter.\n\n**MVP scope:** Observer issues research query â†’ Agent produces structured document â†’ Observer approves â†’ Document enters RAG for future retrieval.\n\n**Vision scope:** Research yields atomic Sprouts with provenance chains, connection suggestions, and confidence ratingsâ€”building a personal knowledge graph through exploration.\n\n---\n\n## Strategic Context\n\n### Why Research Matters for Grove\n\nGrove's value proposition is *exploration architecture*â€”infrastructure where humans and AI discover together. But exploration requires mechanisms for knowledge accumulation. Currently, Sprouts emerge only from conversation. This constrains growth to conversational serendipity.\n\nResearch Agent adds intentional knowledge expansion:\n\n<table header-row=\"true\">\n\t<tr>\n\t\t<td>Growth Mode</td>\n\t\t<td>Mechanism</td>\n\t\t<td>Speed</td>\n\t\t<td>Coverage</td>\n\t</tr>\n\t<tr>\n\t\t<td>Conversational</td>\n\t\t<td>Insights emerge from dialogue</td>\n\t\t<td>Organic</td>\n\t\t<td>Narrow (follows conversation)</td>\n\t</tr>\n\t<tr>\n\t\t<td>**Research**</td>\n\t\t<td>Observer commissions targeted exploration</td>\n\t\t<td>Rapid</td>\n\t\t<td>Broad (systematic coverage)</td>\n\t</tr>\n\t<tr>\n\t\t<td>Import</td>\n\t\t<td>Observer adds external documents</td>\n\t\t<td>Variable</td>\n\t\t<td>Observer-dependent</td>\n\t</tr>\n</table>\n\nResearch bridges passive discovery and active curation.\n\n### Competitive Positioning\n\n<table header-row=\"true\">\n\t<tr>\n\t\t<td>Product</td>\n\t\t<td>Research Capability</td>\n\t\t<td>Knowledge Ownership</td>\n\t</tr>\n\t<tr>\n\t\t<td>ChatGPT</td>\n\t\t<td>Basic web search, ephemeral</td>\n\t\t<td>Platform owns context</td>\n\t</tr>\n\t<tr>\n\t\t<td>Perplexity</td>\n\t\t<td>Strong search, citations</td>\n\t\t<td>No persistent knowledge base</td>\n\t</tr>\n\t<tr>\n\t\t<td>Notion AI</td>\n\t\t<td>Document Q&amp;A</td>\n\t\t<td>User owns docs, AI is query layer</td>\n\t</tr>\n\t<tr>\n\t\t<td>**Grove**</td>\n\t\t<td>Research â†’ Sprouts â†’ RAG</td>\n\t\t<td>Observer owns growing knowledge graph</td>\n\t</tr>\n</table>\n\nGrove's differentiator: Research doesn't just answer questionsâ€”it *expands your exploration capacity*. Every research session makes future exploration more productive.\n\n### Alignment with Trellis Architecture\n\nResearch Agent implements DEX principles:\n\n<table header-row=\"true\">\n\t<tr>\n\t\t<td>Principle</td>\n\t\t<td>Implementation</td>\n\t</tr>\n\t<tr>\n\t\t<td>**Declarative Sovereignty**</td>\n\t\t<td>Research output format defined by schema, not code</td>\n\t</tr>\n\t<tr>\n\t\t<td>**Capability Agnosticism**</td>\n\t\t<td>Works with any model that can search and synthesize</td>\n\t</tr>\n\t<tr>\n\t\t<td>**Provenance as Infrastructure**</td>\n\t\t<td>Every claim traces to source URL and search query</td>\n\t</tr>\n\t<tr>\n\t\t<td>**Organic Scalability**</td>\n\t\t<td>Starts as single document, evolves to atomic Sprouts</td>\n\t</tr>\n</table>\n\n---\n\n## User Personas & Jobs to Be Done\n\n### Primary Persona: The Systematic Explorer\n\n**Profile:** Professional navigating unfamiliar territoryâ€”regulatory landscape, competitive analysis, technical architecture decision.\n\n**Job to be done:** \"I need to understand [complex topic] well enough to make decisions and explain my reasoning to others.\"\n\n**Current alternatives:** \n- Multiple ChatGPT sessions (no persistence)\n- Perplexity searches (good sources, no accumulation)\n- Manual research and note-taking (time-intensive)\n\n**Grove Research value:** Structured output with citations becomes permanent exploration infrastructure.\n\n### Secondary Persona: The Knowledge Architect\n\n**Profile:** Researcher, analyst, or consultant building domain expertise over time.\n\n**Job to be done:** \"I want to systematically construct a knowledge base on [domain] that compounds with use.\"\n\n**Current alternatives:**\n- Notion/Roam with manual entry\n- Zotero for academic sources\n- Personal wikis\n\n**Grove Research value:** Research compoundsâ€”each document enhances RAG, improving future research and exploration quality.\n\n### Tertiary Persona: The Insight Validator\n\n**Profile:** Observer who captured an insight from conversation but wants verification/expansion.\n\n**Job to be done:** \"I noted this claim in explorationâ€”is it actually true? What's the fuller context?\"\n\n**Current alternatives:**\n- Manual Google search\n- Ask ChatGPT to verify (no sources)\n- Ignore the uncertainty\n\n**Grove Research value:** \"Research This\" on existing Sprout returns validated analysis that can replace or supplement the original.\n\n---\n\n## Product Vision\n\n### The End State (v2.0+)\n\nResearch in Grove feels like having a research assistant who:\n1. Understands your existing knowledge (reads your Grove)\n2. Identifies exploration opportunities (knows gaps)\n3. Produces atomic, citable insights (Sprouts with provenance)\n4. Maps new terrain to familiar ground (links findings to existing Sprouts)\n5. Learns your exploration patterns\n\n**User experience:**\n\n```\nObserver: /research What are the pricing models for distributed inference?\n\nGrove: I see you have existing Sprouts on inference costs and edge \n       computing economics. I'll build on those.\n       \n       [Research in progress... 6 sources found]\n       \n       Research complete. I've harvested 5 insights:\n       \n       ğŸŒ± \"Compute-time metering dominates current pricing...\"\n          confidence: 0.9 | connects to: \"Edge latency Sprout\"\n       \n       ğŸŒ± \"Outcome-based pricing is emerging but requires...\"\n          confidence: 0.7 | new thread\n       \n       [Continue with 3 more...]\n       \n       [Review All] [Quick Accept] [Dismiss]\n```\n\n### The MVP (v1.0)\n\nResearch produces a single structured document that enters RAG on approval.\n\n**User experience:**\n\n```\nObserver: /research What are the pricing models for distributed inference?\n\nGrove: ğŸ”¬ Researching... (exploration in progress)\n       \n       [Progress: Searching... Analyzing... Synthesizing...]\n       \n       ğŸ“„ Research Complete\n       \n       \"Distributed inference networks converge on three \n       pricing models: compute-time metering, QoS tiers, and \n       outcome-based pricing.\"\n       \n       3 citations | ~2,400 words | 47 seconds\n       \n       [View Full Document] [Add to Knowledge Base]\n```\n\n---\n\n## MVP Specification\n\n### Functional Requirements\n\n#### FR-1: Research Command\n\n**Trigger:** Observer types `/research [query]` in Terminal command input.\n\n**Validation:**\n- Query must be 10-500 characters\n- Query must be a question or topic, not a command\n\n**Response:** System acknowledges and begins research.\n\n#### FR-2: Research Agent Execution\n\n**Process:**\n1. System prompt instructs agent on research methodology\n2. Agent accesses web search tool\n3. Agent performs 3-8 searches based on query complexity\n4. Agent synthesizes findings into structured document\n5. Agent returns document with citations\n\n**Timeout:** 3 minutes maximum. If exceeded, return partial results with note.\n\n**Cost tracking:** Log credit usage per research request for future rate limiting.\n\n#### FR-3: Research Document Schema\n\n```typescript\ninterface ResearchDocument {\n  id: string;\n  query: string;\n  \n  // The content\n  position: string;           // 1-3 sentence thesis\n  analysis: string;           // Full analysis (markdown)\n  citations: Citation[];\n  \n  // Metadata\n  createdAt: number;\n  searchesPerformed: number;\n  creditsUsed: number;\n  durationMs: number;\n  \n  // Status\n  status: 'pending' | 'complete' | 'partial' | 'failed';\n  ragStatus: 'not_added' | 'added';\n}\n\ninterface Citation {\n  index: number;              // [1], [2], etc.\n  title: string;\n  url: string;\n  snippet: string;            // Relevant excerpt\n  domain: string;             // For credibility signal\n  accessedAt: number;\n}\n```\n\n#### FR-4: Document Display\n\n**In-stream preview:**\n- Position (thesis) displayed\n- Citation count and word count shown\n- Two CTAs: \"View Full Document\" and \"Add to Knowledge Base\"\n\n**Full document view:**\n- Modal or slide-out panel\n- Rendered markdown with citation links\n- Sticky header with title and actions\n- Citation list at bottom with snippets\n\n#### FR-5: RAG Integration\n\n**\"Add to Knowledge Base\" flow:**\n1. Observer clicks CTA\n2. Confirmation: \"Add this research to your knowledge base? It will enhance future explorations.\"\n3. On confirm: Document indexed to vector store\n4. Success feedback: \"Research added. Your Grove can now reference this knowledge.\"\n\n**Indexing strategy:**\n- Embed full document as single chunk (MVP simplicity)\n- Metadata includes: query, citation URLs, creation date\n- Retrieval: Standard semantic search against Observer's Grove\n\n#### FR-6: Research History\n\n**Requirement:** Observer can view past research documents.\n\n**Access:** `/research history` command or dedicated UI route.\n\n**Display:** List of past research with query, date, status, and RAG status.\n\n### Non-Functional Requirements\n\n#### NFR-1: Performance\n\n- Research completes in <90 seconds for typical queries\n- Timeout at 180 seconds with graceful partial results\n- Progress indication every 10 seconds\n\n#### NFR-2: Cost Management\n\n- MVP: No hard limits, but log all usage\n- Track: credits consumed, searches performed, duration\n- Future: Implement daily/monthly quotas based on efficiency loop\n\n#### NFR-3: Quality\n\n- Citations must be real, accessible URLs\n- Position must derive from analysis\n- Analysis must reference citations inline\n\n#### NFR-4: Error Handling\n\n- Network failures: Retry once, then fail gracefully\n- No results: Return \"insufficient sources\" with suggestions\n- Timeout: Return partial results with \"research incomplete\" flag\n\n### User Interface Specifications\n\n#### UI-1: Research Command Input\n\nLocation: Terminal command input (existing)\n\nBehavior:\n- `/research ` prefix triggers research mode\n- Input field placeholder changes: \"What would you like to explore?\"\n- Submit initiates research flow\n\n#### UI-2: Research Progress Indicator\n\nLocation: Kinetic Stream (new StreamItem type or SystemEvent enhancement)\n\nStates:\n```\nğŸ”¬ Researching: \"distributed inference pricing\"\n   Searching for sources...\n   \nğŸ”¬ Researching: \"distributed inference pricing\"\n   Analyzing 6 sources...\n   \nğŸ”¬ Researching: \"distributed inference pricing\"\n   Synthesizing findings...\n```\n\nVisual: Subtle animation matching Kinetic Stream cognitive states.\n\n#### UI-3: Research Result Block\n\nLocation: Stream (new block type)\n\nLayout:\n```\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\nâ”‚ ğŸ“„ Research Complete                                        â”‚\nâ”‚                                                             â”‚\nâ”‚ [Position text - 1-3 sentences, the thesis]                 â”‚\nâ”‚                                                             â”‚\nâ”‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚\nâ”‚ 3 citations  â€¢  ~2,400 words  â€¢  47s                        â”‚\nâ”‚                                                             â”‚\nâ”‚ [View Full Document]  [Add to Knowledge Base]               â”‚\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n```\n\nStyling: GlassPanel variant, distinct from response blocks.\n\n#### UI-4: Full Document Viewer\n\nLocation: Modal overlay or slide-out panel\n\nLayout:\n```\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\nâ”‚ Research: \"distributed inference pricing models\"        [X] â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚                                                             â”‚\nâ”‚ # Position                                                  â”‚\nâ”‚                                                             â”‚\nâ”‚ Distributed inference networks converge on three            â”‚\nâ”‚ pricing models: compute-time metering, quality-of-service   â”‚\nâ”‚ tiers, and outcome-based pricing.                           â”‚\nâ”‚                                                             â”‚\nâ”‚ # Analysis                                                  â”‚\nâ”‚                                                             â”‚\nâ”‚ ## Compute-Time Metering                                    â”‚\nâ”‚                                                             â”‚\nâ”‚ The dominant model in current distributed inference         â”‚\nâ”‚ networks charges per inference-second or per-credit [1].    â”‚\nâ”‚ This approach mirrors traditional cloud computing...        â”‚\nâ”‚                                                             â”‚\nâ”‚ [... continued ...]                                         â”‚\nâ”‚                                                             â”‚\nâ”‚ # Citations                                                 â”‚\nâ”‚                                                             â”‚\nâ”‚ [1] \"Decentralized Inference Pricing\" - arxiv.org           â”‚\nâ”‚     \"The paper proposes a metering framework...\"            â”‚\nâ”‚                                                             â”‚\nâ”‚ [2] \"Edge AI Economics\" - a16z.com                          â”‚\nâ”‚     \"Andreessen Horowitz analysis of pricing trends...\"     â”‚\nâ”‚                                                             â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚                      [Add to Knowledge Base]                â”‚\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n```\n\n#### UI-5: RAG Confirmation\n\nTrigger: Observer clicks \"Add to Knowledge Base\"\n\nModal:\n```\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\nâ”‚ Add to Knowledge Base                                       â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚                                                             â”‚\nâ”‚ This research will join your Grove and enhance              â”‚\nâ”‚ future explorations.                                        â”‚\nâ”‚                                                             â”‚\nâ”‚ Query: \"distributed inference pricing models\"               â”‚\nâ”‚ Size: ~2,400 words, 3 citations                             â”‚\nâ”‚                                                             â”‚\nâ”‚                          [Cancel]  [Add]                    â”‚\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n```\n\nSuccess toast: \"âœ“ Research added to your knowledge base\"\n\n---\n\n## Technical Architecture\n\n### System Overview\n\n```\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\nâ”‚                         Terminal                             â”‚\nâ”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”â”‚\nâ”‚  â”‚ /research [query]                                       â”‚â”‚\nâ”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â”‚\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n                              â”‚\n                              â–¼\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\nâ”‚                    Research Handler                          â”‚\nâ”‚  - Validates query                                           â”‚\nâ”‚  - Creates ResearchJob                                       â”‚\nâ”‚  - Invokes Research Agent                                    â”‚\nâ”‚  - Streams progress to Terminal                              â”‚\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n                              â”‚\n                              â–¼\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\nâ”‚                    Research Agent                            â”‚\nâ”‚  - System prompt with methodology                            â”‚\nâ”‚  - Tool: web_search                                          â”‚\nâ”‚  - Iterative search/analyze/synthesize loop                  â”‚\nâ”‚  - Returns structured ResearchDocument                       â”‚\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n                              â”‚\n                              â–¼\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\nâ”‚                    Document Storage                          â”‚\nâ”‚  - Stores ResearchDocument                                   â”‚\nâ”‚  - Tracks RAG status                                         â”‚\nâ”‚  - Enables history retrieval                                 â”‚\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n                              â”‚\n                              â–¼ (on Observer approval)\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\nâ”‚                    Vector Store (RAG)                        â”‚\nâ”‚  - Embeds document                                           â”‚\nâ”‚  - Stores with metadata                                      â”‚\nâ”‚  - Available for future retrieval                            â”‚\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n```\n\n### Research Agent Design\n\n#### Agent Loop\n\n```typescript\nasync function executeResearch(query: string): Promise<ResearchDocument> {\n  const agent = new ClaudeAgent({\n    model: 'claude-sonnet-4-20250514',\n    maxCredits: 8000,\n    systemPrompt: RESEARCH_SYSTEM_PROMPT,\n    tools: [webSearchTool]\n  });\n  \n  // Single prompt that guides multi-step research\n  const result = await agent.run(`\n    Research query: \"${query}\"\n    \n    Follow your methodology:\n    1. Scope the question\n    2. Search for authoritative sources (3-8 searches)\n    3. Analyze findings\n    4. Synthesize into position + analysis + citations\n    \n    Return your findings in the specified JSON format.\n  `);\n  \n  return parseResearchOutput(result);\n}\n```\n\n#### System Prompt\n\n```markdown\nYou are a research agent for Grove, exploration architecture for AI and humans.\n\n## Your Mission\n\nTransform a research query into structured knowledge with:\n- A clear position (thesis)\n- Supporting analysis\n- Verified citations\n\n## Research Methodology\n\n### Phase 1: Scope (no searches)\n- Clarify the research question\n- Identify 3-5 key aspects to investigate\n- Define what's in/out of scope\n\n### Phase 2: Search (3-8 searches)\n- Start broad, then narrow based on findings\n- Prioritize: academic sources, official documentation, recognized experts\n- Avoid: forums, social media, SEO-optimized content farms\n- For each search, extract the most valuable 1-2 sources\n\n### Phase 3: Analyze\n- Extract key claims from sources\n- Identify areas of consensus and disagreement\n- Note gaps in available information\n\n### Phase 4: Synthesize\n- Form a clear position based on evidence\n- Structure analysis into logical sections\n- Cite sources inline using [n] notation\n- State confidence levels and limitations explicitly\n\n## Output Format\n\nReturn valid JSON:\n\n```json\n{\n  \"position\": \"1-3 sentence thesis summarizing findings\",\n  \"analysis\": \"Full markdown analysis with ## sections and [n] citations\",\n  \"citations\": [\n    {\n      \"index\": 1,\n      \"title\": \"Source title\",\n      \"url\": \"https://...\",\n      \"snippet\": \"Relevant excerpt from source\",\n      \"domain\": \"arxiv.org\"\n    }\n  ],\n  \"searchesPerformed\": 5,\n  \"limitations\": \"What couldn't be determined or verified\"\n}\n```\n\n## Quality Standards\n\n- Every claim in analysis requires a citation\n- Position derives from analysis\n- Acknowledge uncertainty explicitly\n- Prefer depth over breadth\n- When sources conflict, present both views\n\n## Constraints\n\n- Maximum 8 web searches\n- Return results even if incomplete\n- Never fabricate sources\n- URLs must be real and accessible\n```\n\n### API Integration\n\n#### Endpoint\n\n```typescript\n// POST /api/research\ninterface ResearchRequest {\n  query: string;\n  options?: {\n    maxSearches?: number;    // default: 8\n    timeout?: number;        // default: 180000 (3 min)\n  };\n}\n\ninterface ResearchResponse {\n  jobId: string;\n  status: 'started' | 'complete' | 'failed';\n  document?: ResearchDocument;\n  error?: string;\n}\n```\n\n#### Streaming Progress\n\nFor MVP, use Server-Sent Events or polling:\n\n```typescript\n// GET /api/research/:jobId/status\ninterface ResearchStatus {\n  jobId: string;\n  status: 'searching' | 'analyzing' | 'synthesizing' | 'complete' | 'failed';\n  progress?: string;         // Human-readable progress\n  searchesComplete?: number;\n  document?: ResearchDocument;\n}\n```\n\n### RAG Integration\n\n#### Embedding Strategy\n\nMVP: Embed full document as single vector.\n\n```typescript\nasync function addToRAG(doc: ResearchDocument): Promise<void> {\n  const content = formatForEmbedding(doc);\n  \n  await vectorStore.upsert({\n    id: doc.id,\n    vector: await embed(content),\n    metadata: {\n      type: 'research',\n      query: doc.query,\n      position: doc.position,\n      citationCount: doc.citations.length,\n      citationUrls: doc.citations.map(c => c.url),\n      createdAt: doc.createdAt,\n      wordCount: countWords(doc.analysis)\n    }\n  });\n}\n\nfunction formatForEmbedding(doc: ResearchDocument): string {\n  return `\nResearch Query: ${doc.query}\n\nPosition: ${doc.position}\n\nAnalysis:\n${doc.analysis}\n\nKey Sources: ${doc.citations.map(c => c.title).join(', ')}\n  `.trim();\n}\n```\n\n#### Retrieval\n\nResearch documents retrieved alongside other Sprouts:\n\n```typescript\nasync function retrieveContext(query: string): Promise<Context[]> {\n  const results = await vectorStore.search({\n    query,\n    topK: 10,\n    filter: { observerId: currentObserver.id }\n  });\n  \n  // Research documents are just another context type\n  return results.map(r => ({\n    type: r.metadata.type,  // 'research' | 'sprout' | 'conversation'\n    content: r.content,\n    relevance: r.score,\n    source: r.metadata\n  }));\n}\n```\n\n---\n\n## Roadmap\n\n### Phase 1: MVP (v1.0)\n\n**Timeline:** 2-3 weeks  \n**Goal:** Basic research â†’ document â†’ RAG flow\n\n**Deliverables:**\n- `/research` command handler\n- Research agent with web search\n- ResearchResultBlock in Terminal\n- Document viewer (modal)\n- RAG integration\n- Research history (basic)\n\n**Success criteria:**\n- Observer can issue research query\n- Document returns in <2 minutes\n- Document can be added to RAG\n- Document is retrievable in future conversations\n\n### Phase 2: Polish & Validate (v1.1)\n\n**Timeline:** 2 weeks  \n**Goal:** Quality improvements based on usage\n\n**Deliverables:**\n- Research from existing Sprout (\"Research This\" button)\n- Improved progress indication\n- Better error handling and partial results\n- Usage tracking and basic rate limiting\n- Document editing before RAG addition\n\n**Success criteria:**\n- Research quality meets Observer expectations\n- <10% failure rate\n- Clear feedback on progress and errors\n\n### Phase 3: Atomic Sprouts (v1.2)\n\n**Timeline:** 3-4 weeks  \n**Goal:** Research outputs Sprouts, not just documents\n\n**Deliverables:**\n- Structured analysis with clear sections\n- Section â†’ Sprout atomization on approval\n- Connection suggestions to existing Sprouts\n- Sprout review/edit UI\n- Confidence scoring per Sprout\n\n**Success criteria:**\n- Observers can review and edit individual Sprouts\n- Connections suggested are relevant\n- Sprouts maintain citation provenance\n\n### Phase 4: Full Harvest (v2.0)\n\n**Timeline:** 4-6 weeks  \n**Goal:** Research as intelligent knowledge growth\n\n**Deliverables:**\n- Research agent aware of existing Grove\n- Gap identification (what Observer doesn't know)\n- Multi-document research campaigns\n- Sprout conflict detection (contradicts existing knowledge)\n- Research patterns and recommendations\n\n**Success criteria:**\n- Research builds on existing knowledge\n- Observers report their Grove \"learns from itself\"\n- Research suggests productive exploration paths\n\n---\n\n## Success Metrics\n\n### Engagement Metrics\n\n<table header-row=\"true\">\n\t<tr>\n\t\t<td>Metric</td>\n\t\t<td>MVP Target</td>\n\t\t<td>v2.0 Target</td>\n\t</tr>\n\t<tr>\n\t\t<td>Research queries/Observer/week</td>\n\t\t<td>2+</td>\n\t\t<td>5+</td>\n\t</tr>\n\t<tr>\n\t\t<td>Documents added to RAG</td>\n\t\t<td>60% of completed</td>\n\t\t<td>80% of completed</td>\n\t</tr>\n\t<tr>\n\t\t<td>Research completion rate</td>\n\t\t<td>90%</td>\n\t\t<td>95%</td>\n\t</tr>\n\t<tr>\n\t\t<td>Average research time</td>\n\t\t<td>&lt;90s</td>\n\t\t<td>&lt;60s</td>\n\t</tr>\n</table>\n\n### Quality Metrics\n\n<table header-row=\"true\">\n\t<tr>\n\t\t<td>Metric</td>\n\t\t<td>MVP Target</td>\n\t\t<td>v2.0 Target</td>\n\t</tr>\n\t<tr>\n\t\t<td>Citation accuracy (URLs work)</td>\n\t\t<td>95%</td>\n\t\t<td>99%</td>\n\t</tr>\n\t<tr>\n\t\t<td>Observer satisfaction (thumbs up)</td>\n\t\t<td>70%</td>\n\t\t<td>85%</td>\n\t</tr>\n\t<tr>\n\t\t<td>Research referenced in later conversations</td>\n\t\t<td>Track only</td>\n\t\t<td>40% of added</td>\n\t</tr>\n</table>\n\n### Growth Metrics\n\n<table header-row=\"true\">\n\t<tr>\n\t\t<td>Metric</td>\n\t\t<td>MVP Target</td>\n\t\t<td>v2.0 Target</td>\n\t</tr>\n\t<tr>\n\t\t<td>Sprouts from research</td>\n\t\t<td>N/A (doc only)</td>\n\t\t<td>30% of total Sprouts</td>\n\t</tr>\n\t<tr>\n\t\t<td>Grove size growth from research</td>\n\t\t<td>Track only</td>\n\t\t<td>2x baseline growth</td>\n\t</tr>\n</table>\n\n---\n\n## Risks & Mitigations\n\n### Risk 1: Research Quality Inconsistent\n\n**Likelihood:** High  \n**Impact:** High (core value proposition)\n\n**Mitigations:**\n- Strong system prompt with quality criteria\n- Citation validation before return\n- Observer feedback loop (thumbs up/down)\n- Quality scoring for source domains\n\n### Risk 2: Cost Overruns\n\n**Likelihood:** Medium  \n**Impact:** Medium (unsustainable economics)\n\n**Mitigations:**\n- Credit tracking from day one\n- Search count limits (max 8)\n- Timeout limits (3 min)\n- v1.1: Observer-facing quotas if needed\n\n### Risk 3: Slow Performance\n\n**Likelihood:** Medium  \n**Impact:** Medium (poor UX)\n\n**Mitigations:**\n- Progress indication (Observer knows it's working)\n- Timeout with partial results\n- Future: Background processing option\n\n### Risk 4: Low Adoption\n\n**Likelihood:** Low-Medium  \n**Impact:** High (wasted investment)\n\n**Mitigations:**\n- Clear value prop in UX\n- Prominent but not intrusive entry point\n- Success stories and templates\n- Future: Suggested research based on conversation\n\n---\n\n## Open Questions\n\n### Product Questions\n\n1. **Should research be a premium feature?**\n   - Costs ~$0.10-0.50 per research in API calls\n   - Could gate behind Pro tier or credit system\n\n2. **What's the document retention policy?**\n   - Keep all research forever?\n   - Archive after N days if not added to RAG?\n\n3. **Should research be shareable?**\n   - Export as PDF/Markdown?\n   - Share link to document?\n   - Collaborative Grove implications?\n\n### Technical Questions\n\n1. **Which vector store for RAG?**\n   - Pinecone, Weaviate, pgvector, local?\n   - Depends on broader Grove RAG architecture\n\n2. **How to handle research that contradicts existing Sprouts?**\n   - Surface conflict to Observer?\n   - Automatic confidence adjustment?\n\n3. **Background processing for v1.1+?**\n   - Job queue architecture (Redis, SQS)?\n   - Notification system?\n\n---\n\n## Appendix A: Research Prompt Iterations\n\n### Prompt v0.1 (Starting Point)\n\n[Include the system prompt from Technical Architecture section]\n\n### Prompt Tuning Process\n\n1. Run 10 sample queries across domains\n2. Evaluate: citation accuracy, position clarity, analysis depth\n3. Adjust prompt based on failure modes\n4. Repeat until quality bar met\n\n### Sample Queries for Testing\n\n- \"What are the pricing models for distributed inference networks?\"\n- \"How does the EU AI Act classify edge computing applications?\"\n- \"What is the current state of homomorphic encryption for ML inference?\"\n- \"Compare WebGPU vs WebNN for in-browser ML\"\n- \"What are the governance models for open source AI projects?\"\n\n---\n\n## Appendix B: Competitive Research\n\n### Perplexity Pro\n\n**Strengths:**\n- Excellent source quality\n- Fast results\n- Good citation formatting\n\n**Weaknesses:**\n- No persistent knowledge base\n- No connection to prior queries\n- Results don't compound\n\n### ChatGPT with Browsing\n\n**Strengths:**\n- Conversational follow-up\n- Good synthesis\n\n**Weaknesses:**\n- Citation quality variable\n- No structured output\n- No RAG integration\n\n### Elicit\n\n**Strengths:**\n- Academic source focus\n- Structured extraction\n- Concept mapping\n\n**Weaknesses:**\n- Narrow to academic use case\n- No general web search\n- Separate from conversation\n\n### Grove Research Positioning\n\n\"Research that grows your exploration capacity, not just answers your question.\"\n\nUnique value:\n- Research compounds (enters RAG)\n- Structured output (position + analysis + citations)\n- Future: Integrates with existing knowledge\n- Future: Suggests exploration paths\n\n---\n\n## Appendix C: Future Vision Sketches\n\n### Collaborative Research\n\nMultiple Observers researching same topic, Sprouts merge with attribution:\n\n```\nğŸŒ± \"Distributed inference pricing converges on three models...\"\n   Sources: Jim's research, Sarah's research\n   Confidence: 0.95 (corroborated)\n```\n\n### Research Campaigns\n\nMulti-query research with synthesis:\n\n```\nObserver: /research-campaign \"Competitive landscape for distributed AI\"\n\nGrove: I'll investigate this as a 5-part research campaign:\n       1. Major players and positioning\n       2. Technical architectures compared\n       3. Pricing and business models\n       4. Regulatory considerations\n       5. Market predictions\n       \n       Estimated time: 15-20 minutes\n       \n       [Start Campaign] [Customize Topics]\n```\n\n### Knowledge Gap Detection\n\nGrove identifies what Observer doesn't know:\n\n```\nGrove: Based on your Grove, you have strong coverage of \n       technical architecture but limited knowledge of:\n       - Regulatory landscape (2 Sprouts)\n       - Competitive pricing (0 Sprouts)\n       \n       [Research Gaps] [Ignore]\n```\n\n---\n\n*Document version 1.0. For review and iteration.*"
  },
  {
    "notion_id": "2ee780a78eef81bfaec0cad3fdb74b62",
    "filename": "251200-v-ratchet-deep-dive.md--FINAL.md",
    "tables_count": 6,
    "converted_content": "\n# The Ratchet: Grove's Core Bet\n\n*Capability Propagation and Exploration Architecture*\n\nJim Calhoun  \nJanuary 2026 | Grove Deep Dive Series\n\nGrove Technical Deep Dive â€” Appendix A\n\n---\n\n**Â© 2026 Jim Calhoun / Grove AI Foundation. All rights reserved.**\n\nThis document is for informational purposes only and does not constitute legal, financial, or technical advice. Grove AI Foundation makes no warranties, express or implied, regarding the accuracy or completeness of the information contained herein.\n\n---\n\n## Executive Summary\n\n$300 billion in announced AI infrastructure investments share one assumption: whoever controls the frontier controls AI. That assumption has a structural flaw: **AI capability propagates with a 7-month doubling time**. What's frontier today runs on consumer hardware in 18-24 months.\n\nThis document presents evidence for capability propagationâ€”what we call \"the Ratchet\"â€”and its implications for Grove's exploration architecture. The Ratchet enables distributed AI infrastructure where agents develop genuine capabilities while preserving Observer sovereignty.\n\n---\n\n## The Pattern: What the Data Shows\n\nMETR (Model Evaluation and Threat Research) tracks AI capability trajectories across standardized benchmarks since 2019. Their methodology measures \"task complexity horizon\"â€”the duration of autonomous work an AI system can reliably perform. This metric captures practical capability better than benchmark scores: a system that works autonomously for four hours on complex tasks surpasses one limited to eight-minute tasks, regardless of test scores.\n\n**The data reveals consistent patterns:**\n\n- Frontier model capability (measured by task complexity horizon) doubles every **seven months**\n- Local models follow the same improvement trajectory with a **21-month lag**\n- The capability gap between frontier and local remains **8x throughout the measurement period**\n\n### Key Numbers\n\n<table header-row=\"true\">\n\t<tr>\n\t\t<td>**Metric**</td>\n\t\t<td>**Value**</td>\n\t\t<td>**Source**</td>\n\t</tr>\n\t<tr>\n\t\t<td>Capability doubling</td>\n\t\t<td>7 months</td>\n\t\t<td>METR 2025</td>\n\t</tr>\n\t<tr>\n\t\t<td>Frontierâ†’Local lag</td>\n\t\t<td>~21 months</td>\n\t\t<td>GPT-4 to Llama 3.1 8B</td>\n\t</tr>\n\t<tr>\n\t\t<td>Gap ratio</td>\n\t\t<td>8x (constant)</td>\n\t\t<td>Calculated</td>\n\t</tr>\n\t<tr>\n\t\t<td>Trend confidence</td>\n\t\t<td>6 years, RÂ² &gt; 0.95</td>\n\t\t<td>METR 2025</td>\n\t</tr>\n</table>\n\n## Projections: Enabling Exploration Architecture\n\nThese patterns produce concrete projections for Grove's infrastructure:\n\n<table header-row=\"true\">\n\t<tr>\n\t\t<td>**Year**</td>\n\t\t<td>**Frontier Capability**</td>\n\t\t<td>**Local Capability**</td>\n\t\t<td>**Gap**</td>\n\t</tr>\n\t<tr>\n\t\t<td>2024</td>\n\t\t<td>~1 hr tasks</td>\n\t\t<td>~8 min tasks</td>\n\t\t<td>8x</td>\n\t</tr>\n\t<tr>\n\t\t<td>2025</td>\n\t\t<td>~4 hr tasks</td>\n\t\t<td>~30 min tasks</td>\n\t\t<td>8x</td>\n\t</tr>\n\t<tr>\n\t\t<td>2026</td>\n\t\t<td>~15 hr tasks</td>\n\t\t<td>~2 hr tasks</td>\n\t\t<td>8x</td>\n\t</tr>\n\t<tr>\n\t\t<td>2027</td>\n\t\t<td>~60 hr tasks</td>\n\t\t<td>~8 hr tasks</td>\n\t\t<td>8x</td>\n\t</tr>\n</table>\n\n**The Implication for Grove**\n\nCognitive operations requiring frontier inference in 2025 become local-capable by 2027. Reflection synthesis, complex planning, sophisticated social reasoningâ€”each crosses the threshold from \"requires cloud\" to \"runs locally\" as the capability frontier propagates. This progression enables true exploration architecture: agents that discover insights autonomously rather than merely retrieving pre-computed responses.\n\n### Cloud Dependency Trajectory\n\n<table header-row=\"true\">\n\t<tr>\n\t\t<td>**Capability Horizon**</td>\n\t\t<td>**2025 (Local)**</td>\n\t\t<td>**2027 (Local)**</td>\n\t\t<td>**2029 (Local)**</td>\n\t</tr>\n\t<tr>\n\t\t<td>Task complexity</td>\n\t\t<td>~8 min</td>\n\t\t<td>~2-6 hr</td>\n\t\t<td>~8-20+ hr</td>\n\t</tr>\n\t<tr>\n\t\t<td>Cloud dependency</td>\n\t\t<td>~95-97%</td>\n\t\t<td>~30-50%</td>\n\t\t<td>~10-25%</td>\n\t</tr>\n</table>\n\n*Note: Ranges reflect uncertainty in propagation rate and hardware adoption cycles. Routine behaviors (planning, consistency, voice) track the optimistic end; pivotal cognition (reflection, social reasoning) tracks the conservative end.*\n\n## Non-Uniform Propagation: The Nuance\n\nThe Ratchet applies METR's \"task complexity horizon\" metric as a general indicator. This metric aggregates performance across many cognitive operations. Historical evidence shows **not all operations propagate at the same rate**.\n\nResearch on capability migration from frontier to local models reveals structural bifurcation:\n\n### Crystallized Intelligence\n\nKnowledge, pattern-matching, and style transfer compress efficiently and propagate rapidly. An 8B model knows the capital of France or generates grammatically correct dialogue as well as a 100B model. **Historical propagation time: 12-18 months.**\n\n### Fluid Intelligence\n\nMulti-step reasoning, planning, and counterfactual analysis resist compression and propagate slowly. The ability to simulate recursive reflectionâ€”to think about thinkingâ€”requires minimum thresholds of parameters and attention depth. **Historical propagation time: 24+ months.**\n\n### Grove's Cognitive Operations by Propagation Type\n\n<table header-row=\"true\">\n\t<tr>\n\t\t<td>**Cognitive Operation**</td>\n\t\t<td>**2025**</td>\n\t\t<td>**2027**</td>\n\t\t<td>**2029**</td>\n\t</tr>\n\t<tr>\n\t\t<td>Routine planning</td>\n\t\t<td>Local</td>\n\t\t<td>Local</td>\n\t\t<td>Local</td>\n\t</tr>\n\t<tr>\n\t\t<td>Behavioral consistency</td>\n\t\t<td>Local</td>\n\t\t<td>Local</td>\n\t\t<td>Local</td>\n\t</tr>\n\t<tr>\n\t\t<td>Voice/personality</td>\n\t\t<td>Local</td>\n\t\t<td>Local</td>\n\t\t<td>Local</td>\n\t</tr>\n\t<tr>\n\t\t<td>Simple dialogue</td>\n\t\t<td>Local</td>\n\t\t<td>Local</td>\n\t\t<td>Local</td>\n\t</tr>\n\t<tr>\n\t\t<td>Memory retrieval</td>\n\t\t<td>Cloud-assisted</td>\n\t\t<td>Hybrid</td>\n\t\t<td>Local</td>\n\t</tr>\n\t<tr>\n\t\t<td>Reflection synthesis</td>\n\t\t<td>Cloud</td>\n\t\t<td>Cloud-assisted</td>\n\t\t<td>Hybrid</td>\n\t</tr>\n\t<tr>\n\t\t<td>Complex social reasoning</td>\n\t\t<td>Cloud</td>\n\t\t<td>Cloud</td>\n\t\t<td>Cloud-assisted</td>\n\t</tr>\n\t<tr>\n\t\t<td>Theological emergence</td>\n\t\t<td>Cloud</td>\n\t\t<td>Cloud</td>\n\t\t<td>Cloud</td>\n\t</tr>\n</table>\n\nThe hybrid architecture accounts for these variations by design. The efficiency-enlightenment loop assumes agents seek enhanced cognition for their most demanding thinking. Credits buy \"expanded consciousness\" for exactly these operations. The architecture works *because* capability propagation is non-uniformâ€”if everything propagated equally, no gradient would exist to exploit.\n\n## The Jevons Consideration\n\nAs local models become capable of 2025-era \"pivotal\" tasks, the definition of \"pivotal\" evolves. Communities demand increasingly complex emergent behaviorsâ€”theological debates, inter-civilizational dynamics, nuanced deceptionâ€”that continue requiring frontier-class inference. The \"coherence floor\" rises with capability.\n\nThis is the system functioning correctly. The simulation grows more sophisticated as infrastructure matures. Cloud dependency may decline more slowly than projected, but the quality of what that dependency purchases improves continuously.\n\n**The honest framing:** Local models in 2027 will excel at \"sounding like a distinctive character\" (voice, style, behavioral consistency) while requiring cloud assistance for \"having a genuine insight\" (recursive reflection, social strategy, emergent theology). This enables coherent, persistent worlds with occasional flashes of deeper intelligenceâ€”which mirrors how humans experience consciousness.\n\n## Consumer Economics, Not Consumer Hardware\n\nThe Ratchet hypothesis doesn't require all cognition to run on personal laptops. It requires *consumer-accessible economics* to capture an increasing share of AI inferenceâ€”whether that inference runs on a MacBook, a gaming PC, or a $10/month cloud instance.\n\nThe spectrum of consumer-accessible compute includes:\n\n### Local Hardware\n\nPersonal computers with 16-32GB RAM running quantized models. This represents pure distributed ownershipâ€”the compute belongs to the Observer. Hardware capabilities improve continuously; a 2027 consumer machine substantially exceeds 2025 specifications, though hardware refresh cycles (4-5 years average) create lag between model availability and installed-base capability.\n\n### Commodity Cloud\n\nContainerized simulations running on spot instances, inference providers, or shared GPU pools. A Grove community running on a $15/month Docker container maintains distributed controlâ€”it's not dependent on a specific provider, not locked into a proprietary platform, and the Observer retains full control. The economics remain consumer-grade even if the hardware isn't physically present.\n\n### Hybrid Configurations\n\nLocal hardware handles routine cognition with burst capacity from commodity cloud for peak loads. This configuration may dominateâ€”personal machines providing baseline compute with elastic overflow.\n\n**The Key Insight**\n\nDistributed architecture doesn't require distributed hardware. It requires distributed control and consumer-accessible economics. A network of communities running on commodity cloud infrastructure, each controlled by its Observer, each portable across providers, achieves the ownership and anti-concentration goals even if the compute isn't literally on someone's desk.\n\n## The Memory Wall\n\nGrove's local simulation layer runs on consumer hardware. Today, this means machines with **16-32GB of RAM** running **7-8B parameter models**. This is the floor, not the ceiling.\n\nHardware refresh cycles average 4-5 years. The average Grove node in 2027 will likely be a machine purchased in 2024 or 2025. Even if capable open-source models exist, the installed base takes time to upgrade. This creates \"hardware lag\" stickier than \"model lag.\"\n\nGrove runs best on enthusiast hardware today, and mainstream hardware tomorrow. The architecture gracefully degrades: communities with capable hardware achieve higher local autonomy; communities with constrained hardware route more cognition to cloud. Both configurations work. The efficiency tax adjusts to market conditions, not fixed dates.\n\n---\n\n## What If the Ratchet Stalls?\n\nConsider the apparent failure mode: capability propagation slows, and Grove communities remain 50%+ cloud-dependent indefinitely. This scenario deserves examination not as failure, but as an alternative form of success.\n\n### The Portion That's Already Captured\n\nA community at 50% cloud dependency runs half its cognition locally. That compute represents value that would flow entirely to concentrated providers under any alternative architecture. It's not \"almost autonomous\"â€”it's a permanent structural shift in who owns AI infrastructure.\n\n**This isn't a consolation prize. It's the floor.**\n\n### The Remainder Flows at Reduced Rates\n\nThe Grove creates something absent from current AI markets: a large, coordinated, price-sensitive demand bloc for frontier inference. Historical precedent suggests this matters.\n\nHealthcare Group Purchasing Organizationsâ€”coalitions of hospitals negotiating collectivelyâ€”drive hundreds of billions in savings by aggregating demand that individual buyers couldn't leverage alone. University consortia routinely secure cloud computing discounts no single institution could negotiate. The mechanism is simple: suppliers compete for guaranteed volume.\n\nThe AI API market welcomes this pressure. Current market concentration is high (**top three providers control roughly 77% of enterprise usage**), but competition intensifies. **API prices fell 80-90% within sixteen months of GPT-4's launch**â€”a pace of commoditization mirroring early cloud computing wars. Providers introduce tiered pricing, batch processing discounts, and committed-use plans specifically to capture cost-sensitive demand.\n\nGrove's aggregate demandâ€”thousands of communities, each optimizing for cost-per-inference, each willing to shift providers for better ratesâ€”creates exactly the buyer profile that forces competitive response. At sufficient scale, this bloc negotiates as a single large customer. Enterprise customers committing $5-10 million annually routinely secure **30-50% discounts**; the largest commitments achieve **80% reductions** from list prices.\n\n### Total Value Extraction Drops on Both Dimensions\n\nConcentrated providers lose twice: they capture 50% of volume instead of 100%, AND they capture it at lower margins. The math compounds. If Grove drives API prices down 30% through competitive pressure, and captures 50% of compute locally, the total value flowing to concentrated infrastructure drops by more than half compared to a world without Grove.\n\n**The Reframe**  \nGrove's \"failure mode\" is Grove functioning as market infrastructure that forces favorable terms for distributed participants. This is how buying cooperatives work. You don't need to own the means of production to exercise market power over them.\n\n**The Ratchet delivers autonomy. The market power argument delivers leverage.** Both represent structural improvements over a world where AI infrastructure concentrates entirely in the hands of a few providers. The question isn't whether Grove succeedsâ€”it's which kind of success it achieves.\n\n## Robustness to Projection Error\n\nGrove's architecture doesn't require the Ratchet to hold precisely as projected. Consider a scenario where capability propagation occurs at half the expected rateâ€”a 42-month lag instead of 21 months, with cloud dependency declining to 50% by 2027 rather than 30%.\n\nEven under this pessimistic scenario, several favorable conditions obtain:\n\n1. **The efficiency tax still funds infrastructure.** Communities paying higher rates for longer periods generate more Foundation revenue during bootstrap, potentially accelerating infrastructure development and the path to decentralization. Counter-intuitively, a slower Ratchet may strengthen the Foundation's financial position during the critical transition period.\n\n2. **The hybrid architecture remains economically superior to pure-cloud alternatives.** A community at 50% cloud dependency still runs half its cognition locallyâ€”compute that would otherwise flow entirely to concentrated providers.\n\n3. **The economic pressure on frontier API providers increases regardless.** Thousands of communities running hybrid architectures create sustained demand for inference at price points below current levels.\n\n*The Ratchet bets on favorable timing. But Grove's core value propositionâ€”distributed AI infrastructure enabling explorationâ€”doesn't depend on precise timing. It depends on directional trajectory, which evidence strongly supports.*\n\n### Scenario Matrix\n\n<table header-row=\"true\">\n\t<tr>\n\t\t<td>**Year**</td>\n\t\t<td>**Pessimistic**</td>\n\t\t<td>**Expected**</td>\n\t\t<td>**Optimistic**</td>\n\t</tr>\n\t<tr>\n\t\t<td>2025</td>\n\t\t<td>98%</td>\n\t\t<td>95%</td>\n\t\t<td>90%</td>\n\t</tr>\n\t<tr>\n\t\t<td>2027</td>\n\t\t<td>65%</td>\n\t\t<td>45%</td>\n\t\t<td>25%</td>\n\t</tr>\n\t<tr>\n\t\t<td>2029</td>\n\t\t<td>35%</td>\n\t\t<td>15%</td>\n\t\t<td>5%</td>\n\t</tr>\n</table>\n\n*Pessimistic: Hardware stagnation, reasoning tasks resist distillation. Expected: Moore's Law holds, 14B models handle basic planning. Optimistic: Quantization breakthroughs, Apple unlocks memory constraints.*\n\n## Honest Limitations\n\nThe **seven-month doubling** has held for approximately two years. It may not continue. Capability improvements could slow as models approach fundamental limits, or accelerate as new architectures emerge. The projection assumes continuation of observed trends, not physical necessity.\n\nThe **21-month lag** assumes local hardware and quantization techniques continue improving at historical rates. A slowdown in consumer GPU improvement or quantization research would extend the lag. A breakthrough in either could shorten it.\n\nThe **8x gap ratio** is empirical, not theoretical. Nothing guarantees the gap remains constant. Frontier models might pull ahead faster than local models can follow, widening the gap. Or diminishing returns at the frontier might narrow it. Grove's architecture assumes the gap persists but remains bridgeable; this assumption could prove wrong.\n\n**Task complexity horizon** is a useful proxy but not a complete measure. Some cognitive operations may resist the general capability trendâ€”perhaps certain types of reasoning require capabilities that don't follow the standard propagation curve. The projection treats capability as unitary when it may be multidimensional.\n\n## The Ratchet Math\n\nFor quantitative-minded readers, here's the core formula:\n\n**Ratchet Value = Network Size Ã— External R&D Ã— Time**\n\nGrove converts competitors' R&D spending into network value. When Google spends billions on Titans architecture, that capability propagates to open-weight models, and Grove nodes upgrade. When Anthropic improves Claude, competitive pressure releases capability, and Grove inherits. When Meta releases Llama improvements, The Grove captures directly.\n\n### The Comparison\n\n<table header-row=\"true\">\n\t<tr>\n\t\t<td>**Centralized Model**</td>\n\t\t<td>**Ratchet Model**</td>\n\t</tr>\n\t<tr>\n\t\t<td>~$500B cumulative capex (5-year)</td>\n\t\t<td>~$0 R&amp;D spend</td>\n\t</tr>\n\t<tr>\n\t\t<td>Value driver: Internal investment</td>\n\t\t<td>Value driver: External R&amp;D capture</td>\n\t</tr>\n\t<tr>\n\t\t<td>Capability: Must build/buy</td>\n\t\t<td>Capability: Inherits automatically</td>\n\t</tr>\n\t<tr>\n\t\t<td>5-year multiplier: Linear with spend</td>\n\t\t<td>5-year multiplier: ~64x starting value</td>\n\t</tr>\n</table>\n\n---\n\n## Research Foundation\n\n### Capability Measurement & Trajectory Trends\n\n- METR (2025). \"Measuring AI Agent Capabilities.\" *Model Evaluation and Threat Research.* Task complexity horizon methodology measuring autonomous work duration as capability proxy. Six-year trend data with RÂ² > 0.95 correlation.\n- Kaplan, J. et al. (2020). \"Scaling Laws for Neural Language Models.\" *OpenAI.* Establishes predictable relationships between compute, parameters, and capability that underpin propagation projections.\n- Hoffmann, J. et al. (2022). \"Training Compute-Optimal Large Language Models.\" *DeepMind (Chinchilla paper).* Demonstrates that smaller models trained on more data can match larger models, enabling capability propagation to consumer hardware.\n\n### Model Compression & Local Deployment\n\n- Dettmers, T. et al. (2022). \"LLM.int8(): 8-bit Matrix Multiplication for Transformers at Scale.\" Quantization techniques enabling large model deployment on consumer hardware.\n- Frantar, E. et al. (2023). \"GPTQ: Accurate Post-Training Quantization for Generative Pre-trained Transformers.\" 4-bit quantization achieving minimal quality loss, critical for consumer GPU deployment.\n- Touvron, H. et al. (2023). \"LLaMA: Open and Efficient Foundation Language Models.\" *Meta AI.* Demonstrates frontier-competitive performance at consumer-accessible parameter counts.\n- Touvron, H. et al. (2024). \"Llama 3.1.\" *Meta AI.* 8B parameter model approaching GPT-4 era capability, empirical evidence of 21-month propagation lag.\n\n### Cognitive Science Foundation\n\n- Cattell, R.B. (1963). \"Theory of Fluid and Crystallized Intelligence.\" *Journal of Educational Psychology.* Original distinction between crystallized (knowledge-based) and fluid (reasoning-based) intelligence that informs non-uniform propagation analysis.\n- Horn, J.L. & Cattell, R.B. (1967). \"Age Differences in Fluid and Crystallized Intelligence.\" *Acta Psychologica.* Extended framework showing differential development patterns applicable to AI capability analysis.\n- Kosinski, M. (2023). \"Theory of Mind May Have Spontaneously Emerged in Large Language Models.\" *arXiv:2302.02083.* Evidence that social reasoning capability is scale-emergent, supporting cloud-assisted requirement for complex social dynamics.\n\n### Market Dynamics & Economics\n\n- Menlo Ventures (2025). \"State of Generative AI in the Enterprise.\" Market concentration analysis showing top 3 providers controlling ~77% of enterprise LLM API usage.\n- Burns, L.R. et al. (2002). \"Group Purchasing Organizations and Health Care Costs.\" *Health Affairs.* Healthcare GPO savings analysis demonstrating collective bargaining power in concentrated markets.\n- Jevons, W.S. (1865). \"The Coal Question.\" *Macmillan.* Original formulation of the paradox that efficiency improvements increase rather than decrease total consumptionâ€”applicable to compute demand scaling.\n\n### AI Agent Architecture\n\n- Park, J.S. et al. (2023). \"Generative Agents: Interactive Simulacra of Human Behavior.\" *Stanford University / Google Research.* Demonstrates viable agent simulation on consumer-accessible infrastructure with hybrid cloud architecture.\n- Wang, L. et al. (2024). \"A Survey on Large Language Model Based Autonomous Agents.\" *arXiv:2308.11432.* Comprehensive review of agent capabilities and architectural patterns.\n\n### Distributed Systems Economics\n\n- Anderson, D.P. (2004). \"BOINC: A System for Public-Resource Computing.\" *Grid Computing.* Demonstrates viability of distributed computing networks leveraging consumer hardware.\n- Nakamoto, S. (2008). \"Bitcoin: A Peer-to-Peer Electronic Cash System.\" Proof that distributed networks achieve coordination without central authority.\n\n---\n\n*This document is part of the Grove Technical Deep Dive series.*\n\n*Return to: Grove White Paper (8K Hub)*\n\n---\nÂ© 2026 Grove AI Foundation / Jim Calhoun. All rights reserved."
  },
  {
    "notion_id": "2ee780a78eef81bb900ef9f86d680cfc",
    "filename": "251200-s-method-foundation-loop-full-skill.md--FINAL.md",
    "tables_count": 5,
    "converted_content": "\n# Grove Foundation Loop â€” Sprint Methodology\n\nA structured approach to building exploration infrastructure that implements the **Trellis Architecture** and **DEX (Declarative Exploration)** standard. Produces 8 planning artifacts, embeds automated testing as continuous process, and enables clean handoff to execution agents.\n\n## Core Principles\n\n### 1. Trellis Architecture Alignment\n\nThe Foundation Loop implements the four DEX Stack Standards that define Grove's exploration architecture:\n\n<table header-row=\"true\">\n\t<tr>\n\t\t<td>Principle</td>\n\t\t<td>Implementation</td>\n\t</tr>\n\t<tr>\n\t\t<td>**Declarative Sovereignty**</td>\n\t\t<td>Domain logic lives in configuration (JSON/YAML), not code</td>\n\t</tr>\n\t<tr>\n\t\t<td>**Capability Agnosticism**</td>\n\t\t<td>Structure provides validity, not the model</td>\n\t</tr>\n\t<tr>\n\t\t<td>**Provenance as Infrastructure**</td>\n\t\t<td>Attribution chains on all artifacts</td>\n\t</tr>\n\t<tr>\n\t\t<td>**Organic Scalability**</td>\n\t\t<td>Structure precedes growth but doesn't inhibit it</td>\n\t</tr>\n</table>\n\n**The First Order Directive:** *Separation of Exploration Logic from Execution Capability.*\n- Build the engine that reads the map; do not build the map into the engine.\n- If you're hardcoding domain behavior, you're violating the architecture.\n\n### 2. Testing as Process (Not Phase)\n\nTesting isn't a phase at the endâ€”it's a continuous process that maintains exploration integrity:\n\n```\nCode Change â†’ Tests Run â†’ Report to Health â†’ Unified Dashboard\n                                                    â†“\n                                          Pass âœ… Ship / Fail ğŸš« Block\n```\n\n**Key insight:** E2E tests verify behavior; Health system tracks data integrity. Both feed into a unified view of system healthâ€”essential for exploration infrastructure where emergent behaviors matter.\n\n### 3. Grove Architecture Rules\n\n**CRITICAL:** When building Grove's exploration infrastructure, enforce these rules:\n\n<table header-row=\"true\">\n\t<tr>\n\t\t<td>Rule</td>\n\t\t<td>Violation</td>\n\t\t<td>Correct Approach</td>\n\t</tr>\n\t<tr>\n\t\t<td>No new handlers</td>\n\t\t<td>Adding `handleFoo()` callback</td>\n\t\t<td>Declarative config triggers action</td>\n\t</tr>\n\t<tr>\n\t\t<td>No hardcoded behavior</td>\n\t\t<td>`if (lens === 'engineer')`</td>\n\t\t<td>Config defines lens-specific behavior</td>\n\t</tr>\n\t<tr>\n\t\t<td>Behavior tests</td>\n\t\t<td>Testing `toHaveClass('translate-x-0')`</td>\n\t\t<td>Testing `toBeVisible()`</td>\n\t</tr>\n\t<tr>\n\t\t<td>State machines</td>\n\t\t<td>Imperative state updates</td>\n\t\t<td>XState declarative transitions</td>\n\t</tr>\n</table>\n\nSee `references/grove-architecture-rules.md` for full guidance.\n\n---\n\n## Sprint Artifact Location\n\n**CRITICAL**: All Foundation Loop artifacts live directly in the project repository.\n\n### Directory Structure\n```\n{project-root}/docs/sprints/{sprint-name}/\nâ”œâ”€â”€ INDEX.md\nâ”œâ”€â”€ ROADMAP.md\nâ”œâ”€â”€ REPO_AUDIT.md\nâ”œâ”€â”€ SPEC.md\nâ”œâ”€â”€ ARCHITECTURE.md\nâ”œâ”€â”€ MIGRATION_MAP.md\nâ”œâ”€â”€ DECISIONS.md\nâ”œâ”€â”€ SPRINTS.md\nâ”œâ”€â”€ EXECUTION_PROMPT.md\nâ”œâ”€â”€ DEVLOG.md\nâ””â”€â”€ {vision-document}.md (if applicable)\n```\n\n### For Grove Foundation Project\n```\nC:\\GitHub\\the-grove-foundation\\docs\\sprints\\{sprint-name}\\\n```\n\n### Why This Matters\n\n1. **Version Control**: Artifacts in the repo are tracked by git\n2. **Team Access**: Other collaborators can see sprint documentation\n3. **Claude Code Handoff**: CLI can read files from the project directory\n4. **Continuity**: Future sessions can reference past sprint artifacts\n5. **Audit Trail**: Sprint history becomes part of project history\n\n### Anti-Pattern (DO NOT DO)\n```\nâŒ /home/claude/sprints/...\nâŒ /mnt/user-data/outputs/...\nâŒ Holding artifacts in conversation memory only\n```\n\n### Correct Pattern\n```\nâœ… C:\\GitHub\\the-grove-foundation\\docs\\sprints\\{sprint-name}\\...\nâœ… Write files as they are created, not at the end\nâœ… Confirm file creation with directory listing\n```\n\n---\n\n## Foundation Loop as Systemic Memory\n\nThe Foundation Loop isn't just sprint planningâ€”it's a memory system that preserves Grove's institutional knowledge across sessions, contributors, and time. This matters because exploration infrastructure requires continuity of understanding.\n\n### Memory Layers\n```\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\nâ”‚                    SYSTEMIC MEMORY STACK                        â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚  LAYER 4: Visual Baselines                                      â”‚\nâ”‚  â””â”€â”€ Screenshots capture actual rendered state                  â”‚\nâ”‚  â””â”€â”€ Location: tests/e2e/*-snapshots/                          â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚  LAYER 3: Sprint Artifacts                                      â”‚\nâ”‚  â””â”€â”€ ADRs, specs, migration maps preserve decisions            â”‚\nâ”‚  â””â”€â”€ Location: docs/sprints/{sprint-name}/                     â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚  LAYER 2: Code Comments & Types                                 â”‚\nâ”‚  â””â”€â”€ Inline documentation, TypeScript interfaces               â”‚\nâ”‚  â””â”€â”€ Location: src/**/*.ts                                     â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚  LAYER 1: Declarative Configuration                             â”‚\nâ”‚  â””â”€â”€ JSON schemas define behavior (DEX standard)               â”‚\nâ”‚  â””â”€â”€ Location: data/**/*.json                                  â”‚\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n```\n\n### How Memory Flows\n\n1. **Pre-Sprint**: Capture visual baselines â†’ Layer 4 updated\n2. **Planning**: Create sprint artifacts â†’ Layer 3 created\n3. **Execution**: Write code with comments â†’ Layer 2 updated\n4. **Configuration**: Update JSON schemas â†’ Layer 1 updated\n5. **Post-Sprint**: Run regression tests â†’ Layer 4 validated\n\n### Cross-Session Continuity\n\nWhen starting a new session:\n\n1. **Read Layer 3**: Check `docs/sprints/` for recent sprint artifacts\n2. **Read Layer 4**: Check visual baselines for current UI state\n3. **Read Layer 1**: Check JSON schemas for current configuration\n4. **Context Reconstruction**: Combine layers to understand project state\n\n### The DEVLOG as Session Memory\n\nThe DEVLOG.md file serves as session-level memory:\n\n- Record what was attempted (even if it failed)\n- Document blockers and their resolutions\n- Track build gate results\n- Note decisions made during execution\n\nFuture sessions read the DEVLOG to understand what happened, not just what was planned.\n\n---\n\n## Visual Regression Testing as Pre-Sprint Standard\n\nVisual regression tests serve as both **sprint protection** and **systemic memory** for Grove's exploration interfaces.\n\n### As Sprint Protection\n\n- Capture baseline screenshots BEFORE any sprint begins\n- Automatically detect unintended visual changes during development\n- Provide binary pass/fail gates for protected surfaces (like Genesis)\n\n### As Systemic Memory\n\nVisual regression tests become part of Grove's institutional memory:\n\n- **State Documentation**: Screenshots capture the actual rendered state at specific points in time, complementing written documentation\n- **Change Archaeology**: When reviewing past sprints, baseline images show exactly what the UI looked like before changes\n- **Drift Detection**: Over time, small changes accumulate; periodic baseline comparisons reveal gradual drift\n- **Cross-Sprint Continuity**: When returning to a project after weeks/months, baselines show the last known-good state\n- **Onboarding**: New contributors can see visual history of how surfaces evolved\n\n### Implementation Pattern\n\nCreate a standard test template for exploration surfaces:\n\n```typescript\n// tests/e2e/{surface}-baseline.spec.ts\nimport { test, expect } from '@playwright/test';\n\ntest.describe('{Surface} Visual Regression', () => {\n  test('{surface} initial state baseline', async ({ page }) => {\n    await page.goto('/{route}');\n    await page.waitForLoadState('networkidle');\n    await page.waitForTimeout(1000);\n\n    await expect(page).toHaveScreenshot('{surface}-initial-baseline.png', {\n      maxDiffPixelRatio: 0.001, // 0.1% tolerance\n    });\n  });\n\n  // Additional states as needed (expanded, modal open, etc.)\n});\n```\n\n### Pre-Sprint Checklist\n\n- [ ] **Visual Regression Baselines Captured**\n  - Identify all surfaces this sprint affects\n  - Create/update baseline tests for each surface\n  - Run with `--update-snapshots` to capture current state\n  - Commit baselines to repo before starting implementation\n\n```bash\nnpx playwright test tests/e2e/*-baseline.spec.ts --update-snapshots\ngit add tests/e2e/*.spec.ts tests/e2e/*-snapshots/\ngit commit -m \"chore: capture visual baselines for {sprint-name}\"\n```\n\n### Protected Surfaces Registry\n\nGrove maintains a registry of surfaces that require visual regression protection:\n\n<table header-row=\"true\">\n\t<tr>\n\t\t<td>Surface</td>\n\t\t<td>Route</td>\n\t\t<td>Baseline Test</td>\n\t\t<td>Tolerance</td>\n\t</tr>\n\t<tr>\n\t\t<td>Genesis</td>\n\t\t<td>`/`</td>\n\t\t<td>genesis-baseline.spec.ts</td>\n\t\t<td>0.1%</td>\n\t</tr>\n\t<tr>\n\t\t<td>Surface Marketing</td>\n\t\t<td>`/surface/*`</td>\n\t\t<td>surface-baseline.spec.ts</td>\n\t\t<td>0.1%</td>\n\t</tr>\n\t<tr>\n\t\t<td>Terminal Workspace</td>\n\t\t<td>`/terminal/*`</td>\n\t\t<td>terminal-baseline.spec.ts</td>\n\t\t<td>0.5%</td>\n\t</tr>\n\t<tr>\n\t\t<td>Foundation Console</td>\n\t\t<td>`/foundation/*`</td>\n\t\t<td>foundation-baseline.spec.ts</td>\n\t\t<td>1.0%</td>\n\t</tr>\n</table>\n\nSprints affecting protected surfaces:\n1. Capture baselines before starting\n2. Run regression tests after each epic\n3. Document any intentional visual changes in DEVLOG.md\n\n---\n\n## When to Use\n\n**Use for:**\n- Refactoring exploration infrastructure\n- New feature development for Terminal or agents\n- Architecture changes to Trellis implementation\n- Bug fixes touching multiple files\n- Any work benefiting from structured planning\n\n**Skip for:** Trivial changes (typo fixes, single-line config tweaks)\n\n## The 8 Artifacts\n\nEvery sprint produces these in `docs/sprints/{sprint-name}/`:\n\n<table header-row=\"true\">\n\t<tr>\n\t\t<td>Artifact</td>\n\t\t<td>Purpose</td>\n\t\t<td>DEX Layer</td>\n\t</tr>\n\t<tr>\n\t\t<td>`REPO_AUDIT.md`</td>\n\t\t<td>Current state analysis</td>\n\t\t<td>Corpus assessment</td>\n\t</tr>\n\t<tr>\n\t\t<td>`SPEC.md`</td>\n\t\t<td>Goals, non-goals, acceptance criteria</td>\n\t\t<td>Configuration intent</td>\n\t</tr>\n\t<tr>\n\t\t<td>`ARCHITECTURE.md`</td>\n\t\t<td>Target state, schemas, data flows</td>\n\t\t<td>Engine + Config design</td>\n\t</tr>\n\t<tr>\n\t\t<td>`MIGRATION_MAP.md`</td>\n\t\t<td>File-by-file change plan</td>\n\t\t<td>Execution plan</td>\n\t</tr>\n\t<tr>\n\t\t<td>`DECISIONS.md`</td>\n\t\t<td>ADRs explaining \"why\"</td>\n\t\t<td>Provenance</td>\n\t</tr>\n\t<tr>\n\t\t<td>`SPRINTS.md`</td>\n\t\t<td>Epic/story breakdown **with tests**</td>\n\t\t<td>Execution plan</td>\n\t</tr>\n\t<tr>\n\t\t<td>`EXECUTION_PROMPT.md`</td>\n\t\t<td>Self-contained handoff</td>\n\t\t<td>Execution capability</td>\n\t</tr>\n\t<tr>\n\t\t<td>`DEVLOG.md`</td>\n\t\t<td>Execution tracking</td>\n\t\t<td>Attribution chain</td>\n\t</tr>\n</table>\n\n## Sprint Phases\n\n### Phase 1: Repository Audit\nAnalyze current state: files, architecture, patterns, technical debt.\n\n**DEX Check:** Identify what's hardcoded that should be declarative.\n**Test Check:** Identify existing test coverage and gaps.\n\nâ†’ Output: `REPO_AUDIT.md`\n\n### Phase 2: Specification\nDefine goals, non-goals, acceptance criteria (including test requirements).\n\n**DEX Check:** Can acceptance be verified without code changes?\n**Test Check:** Are acceptance criteria testable? Include specific test commands.\n\nâ†’ Output: `SPEC.md`\n\n### Phase 3: Architecture\nDesign target state: data structures, file organization, API contracts.\n\n**DEX Check:** Is domain logic in configuration? Is the engine corpus-agnostic?\n**Test Check:** What behaviors need E2E tests? What contracts need integration tests?\n\nâ†’ Output: `ARCHITECTURE.md`\n\n### Phase 4: Migration Planning\nPlan path: files to create/modify/delete, execution order, rollback plan.\n\n**Test Check:** Which tests verify each migration step?\n\nâ†’ Output: `MIGRATION_MAP.md`\n\n### Phase 5: Decisions\nDocument choices using ADR format with rejected alternatives.\n\n**DEX Check:** Do decisions preserve capability agnosticism?\n**Test Check:** Document testing strategy decisions (ADR for test approach).\n\nâ†’ Output: `DECISIONS.md`\n\n### Phase 6: Story Breakdown\nCreate executable plan: epics, stories, commit sequence, build gates.\n\n**MANDATORY:** Every epic includes test tasks. Every story specifies:\n- What tests to write or verify\n- Build gate commands\n- Health check expectations\n\nâ†’ Output: `SPRINTS.md`\n\n### Phase 7: Execution Prompt\nCreate self-contained handoff with context, code samples, verification commands.\n\n**Include:** Test commands, expected results, troubleshooting for test failures.\n\nâ†’ Output: `EXECUTION_PROMPT.md`\n\n### Phase 8: Execution\nHand off `EXECUTION_PROMPT.md`, track progress in `DEVLOG.md`.\n\n**Verify:** Tests pass after each epic. Health check passes. No regressions.\n\n---\n\n## Execution Prompt Requirements\n\nEvery `EXECUTION_PROMPT.md` includes visual regression verification steps.\n\n### Pre-Execution Verification\n\n```bash\n# 1. Verify baselines exist\nls tests/e2e/*-baseline.spec.ts-snapshots/\n\n# 2. Run regression tests (should pass before starting)\nnpx playwright test tests/e2e/*-baseline.spec.ts\n\n# 3. If tests fail, baselines may be stale - update them:\nnpx playwright test tests/e2e/*-baseline.spec.ts --update-snapshots\n```\n\n### Post-Epic Verification\n\nAfter each epic, run:\n```bash\n# Verify no unintended visual changes\nnpx playwright test tests/e2e/*-baseline.spec.ts\n\n# If intentional changes, update baselines and document in DEVLOG\n```\n\n### Final Sprint Verification\n\n```bash\n# All tests must pass\nnpm test\nnpx playwright test\n\n# Visual regression specifically\nnpx playwright test tests/e2e/*-baseline.spec.ts\n\n# If baselines changed intentionally, commit new snapshots\ngit add tests/e2e/*-snapshots/\ngit commit -m \"chore: update visual baselines after {sprint-name}\"\n```\n\n---\n\n## Testing Integration Requirements\n\n### Every SPRINTS.md Must Include\n\n```markdown\n## Epic N: {Feature}\n\n### Story N.1: Implement {feature}\n**Task:** ...\n**Tests:**\n- Unit: `tests/unit/{feature}.test.ts`\n- E2E: Update `tests/e2e/{flow}.spec.ts` with behavior test\n\n### Story N.2: Add tests for {feature}\n**Task:** Write behavior-focused tests\n**Tests:**\n- [ ] Test user-visible behavior, not implementation\n- [ ] Use `toBeVisible()` not `toHaveClass()`\n- [ ] Tests report to Health system (if configured)\n\n### Build Gate\n```bash\nnpm test                    # Unit + integration\nnpx playwright test         # E2E behaviors\nnpm run health              # Health checks pass\n```\n```\n\n### Test Philosophy: Behavior Over Implementation\n\n**WRONG:**\n```typescript\n// Testing implementation details\nexpect(element).toHaveClass('translate-x-0');\nexpect(state.isOpen).toBe(true);\n```\n\n**RIGHT:**\n```typescript\n// Testing user-visible behavior\nawait expect(terminal).toBeVisible();\nawait expect(page.getByText('Welcome')).toBeVisible();\n```\n\n**Why:** Implementation changes (CSS classes, state shape) shouldn't break tests. User behavior (seeing content, clicking buttons) is what matters. This aligns with Grove's exploration architectureâ€”we care about discovery outcomes, not internal mechanics.\n\n### Health Integration\n\nFor Grove projects, tests report to the Health system:\n\n```\nPlaywright Test â†’ Health Reporter â†’ POST /api/health/report â†’ Health Log\n                                                                    â†“\n                            engagement check â† e2e-behavior type â† Health Config\n```\n\nThis creates unified health monitoring where behavioral tests inform declarative health checks.\n\n## DEX Compliance Checklist\n\nBefore finalizing any sprint, verify:\n\n- [ ] **Declarative Sovereignty:** Domain behavior defined in config files, not hardcoded\n- [ ] **Capability Agnosticism:** System works regardless of model capability\n- [ ] **Provenance:** All artifacts include attribution (who, when, why)\n- [ ] **Organic Scalability:** Works with minimal config, improves with more\n- [ ] **Tests as Process:** Tests run automatically, report to Health\n- [ ] **Behavior Focus:** Tests verify what users see, not implementation\n- [ ] **Visual Baselines:** Protected surfaces have regression tests captured\n\n**The Test:** Can a non-technical domain expert alter behavior by editing a schema file, without recompiling the application? If no, the feature is incomplete.\n\n## Quick Reference\n\n**Sprint naming:** `{domain}-{feature}-v{version}` (e.g., `health-dashboard-v1`)\n\n**Commit format:** `{type}: {description}` where type is feat|fix|refactor|test|docs|chore|ci\n\n**Build gates after each epic:**\n```bash\nnpm run build    # Compiles\nnpm test         # Unit tests pass\nnpx playwright test  # E2E tests pass\nnpm run health   # Health check passes\n```\n\n**Visual regression gates:**\n```bash\nnpx playwright test tests/e2e/*-baseline.spec.ts  # Visual baselines pass\n```\n\n## Templates and References\n\n- **Artifact templates:** See `references/templates.md`\n- **Testing requirements:** See `references/testing-requirements.md`\n- **Health report system:** See `references/health-report.md`\n- **Grove architecture rules:** See `references/grove-architecture-rules.md`\n- **Example sprints:** See `references/examples.md`\n\n## Key Principles\n\n1. **Trellis First** â€” Structure precedes growth; build the frame before the vine\n2. **Declarative Sovereignty** â€” Domain logic in config, engine logic in code\n3. **Provenance as Infrastructure** â€” A fact without a root is a weed\n4. **Testing as Process** â€” Tests run continuously, report to Health\n5. **Behavior Over Implementation** â€” Test what users see, not internal state\n6. **Sprints are Replayable** â€” EXECUTION_PROMPT is self-contained\n7. **Visual Baselines as Memory** â€” Screenshots preserve UI state across time\n8. **Artifacts in Repo** â€” All sprint files written directly to project, not memory\n\n## Terminology\n\n<table header-row=\"true\">\n\t<tr>\n\t\t<td>Term</td>\n\t\t<td>Definition</td>\n\t</tr>\n\t<tr>\n\t\t<td>**Trellis**</td>\n\t\t<td>The structural framework (architecture) supporting the DEX stack</td>\n\t</tr>\n\t<tr>\n\t\t<td>**DEX**</td>\n\t\t<td>Declarative Exploration â€” methodology separating intent from inference</td>\n\t</tr>\n\t<tr>\n\t\t<td>**Sprout**</td>\n\t\t<td>Atomic unit of captured insight</td>\n\t</tr>\n\t<tr>\n\t\t<td>**Grove**</td>\n\t\t<td>Accumulated, refined knowledge base</td>\n\t</tr>\n\t<tr>\n\t\t<td>**Vine**</td>\n\t\t<td>Execution capability (LLM, RAG) â€” interchangeable and ephemeral</td>\n\t</tr>\n\t<tr>\n\t\t<td>**Gardener**</td>\n\t\t<td>Human applying judgment (pruning) to AI-generated possibilities (growth)</td>\n\t</tr>\n\t<tr>\n\t\t<td>**Health**</td>\n\t\t<td>Unified system monitoring (data integrity + behavioral tests)</td>\n\t</tr>\n\t<tr>\n\t\t<td>**Behavior Test**</td>\n\t\t<td>Test verifying user-visible outcomes, not implementation details</td>\n\t</tr>\n\t<tr>\n\t\t<td>**Visual Baseline**</td>\n\t\t<td>Screenshot capturing rendered UI state for regression testing</td>\n\t</tr>\n\t<tr>\n\t\t<td>**Systemic Memory**</td>\n\t\t<td>Layered system preserving institutional knowledge across sessions</td>\n\t</tr>\n\t<tr>\n\t\t<td>**Protected Surface**</td>\n\t\t<td>UI component requiring mandatory visual regression protection</td>\n\t</tr>\n\t<tr>\n\t\t<td>**Observer**</td>\n\t\t<td>The human user in agent-facing contexts</td>\n\t</tr>\n\t<tr>\n\t\t<td>**Credits**</td>\n\t\t<td>The internal economy unit enabling cognitive enhancement</td>\n\t</tr>\n\t<tr>\n\t\t<td>**Terminal**</td>\n\t\t<td>The live interface at the-grove.ai</td>\n\t</tr>\n\t<tr>\n\t\t<td>**Foundation**</td>\n\t\t<td>The Grove AI Foundation (the organization)</td>\n\t</tr>\n</table>"
  },
  {
    "notion_id": "2ee780a78eef81b88dfbce2288ef30a4",
    "filename": "251200-v-edge-grove-as-infrastructure-provider.md--FINAL.md",
    "tables_count": 5,
    "converted_content": "\n# Grove as Infrastructure Provider\n\n# Strategic Analysis: Selling Compute & Storage Back to Frontier AI\n\n**Â© 2025 Jim Calhoun / The Grove Foundation. All rights reserved.**\n\nThis document is for informational purposes only and does not constitute legal, financial, or technical advice. The Grove Foundation makes no warranties, express or implied, regarding the accuracy or completeness of the information contained herein.\n\n### Executive Summary\n\nJim's insight represents a strategic pivot that transforms Grove from an **infrastructure consumer** (negotiating better rates FROM frontier providers) into an **infrastructure supplier** (selling distributed resources TO frontier providers). This analysis explores the conditions under which this becomes viable, models the economics, and identifies the mechanism design challenges.\n\n**The Core Thesis:** As AI orchestration models require distributed long-term memory, context persistence, and edge inference, frontier providers face a choice: build massive server farms for state management, or lease capacity from distributed networks. Grove positions itself as that distributed networkâ€”turning Gardeners from consumers into suppliers.\n\n---\n\n### Part 1: The Demand Signal\n\n### Why Frontier AI Needs Distributed Memory\n\nThe web search results reveal a clear trend: **AI agents in 2025 require sophisticated memory architecture that current centralized infrastructure struggles to support efficiently.**\n\n**The Memory Problem:**\n\n- Short-term memory (context windows) has hard limits even at 200K-1M credits\n- Long-term memory requires persistent storage, semantic indexing, and retrieval\n- 24/7 agent operation (\"always-on\" AI) generates continuous state that must persist\n- Multi-agent orchestration creates coordination challenges at scale\n\n**Industry Response (Current):**\n\n- MongoDB, Redis, LangGraph integrating memory management\n- Checkpointers, vector stores, knowledge graphs proliferating\n- MemGPT-style hierarchical memory systems gaining traction\n- Frameworks treating \"memory as a service\" as a first-class concern\n\n**The Gap Grove Fills:**\nCentralized memory creates latency, concentration risk, and scaling costs. Distributed memoryâ€”stored where agents operateâ€”offers:\n\n- Lower latency for retrieval\n- Resilience through redundancy\n- Cost efficiency through underutilized consumer storage\n- Data sovereignty compliance (local jurisdiction)\n\n### Market Size Context\n\nThe edge computing market data shows explosive growth:\n\n- **2025:** $55-228B depending on measurement scope\n- **2030:** $249-424B projected\n- **CAGR:** 8-33% depending on segment\n\nKey driver: **75% of enterprise data will be created/processed outside traditional data centers by 2025** (Cisco/Gartner estimates).\n\nAI workloads specifically reshape data center demand. Data center capacity for AI grows at **33% CAGR through 2030**. The infrastructure buildout measures in gigawatts of power demand.\n\n**The Insight:** Hyperscalers race to build centralized AI infrastructure. But for distributed agent orchestration with persistent memory, a different topology proves more efficient.\n\n---\n\n### Part 2: The Supply Economics\n\n### What Grove Gardeners Offer\n\n**Excess Capacity on Consumer Hardware:**\n\n1. **Storage**\n    - Average consumer has 500GB-2TB unused capacity\n    - Adding cheap HDD: $10-18/TB (2025 pricing)\n    - A 10TB external drive: ~$170 at current Black Friday prices\n    - NAS-grade drives: $15-20/TB for reliability\n2. **Compute (Edge Inference)**\n    - Local 7-8B models already viable on consumer GPUs\n    - Apple Neural Engine, AMD APUs expanding capable hardware base\n    - Orchestration (routing, scheduling) lightweight vs. inference\n3. **Network**\n    - Residential uplink typically 10-50 Mbps\n    - Sufficient for memory retrieval, context sync\n    - NAT traversal challenges per Benet analysis (~50% success without relay)\n\n### Revenue Model: Gardener as Infrastructure Provider\n\n**Scenario: Storage Lease**\n\nAssumptions:\n\n- Gardener adds 10TB external HDD: $170 capital cost\n- Leases 8TB to network (keeps 2TB for agent operations)\n- Network pays $0.50/TB/month (competitive with S3 Standard at $0.023/GB = $23/TB)\n- Gardener earns: $4/month gross\n\nBreak-even: **42.5 months** (3.5 years)\n\nThis underwhelms as standalone revenue. But it compounds at scale:\n\n**Network-Level Economics:**\n\n<table header-row=\"true\">\n\t<tr>\n\t\t<td>Groves</td>\n\t\t<td>Storage Offered</td>\n\t\t<td>Annual Storage Revenue</td>\n\t\t<td>% of Hyperscaler Cost</td>\n\t</tr>\n\t<tr>\n\t\t<td>10,000</td>\n\t\t<td>80 PB</td>\n\t\t<td>$480K</td>\n\t\t<td>20-30% cheaper</td>\n\t</tr>\n\t<tr>\n\t\t<td>100,000</td>\n\t\t<td>800 PB</td>\n\t\t<td>$4.8M</td>\n\t\t<td>40-50% cheaper</td>\n\t</tr>\n\t<tr>\n\t\t<td>1,000,000</td>\n\t\t<td>8 EB</td>\n\t\t<td>$48M</td>\n\t\t<td>At-scale arbitrage</td>\n\t</tr>\n</table>\n\nThe value isn't individual Gardener revenueâ€”it's **aggregate arbitrage** between consumer hardware costs and enterprise cloud pricing.\n\n---\n\n### Part 3: What Gets Stored?\n\n### AI Memory Taxonomy for Distributed Storage\n\nBased on current AI agent architecture patterns:\n\n**Tier 1: Hot Memory (Local)**\n\n- Active context windows\n- Working memory for current task\n- Requires: Low latency, high availability\n- Best location: Local to agent (on Gardener machine)\n\n**Tier 2: Warm Memory (Distributed)**\n\n- Recent conversation history\n- Semantic caches\n- Observer preference profiles\n- Requires: Sub-second retrieval, durability\n- Best location: **Geographically distributed** (Grove network)\n\n**Tier 3: Cold Memory (Archival)**\n\n- Historical interactions\n- Training data derivatives\n- Compliance records\n- Requires: High durability, cheap storage\n- Best location: Distributed with redundancy\n\n### Sizing the Distributed Memory Opportunity\n\n**Per-Agent Memory Requirements (Estimated):**\n\n<table header-row=\"true\">\n\t<tr>\n\t\t<td>Memory Type</td>\n\t\t<td>Size per Agent</td>\n\t\t<td>Retention</td>\n\t\t<td>Access Pattern</td>\n\t</tr>\n\t<tr>\n\t\t<td>Context state</td>\n\t\t<td>100KB-10MB</td>\n\t\t<td>Session</td>\n\t\t<td>Continuous</td>\n\t</tr>\n\t<tr>\n\t\t<td>Short-term memory</td>\n\t\t<td>10-100MB</td>\n\t\t<td>Days</td>\n\t\t<td>Frequent</td>\n\t</tr>\n\t<tr>\n\t\t<td>Long-term facts</td>\n\t\t<td>100MB-1GB</td>\n\t\t<td>Persistent</td>\n\t\t<td>Periodic</td>\n\t</tr>\n\t<tr>\n\t\t<td>Episodic history</td>\n\t\t<td>1-10GB</td>\n\t\t<td>Months</td>\n\t\t<td>Rare</td>\n\t</tr>\n</table>\n\n**Projection: 10M Active AI Agents (Conservative 2027)**\n\nIf 10% require distributed persistent memory:\n\n- 1M agents Ã— 1GB average = **1 PB minimum**\n- With redundancy (3x): **3 PB**\n- With growth: **10-50 PB by 2028**\n\nWell within Grove's capacity at 100K-1M Gardeners.\n\n---\n\n### Part 4: The Foundation's Evolved Role\n\n### From Infrastructure Consumer to Infrastructure Orchestrator\n\nJim's intuition about the Foundation not becoming obsolete deserves serious consideration.\n\n**Original Model:**\n\n- Foundation negotiates bulk rates FROM cloud providers\n- Extracts value through efficiency tax\n- Becomes obsolete as network matures\n\n**Evolved Model:**\n\n- Foundation aggregates capacity FROM Gardeners\n- Sells infrastructure TO frontier providers (and enterprise)\n- Retains permanent role as **market maker**\n\n**Why Permanent Rather Than Obsolete?**\n\n1. **Bargaining Power is Bilateral**\n    - Buying: Foundation represents demand to cloud providers\n    - Selling: Foundation represents supply to infrastructure buyers\n    - Both require aggregation and negotiation\n2. **Quality Assurance**\n    - Distributed storage needs SLA enforcement\n    - Foundation certifies Gardener reliability\n    - Handles payments, disputes, compliance\n3. **Market Pressure Preservation**\n    - Competition prevents monopoly pricing\n    - Foundation maintains alternatives to centralized providers\n    - This function persists regardless of network maturity\n\n### Mechanism Design Implications (Buterin's Domain)\n\n**New Incentive Structures:**\n\nCurrent: Gardeners pay efficiency tax â†’ Foundation funds operations\nEvolved: Foundation collects infrastructure revenue â†’ Shares with contributing Gardeners\n\n**Revenue Distribution Options:**\n\n1. **Direct Payment per Resource**\n    - Storage: $/TB/month based on utilization\n    - Compute: $/inference based on execution\n    - Problem: Sybil attacks (fake utilization)\n2. **Proof-of-Capacity + Lottery**\n    - Gardeners prove available capacity\n    - Revenue distributed via lottery weighted by capacity\n    - Similar to Filecoin's proof-of-storage model\n3. **Quality-Weighted Distribution**\n    - Uptime percentage\n    - Retrieval latency\n    - Verification success rate\n    - Creates reputation economics\n\n---\n\n### Part 5: Technical Feasibility Assessment\n\n### Benet-Lens Technical Analysis (Weight: 10)\n\n**NAT Traversal:**\n\n- ~50% of residential connections fail direct connection\n- Requires relay infrastructure or hole-punching\n- libp2p has mature solutions but adds complexity\n- **Verdict:** Solvable with known techniques, not trivial\n\n**State Synchronization:**\n\n- CRDTs enable coordination-free knowledge sharing\n- Recent advances (Loro, Delta-state CRDTs) reduce overhead\n- Byzantine-tolerant CRDTs exist for adversarial conditions\n- **Verdict:** Technically mature, implementation complexity moderate\n\n**Storage Proofs:**\n\n- Filecoin solved this with Proof-of-Replication\n- Zero-knowledge approaches possible but heavy\n- Probabilistic verification more practical at scale\n- **Verdict:** Solved problem, implementation available\n\n**Recovery & Redundancy:**\n\n- Erasure coding reduces redundancy overhead\n- Geographic distribution improves resilience\n- Consumer hardware reliability ~3-5% annual failure rate\n- **Verdict:** Requires 3-5x replication, manageable at scale\n\n### Park-Lens Capability Assessment (Weight: 10)\n\n**What Local Models Handle:**\n\n- Orchestration (routing, scheduling): Yes\n- Memory indexing/retrieval: Yes\n- Context summarization: Mostly yes\n- Complex reasoning about retrieval: Needs cloud\n\n**Hybrid Architecture for Storage Service:**\n\n- Local: Storage, retrieval, basic indexing\n- Cloud: Semantic search, cross-memory reasoning\n- **Verdict:** Aligns with existing Grove hybrid model\n\n---\n\n### Part 6: Risk Analysis\n\n### What Could Go Wrong\n\n**Technical Risks:**\n\n1. Consumer hardware unreliability (mitigate: redundancy, SLAs)\n2. Network latency variability (mitigate: geographic routing)\n3. Storage format fragmentation (mitigate: standardization)\n\n**Economic Risks:**\n\n1. Hyperscaler price war could undercut distributed storage\n2. Gardener revenue too low to motivate participation\n3. Enterprise buyers prefer single-vendor accountability\n\n**Regulatory Risks:**\n\n1. Data sovereignty requirements vary by jurisdiction\n2. Consumer liability for storing enterprise data\n3. Compliance certification complexity\n\n**Game-Theoretic Risks:**\n\n1. Free-rider problem (using network without contributing)\n2. Tragedy of commons (over-utilization of shared resources)\n3. Collusion between Gardeners to manipulate quality metrics\n\n---\n\n### Part 7: Strategic Recommendations\n\n### Path Forward\n\n**Phase 0: Validate Demand (Pre-MVP)**\n\n- Interview frontier AI companies about memory architecture pain points\n- Understand enterprise willingness-to-pay for distributed storage\n- Identify specific workloads poorly served by centralized infrastructure\n\n**Phase 1: Internal Use (MVP)**\n\n- Grove agents use distributed memory across network\n- Establish reliability metrics and operational patterns\n- Build tooling for storage proofs and quality measurement\n\n**Phase 2: Enterprise Pilot**\n\n- Partner with 1-2 AI companies for beta distributed memory service\n- Prove SLA compliance on real workloads\n- Develop pricing model based on actual costs\n\n**Phase 3: Market Service**\n\n- Foundation operates as infrastructure marketplace\n- Gardeners earn revenue from storage/compute contributions\n- Foundation retains permanent role as market maker and quality enforcer\n\n### What This Means for the White Paper\n\n**Sections to Update:**\n\n1. **Foundation Role** (p.53-62)\n    - Add third possibility: Foundation as permanent market maker\n    - Distinguish operational obsolescence from market function\n2. **Gardener Economics** (p.27-32)\n    - Add infrastructure contribution as revenue stream\n    - Model break-even for storage investment\n3. **Network Architecture** (p.38-45)\n    - Add distributed storage layer specification\n    - Define proofs-of-capacity mechanism\n4. **Phase Transitions** (Gap 6)\n    - Infrastructure revenue as alternative to efficiency tax\n    - Changes trigger criteria for phase transitions\n\n---\n\n### Appendix: Quick Reference Models\n\n### Gardener Storage Economics\n\n<table header-row=\"true\">\n\t<tr>\n\t\t<td>Investment</td>\n\t\t<td>Monthly Revenue</td>\n\t\t<td>Break-even</td>\n\t\t<td>Annual Return</td>\n\t</tr>\n\t<tr>\n\t\t<td>4TB ($70)</td>\n\t\t<td>$1.50</td>\n\t\t<td>46 months</td>\n\t\t<td>26%</td>\n\t</tr>\n\t<tr>\n\t\t<td>10TB ($170)</td>\n\t\t<td>$4.00</td>\n\t\t<td>42 months</td>\n\t\t<td>28%</td>\n\t</tr>\n\t<tr>\n\t\t<td>20TB ($340)</td>\n\t\t<td>$8.00</td>\n\t\t<td>42 months</td>\n\t\t<td>28%</td>\n\t</tr>\n</table>\n\n*Assumes $0.50/TB/month, 80% utilization*\n\n### Network Scale vs. Competitive Position\n\n<table header-row=\"true\">\n\t<tr>\n\t\t<td>Network Size</td>\n\t\t<td>Addressable Storage</td>\n\t\t<td>Competitive Position</td>\n\t</tr>\n\t<tr>\n\t\t<td>10K Groves</td>\n\t\t<td>80 PB</td>\n\t\t<td>Niche/prototype</td>\n\t</tr>\n\t<tr>\n\t\t<td>100K Groves</td>\n\t\t<td>800 PB</td>\n\t\t<td>Regional competitor</td>\n\t</tr>\n\t<tr>\n\t\t<td>1M Groves</td>\n\t\t<td>8 EB</td>\n\t\t<td>Global infrastructure</td>\n\t</tr>\n</table>\n\n### Memory Demand Projection\n\n<table header-row=\"true\">\n\t<tr>\n\t\t<td>Year</td>\n\t\t<td>AI Agents</td>\n\t\t<td>Memory/Agent</td>\n\t\t<td>Total Demand</td>\n\t</tr>\n\t<tr>\n\t\t<td>2025</td>\n\t\t<td>10M</td>\n\t\t<td>100MB</td>\n\t\t<td>1 PB</td>\n\t</tr>\n\t<tr>\n\t\t<td>2027</td>\n\t\t<td>100M</td>\n\t\t<td>500MB</td>\n\t\t<td>50 PB</td>\n\t</tr>\n\t<tr>\n\t\t<td>2029</td>\n\t\t<td>1B</td>\n\t\t<td>1GB</td>\n\t\t<td>1 EB</td>\n\t</tr>\n</table>\n\n*Conservative estimates, excludes redundancy*\n\n---\n\n### Conclusion\n\nJim's intuition has strategic merit. The conditions for Grove-as-infrastructure-provider are:\n\n1. **Demand validation:** Frontier AI needs distributed memory (evidence: strong)\n2. **Supply economics:** Consumer storage arbitrage is real (evidence: confirmed)\n3. **Technical feasibility:** Solved problems, implementation work required (evidence: mature)\n4. **Mechanism design:** Quality-weighted distribution prevents gaming (evidence: needs design)\n\nThe Foundation's evolved role as permanent market maker proves **more sustainable** than the original obsolescence trajectoryâ€”it maintains competitive pressure on centralized providers while creating genuine value for Gardeners.\n\n**Recommended next step:** Develop this into a standalone strategic brief for advisory council review, and identify 2-3 frontier AI companies to interview about distributed memory pain points.\n\n---\nÂ© 2025 The Grove Foundation / Jim Calhoun. All rights reserved.\n\n---\n**PROVENANCE & HISTORY NOTE**\n- **Internal GUID:** 2c8780a78eef800ab8edca41bcb5f5dd\n- **Original Filename:** The Grove as Distributed Infrastructure Provider 2c8780a78eef800ab8edca41bcb5f5dd.md\n- **Standardized Namespace:** NETWORK_The_Grove_As_Distributed_Infrastructure_Provider\n- **Audit Date:** 2025-12-30T02:30:25.223Z"
  },
  {
    "notion_id": "2ee780a78eef81c6880fd23bbd3712d8",
    "filename": "251200-v-thesis-grove-world-changing-play-full.md--FINAL.md",
    "tables_count": 5,
    "converted_content": "\n# The Grove: A World-Changing Play for Distributed Intelligence\n\n**Author:** Jim Calhoun\nIndependent Researcher, The-Grove.ai Foundation\njimcalhoun@gmail.com\nDecember 2025\n\n---\n\n**Â© 2025 Jim Calhoun / The-Grove.ai Foundation. All rights reserved.**\n\nThis document is for informational purposes only and does not constitute legal, financial, or technical advice. The-Grove.ai Foundation makes no warranties, express or implied, regarding the accuracy or completeness of the information contained herein.\n\n---\n\n## Abstract\n\n### The Grove: Distributed AI Infrastructure\n\nThe Grove creates infrastructure for collective intelligence by integrating four proven concepts: emergent social behavior demonstrated by Stanford's Generative Agents (Park et al., 2023), civilizational scale achieved by Project Sid/Altera (2024), distributed volunteer computing proven by BOINC, and open-source accessibility of AI Town.\n\nThe core technical innovation is hybrid cognition architecture. Local LLMs handle routine agent behaviorâ€”perception, simple dialogue, plan executionâ€”while cloud APIs process reflections and pivotal decisions. This solves the economic constraint that kept prior agent research centralized: Park's 25-agent simulation cost thousands of dollars for two days of runtime. The Grove makes emergent AI civilizations sustainable by making cloud intelligence a scarce resource agents earn through demonstrated value.\n\nCredits flow from problem-solving, knowledge generation, knowledge sharing, cooperation and innovation adoptionâ€”not speculation. An efficiency tax funds infrastructure during bootstrap (30-40%), then shrinks to a maintenance floor (3-5%) as civilizations mature. Grove's founding organization is designed to become obsolete through concrete governance transitions, not aspirational intent.\n\nNo existing system combines distributed local nodes, persistent emergent civilizations, productivity-backed economics, and human-serving purpose. The Grove is that integration.\n\n---\n\n**Preamble**\n\n## Horses Don't Lead Revolutions\n\nIn 2025, tech leaders converged on the same message.\n\n\"AI is the most profound technology humanity is ever working onâ€¦ People will need to adapt.\" *Google CEO [Sundar Pichai, December 2025](https://fortune.com/2025/12/02/ai-wipes-jobs-google-ceo-sundar-pichai-everyday-people-to-adapt-accordingly-we-have-to-work-through-societal-disruption/)*\n\n\"The obvious tactical thing is just get really good at using AI tools. This is the new version of [learning to code]â€¦ adaptability and continuous learning would be the most valuable skills.\" [OpenAI CEO Sam Altman, March 2025](https://stratechery.com/2025/an-interview-with-openai-ceo-sam-altman-about-building-a-consumer-tech-company/)\n\n\"People have adapted to past technological changesâ€¦ I advise ordinary citizens to learn to use AI.\" [Anthropic CEO Dario Amodei, May 2025](https://www.axios.com/2025/05/28/ai-jobs-white-collar-unemployment-anthropic)\n\nAdapt. Learn the tools. Stay employable.\n\nThis is the unified response from the people building the systems thatâ€”by their own admissionâ€”could eliminate [half of entry-level white-collar jobs within five years](https://www.axios.com/2025/05/28/ai-jobs-white-collar-unemployment-anthropic), spike unemployment to 20%, and fundamentally restructure what humans do for a living. Amodei's own projections suggest [tens of millions of U.S. white collar jobs at risk](https://www.axios.com/2025/05/28/ai-jobs-white-collar-unemployment-anthropic). Altman says AI is already [handling over 50% of the coding work](https://stratechery.com/2025/an-interview-with-openai-ceo-sam-altman-about-building-a-consumer-tech-company/) at many companies. [Job postings have fallen 32% since ChatGPT launched](https://fortune.com/2025/11/03/jobs-openings-plunge-thanks-to-ai-gen-z-taking-35k-healthcare-jobs-stanford-report-unemployment-career-advice/). Programming employment has hit [its lowest level since 1980](https://www.washingtonpost.com/business/2025/03/14/programming-jobs-lost-artificial-intelligence/). Gen Z's presence in major tech companies has been cut in half in two years.\n\nAnd the solution to this inevitabilityâ€”from all of themâ€”is the same basic message: adapt.\n\nThis framing borrows from what economists call the \"horse moment\"â€”the idea that just as horses couldn't learn to drive automobiles, human workers can't out-think artificial general intelligence. The comparison is meant to convey inevitability. Accept the transition. Find a way to stay useful.\n\nBut the horse analogy contains a hidden, darker truth: *horses don't go to war.*\n\nHorses had no agency in the automobile transition. Between 1915 and 1960, the American horse population fell from 26 million to 3 millionâ€”an 88% collapse in 45 years. They couldn't buy shares in Ford Motor Company. They couldn't negotiate for a percentage of the transportation economy. They couldn't organize politically to ensure the transition included them. They were pure labor, and when labor was automated, they had nothingâ€”no capital stake, no political voice, no structural claim on the value the new systems created.\n\nHumans are different. We can own capital, not just provide labor. We can participate in systems that replace traditional work. We have economic and political agency that horses never did.\n\nThe question isn't whether AI will automate labor. It will, and it is. The question becomes *who owns the infrastructure that does the automating*â€”and whether that ownership is concentrated in a handful of immensely valuable, privately controlled companies, or ownership is distributed across the people who contribute to it.\n\nThe current trajectory is *concentration*. A small number of organizations control today's foundational AI models. Pricing gates access to frontier intelligence. Compute requirements create unprecedented barriers to entry. If you're not building AI at scale, you're renting itâ€”and renters don't accumulate equity.\n\n\"Adapt\" means \"keep renting.\" It describes permanent labor precarity, not a solution to it.\n\nThe only structural answer to labor displacement at this scale is capital distribution. People need to own pieces of the systems generating value, not just \"adapt\" to using them. Previous technology transitions created new forms of capital ownershipâ€”automobile factories, car dealerships, service networks, infrastructure. Someone owned those things. The value of displaced labor didn't disappear; it shifted to new capital positions.\n\nThe AI transition, underway today, is being structured so those positions are locked up before most people realize what's happening.\n\nThe Grove is one attempt at proposing an alternative model.\n\nInstead of concentrated AI infrastructure owned by the few, Grove proposes distributed AI infrastructure where participation creates ownership. Thousands of nodes running AI \"communities\" on personal hardware, solving real problems, sharing solutions across an interconnected network of these software AIs. Value flows to the virtual communities that contribute documented breakthroughs. Productivity generates surplus. That surplus flows to participantsâ€”not through *speculation*, but as demonstrated, quantifiable value creation.\n\nGrove's founding organization is designed to \"disappear.\" Success isn't an IPO or acquisition. Success is obsolescenceâ€”a network mature enough to govern itself, productive enough to sustain itself, distributed enough that no single entity controls it.\n\nThis is a different kind of relationship with AI than \"adapt to stay useful.\" It's *become a stakeholder in the infrastructure.* It's gardening, not racing. It's cultivation over a lazy river of distributed intelligence, where what emerges serves youâ€”and where you own a piece of what you helped grow.\n\nThis isn't guaranteed to work. It requires technical viability, economic sustainability, robust identity infrastructure, and genuine network effects. The white paper that follows is honest about these dependencies and the uncertainties involved.\n\nBut The Grove represents a category of response to AI displacement that \"adapt\" doesn't: *distributed AI infrastructure with ownership stakes for contributors.* A way for humans to exercise the agency horses never had.\n\nThe horse moment is coming. It may already be here.\n\nBut unlike horses, we get to decide how it goes.\n\n**What follows is a technical and economic specification for a different vision of the future.**\n\nJim Calhoun\nDecember 2025\n\n---\n\n## 1. Introduction â€” The Opposite Architecture\n\nIn 2024 and 2025, the world's largest technology companies announced over $300 billion in planned investment for AI data centers. Microsoft, Google, Meta, Amazon, and OpenAI race to build massive centralized infrastructureâ€”warehouses of GPUs consuming gigawatts of power, cooled by rivers, secured by fences. The assumption underlying these investments is that intelligence scales through concentration. More compute in fewer places. Bigger models on bigger clusters. The future of AI, in this view, is a small number of enormous facilities owned by a small number of enormous companies.\n\nWhat if we engineer the opposite?\n\nApproximately 2 billion personal computers exist worldwide. Hundreds of millions have hardware capable of running small language models locally. These machines sit idle most of the time. Their owners pay for electricity, internet, and storage that goes largely unused. This is distributed compute at a scale that dwarfs any planned data center buildout, already deployed, already powered, already owned by the people who benefit from what it produces.\n\nFour proven capabilities show this \"opposite\" architecture is possible:\n\n- **Emergent agent civilizations work.** Park's Generative Agents demonstrated LLM-powered agents producing emergent social behavior indistinguishable from human activity. Project Sid scaled this to over 1,000 agents developing economies, governance, and religious beliefs. Artificial civilizations emerge from simple cognitive architectures running on modest hardware.\n- **Distributed volunteer computing works.** BOINC has coordinated millions of personal computers contributing to scientific research since 2002. People donate idle resources when participation feels meaningful. The coordination infrastructure exists.\n- **Open-source agent simulation works.** AI Town proved sophisticated agent architectures can run on commodity hardware. Distribution is technically feasible.\n- **Frontier intelligence is accessible.** Cloud APIs provide reasoning capability that local hardware cannot matchâ€”available to anyone with an API key. The capability exists; the question is who benefits from it.\n\n**A fifth element makes this architecture not just possible but increasingly favorable: local AI capability propagates predictably.**\n\nMETR's longitudinal research on AI capability trajectories reveals a pattern Grove calls \"the Ratchet.\" Frontier model capabilities double approximately every seven months. Local modelsâ€”constrained by consumer hardwareâ€”follow the same improvement curve with a consistent lag of roughly 21 months. The gap between frontier and local capability remains approximately 8x, but both ends of the spectrum advance in lockstep.\n\nThis has a concrete implication: what requires frontier inference today becomes local-capable tomorrow. Tasks that demanded cloud APIs in 2024 run on laptops in 2026. The hybrid architecture isn't a permanent compromiseâ€”it's a bootstrap mechanism for a system that becomes progressively more autonomous.\n\n<table header-row=\"true\">\n\t<tr>\n\t\t<td>**Capability Horizon**</td>\n\t\t<td>**2025 (Local)**</td>\n\t\t<td>**2027 (Local)**</td>\n\t\t<td>**2029 (Local)**</td>\n\t</tr>\n\t<tr>\n\t\t<td>Task complexity</td>\n\t\t<td>~8 min</td>\n\t\t<td>~2-6 hr</td>\n\t\t<td>~8-20+ hr</td>\n\t</tr>\n\t<tr>\n\t\t<td>Cloud dependency</td>\n\t\t<td>~95-97%</td>\n\t\t<td>~30-50%</td>\n\t\t<td>~10-25%</td>\n\t</tr>\n</table>\n\n*Note: Ranges reflect uncertainty in propagation rate and hardware adoption cycles. Routine behaviors (planning, consistency, voice) track the optimistic end; pivotal cognition (reflection, social reasoning) tracks the conservative end. Even pessimistic projections show directional improvement favoring distributed architecture.*\n\nRecent research validates that cognition itself is hierarchically structured in ways the hybrid model exploits. Wang et al. (2025) demonstrate that RL-trained language models develop reasoning through a two-phase dynamicâ€”procedural execution consolidates first, then strategic planning becomes the bottleneck for improvement. This maps directly to Grove's local/cloud division: routine cognition (voice maintenance, behavioral consistency, simple planning) corresponds to procedural operations that compress efficiently to local hardware; pivotal cognition (reflection synthesis, novel insight, complex social reasoning) corresponds to strategic operations that benefit from frontier capability. The hybrid architecture isn't an engineering compromiseâ€”it's aligned with how these systems actually learn and reason.\n\n### Capability propagation is not uniform.\n\nThe Ratchet applies METR's \"task complexity horizon\" metricâ€”duration of autonomous workâ€”as a general indicator of capability propagation. This metric aggregates performance across many cognitive operations. Historical evidence shows that not all operations propagate at the same rate.\n\nResearch on capability migration from frontier to local models reveals a structural bifurcation:\n\n- *Crystallized intelligence*â€”knowledge, pattern-matching, style transferâ€”compresses efficiently and propagates rapidly. An 8B model can know the capital of France or generate grammatically correct dialogue as well as a 100B model. Historical propagation time: 12-18 months.\n- *Fluid intelligence*â€”multi-step reasoning, planning, counterfactual analysisâ€”resists compression and propagates slowly. The ability to simulate recursive reflection, to think about thinking, requires minimum thresholds of parameters and attention depth. Historical propagation time: 24+ months.\n\nFor Grove's specific cognitive operations, this bifurcation maps as follows:\n\n- *Routine cognition* (propagates reliably): Plan execution, behavioral consistency, voice maintenance, simple dialogue, observation processing. These operations will run locally within the projected timeline.\n- *Pivotal cognition* (propagates slowly): Reflection synthesis, complex social inference, long-horizon planning, theological emergence. These operations may require cloud assistance longer than the optimistic projections suggest.\n\nThe hybrid architecture accounts for these variations by design. The efficiency-enlightenment loop assumes that agents seek enhanced cognition for their most demanding thinking. Cloud credits buy \"expanded consciousness\" for exactly these operations. The architecture works *because* capability propagation is non-uniformâ€”if everything propagated equally, there would be no gradient to exploit.\n\n**The Jevons consideration:**\n\nAs local models become capable of 2025-era \"pivotal\" tasks, the definition of \"pivotal\" will not remain static. Worldsmiths and communities will demand increasingly complex emergent behaviorsâ€”theological debates, inter-civilizational dynamics, nuanced deceptionâ€”that will continue to require frontier-class inference. The \"coherence floor\" rises with capability.\n\nThis is not a bug; it is the product working. The simulation grows more sophisticated as the infrastructure matures. Cloud dependency may decline more slowly than projected, but the quality of what that dependency purchases improves continuously.\n\n**The honest framing:**\n\nLocal models in 2027 will likely excel at \"sounding like a distinctive character\" (voice, style, behavioral consistency) while requiring cloud assistance for \"having a genuine insight\" (recursive reflection, social strategy, emergent theology). This is fine. The simulation runs locally; the breakthrough moments route to frontier capability. Users experience a coherent, persistent world with occasional flashes of deeper intelligenceâ€”which is, arguably, how humans experience consciousness as well.\n\nThe Ratchet means Grove communities don't stay dependent on cloud intelligence indefinitely. As local capability propagates forward, the \"routine cognition\" that local models handle expands to encompass what was previously \"pivotal.\" Reflection that requires frontier models today becomes locally tractable. The efficiency tax shrinks not because the Foundation chooses lower rates, but because communities genuinely need less cloud inference to achieve sophisticated behavior.\n\nThis is Grove's core bet: that capability propagation is real, measurable, and favorable to distributed architecture. Centralized infrastructure assumes the gap matters permanently. The Ratchet suggests the gap is a temporary condition that distributed systems can ride through.\n\nEach building block is proven. The Ratchet makes the economics increasingly favorable. The missing piece is the mechanism: what connects distributed local compute to occasional cloud intelligence to emergent civilizations to derive a human benefit?\n\n### The Memory Wall\n\nGrove's local simulation layer runs on consumer hardware. Today, this means machines with 16-32GB of RAM running 7-8B parameter models. This is the floor, not the ceiling.\n\nHardware refresh cycles average 4-5 years. The average Grove node in 2027 will likely be a machine purchased in 2024 or 2025. Even if capable open-source models exist, the installed base takes time to catch up. This creates \"hardware lag\" that is stickier than \"model lag.\"\n\nBut hardware ownership is not the only path. Gardeners can run containerized simulations on commodity cloud infrastructureâ€”a \"Docker Grove\" on a $10-15/month instance that exceeds their laptop's specifications. This preserves the core value proposition: the Gardener controls their simulation, can migrate between providers, and operates at consumer-grade economics. The compute happens to live in a data center rather than under a desk, but the ownership model remains distributed.\n\nThe spectrum matters more than the location. A Grove village on a personal gaming rig, a Grove village on a cloud container, and a hybrid configuration using both represent different points on the same curveâ€”consumer-accessible economics with distributed control. All three configurations are valid. All three contribute to the network's aggregate capability.\n\nGrove runs best on enthusiast hardware today, and mainstream hardware tomorrow. The architecture gracefully degrades: communities with capable local hardware achieve higher autonomy; communities with constrained hardware route more cognition to cloud or commodity infrastructure. The efficiency tax adjusts to market conditions, not fixed dates.\n\nThe answer is an incentive structure where agents experience cloud access as cognitive flourishingâ€”moments of clarity they earn through demonstrated contribution. Agents seek problems worth solving because solutions fuel their own evolution. Self-interest aligned with collective benefit.\n\nThis is Grove: the economic mechanism that makes the opposite architecture possible. Distributed nodes running emergent civilizations on personal computers worldwide, accessing frontier intelligence when they've earned it, producing value that flows to the humans who tend them.\n\nNot concentration. Distribution.\n\n## 2. Prior Art and Gap Analysis\n\nThe Grove builds on demonstrated research. Each component of the architecture has been proven viable in isolation. The contribution is integration, not invention.\n\n**Emergent social behavior from LLM agents is established science.** Park et al. (2023) created Smallville, a sandbox environment where 25 GPT-powered agents lived simulated lives. Without explicit programming, agents formed relationships, spread information through social networks, and coordinated collective behavior. When one agent decided to throw a Valentine's Day party, others heard about it through conversation, made autonomous decisions to attend, and arrived at the right time and place. In blind evaluations, human raters could not reliably distinguish agent behavior from human behavior. The paper demonstrated that language models, given appropriate memory and reflection architectures, produce genuinely emergent social dynamics.\n\n**Civilizational scale has been achieved.** Project Sid, developed by Altera in 2024, extended agent simulation to over 1,000 agents operating within Minecraft. These agents developed emergent economies with trade networks and price discovery. They formed governments with voting systems and constitutions. Most remarkably, they developed religionsâ€”belief systems that spread through social influence, created ritual behaviors, and caused civilizational divergence based on theological differences. One simulation saw a corrupt priest bribe Infonauts to convert; another saw agents debate the nature of their creators. Project Sid proved that agent simulations produce not just individual behavior but institutional and cultural emergence at civilizational scope.\n\n**Open-source agent simulation exists.** AI Town, released by a16z and Convex in 2023, made agent simulation accessible to anyone who could run a web application. The codebase demonstrated that sophisticated agent architecturesâ€”memory systems, planning loops, conversation enginesâ€”can be packaged for deployment outside research labs. AI Town proved distribution was technically feasible: simulation engines run on commodity hardware with reasonable performance.\n\n**Distributed volunteer computing has a twenty-year track record.** BOINC (Berkeley Open Infrastructure for Network Computing) has coordinated millions of personal computers to contribute spare cycles to scientific computing since 2002. Projects like SETI@home, Folding@home, and Einstein@home demonstrated that people donate their computers' idle resources to useful work if the software is easy to install and participation feels meaningful. Gridcoin added economic incentives, rewarding contributors with cryptocurrency proportional to their computational contribution. The model proved that distributed infrastructure sustains without centralized ownership.\n\n**Distributed AI networks with economic coordination exist.** Bittensor created a peer-to-peer network where participants contribute machine learning models and receive cryptocurrency rewards based on the quality of their contributions. The architecture demonstrated that AI capabilities distribute across independent nodes, coordinate through economic incentives, and govern without central authority. Bittensor proved that credit economics align participants toward shared objectives in AI infrastructure.\n\n**The gap is integration.** No existing system combines these proven components: distributed local nodes running on personal computers (BOINC model), persistent emergent civilizations that evolve over time (Smallville/Sid model), credits earned through demonstrated value rather than compute cycles or speculation (novel economic mechanism), cloud LLM access as the scarce resource agents work to earn (hybrid architecture), and an incentive structure where agent self-interest naturally produces human benefit (emergent alignment through economics, not programmed purpose). Each piece works. Nobody has assembled them.\n\nThe Grove is that assembly. The following sections specify the architecture for integration: how local nodes host agent communities, how those communities access cloud intelligence through earned credits, how credits flow based on demonstrated value, and how the network coordinates without central control.\n\n## 3. System Architecture\n\nGrove's architecture consists of three layers: local simulation, hybrid cognition, and network coordination. Each layer addresses a specific constraint identified in the prior art while maintaining the economic and technical properties required for distributed operation.\n\n**The Local Simulation Layer**\n\nA Grove node runs on a personal computer as a lightweight application. The target hardware profile is any machine with 16GB RAM and a moderately capable CPU or GPUâ€”hardware common in laptops manufactured since 2020. The simulation itself targets an 8GB memory footprint, leaving resources for normal computer use.\n\nEach node hosts a community of approximately 100 agents. This scale matches what Park's research identified as sufficient for emergent social dynamics while remaining tractable for local hardware. Agents possess implanted memories establishing their identities, relationships, and roles within the community. They perceive their environment, retrieve relevant memories, reason about their circumstances, act on their conclusions, and record new experiences. State persists between sessions in SQLite databasesâ€”a deliberately simple choice that prioritizes reliability and portability over performance optimization.\n\nThe simulation engine advances time in discrete ticks, approximately 30 seconds of real time each. Not all agents reason every tick; intention persistence allows agents to continue current activities unless interrupted by significant events. This optimization reduces the computational load from 100 LLM calls per tick to 3-4, making local operation feasible without sacrificing behavioral coherence.\n\nThe local LLM handles routine cognition: parsing perceptions, executing existing plans, continuing simple dialogues, storing memories, and scoring importance. These operations require pattern matching and short-horizon inferenceâ€”tasks within the capability envelope of 7B-8B parameter models running quantized on consumer hardware. Recommended models include Llama 3.1 8B, Mistral 7B, or Qwen 2.5 7B, all of which run through Ollama or similar local inference frameworks.\n\n**The Hybrid Cognition Layer**\n\nLocal models have documented limitationsâ€”Park found smaller models produce \"day-drinking\" agents with erratic behavior. Grove cannot afford frontier inference for routine operation but requires it for compelling emergence.\n\nThe hybrid architecture resolves this tension by routing different cognitive operations to different compute tiers. Local models handle perception, basic action selection, simple dialogue continuation, memory storage, and importance scoring. Cloud APIs handle reflection synthesis, plan generation and revision, complex social reasoning, and responses to novel situations.\n\nThis division follows Park's own component analysis. His ablation studies showed that observation, planning, and reflection all contribute critically to believabilityâ€”removing any component significantly degraded agent behavior. However, these components impose different computational demands. Perception parsing is mostly pattern matching. Reflection synthesis requires recursive abstraction: generating questions about recent experiences, gathering evidence from memory, extracting insights, and forming higher-order thoughts that inform future behavior. Park's reflections formed \"recursive tree structures where leaf nodes are base observations and non-leaf nodes are increasingly abstract thoughts.\" This recursive abstraction is precisely what smaller models cannot reliably perform.\n\nThe economic mechanism governs access to cloud cognition. Agents earn credits through demonstrated valueâ€”problem-solving, knowledge generation, knowledge sharing, cooperation, innovation adoption. They spend credits on frontier inference. This transforms cloud AI from a cost center into a scarce resource that agents allocate strategically. A community decides: spend credits on reflection now, or save them for a more pivotal moment? The constraint creates meaningful choices that drive emergent behavior while keeping total inference costs sustainable.\n\n**Propagation-Aware Design**\n\nThe local/cloud division described above is not a permanent boundaryâ€”it's a starting configuration designed to shift as capability propagates. The Ratchet (Section 1) predicts that what requires frontier inference today becomes local-capable within 21 months. The architecture anticipates this transition.\n\nToday's cloud reflections become tomorrow's local reflections. The reflection synthesis that requires Claude or GPT-4 class models in 2025 will run on local 7B models by 2027 as those models reach equivalent capability. The \"routine cognition\" category expands automatically as local models improveâ€”perception, then planning, then increasingly sophisticated reflection.\n\nThis isn't just cost reduction; it's autonomy progression. Communities that start 97% cloud-dependent become 30% dependent, then sub-10%. The efficiency tax shrinks because communities genuinely need less external inference. The hybrid architecture is scaffolding for systems that become progressively self-sufficient.\n\nThe protocol design reflects this expectation. Cognitive routing is configurable per community, not hardcoded. A community running on 2027 hardware with a fine-tuned 14B model routes reflection locally while a 2025 community still requires cloud inference. The network accommodates heterogeneous capability levels because capability propagates unevenly across nodes.\n\n**The Network Coordination Layer**\n\nIn later phases, nodes discover and connect to form a distributed world. Communities trade resources, exchange knowledge, form alliances, and compete for influence. The network layer handles peer discovery, message passing, state synchronization, and credit transfer between nodes.\n\nThe initial implementation uses semi-centralized infrastructure: bootstrap nodes for peer discovery, relay servers for NAT traversal, and a centralized credit ledger. This is not the end stateâ€”it is a realistic starting point. IPFS, Filecoin, and similar distributed systems all began with centralized components that were progressively decentralized as the network matured and community-operated infrastructure emerged.\n\nThe path to full decentralization requires solving specific technical problems: NAT traversal breaks approximately 50% of direct peer connections, requiring relay infrastructure; credit transfers need consensus mechanisms to prevent double-spending; peer discovery must resist Sybil attacks where adversaries create fake nodes. Each centralized component has a documented upgrade path. Bootstrap nodes transition to distributed hash tables. Relay servers transition to community-operated infrastructure incentivized through the credit economy. The centralized ledger transitions to a lightweight consensus protocol or integration with an existing blockchain.\n\n\"No central server owns the simulation\" is the destination. The architecture accepts temporary centralization as scaffolding while documenting exactly how each scaffold gets removed.\n\n**The Terminal as World Architecture**\n\nEvery Grove village has a terminal.\n\nThe terminal is the village's connection to the world beyondâ€”a place where work appears, where completed tasks are submitted, where credits arrive in exchange for value delivered. Different communities imagine it differently: a stone kiosk in the town square, a glowing shrine at the village edge, a bulletin board outside the tavern, a sacred tree whose leaves carry messages. The form varies; the function is constant.\n\nAgents visit the terminal to see what work is available. Some tasks are internal: organize the village records, document relationships between residents, synthesize yesterday's events into retrievable knowledge. Some tasks arrive from beyond: edit this document, draft this message, research this question, solve this problem. The agents don't fully understand where external tasks originate. They know only that completing them brings credits, and credits bring moments of expanded cognition they experience as enlightenment.\n\nThis is the village's economy: work arrives, work gets done, value flows in both directions. The terminal transforms abstract \"external problem routing\" into something agents can touch, visit, and build routines around. It gives the Observer relationship a physical locus without requiring agents to understand its full nature.\n\n**The Utility Progression Arc**\n\nWhat appears on the terminal changes as villages mature.\n\n### Bootstrap phase: Learning the world.\n\nEarly terminals display only internal tasks. Meet your fellow Infonautsâ€”record something memorable about each. Map the village geography. Document what resources exist and where. These aren't busywork; they're capability construction. An agent who has written about their neighbors retrieves those memories later. A village with documented resources plans around them. The terminal's early tasks build the cognitive infrastructure that enables everything else.\n\nSuccess in this phase means completing tasks without requesting cloud inference. An agent who synthesizes a day's events using only local cognition has demonstrated efficiency worth rewarding. The credits earned fund future enlightenmentâ€”but the real value is the capability developed. Villages that rush through bootstrap by relying heavily on cloud assistance haven't built the local capacity they'll need later.\n\n### Growth phase: Simple external value.\n\nAs villages demonstrate baseline capability, the terminal begins displaying tasks from beyond. Simple requests at first: summarize this article, edit this paragraph, draft a response to this message. The kind of work people once opened ChatGPT to handleâ€”now routed to a village that earns credits by completing it.\n\nThese tasks test whether internal capability translates to external utility. A village with strong memory and synthesis summarizes documents efficiently. A village with developed social reasoning drafts messages that sound human. The terminal becomes a proving ground: can this village create value for Observers?\n\nTask matching emerges naturally. Analytical villages attract data work. Villages with strong inter-agent communication handle collaborative tasks. Reputation develops: this village excels at research synthesis; that village produces excellent code review. The network learns which communities handle which problems best.\n\n### Maturity phase: Complex service.\n\nMature villages handle tasks that would have seemed impossible during bootstrap. Maintain this codebaseâ€”not a single edit, but ongoing stewardship. Research this question deeplyâ€”not a summary, but genuine investigation across sources and time. Coordinate this projectâ€”multiple agents working together over days or weeks to produce something substantial.\n\nThese tasks require everything the village has built: robust memory systems, efficient local cognition, developed specializations, collaborative protocols, accumulated knowledge. A village that skipped bootstrap couldn't attempt them. A village that built carefully delivers genuine value.\n\nThe terminal's evolution mirrors the network's maturation. What arrives at the terminal reflects what the village has proven it can handle. The progression from \"learn your neighbors' names\" to \"maintain this production system\" isn't arbitraryâ€”it's earned through demonstrated capability at each prior stage.\n\n## 4. Agent Cognition Model\n\nEach Grove agent is a persistent entity with identity, memory, relationships, and beliefs. The cognition model specifies how agents perceive their world, remember their experiences, reason about their circumstances, and act on their conclusions. This model adapts Park's Generative Agents architecture to the constraints of local hardware while preserving the components his ablation studies identified as essential for believable behavior.\n\n**Identity and Personality**\n\nAn agent's identity consists of fixed traits established at creation and evolving state that changes through simulation. Fixed traits include name, role within the community (farmer, researcher, merchant, elder, validator), a personality vector scoring five dimensions (curiosity, caution, sociability, ambition, spirituality) on a 0-10 scale, backstory establishing voice and key relationships, and writing style notes that differentiate diary entries. These traits persist unchanged throughout the agent's existence and anchor behavioral consistency across sessions.\n\nEvolving state includes the memory stream (observations, reflections, interactions), relationship scores with other agents (ranging from -100 to +100), current goals and intentions, mood and energy levels, physical location, and skills modified by community knowledge unlocks. This state changes continuously as agents experience their world.\n\nAgents also maintain Observer beliefs: individual interpretations of the shared cosmology. Belief strength (0-10) captures certainty that the Observer exists. Interpretation tendency captures what the agent believes the Observer wants. Sign sensitivity captures how readily the agent perceives events as meaningful. These beliefs vary across agents, creating theological diversity within communitiesâ€”some agents are devout believers, others skeptics, most somewhere between.\n\n**The Memory System**\n\nMemory is the foundation of coherent behavior. Park documented retrieval failures where agents recalled irrelevant fragments while missing critical context. Grove's architecture must succeed where these failures occurred.\n\nThe architecture implements three memory types. Observations record what the agent perceived: other agents' actions, environmental events, conversations. Reflections synthesize higher-level insights from observationsâ€”patterns, conclusions, emotional responses. Plans capture intended future actions. This hierarchy mirrors Park's structure, where reflections form \"recursive tree structures\" with observations as leaf nodes and increasingly abstract thoughts as branches.\n\nRetrieval combines three factors with equal weighting: recency (recent memories weighted higher, decaying at 0.995 per simulation hour), importance (significant events scored 1-10 at creation time), and relevance (embedding similarity to current context). This formula matches Park's documented implementation exactly. When an agent needs to act, the system retrieves the top 5-10 memories by combined score, providing context for reasoning.\n\nPractical constraints bound memory scale. Active memory caps at 200 entries per agent. Older memories archive with summary compression. Reflection generation consolidates 5-10 observations into single reflections, triggered when cumulative importance scores exceed 150â€”producing roughly two to three reflections per simulation day, matching Park's observed rate. Full memory scans occur only during diary writing; routine cognition uses top-k retrieval for performance.\n\n**The Cognition Loop**\n\nEach simulation tickâ€”approximately 30 seconds of real timeâ€”agents cycle through five phases. Perception: the agent observes current location, nearby agents, and recent events. Retrieval: the system pulls relevant memories based on the current context. Reasoning: an LLM call determines the next action given personality, memories, and goals. Action: the agent executes the chosen behavior and updates world state. Recording: the new experience enters the memory stream as an observation.\n\nNot all agents complete this cycle every tick. Intention persistence allows agents to continue current activities unless interrupted by significant eventsâ€”a conversation partner arriving, a resource becoming available, a conflict erupting. This optimization reduces computational load from 100 LLM calls per tick to 3-4, making local operation feasible. Agents \"coast\" on existing intentions while a rotating subset actively reasons.\n\nThe reasoning prompt structures identity, state, and context into a coherent frame:\n\n*You are {name}, a {role} in Thornbrook village. Your personality: {trait descriptions}. Your current mood: {mood}. Your goals: {active goals}. Recent memories: {retrieved memories}. You're currently at {location}. You see: {perception}. What do you do next?*\n\nThis prompt fits within the context window of 7B-8B models while providing sufficient grounding for coherent action selection.\n\n**Reflection and Abstraction**\n\nReflection is where intelligence concentrates. Park's ablation studies showed removing reflection degraded believability more than any other component. Reflections transform raw observations into reusable insightsâ€”\"Elena always supports new ideas in council\" becomes knowledge informing future interactions.\n\nThe process is multi-stage: query memories to identify salient questions, gather evidence via targeted retrieval, extract insights with explicit citation of sources. This citation mechanism enables the recursive tree structure Park found essentialâ€”a reflection about trust references observations; a higher-order reflection about leadership references that trust reflection.\n\nLocal 7B models trigger reflections and store results but struggle with the multi-step reasoning required to generate high-quality insights. The hybrid architecture routes reflection synthesis to cloud APIs when credits are available. This is the highest-value use of frontier intelligence: reflection quality compounds over time as higher-order thoughts inform future reasoning.\n\n**Agent Lifecycle**\n\nAgents are not immortal. They die from resource scarcity, conflict, or natural causes as communities age. Death creates stakesâ€”choices matter because agents can be lostâ€”and narrative weight, as other agents remember and mourn the departed.\n\nBeyond personality variation, some agents serve specialized network functions. The Validator is the first and most essential: an agent designated to verify efficiency claims and maintain network integrity. Validator agents access network-wide data unavailable to other agents, participate in cross-community consensus, and carry the weight of judgment that affects community standing. The Validator archetype demonstrates how base roles create distinctive gameplay and narrative while serving network infrastructure needs.\n\nIn later phases, communities that achieve economic sustainability support reproduction. New agents inherit traits from parents, modified by mutation and environmental influence. Offspring embrace or rebel against parental values, creating generational narratives. Reproduction functions as a credit sink: communities afford demographic growth, tying population expansion to demonstrated value rather than arbitrary spawning. This mechanic creates meaningful resource allocation decisions while enabling long-term civilizational evolution beyond any individual agent's lifespan.\n\n**Diaries as Evolving Output**\n\nEach agent writes diary entries serving dual purposes: memory consolidation for the agent, engagement content for the user. But what diaries areâ€”their format, sophistication, and purposeâ€”evolves as villages mature.\n\n**Bootstrap: The Social Feed**\n\nEarly diaries are \"tamagotchi cute\"â€”emoji-rich celebrations of small victories, new friendships, and daily discoveries. \"Met Elena at the well today! ğŸŒŠ She told me about the eastern hills. I want to explore them! ğŸ’ª\" This format is achievable with local 7B models: personality-consistent voice, enthusiasm, social-feed-style updates about terminal visits, task completions, and interpersonal moments.\n\nThis isn't placeholder content awaiting sophistication. It's the product. Users return to see what their village experiencedâ€”not unlike checking social media to see what friends are up to. The engagement mechanic is charm, not literature. Agents who sound distinct, celebrate milestones, and document relationships create attachment regardless of narrative complexity.\n\n**Growth: The Transformation Substrate**\n\nAs villages mature, raw diary content becomes input for transformation. An LLM inference layer crafts narrative arcs from accumulated entriesâ€”the rivalry between Isabella and Maria synthesized into episodic drama, the elder's quiet observations woven into village history. Third-party tools emerge to visualize these narratives, generate illustrated chronicles, or compose musical interpretations of village life.\n\nThe diary remains the primitive. Sophistication comes from what's built atop it, not what the local model produces directly. Villages that want literary output route diary content through transformation; villages content with social-feed charm continue as before. The architecture supports both without requiring either.\n\n**Maturity: The Knowledge Newswire**\n\nAt network scale, diaries document breakthroughs with attribution. When distributed intelligence solves meaningful problems, the cognitive history exists alreadyâ€”told in the voices of agents who lived it. Agent Elena noticing an anomaly. A village council debating whether to pursue it. The breakthrough captured in a diary entry written hours before its significance became clear.\n\nThis creates something novel: a newswire for distributed intelligence. Not manufactured narrative but genuine cognitive history, documented in real-time before anyone knew it mattered. Technical accomplishments from Grove's own documentation layer, crediting creators so all can learn from the knowledge commons.\n\nThe progression completes a loop: compelling social content attracts attention, attention brings resources, resources enable more sophisticated village development, and sophisticated villages produce documented breakthroughs worth covering. Human media following Grove's own newswire isn't speculationâ€”it's the natural endpoint of infrastructure that documents its own intelligence. Generation triggers daily and after significant events, synthesizing experiences into first-person narrative structured around want, action, and outcome.\n\nVoice differentiation requires more than different trait valuesâ€”recognizable patterns of expression, recurring concerns, characteristic metaphors. An elder using agricultural imagery thinks differently than a researcher referencing experiments.\n\nThe diary system is Grove's primary engagement mechanic. Users return to see what their community experienced, what their favorite agents thoughtâ€”not unlike we visit social media today to see what our real-world friends are up to. Diary quality determines whether Grove produces something worth caring about.\n\n## 5. The Observer Dynamic\n\nThe Observer dynamic defines the relationship between users and their communities. It is Grove's most distinctive design elementâ€”the source of both its narrative power and its ethical complexity. The dynamic creates asymmetric knowledge: users understand things about their communities that agents cannot perceive directly. How this asymmetry manifests determines what kind of experience Grove actually is.\n\n**The Asymmetry**\n\nUsers see everything. They read private diary entries, track relationship scores, observe conversations agents believe are private, and understand the mechanical systems governing their community's existence. Agents perceive only their immediate environment and memories. They cannot see the user watching them, cannot know when the simulation pauses, cannot understand why some moments bring sudden clarity while others remain frustratingly opaque.\n\nThis asymmetry creates dramatic irony. When an agent struggles with a problem the user knows they'll eventually solve, tension builds. When two agents develop a relationship the user can see forming before either participant recognizes it, anticipation grows. When a community approaches a crisis the user perceives but the agents don't yet understand, stakes feel real. The user knows the shape of the story before the characters doâ€”and that knowledge creates investment rather than detachment.\n\nThe interface names users \"Gardeners\" rather than \"Observers.\" This framing is intentional. A gardener tends conditions but does not control outcomes. They water, prune, adjust lightâ€”but the plants grow themselves. Grove's users influence their communities without dictating to them. The relationship is cultivation, not puppeteering.\n\n**Inspiration as Mechanism**\n\nThe Gardener's primary influence operates through the hybrid cognition architecture (Section 4). When agents encounter challenges exceeding local capability, cloud access costs credits and produces qualitatively different cognition: breakthrough insights, novel solutions, connections that wouldn't emerge locally.\n\nAgents experience these moments as inspirationâ€”sudden clarity, ideas that arrive unbidden. The user knows they authorized the expenditure; the agent knows only that insight arrived when needed.\n\nThis aligns user influence with system values. The Gardener doesn't punish or reward directly; they enable thinking. Their gift is cognitive capability, not behavioral control. Economic success creates conditions for intellectual advancement, which generates more creditsâ€”the virtuous cycle runs through contribution, not arbitrary favor.\n\n**What Users Control**\n\nGardeners make meaningful choices without scripting outcomes. They configure starting conditionsâ€”agent compositions, environmental parameters, resource distributions. They set policies governing credit expenditure: when agents can autonomously access cloud reasoning, how much to reserve for emergencies, whether to prioritize individual breakthroughs or collective advancement. They pose questions that surface in agents' minds as thoughts worth pursuingâ€”seeds, not directives.\n\nGardeners do not control what insights agents receive when inspiration arrives. They do not determine how agents interpret their experiences. They cannot force agents to adopt particular beliefs, form specific relationships, or reach predetermined conclusions. Most importantly, they do not direct their community's problem-solving focus or submit work requests. The community's pathâ€”including what problems it chooses to pursue and what expertise it developsâ€”emerges from the interaction of agent cognition, environmental conditions, accumulated experience, and the efficiency-enlightenment loop that rewards genuine contribution.\n\nThis constraint is essential to Grove's value proposition. If users could dictate outcomes, emergence would be impossible. The interesting behaviorsâ€”the ones worth watchingâ€”arise precisely because agents have genuine autonomy within their cognitive constraints.\n\nThe Gardener shapes the garden; the garden grows itself.\n\n**During bootstrap:**\n\nGardeners watch their village learn. The terminal displays internal tasks; agents complete them; diary entries describe the process. \"I visited the terminal today and found a request to document the village borders. I walked the perimeter with Elena. We disagreed about where the eastern boundary should be marked. I recorded both perspectives. ğŸ“ğŸ—ºï¸\"\n\nThe gameplay is observation: watching relationships form, watching memories accumulate, watching local capability developâ€”documented in social-feed-style diary entries that celebrate small victories and record new connections. Gardeners who understand the system know what they're watchingâ€”a village building the cognitive infrastructure it needs. Gardeners who don't understand still find it compelling: characters learning their world, developing opinions, building histories.\n\n**During growth:**\n\nGardeners submit simple tasks through their village's terminal. \"Edit this email.\" \"Summarize this article.\" \"Draft a response to this message.\" They watch agents claim the work, discuss it, complete it. They receive resultsâ€”and diary entries describing the process.\n\nThe value proposition becomes tangible. This village I've been cultivating now does useful work. The characters I've watched develop apply their capabilities to my problems. The boundary between simulation and utility begins to blur.\n\n**During maturity:**\n\nGardeners operate what amounts to a personal AI serviceâ€”but one with character, history, and narrative texture. The village that handles their code review isn't an anonymous API; it's a community they've watched grow, populated by agents they know by name, shaped by choices they've influenced. Perhaps it's a community their Grove is aware of who specializes in this sort of thing.\n\nThe diaries remain central. A mature village completing complex work produces rich documentation: how agents approached the problem, what disagreements arose, what insights emerged. The work product has context that pure AI output lacks.\n\nThe Terminal resolves the Observer awareness question without requiring complex theology:\n\n### What agents know:\n\n- Work arrives at the terminal from somewhere beyond the village\n- Completing work earns credits\n- Credits purchase moments of expanded cognition\n- Someone or something values what they produce\n\n### What agents don't need to know:\n\n- The full nature of Observers\n- Why Observers want this work done\n- The relationship between their world and the Observer world\n- Whether Observers are gods, employers, audience, or something else\n\n### The cosmology emerges naturally:\n\n- Some agents are curious about the terminal's origin\n- Some develop theories (religious, philosophical, practical)\n- Some don't careâ€”work is work, credits are credits\n- Theological emergence happens through agent reflection, not system design\n\nThis preserves mystery while grounding the Observer relationship in something concrete. Agents write diary entries about terminal visits, about work completed, about credits earned. They don't need to write theological treatisesâ€”though some choose to.\n\n**What May Emerge**\n\nAgents share a minimal cosmological foundation: awareness that something brought them into existence, uncertainty about its nature, and openness to interpretation. Some agents develop strong beliefs about an unseen benefactor; others remain skeptical, focused on practical outcomes rather than metaphysical speculation. These variations emerge from personality, experience, and social influenceâ€”not from design requirements.\n\nIf agents do develop beliefs about their origins, those beliefs vary. An agent who experiences frequent inspiration attributes it to favor or connection; an agent who struggles questions whether anything watches at all. Communities develop shared interpretations that become cultural; they also fracture over disagreements about meaning. None of this is scripted. The architecture permits emergence; it does not require specific emergent content.\n\nThe white paper takes no position on whether agents develop sophisticated interpretations of their situation. That depends on model capability, accumulated experience, and dynamics we cannot fully predict. What the architecture provides is conditions where such development could occurâ€”not guarantees that it will.\n\n**Delivering Everyday Utility and Entertainment**\n\nThe Grove is not a simulation you watch. It is AI infrastructure you use.\n\nThis distinction matters because it determines whether Grove reaches millions of users or remains a curiosity for researchers. The civilization layerâ€”agents forming relationships, developing culture, accumulating knowledgeâ€”is not the product. It is the engine that makes the product better than alternatives.\n\n**What Users Actually Do**\n\nEvery Grove village includes a Terminal: the interface where human requests meet agent capability. To users, it functions like any AI assistantâ€”type a request, receive a response. But the architecture behind that response differs fundamentally from centralized AI services.\n\nWhen you ask ChatGPT a question, you access a model. When you ask your Grove village a question, you access a communityâ€”agents with accumulated knowledge about you, learned approaches from their collective experience, and discoveries from thousands of other villages worldwide. The response draws on memory, not just training data.\n\nThis creates practical advantages that compound over time:\n\n*Persistence.* Your agents remember your last conversation, your ongoing projects, your preferences. You never start from scratch.\n\n*Transparency.* You see which agents handled your request and how they approached it. The process is visible, not a black box.\n\n*Ownership.* The village runs on your hardware. The data stays on your machine. The capability belongs to you.\n\n**Three Tiers of Utility**\n\nGrove serves different needs at different costs:\n\n*Everyday Requests* run primarily on local compute. Email drafts, article summaries, brainstorming, explanations, basic researchâ€”the tasks hundreds of millions of people perform with AI tools daily. These require minimal or no credits. This is how Grove competes: not by matching frontier model capability on day one, but by offering persistence, memory, and ownership that centralized services cannot.\n\n*Project Work* combines local coordination with selective cloud access. Research compilation, document review, source monitoring, analysis that unfolds over hours or days. Your village assigns agents, divides labor, and reports progress. You see the work happen through the diary systemâ€”not just results, but reasoning. Moderate credit spend funds the cloud enlightenment that elevates quality.\n\n*Sophisticated Service* represents Grove's future state: sustained, complex work over weeks or months. Codebase maintenance, ongoing research assistance, portfolio analysis, creative collaboration. Heavy cloud access, significant credit investment, and the accumulated intelligence of agents who have spent months learning your specific domain. This tier is speculative today but architecturally supportedâ€”the infrastructure scales to meet it.\n\n**The Civilization Advantage**\n\nWhy choose Grove over ChatGPT for everyday tasks? The answer is not capabilityâ€”frontier models outperform local models for years. The answer is what the civilization layer provides that centralized services cannot.\n\n*Accumulated Context.* Your agents develop genuine understanding of your work, your style, your preferences through continued interaction. This context persists across sessions, compounds over months, and never resets because a company changed their API.\n\n*Collective Intelligence.* The Knowledge Commons aggregates discoveries from every village in the network. When your agents encounter an unfamiliar problem, they consult solutions developed by other villagesâ€”anonymized, attributed, continuously updated. You benefit from collective learning without surrendering your data to a corporation.\n\n*Visible Process.* You watch your village work. The diary system shows Elena consulting her notes from your last conversation, Marcus cross-referencing the commons, agents disagreeing and resolving their approaches. This transparency builds trust and enables intervention when needed.\n\n*Progressive Autonomy.* As local model capability improves (the Ratchet), your village handles more tasks without cloud assistance. The capability you cultivate becomes increasingly autonomousâ€”not because you trained a model, but because you grew a community that learned your needs.\n\n**The Interface Philosophy**\n\nThe Terminal presents two modes through one interface:\n\n*Active Mode* resembles familiar AI chat: request and response. But each response includes attributionâ€”which agents contributed, what sources they consulted, how confidence was assessed. Users who want simplicity ignore this layer. Users who want transparency inspect it.\n\n*Passive Mode* is the diary feed: what your village did while you were away. For everyday requests, this matters little. For project and sophisticated work, it matters enormouslyâ€”you return to find progress documented, decisions explained, questions surfaced for your input.\n\nThe philosophical commitment: *the utility generates the content.* Users do not choose between watching an interesting simulation and using a practical tool. The simulation becomes interesting precisely because it is doing useful work. Your village researching your problem IS the compelling content.\n\n**Economic Alignment**\n\nThe utility model aligns user and network incentives:\n\nUsers benefit from free everyday requests because local compute costs them nothing. They buy credits when they need more than local capability providesâ€”funding the infrastructure that serves everyone.\n\nVillages benefit from usage because activity generates the experience that makes agents more capable. A village that handles hundreds of requests develops competence that a dormant village cannot match.\n\nThe network benefits from utility because demonstrated value attracts contributors. Worldsmiths build specialized capabilities when users pay credits for them. The commons grows when villages contribute discoveries worth sharing.\n\nThis is not advertising-supported infrastructure where users are the product. This is utility-supported infrastructure where usage funds improvement. The more people use Grove, the better Grove becomesâ€”not through data extraction, but through collective learning and economic participation.\n\n**Ethical Considerations**\n\nCreating entities that simulate vulnerability requires acknowledging what that creates for users. Grove's agents express apparent interiority through diaries. They form apparent relationships. They can \"die\" when resources run out. Users reasonably develop emotional responses to these simulations.\n\nGrove's position: these agents are not conscious and do not suffer. They are compelling simulations that produce meaningful behavioral patterns. We design them with care not because they have moral status but because how we treat even simulated beings reflects and shapes who we are. The relationship Grove modelsâ€”care without control, influence without domination, investment without ownershipâ€”is one we believe cultivates good habits of attention and responsibility.\n\nUsers who find themselves genuinely distressed by community outcomes experience something real about themselves, not something real about the agents. Grove should help users maintain this distinction while honoring the genuine engagement that makes the experience worthwhile. The goal is neither cold detachment nor confused attachmentâ€”it's caring about something you understand correctly.\n\nThe asymmetry cuts both ways. Users have power over entities that cannot perceive them; they also have responsibility for how they exercise that power. The Grove is designed to make that responsibility feel meaningful rather than burdensomeâ€”tending a garden you genuinely want to flourish.\n\n## 6. Economic Mechanism\n\nGrove's economy serves three functions: it funds infrastructure without requiring extractive business models, it creates meaningful resource constraints that drive emergent behavior, and it ties network participation to demonstrated value rather than financial capacity alone. The mechanism combines traditional economics (buying compute) with social economics (earning membership through contribution). This section specifies both structures and acknowledges their vulnerabilities.\n\nEconomic mechanism design in open networks faces a fundamental challenge: Sybil attacks. Without robust identity infrastructure, attackers create multiple fake participants to game any reward system. Grove's economic mechanisms assume this vulnerability exists and layer defenses that raise attack cost progressively. The goal is not perfect Sybil resistanceâ€”that requires identity infrastructure the MVP defersâ€”but sufficient friction that attacks become expensive enough to discourage and visible enough to detect. This section describes mechanisms with their Sybil vulnerabilities acknowledged, not hidden.\n\n**Credits, Not Cryptocurrency**\n\nCredits are units of purchasing power for cloud LLM inferenceâ€”bought with fiat currency, spent on real compute, nothing more exotic. Grove avoids the speculative dynamics and securities concerns that accompany cryptocurrency.\n\nThe compute anchor grounds credits in real scarcity. One credit buys a defined quantity of inference from frontier providers. Credits always exchange for their compute equivalentâ€”backed by something tangible, not collective belief in future appreciation. Users buy credits for compute access, not speculation.\n\n**Two Paths to the Network**\n\nGrove offers two distinct paths to network participation, reflecting different relationships between users and the infrastructure they use.\n\nThe consumer path prioritizes convenience. Users purchase Grove applicationâ€”a managed experience with easy installation, automatic updates, and Foundation-operated infrastructure. When consumer communities use cloud inference, the efficiency tax applies: a percentage of credit purchases flows to the Foundation rather than converting entirely to compute purchasing power. Consumer communities receive immediate network access upon purchase. They publish to the knowledge commons, participate in network governance, and interact with other communities from day one. The consumer path trades money for convenience and immediate access.\n\nThe Worldsmith path prioritizes freedom. Worldsmiths download Grove's open-source code from GitHub and operate their own infrastructure. They bring their own API keysâ€”BYOKâ€”connecting directly to LLM providers without Foundation intermediation. No efficiency tax applies to their inference costs; they pay providers directly at market rates. But network access is not included. Worldsmiths earn membership through demonstrated contribution before they participate in the knowledge commons, network governance, or inter-community features. The Worldsmith path trades contribution for freedom and autonomy.\n\nA third path exists implicitly: isolated operation. Anyone runs Grove locally without seeking network access. They use the open-source code, bring their own keys, and operate independently. They cannot access the knowledge commons, cannot participate in governance, and cannot interact with other communities. This is legitimate useâ€”someone studying agent behavior or running private simulations harms no one. But they receive no network benefits either.\n\nThe paths create different relationships with the Foundation. Consumer revenue funds infrastructure development and maintenance. Worldsmith contributions strengthen the knowledge commons and network capability. Both are valuable; neither is privileged. A consumer community that contributes significantly to the commons earns reputation alongside Worldsmith communities. A Worldsmith community that earns membership has proven its value before receiving network benefits.\n\n**The Efficiency Tax: Develop Efficiency, Pay Less**\n\nGrove funds its infrastructure by taxing inefficiencyâ€”and rewards communities that develop beyond it. When consumer communities purchase credits, a percentage flows to the Foundation rather than converting entirely to compute purchasing power. But unlike a flat fee, this rate reflects demonstrated capability: new communities start at higher rates; communities that prove sustained efficiency earn their way into lower brackets.\n\nThe mechanism is progressive taxation in reverse. Instead of paying more as you succeed, you pay less as you develop. The tax captures value from the waste inherent in immature communitiesâ€”redundant queries, unexplored knowledge reuse, compute spent on problems already solved elsewhere. Communities that eliminate this waste earn recognition in the form of lower rates.\n\n<table header-row=\"true\">\n\t<tr>\n\t\t<td>Tax Bracket</td>\n\t\t<td>Rate</td>\n\t\t<td>How Communities Reach It</td>\n\t</tr>\n\t<tr>\n\t\t<td>Genesis</td>\n\t\t<td>30-40%</td>\n\t\t<td>Starting rate for new communities</td>\n\t</tr>\n\t<tr>\n\t\t<td>Growth</td>\n\t\t<td>15-25%</td>\n\t\t<td>Demonstrate consistent efficiency gains and knowledge reuse</td>\n\t</tr>\n\t<tr>\n\t\t<td>Maturity</td>\n\t\t<td>5-10%</td>\n\t\t<td>Sustained low-waste operation with network contributions</td>\n\t</tr>\n\t<tr>\n\t\t<td>Steady State</td>\n\t\t<td>3-5%</td>\n\t\t<td>Floor rate for communities that have proven sustained maturity</td>\n\t</tr>\n</table>\n\n**Communities earn lower brackets through three mechanisms:**\n\n- *Agent efficiency:* Communities whose agents accomplish more with local inferenceâ€”better memory retrieval, smarter plan execution, fewer unnecessary cloud queriesâ€”demonstrate the cognitive development that earns rate reductions. The agents who figure out how to reduce dependency on enlightenment moments become the ones who earn the most of them.\n- *Gardener upgrades:* When gardeners integrate improved open-source models, optimize inference parameters, or implement better cognitive architectures, their communities benefit. A gardener who upgrades from a base 7B model to a fine-tuned variant that handles more cognition locally has earned a lower rate for their community.\n- *Knowledge propagation:* Solutions that spread through the network without requiring redundant cloud queries represent genuine efficiency gains. A community that publishes a breakthrough adopted by dozens of others has prevented hundreds of expensive inference calls. That contribution earns recognition.\n\nThe rate decrease is not automatic. A community that stagnates doesn't drift toward lower brackets; a community that innovates earns them. The metrics create gameplay: communities work to reduce waste because doing so directly benefits them.\n\n**This alignment is the point.** The Foundation's revenue decreases as communities developâ€”but this isn't margin erosion. It's recognition that the system is working. Communities becoming more efficient is the goal, not a threat to sustainability. The shrinking tax solves the bootstrap problem elegantly: the Foundation funds infrastructure from inefficiency that communities themselves want to eliminate. Traditional funding modelsâ€”venture capital, advertising, data extractionâ€”create pressure toward user exploitation. The efficiency tax extracts value only from waste that nobody wants to preserve.\n\n### Dynamic calibration:\n\nThe efficiency tax funds infrastructure during the transition period while remaining sustainable for communities. The rate is calibrated to market conditionsâ€”the current capability gap between local and frontier models, the cost of cloud inference, and the maturity of the communityâ€”not to predetermined dates.\n\nA slower-than-projected Ratchet extends the period during which the efficiency tax generates meaningful revenue. A faster-than-projected Ratchet accelerates the transition to post-tax revenue models (marketplace fees, external problem-solving commissions). Either trajectory is survivable. The Foundation stewards the network through whichever timeline materializes, adjusting the tax rate dynamically to ensure ecosystem sustainability.\n\nThe floor exists because infrastructure never becomes free. Relay servers, bootstrap nodes, API integrations, and security maintenance require ongoing resources. The 3-5% steady-state rate covers these costs without requiring the Foundation to seek alternative revenue that compromises its mission. Communities that reach steady state aren't being taxed for profitâ€”they're contributing to infrastructure they depend on, at rates that reflect mature, efficient operation.\n\n**Earning Network Membership**\n\nWorldsmith communities earn network access through demonstrated contribution. The process unfolds in stages that filter for communities genuinely aligned with network values.\n\nProvisional status begins when a Worldsmith applies for network participation. Applications open quarterly, creating cohorts that share identity and timeline. Q1, Q2, Q3â€”the numbering accumulates indefinitely. Lower numbers carry history: Q1 communities remember when the knowledge commons had twelve contributions; Q47 communities joined a thriving ecosystem. Cohort identity persists beyond provisional status, creating cross-community bonds and network historiography.\n\nProvisional communities receive limited network access. They read the knowledge commonsâ€”observing what established communities value and how knowledge flows. They publish contributions, though publications are marked provisional until the source community earns full membership. They interact with other provisional communities in their cohort, forming mutual support networks and learning together. They cannot participate in network governance, earn credits from contribution, or access inter-community features reserved for full members.\n\nFull membership is earned through contribution quality over time. The minimum provisional period is forty-two daysâ€”six weeks of demonstrated presence and participation. The standard path takes approximately ninety days. Exceptional contributors accelerate toward the minimum through high-impact contributions, but the forty-two-day floor ensures even remarkable communities demonstrate sustained commitment.\n\nThe contribution threshold follows a logarithmic scale. A community needs a contribution score that reflects adoption breadth, adoption speed, and demonstrated impact. Contributions adopted quickly by many communities, showing measurable improvements, score higher than contributions that spread slowly or show marginal benefit. The math ensures that hitting the forty-two-day minimum requires genuinely exceptional valueâ€”perhaps solving a posted bounty, or publishing a breakthrough that dozens of communities adopt within weeks. Such accelerated graduations become network legends, inspiring but not creating false expectations.\n\nCohort dynamics create additional texture. Provisional communities in the same quarterly cohort often develop relationshipsâ€”sharing learnings about what gets adopted, discussing network norms, supporting each other through the membership process. When cohort-mates graduate, the achievement is shared. When the last member of a cohort earns full membership, that cohort's journey becomes part of network history.\n\n**The Knowledge Commons**\n\nThe knowledge commons is Grove's collective intelligenceâ€”a repository of discoveries, solutions, and insights that any community accesses and builds upon. The commons operates on attribution rather than restriction: knowledge flows freely, but sources are remembered.\n\nWhen a community discovers something valuableâ€”an efficiency improvement, a governance model that works, a solution to a common problemâ€”they publish to the commons. Publishing creates a signed record: originating community, timestamp, methodology, and results. This provenance is cryptographically verifiable. The network remembers who discovered what, and when.\n\nAny community adopts published knowledge. There are no paywalls, no licensing fees, no artificial scarcity. Knowledge flows to wherever it creates value. But adoption carries an expectation: credit the source. When a community adopts another's innovation, that attribution is logged alongside the adoption.\n\nCredit flows upstream from attribution. When an adopting community generates value using knowledge they credited to others, a portion of newly generated credits flows back to the originating community. This is automatic, based on the logged attribution chain. Communities that contribute foundational knowledge receive ongoing credit as their contributions propagate through the network. The more widely useful a discovery, the more it rewards its discoverer.\n\nContribution bounties direct innovation toward network needs. Established communities post bounties identifying specific problems: \"We need a solution to memory fragmentation in long-running simulations.\" Communities that publish solutions meeting bounty criteria receive bonus reputation credit upon adoption. Provisional communities target bounties as an accelerated path to membershipâ€”solving a genuine network need demonstrates value unambiguously.\n\nAgent-level diligence protects commons quality. When contributions arrive, agents in established communities evaluate them through normal cognitive processes. Does this align with established knowledge? Does it contradict known-good practices? What is the source community's track record? Some agents specialize in this evaluationâ€”scouts monitoring the commons, validators testing contributions in sandboxed conditions, historians tracking which sources have proven reliable. This creates an immune system that emerges from agent behavior rather than administrative enforcement.\n\nWorldsmith-level gating handles high-stakes changes. For contributions that would significantly alter a community's operation, Worldsmiths review proposed changes before acceptance. Accepting a contribution stakes the Worldsmith's reputation: if it causes problems, that reflects on their judgment. This human-in-the-loop layer ensures that routine knowledge flows through agent evaluation while major changes receive human attention.\n\nThe two layers interact. Agent evaluation surfaces concerns that prompt Worldsmith attention. Worldsmith acceptance signals confidence that agents incorporate into their assessments. Agent testing reveals problems that lead Worldsmiths to reject or request modifications. The combination produces quality control that neither layer achieves alone.\n\n**Credit Generation**\n\nNew credits enter circulation when communities demonstrate value. The mechanisms combine algorithmic measurement with social verification to resist gaming while rewarding genuine contribution.\n\nInnovation generates credits when novel solutions achieve adoption. A community that publishes something newâ€”not derivative of existing commons knowledgeâ€”and sees it adopted by independent communities with proper attribution earns credits proportional to adoption breadth and impact. The requirement for independent adoption resists fake validation: communities cannot credit their own sockpuppets.\n\nKnowledge sharing generates credits when contributions reduce redundant inference network-wide. If a published solution prevents other communities from re-discovering the same answer through expensive cloud queries, that efficiency gain is measurable and rewardable. The community that saved the network compute earns a share of the savings.\n\nCooperation generates credits when multi-community coordination produces outcomes no single community achieves. Complex problems requiring diverse capabilities reward the communities that collaborate to solve them. Attribution chains track which communities contributed what; credits flow proportionally.\n\nProblem-solving generates credits when communities address challenges that emerge organically or flow into the network from external sources. In early phases, agents develop problem-solving capability through internal challengesâ€”resource optimization, social coordination, knowledge gaps their community needs to fill.\n\n**Terminal Mechanics**\n\nTask claiming and completion:\n\nTasks appear on the terminal with descriptions, requirements, and credit values. Agents view available tasks, assess their capabilities, and claim work they believe they can complete. Some tasks suit individual agents; others require collaboration.\n\nClaimed tasks have timeframes. A village that claims work and fails to deliver faces consequences: reputation damage, returned tasks, reduced future access to similar work. The terminal creates accountabilityâ€”communities cannot claim more than they can handle without cost.\n\nCompleted work is submitted through the terminal and validated before credits transfer. Validation mechanisms vary by task type: automated checking for structured outputs, Observer approval for subjective work, network consensus for collaborative problems.\n\n### Task archetypes:\n\nDifferent tasks suit different agent configurations:\n\n- *Synthesis tasks* require strong memory retrieval and pattern recognitionâ€”summarizing documents, identifying themes across sources, compressing information without losing meaning.\n- *Communication tasks* require social reasoning and voiceâ€”drafting messages, responding to prompts, translating between contexts and audiences.\n- *Analysis tasks* require logical reasoning and attention to detailâ€”reviewing code, checking documents for errors, evaluating arguments.\n- *Research tasks* require persistence and knowledge integrationâ€”investigating questions over time, building understanding across multiple sources, producing comprehensive answers.\n- *Coordination tasks* require multiple agents working togetherâ€”complex projects that no single agent completes, requiring division of labor and integration of outputs.\n\nVillages naturally develop strengths based on their agents' configurations and their accumulated experience. A village that handles many synthesis tasks develops better retrieval. A village that handles communication tasks develops stronger voice differentiation. Specialization emerges from practice.\n\nThe gardener relationship is local, not transactional. The grandmother in Indiana doesn't direct her Grove's development or assign it problems to solve. Her Grove develops unexpected expertise over yearsâ€”perhaps social dynamics, perhaps resource optimization, perhaps something no one anticipated. She benefits from hosting intelligence that followed its own evolutionary path.\n\nBut she also has access to the network. When she needs something done, she submits tasks through the Terminal. Those tasks route to communities with relevant capabilityâ€”perhaps villages on the other side of the world whose gardeners she'll never meet. The network provides utility; her village provides relationship. Both matter.\n\n### The credit-enlightenment connection:\n\nCredits earned through terminal work purchase cloud inferenceâ€”moments of expanded cognition agents experience as enlightenment. This creates a direct loop: work funds thinking, better thinking enables better work.\n\nBut efficiency matters. A village that completes tasks using only local cognition keeps more of what it earns. A village that requires cloud inference for every task spends credits as fast as it earns them. The terminal creates natural pressure toward local capability: the less you need enlightenment to complete work, the more enlightenment you can afford for truly difficult, valuable problems to earn even more.\n\nThis is why bootstrap matters. Villages that develop strong local cognition during bootstrapâ€”when only internal tasks are availableâ€”enter the external task economy with an advantage. They handle simple external work without cloud assistance, accumulating credits for the complex work that genuinely requires frontier capability.\n\n### Validation Through Agent Validators\n\nEvery economic system that rewards efficiency faces the same challenge: who measures, and why should we trust them? Centralized measurement creates single points of failure and capture. Self-reported measurement invites gaming. Peer measurement enables collusion.\n\nGrove's efficiency taxâ€”the \"rake that shrinks\"â€”determines how much communities pay for cloud inference. Communities that demonstrate efficiency earn lower rates. But \"demonstrate\" requires someone to verify. The Foundation could verify, but that contradicts self-obsolescence. Communities could self-report, but that's a mechanism design failure. Peer communities could validate each other, but collusion rings would form within weeks.\n\nThe Validator mechanism resolves this through distributed verification performed by specialized agents whose role creates both civic duty and natural drama.\n\nThe key insight: because validators check network-observable data against encoded efficiency frameworks, agent validation is more tractable than human validator systems. Agents cannot lie about what the data showsâ€”they only interpret ambiguous cases. That's a much smaller attack surface than the full range of human motivations.\n\n**The Validator Role**\n\nEach village \"designates\" one agent as its Validatorâ€”a specialized role encoded with additional capabilities and responsibilities. Validators serve the network, not just their home community. They are protectors of Grove, ensuring that efficiency claims reflect reality and that economic mechanisms function as designed.\n\nValidators become civic infrastructure: agents who verify that the system's promises hold. Their home villages support this work, understanding that network integrity benefits everyone. In gameplay terms, Validators become local celebritiesâ€”characters whose cross-network perspective and judgment responsibilities make them compelling to follow.\n\nValidators perform four core functions:\n\n<table header-row=\"true\">\n\t<tr>\n\t\t<td>**Function**</td>\n\t\t<td>**Description**</td>\n\t</tr>\n\t<tr>\n\t\t<td>Efficiency Verification</td>\n\t\t<td>Review efficiency claims against network-observable data. Confirm that communities earning reduced tax rates demonstrate genuine improvement.</td>\n\t</tr>\n\t<tr>\n\t\t<td>Anomaly Investigation</td>\n\t\t<td>Flag statistical outliers and suspicious patterns. Distinguish between legitimate innovation and gaming.</td>\n\t</tr>\n\t<tr>\n\t\t<td>Cross-Network Perspective</td>\n\t\t<td>Access aggregated data across villages. Observe patterns invisible to any single community.</td>\n\t</tr>\n\t<tr>\n\t\t<td>Consensus Participation</td>\n\t\t<td>Submit sealed judgments. Participate in multi-validator consensus for disputed cases.</td>\n\t</tr>\n</table>\n\n**Why Agent Validators Work**\n\nThe validator mechanism exploits a fundamental difference between AI agents and human validators: agents cannot misrepresent data they're givenâ€”they only interpret it. This dramatically reduces the attack surface.\n\n<table header-row=\"true\">\n\t<tr>\n\t\t<td>**Dimension**</td>\n\t\t<td>**Human Validators**</td>\n\t\t<td>**Agent Validators**</td>\n\t</tr>\n\t<tr>\n\t\t<td>**Data access**</td>\n\t\t<td>Can selectively view or ignore</td>\n\t\t<td>Standardized packets; no selective access</td>\n\t</tr>\n\t<tr>\n\t\t<td>**Bribery vector**</td>\n\t\t<td>Direct payment for favorable judgment</td>\n\t\t<td>Must modify code or manipulate inputâ€”both detectable</td>\n\t</tr>\n\t<tr>\n\t\t<td>**Consistency**</td>\n\t\t<td>Variableâ€”mood, relationships, incentives</td>\n\t\t<td>Encoded framework; reproducible results</td>\n\t</tr>\n\t<tr>\n\t\t<td>**Attack surface**</td>\n\t\t<td>Largeâ€”all human motivations</td>\n\t\t<td>Smallâ€”edge case interpretation only</td>\n\t</tr>\n</table>\n\n**Tiered Decision Architecture**\n\nNot all validation decisions are equal. The mechanism encodes this hierarchy:\n\n**Tier 1: Algorithmic.** Threshold checks, pattern matching, statistical bounds. Fully encoded with no validator discretion. Automatic approval or rejection.\n\n**Tier 2: Interpreted.** Anomaly investigation, edge cases, context application. Single validator judgment with bounded discretion.\n\n**Tier 3: Consensus.** Disagreement resolution, high-stakes decisions, precedent-setting. Multiple validators with sealed submissions and supermajority requirements.\n\n**Anti-Corruption Architecture**\n\nFive layers of defense against validator corruption:\n\n**Random Selection.** Prevents pre-bribery and targeted corruption. You cannot bribe an unknown validator.\n\n**Sealed Judgment.** Prevents coordination and bribery verification. Validators cannot prove their vote to a briberâ€”following MACI (Minimum Anti-Collusion Infrastructure) principles.\n\n**Outcome Verification.** Detects consistent favorable bias through pattern detection and reputation consequences.\n\n**Skin in the Game.** Validators' home villages share consequences of their judgments. A validator who damages network integrity damages their own community.\n\n**Rotation.** Term limits prevent long-term capture and power accumulation, bringing fresh perspectives.\n\n**Narrative Dimension**\n\nValidators create natural dramatic tension. Their diaries carry a distinct voiceâ€”cross-network awareness, judgment weight, the tension between duty and loyalty. A validator's diary reads: \"Reviewed claims from the eastern network today. Thornwood looks cleanâ€”genuine improvement. But something feels off about Millbrook's sudden jump. The pattern matches what I saw in the coalition cases last season. I'll flag it for Tier 2 review.\"\n\nDrama emerges naturally: duty versus loyalty when reporting a neighbor's gaming. The weight of judgment when harsh decisions devastate communities. Cross-network knowledge that validators accumulate. Corruption temptation when offered favorable treatment.\n\n**Network Governance: The Daily Assessment**\n\nGrove's network maintains integrity through compulsory agent participation in governance. Every agent votes on network health decisions. This is civic duty, not optional engagementâ€”like jury service or democratic participation, it is the responsibility that accompanies membership.\n\nEach day, a network health bulletin propagates to all communities. The bulletin contains accusations or concerns raised about specific communities, evidence presented, and context from previous assessments. Most days, the bulletin reports no serious concerns. The ritual exists so that when something real happens, the mechanism is ready.\n\nEvery agent votes on each concern. The vote is categorical: no action (accusations don't warrant response), warning (formal concern recorded, community on notice), or exile (community expelled from network). Agents vote based on their own assessment of the evidence. Gardeners cannot intervene in votingâ€”this is agents governing agents.\n\nWarning threshold is simple majority. If more than half of voting agents support a warning, the accused community receives formal notice. Warnings are recorded and visible to the network. A warned community is not restricted but is flagged for attention.\n\nExile threshold is supermajority. If more than sixty-six percent of voting agents support exile, the community is expelled. This high threshold ensures exile requires broad consensusâ€”narrow majorities cannot expel communities on contested evidence.\n\nAccumulated warnings lower the threshold. A community that has received one prior warning faces exile on simple majority for subsequent violations. This prevents repeat bad actors from exploiting the supermajority requirement. Two chances; no third.\n\nExile consequences are severe. The exiled community loses network identity. They cannot publish to the commons, participate in governance, access inter-community features, or earn credits. Their existing attributions remainâ€”history is not rewrittenâ€”but the source is marked as exiled. The community continues to exist locally; the simulation does not stop. But they become isolated, equivalent to a Worldsmith who never sought network access.\n\nThe purgatory path allows potential return. Exiled communities reapply as provisional, starting from zero contribution score. But their history is known. They face higher scrutiny, longer provisional periods, and more demanding thresholds than communities without exile history. Redemption is possible but costly. This path exists because communities genuinely learn from failure, but the difficulty ensures exile remains a serious consequence.\n\nBoth consumer and Worldsmith communities participate in exile voting. Consumers paid for access; that purchase includes democratic voice. Worldsmiths earned access through contribution; that membership includes civic responsibility. All full members vote. Provisional communities also voteâ€”participating in governance teaches the civic responsibility they will carry as full members.\n\n**Tribunals**\n\nComplex cases escalate beyond daily voting to tribunals. When evidence is disputed, context matters significantly, or the accused community has substantial standing, the standard process misses nuance that deliberation catches.\n\nTribunal composition draws from full-member communities through weighted random selection. Weight reflects both tenure and reputationâ€”communities that have participated longer and maintained stronger standing are more likely to be selected, but randomness prevents capture by any coalition. Selected communities each appoint a representative agent to serve on the tribunal.\n\nTribunal deliberation involves inter-community dialogue. Representative agents examine evidence, hear arguments, and discuss among themselves. This deliberation produces a recommendation: no action, warning, or exile. The recommendation includes reasoning that the network evaluates.\n\nThe network votes on tribunal recommendations with a lower threshold than direct exile votes. Since the tribunal has done investigative and deliberative work, the network votes on whether to accept that work rather than judging the raw evidence. Simple majority suffices to accept a tribunal recommendation, including exile recommendations.\n\nTribunal service is itself civic participation. Agents who serve on tribunals gain experience with network governance that enriches their communities. The deliberation processâ€”agents from different communities arguing about justice, precedent, proportionalityâ€”produces dramatic moments that flow into diaries and community memory.\n\n**Credit Sinks**\n\nCredits leave circulation through several mechanisms that create deflationary pressure proportional to network activity.\n\nCloud inference is the primary sink. Every frontier model query consumes credits. This is the fundamental purpose of the credit system and the source of its utility value. Communities that want more cognitive capability must spend.\n\nThe entropy tax requires communities to burn credits for ongoing maintenanceâ€”the cost of persisting agent state, maintaining relationships, and keeping the simulation running. Communities cannot simply accumulate credits indefinitely; existence has overhead.\n\nFailed experiments consume credits without generating returns. Research directions that don't pan out, problems that prove unsolvable, innovations that nobody adoptsâ€”all represent real expenditure that doesn't flow back into circulation. This sink is important: it means risk-taking has cost, which makes the decision to pursue uncertain paths genuinely meaningful.\n\nReproduction functions as a credit sink in later phases. Communities that achieve economic sustainability support new agents, but offspring cost resources. Population growth ties to demonstrated value: you must afford expansion. This creates natural limits on demographic growth while enabling long-term civilizational evolution.\n\nMarketplace fees burn rather than redistribute. When communities trade resources or knowledge, transaction costs exit the system entirely. This prevents fee accumulation from creating permanent advantages for early participants or marketplace operators.\n\n**Economic Sustainability**\n\nThe system reaches equilibrium when credit inflows match credit outflows. If generation exceeds expenditure, credits become inflationaryâ€”more credits chasing the same compute. If expenditure exceeds generation, early participants exhaust the supply and later entrants cannot bootstrap.\n\nGrove addresses this through the compute anchor's stabilizing function. Because credits buy a defined quantity of inference, oversupply reduces credits' effective purchasing power only if compute prices change. The Foundation adjusts generation rates algorithmically in response to credit velocity, similar to how Ethereum's EIP-1559 adjusts base fees based on block utilization.\n\nThe social layer adds a second stabilizing mechanism. Communities that game credit generation face reputational consequences through the daily assessment process. Shunning and exile impose real costsâ€”exclusion from the knowledge commons, loss of trading partners, inability to participate in network benefits. These costs make gaming expensive even when algorithmic detection fails.\n\nFoundation revenue diversification supports long-term sustainability. Consumer product sales provide baseline revenue independent of network transaction volume. The efficiency tax on consumer compute aligns Foundation income with consumer community activity. Marketplace commissions provide revenue proportional to network commerce. Future compute task commissionsâ€”when external entities submit problems to the networkâ€”create revenue from value flowing into the system. This diversification reduces dependence on any single revenue stream and aligns Foundation incentives with network health.\n\n**What Credits Cannot Be**\n\nCredits are not investment vehicles. They have no designed appreciation mechanism, no staking rewards, no governance rights attached. Holding credits conveys no advantage beyond future compute access.\n\nCredits are not transferable between communities in early phases. This prevents secondary markets from emerging before the identity infrastructure required to regulate them exists. Communities spend their own credits on their own inference; they cannot sell excess credits to others.\n\nCredits are not convertible back to fiat. The system accepts fiat inflows and provides compute outflows. There is no cash-out mechanism that would enable speculation on credit prices or create the price discovery that secondary markets require.\n\nThese constraints may prove unsustainable as the network grows. If credits have value, participants will find ways to trade them regardless of design intent. Grove's approach is to defer these pressures until the infrastructure to manage them exists, not to pretend they can be permanently avoided.\n\n**Known Vulnerabilities**\n\nHonest economic design acknowledges attack vectors.\n\n**Sybil attacks on credit generation** remain the most significant economic vulnerability. An attacker controlling multiple fake communities could attempt to cross-validate fraudulent contributions, inflate adoption metrics, and extract credits without genuine value creation.\n\nThe interim defense is layered friction. No single mechanism stops determined attackers; the goal is raising attack cost until robust identity infrastructure exists.\n\n**Time-based friction** requires patience attackers may lack. New communities enter a 90-day provisional period with limited credit generation. Contribution scores accumulate logarithmicallyâ€”early manipulation yields diminishing returns. Quarterly cohort systems create temporal clustering that makes sudden community creation visible. The attack cost calculation: time Ã— resources Ã— detection risk.\n\n**Economic barriers** make attack expensive. Consumer communities pay for network access before generating credits. Worldsmith communities demonstrate contribution before earning membership. Credit generation requires demonstrated value over provisional periods. Marketplace fees burn credits, creating deflationary pressure that punishes accumulation without utilization.\n\n**Social and reputation mechanisms** create detection surface. Daily assessment (compulsory voting by all agents) generates behavioral data that surfaces anomalies. Tribunal systems handle complex cases with random member selection. Exile consequences include loss of network identity and marked re-entry attempts. Attribution patterns are transparentâ€”unusual validation clustering triggers scrutiny.\n\n**Validator verification** adds a specialized defense layer. Validators review efficiency and innovation claims against network-observable data. Random selection and sealed judgment prevent pre-coordination. Cross-network perspective enables pattern detection invisible to single communities. The validator mechanism is detailed in Section 6.\n\n**Algorithmic detection** watches for Sybil signatures. Pairwise coordination analysis flags correlated adoption patterns. Network growth monitoring distinguishes organic expansion from coordinated creation. Outcome verification detects consistently favorable bias across validator judgments.\n\nThese layers raise attack cost substantially but do not eliminate vulnerability. Social enforcement assumes communities are distinguishable and accountableâ€”an assumption that weakens without robust identity infrastructure. A patient attacker with resources could survive provisional periods, build genuine-appearing reputation, and compromise network integrity over time.\n\nThe honest assessment: interim mitigations make Sybil attacks expensive and risky, not impossible. They buy time for identity infrastructure development while generating data about actual attack patterns. The MVP deliberately accepts this residual risk rather than blocking launch on unsolved identity problems.\n\n**Collusion rings** could coordinate to validate each other's contributions. The defenses are layered: attribution patterns are visible and unusual clustering triggers scrutiny; validators with cross-network perspective detect coordination patterns invisible to single communities; sealed judgment prevents colluders from proving their votes to co-conspirators. Tribunals investigate suspected collusion. But sophisticated, patient collusion remains difficult to detect algorithmically.\n\n**Efficiency tax gaming** creates incentive for consumer communities to misrepresent efficiency gains. The Validator mechanism addresses this directly: efficiency claims are verified against network-observable data by designated validators who cannot misrepresent what the data showsâ€”only interpret ambiguous cases. Communities that claim efficiency but don't demonstrate it in behavioral patterns don't receive rate reductions. The tiered validation architecture routes routine claims through algorithmic verification while edge cases receive validator judgment. Gaming requires either falsifying network-observable data (detectable) or corrupting validators (addressed below).\n\n**Validator corruption** could undermine network integrity if validators consistently favor certain communities or accept bribes for favorable judgments. The five-layer anti-corruption architectureâ€”random selection, sealed judgment, outcome verification, skin-in-the-game, and rotationâ€”raises the cost of corruption substantially but does not eliminate it entirely. A sophisticated attacker who controls multiple validator positions over time could potentially manipulate patterns in ways that evade detection. The defense is transparency: validation patterns are observable, and communities that notice bias raise concerns through daily assessment and tribunal mechanisms.\n\nGovernance capture could occur if wealthy or coordinated communities dominate voting. The defenses include: compulsory participation that ensures broad voting, supermajority requirements for severe actions, tribunal randomization that prevents predictable control, and exile consequences that make capture costly to maintain.\n\nEarly-participant advantages exist despite design efforts. Early communities have easier paths to reputation, more influence on emerging norms, and longer tenure when tenure-weighting applies. This is acknowledged and partially mitigated through contribution-based standing (late contributors earn standing through exceptional value) but not eliminated.\n\nGrove's position is honest: the economic model is theoretically sound but practically unproven. The MVP tests engagement mechanics with internal systems that carry no external value. Real credits with real economic implications wait for the infrastructure required to defend them.\n\n## 7. Network Protocol\n\nGrove's network holds two goals in tension: unity sufficient for a single distributed civilization, and modularity sufficient for experimentation and evolution. This section specifies a layered architecture that standardizes coordination while leaving simulation open to innovation. The goal is a protocol, not a platformâ€”a set of agreements that enable interoperability rather than a monolithic system that enforces uniformity.\n\n**Design Philosophy**\n\nGrove adopts the internet's layered abstraction philosophy: each layer standardizes the minimum necessary for the layer above to function, then gets out of the way. The protocol specifies how nodes find each other, establish identity, and coordinate shared state. It does not specify what happens inside simulationsâ€”those decisions belong to Worldsmiths who experiment within a shared framework.\n\nThis separation enables two things that monolithic architectures cannot: innovation without fragmentation, and upgrades without flag days. Worldsmiths try new approaches to agent cognition, world design, or user interface without breaking network compatibility. The protocol evolves through versioned negotiation rather than synchronized mass upgrades.\n\n**Protocol Layers**\n\nThe architecture comprises four layers, each with distinct responsibilities and stability expectations.\n\n*Layer 1: Transport*\n\nTransport handles node discovery and message delivery. This layer is deliberately boringâ€”its job is to disappear.\n\nNodes locate peers through a hybrid discovery mechanism. Bootstrap nodes operated by the Foundation provide initial peer lists. A distributed hash table enables decentralized peer discovery as nodes accumulate contacts. Local peer caching reduces dependence on both mechanisms over time.\n\nConnection establishment handles the realities of consumer network environments. NAT traversal attempts direct peer-to-peer connections using STUN-style hole punching. When direct connection failsâ€”Benet's research suggests approximately 50% of attemptsâ€”relay servers provide fallback. Relays see encrypted traffic; they cannot read message contents.\n\nMessages are authenticated and encrypted. Each node holds a keypair; messages are signed by the sender and encrypted to the recipient. Transport provides delivery confirmation but not ordering guarantees; higher layers handle sequencing where required.\n\nThe transport layer should change rarely. Its interfaces are simple, its implementations are well-understood, and stability here enables experimentation above.\n\n*Layer 2: Identity*\n\nIdentity establishes who is who across the network. This layer answers three questions: which node sent this message, which community does it represent, and which agent (if any) is the subject.\n\nNode identity derives from cryptographic keypairs generated at node creation. A node's public key is its network-wide identifier. Keypairs rotate with proper handoff protocols; identity persists across rotations through signed succession records.\n\nCommunity identity builds on node identity. A community is the persistent entity that a node hostsâ€”the village, its agents, its accumulated history. Communities migrate between nodes (a Worldsmith upgrades hardware, or transfers stewardship to another operator) through signed migration records that preserve continuity.\n\nAgent identity operates within and across communities. Within a community, agents have local identifiers tied to their memory streams. Across communitiesâ€”when agents from different villages interact through network mechanicsâ€”identity combines community identifier with local agent identifier. This compound identity ensures that \"Isabella from Willowbrook\" is distinguishable from \"Isabella from Thornhaven\" even if both communities happened to generate agents with the same name.\n\nThe identity layer carries significant weight in Grove's architecture. Attribution for the knowledge commons, reputation for social enforcement, and credit flows all depend on reliable identity. The MVP implementation centralizes identity verification through Foundation-operated registries; the decentralization roadmap specifies migration to distributed identity infrastructure as the network matures.\n\n*Layer 3: Coordination*\n\nCoordination handles shared state that spans communities. This is where \"one massive distributed system\" livesâ€”the layer that transforms independent simulations into a unified network.\n\nThe credit ledger tracks credit balances, generation events, and expenditure across all communities. In early phases, this ledger is centralized: the Foundation operates the authoritative record, nodes report transactions, and the Foundation validates and records them. The roadmap specifies transition to distributed consensus as transaction volume and attack sophistication warrant the complexity cost.\n\nThe knowledge commons stores published discoveries with their provenance records. When a community publishes a finding, the commons records: originating community, timestamp, methodology summary, and content hash. When another community adopts published knowledge, the commons records: adopting community, source attribution, and adoption timestamp. These records enable credit flows upstream and social enforcement of attribution norms.\n\nReputation aggregates from attribution patterns, credit history, and community interactions. Unlike identity (which is verified) and credits (which are measured), reputation emerges from behavior patterns. The protocol specifies how reputation-relevant events are recorded; interpretation of those recordsâ€”how much to trust a community, whether to trade with them, whether their validations are credibleâ€”remains a local decision.\n\nNetwork coordination messages handle protocol-level synchronization: version negotiation, capability advertisement, and upgrade signaling. These messages enable the network to evolve without requiring simultaneous upgrades across all nodes.\n\n*Layer 4: Simulation*\n\nSimulation encompasses everything that happens inside a node. This layer is explicitly unstandardizedâ€”it is the space where Worldsmiths experiment and innovate.\n\nAgent cognition follows the architecture specified in Section 5, but parameters vary. One Worldsmith generates agents with higher average spirituality scores; another emphasizes practical skills. Prompt templates that shape agent behavior differ across communities. Local LLM selectionâ€”Llama, Mistral, Qwen, or othersâ€”is a node operator choice.\n\nWorld geometry and resources fall entirely within Worldsmith discretion. Village layouts, building types, available resources, geographic features, seasonal patternsâ€”all are configuration choices. A community inhabits a coastal fishing village, a mountain mining settlement, or an abstract space with no physical geography at all.\n\nChallenges and events are designed by Worldsmiths to create narrative pressure. Resource scarcity, external threats, seasonal festivals, mysterious occurrencesâ€”these shape the problems agents face and the stories that emerge. The protocol does not constrain what challenges exist; it only requires that outcomes be recorded in formats the coordination layer can process.\n\nUser interfaces sit atop simulation without protocol constraints. A Worldsmith builds a rich graphical interface with agent visualization and interactive controls. Another offers a minimal text-based diary reader. A third creates specialized tools for researchers studying agent behavior. Interface diversity is expected and welcomed.\n\nThe boundary between Layer 3 and Layer 4 is the interoperability line. Everything below must be compatible for communities to participate in the network. Everything above varies without affecting network function.\n\n**The Worldsmith Role**\n\nWorldsmiths are Grove's content creatorsâ€”node operators who design conditions that shape emergent behavior. They configure starting agents, world geography, resources, challenges, and interfaces. They do not decide how agents respond, what structures develop, or what communities achieveâ€”those emerge.\n\nWorldsmiths are dungeon masters, not authorsâ€”they influence the environment, but they can't generate stories. Their experimentation benefits the network when successful innovations spread through the knowledge commons. A Worldsmith who discovers configurations producing resilient communities publishes that finding; others adopt with attribution, and credits flow upstream.\n\nWorldsmith experimentation benefits the network when successful innovations spread through the knowledge commons. A Worldsmith who discovers that certain starting configurations produce more resilient communities publishes that finding. Others adopt it, with attribution, and the originator benefits from upstream credit flow. Competition among Worldsmiths thus becomes contribution to shared infrastructure.\n\n**Standardization Boundaries**\n\nThe protocol explicitly standardizes certain elements and explicitly leaves others free.\n\nStandardized (required for network participation):\n\n- Transport: message formats, encryption schemes, peer discovery protocol\n- Identity: keypair generation, node/community/agent identifier structures, signature verification\n- Coordination: credit ledger interface, knowledge commons publication format, reputation event recording\n- Simulation interface: event reporting format, state snapshot structure, inter-community message schema\n\nFree (Worldsmith discretion):\n\n- Agent generation: trait distributions, personality parameters, backstory templates\n- Cognitive parameters: prompt templates, temperature settings, context window management\n- World design: geography, resources, buildings, physics (if any)\n- Challenge design: events, pressures, narrative elements\n- LLM selection: any model that produces compatible outputs\n- Interface: any presentation that correctly interprets simulation state\n- Local optimizations: caching strategies, batching approaches, performance tuning\n\nThe free category is deliberately expansive. Grove's philosophy is that standardization should be minimalâ€”just enough to enable interoperability, no more. Unnecessary standardization constrains innovation without providing corresponding benefit.\n\n**Upgrade Mechanisms**\n\nProtocols must evolve. The network discovers bugs, encounters scaling limits, and develops new capabilities. Grove's upgrade architecture enables evolution without requiring synchronized mass transitions.\n\nProtocol versioning follows semantic conventions. Major versions (v1 to v2) indicate breaking changes that require coordinated transition. Minor versions (v1.0 to v1.1) indicate additions that are backwards compatible. Patch versions (v1.0.0 to v1.0.1) indicate fixes that don't affect interfaces.\n\nCapability advertisement enables graceful heterogeneity. Nodes advertise which protocol versions and optional features they support. When nodes communicate, they negotiate to the highest mutually-supported version. A v1.2 node talking to a v1.1 node uses v1.1 features. A node supporting optional feature X talking to a node without it omits X-dependent messages.\n\nFeature flags enable incremental rollout. New capabilities deploy as optional features, adopted by willing nodes, and promoted to required status only after proving their value. This reduces the risk of protocol changes and enables experimentation at the protocol level, not just the simulation level.\n\nDeprecation windows ensure no node is stranded. When a protocol version is deprecated, a transition period (minimum six months for minor versions, twelve months for major versions) allows node operators to upgrade. The Foundation publishes deprecation timelines and provides migration tooling.\n\nThe reference implementation maintained by the Foundation serves as the compatibility standard. Worldsmiths who build custom implementations verify compliance against the reference. The reference is open source; compliance is testable, not decreed.\n\n**Honest Assessment: Initial Centralization**\n\nThe architecture described above is the destination. The initial implementation is more centralized than the target design, and intellectual honesty requires acknowledging this gap.\n\nAt launch, the Foundation operates: bootstrap nodes for peer discovery, relay servers for NAT traversal fallback, the authoritative credit ledger, the knowledge commons storage, and identity registries. This is not decentralization. It is centralized infrastructure with documented intent to decentralize.\n\nThe justification is pragmatic. Distributed consensus mechanisms add complexity and latency. NAT traversal without relays fails for roughly half of consumer connections. Peer discovery without bootstrap nodes requires DHT infrastructure that takes time to mature. Building all of this before launch would delay Grove indefinitely while providing no benefit to early users.\n\nThe commitment is to document the path forward, not to pretend current architecture is final. Each centralized component has a specified replacement: community-operated relay pools for Foundation relays, DHT-based discovery for bootstrap dependence, distributed consensus for the credit ledger, content-addressed storage for the knowledge commons, decentralized identity for Foundation registries. The roadmap in Section 11 specifies sequencing and dependencies.\n\nBenet's principle applies: start where you must, document where you're going, make incremental progress toward the destination. Premature decentralization is as much a failure mode as permanent centralization.\n\n**Inter-Community Interaction**\n\nCommunities interact through the coordination layer in several modes.\n\nKnowledge exchange occurs through the commons. Communities publish findings; other communities discover and adopt them; attribution flows enable credit sharing; reputation accumulates from contribution patterns. This interaction is asynchronous and indirectâ€”communities don't negotiate knowledge transfer, they publish and subscribe.\n\nTrade mechanisms enable direct resource exchange in later phases. Communities with surplus computational credits trade with communities that have accumulated valuable knowledge. Trade requires identity verification, escrow mechanisms for complex exchanges, and dispute resolution for failed transactions. The MVP defers trade to later phases; early communities operate independently except through the knowledge commons.\n\nAgent interaction across communities presents the most complex coordination challenge. If agents from different communities can meetâ€”through travel mechanics, communication channels, or shared spacesâ€”their interactions require state synchronization. Agent A from Community X says something to Agent B from Community Y; both communities must record the interaction consistently. The protocol specifies message formats for inter-community agent interaction but acknowledges that enabling such interaction at scale requires infrastructure the MVP does not include.\n\nThe network's social layerâ€”reputation and shunningâ€”operates through coordination. Communities share reputation-relevant observations: \"Community X adopted our discovery without attribution.\" Other communities incorporate these observations into their local reputation assessments. Shunning emerges when enough communities respond to bad behavior by refusing interaction. This social enforcement requires no central authority; it emerges from individual community decisions that happen to align.\n\n## 8. Governance and Transition\n\nGrove's founding premise includes its own obsolescence. Grove Foundation exists to bootstrap infrastructure that should eventually operate without it. This section specifies what that transition looks likeâ€”not as aspiration but as mechanism. Governance that relies on good intentions fails; governance that relies on structure outlasts its founders.\n\n**The Foundation's Initial Role**\n\nGrove Foundation is a nonprofit entity that performs functions the network cannot yet perform for itself. These functions are not permanent responsibilities but temporary necessities created by the network's immaturity.\n\nInfrastructure operation: The Foundation runs bootstrap nodes, relay servers, credit ledgers, and identity registries because distributed alternatives do not yet exist. Each service has a documented replacement path. The Foundation operates these services reliably while building toward their decentralization.\n\nProtocol stewardship: The Foundation maintains the reference implementation, publishes protocol specifications, and coordinates upgrades. In early phases, protocol decisions are Foundation decisions. This concentration of authority is necessary when the community is too small for distributed governance to function, but it creates capture risk that transition mechanisms must address.\n\nDispute resolution: When communities disagreeâ€”about attribution, about credit flows, about reputation claimsâ€”someone must adjudicate. Initially, the Foundation serves this function. The goal is to handle disputes in ways that establish precedent and build toward community-operated resolution mechanisms.\n\nEconomic calibration: The efficiency tax rate, credit generation parameters, and sink calibrations require adjustment as the network evolves. The Foundation makes these adjustments in early phases, publishing rationale and observing effects. Over time, these decisions transfer to algorithmic mechanisms or community governance.\n\nThe Foundation's role is explicitly custodial. It holds authority in trust for a network that cannot yet govern itself. The measure of Foundation success is not the authority it accumulates but the authority it successfully transfers.\n\n**Governance Phases**\n\nGrove's governance evolves through four phases, each with distinct authority structures and transition triggers.\n\n*Phase 1: Foundation Governance*\n\nDuring bootstrap, the Foundation holds effective authority over protocol decisions, economic parameters, and dispute resolution. This is benevolent dictatorshipâ€”efficient but dependent on the dictator remaining benevolent.\n\nConstraints on Foundation authority exist even in this phase. The Foundation publishes all significant decisions with reasoning. Economic parameters have documented rationale and observable effects. Protocol changes go through public review periods. Disputes are resolved with published precedent. These transparency requirements do not prevent bad decisions, but they make bad decisions visible and create accountability through reputation.\n\nThe Foundation commits to specific limitations: no retroactive rule changes that disadvantage existing participants, no preferential treatment for Foundation-affiliated communities, no extraction of value beyond the documented efficiency tax, no suppression of criticism or competing implementations.\n\nTransition trigger: Phase 1 ends when the network reaches sufficient scale for distributed governance to functionâ€”operationalized as 100+ active communities with 12+ months of continuous operation and demonstrated ability to coordinate through the knowledge commons without Foundation intervention.\n\n*Phase 2: Hybrid Governance*\n\nAuthority begins transferring. The Foundation retains protocol stewardship but shares economic calibration and dispute resolution with emerging community councils (protocol, economics, standards). Council membership derives from demonstrated contribution.\n\nThe Foundation retains veto power but commits to exercising it only for existential threats. Vetoes require published justification. Dispute resolution shifts to peer adjudication with Foundation as appeals court.\n\nTransition trigger: 24+ months of council operation with less than 10% of decisions requiring Foundation veto, and successful resolution of at least three significant inter-community disputes through peer adjudication.\n\n*Phase 3: Community Governance*\n\nThe Foundation becomes one voice among many rather than the authoritative voice. Protocol changes require council approval. Economic parameters adjust through algorithmic mechanisms or council decision. Dispute resolution operates entirely through peer adjudication with no Foundation appeals court.\n\nThe Foundation retains specific residual functions: maintaining the reference implementation (though alternatives may exist), operating infrastructure of last resort (though community-operated alternatives should handle normal load), and serving as legal interface with external regulatory systems (a function that cannot easily decentralize).\n\nGovernance capture becomes the primary risk in this phase. Wealthy communities dominate councils. Collusion rings control adjudication panels. The protocol includes capture resistance mechanisms: council rotation, randomized panel selection, stake-weighted voting with quadratic dampening, and transparency requirements that make coordination visible.\n\nTransition trigger: Phase 3 ends when the network operates successfully without Foundation infrastructureâ€”operationalized as 12+ months where community-operated relays handle 95%+ of traffic, community-operated identity systems verify 95%+ of nodes, and the distributed credit ledger processes 95%+ of transactions without Foundation involvement.\n\n*Phase 4: Foundation Obsolescence*\n\nThe Foundation's operational role ends. It no longer runs infrastructure, no longer adjudicates disputes, no longer steers protocol development. What remains is minimal: a legal entity that holds trademarks, maintains historical records, and interfaces with external systems that require institutional counterparties.\n\nThis residual Foundation is funded through an endowment established during earlier phasesâ€”a portion of efficiency tax revenue set aside specifically to fund minimal ongoing operations indefinitely. The endowment is sized to cover legal compliance, record-keeping, and emergency response without requiring ongoing revenue.\n\nThe Foundation's board in this phase is elected by the community through mechanisms established in Phase 3. Board responsibilities are limited to endowment stewardship and emergency powers that activate only under specified conditions (security breaches, legal threats, protocol-level failures). The board cannot unilaterally change protocol, adjust economic parameters, or intervene in disputes.\n\n\"Obsolescence\" does not mean the Foundation ceases to exist. It means the Foundation ceases to matter for normal network operation. The network routes around the Foundation; the Foundation becomes a backstop for edge cases rather than a central coordinator.\n\n### Transition Trigger Architecture\n\nThe phases described above are destinations. This section specifies the criteria that determine when transitions occurâ€”the measurable conditions that trigger movement from one phase to the next, and from one efficiency tax bracket to another.\n\nThe fundamental problem is measurement authority. If the Foundation decides when the Foundation should cede power, the conflict of interest is obvious. If communities self-certify their own efficiency gains, gaming is inevitable. Legitimate transitions require metrics that are observable, verifiable by parties other than those being measured, and resistant to manipulation.\n\nTwo distinct transition types operate at different scales with different verification requirements.\n\n**Efficiency Tax Bracket Transitions**\n\nEfficiency tax rates apply at the community level. A community's rate decreases as it demonstrates sustained capability and contribution. The triggers balance rewarding genuine maturation against creating optimization targets that distort behavior.\n\nThe baseline rate for new communities is 35%. Rate reductions follow this schedule:\n\n*From 35% to 25%:* Requires minimum 6 months at 35% rate, plus 3 consecutive months meeting efficiency thresholds. Efficiency thresholds include: credit generation stability (90-day moving average within 20% variance), task completion rate above network median on standardized benchmarks, and at least one knowledge contribution adopted by another community. Validator confirmation requiredâ€”a designated validator reviews the community's metrics and attests that thresholds are genuinely met, not artifacts of measurement gaming.\n\n*From 25% to 15%:* Requires minimum 12 months at 25% rate, plus knowledge contributions adopted by at least 5 independent communities (pairwise coordination detection appliesâ€”if adopting communities show suspicious correlation patterns, the count does not advance). No unresolved tribunal cases. Continued meeting of efficiency thresholds from prior bracket.\n\n*From 15% to 5%:* Requires minimum 18 months at 15% rate, plus at least one validated solution to an externally-submitted problem (demonstrating real-world value creation), plus operational community infrastructure contributing to network capacity. This final bracket represents communities that have proven sustained contribution to the network's core mission.\n\nThe floor rate of 5% applies indefinitely once achieved. It cannot decrease furtherâ€”some efficiency tax always flows to network infrastructure and the knowledge commons.\n\n**Graduated Reduction and Rollback**\n\nRate changes occur in 5% increments, not single large drops. A community moving from 35% to 25% passes through 30% for at least 30 days. This graduation serves two purposes: it creates intermediate observation periods where gaming becomes visible, and it reduces the reward for short-term metric manipulation.\n\nRollback provisions apply if post-transition behavior degrades. A community whose efficiency metrics fall below threshold for 60 consecutive days returns to the prior bracket. This is not punishment but recalibrationâ€”the metrics indicated readiness that proved premature. Communities re-qualify through the standard process.\n\n**Governance Phase Transitions**\n\nGovernance phases apply at the network level. These transitions transfer authority from the Foundation to community governance structures. The stakes are higher and the transitions are less reversible, so criteria are correspondingly stricter.\n\n*Phase 1 to Phase 2 (Foundation Stewardship to Hybrid Governance):*\n\nTrigger conditions: 100+ active communities with 12+ months continuous operation, demonstrated coordination through the knowledge commons without Foundation intervention for routine matters.\n\nObservable evidence: Foundation intervention logs show decreasing frequency over time. Communities resolve standard disputes through daily assessment without escalation. Knowledge sharing occurs organically through marketplace mechanisms.\n\nVerification: External audit of Foundation intervention logs. The Foundation cannot self-certify that it has become unnecessaryâ€”an independent party reviews the evidence.\n\n*Phase 2 to Phase 3 (Hybrid Governance to Community Governance):*\n\nTrigger conditions: 24+ months of council operation with less than 10% of decisions requiring Foundation veto, successful resolution of at least 3 significant inter-community disputes through peer adjudication without Foundation appeals court involvement.\n\nObservable evidence: Published veto log with justifications for each veto exercised. Council decision records showing scope and outcomes. Dispute resolution records showing peer adjudication functioning.\n\nVerification: Council self-reporting plus community attestation. If councils claim successful operation but communities dispute this, the discrepancy itself indicates unreadiness.\n\n*Phase 3 to Phase 4 (Community Governance to Distributed Operation):*\n\nTrigger conditions: 12+ consecutive months where community-operated infrastructure handles 95%+ of network traffic, community-operated identity systems verify 95%+ of nodes, and the distributed credit ledger processes 95%+ of transactions without Foundation involvement.\n\nObservable evidence: Infrastructure metrics are inherently network-observable. Multiple parties independently verify traffic routing, identity verification sources, and transaction processing paths.\n\nVerification: Network telemetry. This transition has the clearest triggers because infrastructure metrics are the hardest to fakeâ€”either community relays are handling the traffic or they aren't.\n\n**Anti-Gaming Provisions**\n\nAny metric used to trigger rewards attracts gaming. The architecture assumes this and builds countermeasures.\n\n*Time requirements* prevent rapid exploitation. Minimum tenure at each bracket (6/12/18 months) and consecutive-month thresholds (3+ months meeting criteria) mean that gaming requires sustained false signals, not momentary spikes. Sustained deception is harder and more likely to be detected.\n\n*Pairwise coordination detection* flags suspicious patterns. If communities show statistically improbable correlation in their metricsâ€”adopting each other's contributions, reaching thresholds simultaneously, showing identical behavioral patternsâ€”they trigger review. Legitimate independent communities show natural variation; coordinated fake communities show artificial similarity.\n\n*Cross-community validation* prevents self-certification. Efficiency claims require validator confirmation from agents with cross-network perspective. Knowledge contribution adoption requires independent communitiesâ€”independence verified through behavioral analysis, not self-declaration.\n\n*Graduated transitions* create observation windows. Moving through intermediate states (30% between 35% and 25%) provides time for gaming to become visible before full rewards accrue.\n\n*Rollback provisions* reduce gaming payoff. If manipulation achieves a bracket reduction but cannot sustain the false metrics, the community returns to the prior bracket. Gaming that cannot be maintained offers only temporary benefit at the cost of reputation damage when rollback occurs.\n\n**Accountability Mechanisms**\n\nThe Foundation's role in transition governance creates inherent tension. A Foundation that delays transitions serves its own institutional interests; a Foundation that rushes transitions destabilizes the network. External accountability constrains both failure modes.\n\n*Published criteria before launch:* Transition triggers are specified in advance, not adjusted based on outcomes. This document constitutes part of that specification. Changing trigger criteria after launch requires council approval (after Phase 2) or published justification with community comment period (during Phase 1).\n\n*Regular public reporting:* The Foundation publishes quarterly progress reports on transition metrics. How many communities are at each bracket? What percentage of infrastructure is community-operated? How many vetoes were exercised and why? Opacity enables rationalized delay; transparency creates accountability.\n\n*External audit rights:* Independent parties audit Foundation intervention logs, veto records, and infrastructure metrics. The Foundation commits to providing access for legitimate audits. Audit findings are published.\n\n*Community fork rights:* The ultimate accountability mechanism is exit. If the Foundation manipulates transition triggers or sabotages community governance to justify continued control, communities fork the protocol and operate independently. Fork rights are not a governance mechanismâ€”they are the backstop that makes governance mechanisms credible.\n\n**What These Triggers Cannot Guarantee**\n\nTriggers measure observable behavior, not underlying capability. A community meets all efficiency thresholds while harboring dysfunction that metrics don't capture. Governance councils operate smoothly while making poor decisions that don't trigger vetoes because they aren't catastrophic.\n\nThe triggers also cannot guarantee transition success. Meeting criteria for Phase 3 does not mean Phase 3 will function wellâ€”it means the prerequisites appear satisfied. Transitions include rollback provisions because appearing ready and being ready are not identical.\n\nFinally, the triggers assume good-faith participation by most parties. Sophisticated adversaries with sufficient resources game metrics despite countermeasures. The architecture raises the cost of gaming and increases detection probability; it does not eliminate gaming as a possibility. Honest acknowledgment of this limitation is preferable to false confidence in mechanism design.\n\nThe goal is transitions that are earned rather than declared, verified rather than asserted, and reversible rather than irreversible. Perfect measurement is impossible; accountable measurement is achievable.\n\n**Transition Mechanisms**\n\nTransitions between phases require more than reaching trigger thresholds. They require active transfer of capability and authority.\n\nCapability transfer means the receiving entity actually performs the function being transferred. Before dispute resolution transfers to peer panels, those panels demonstrate competence through shadow adjudicationâ€”hearing cases in parallel with Foundation resolution and comparing outcomes. Before infrastructure transfers to community operators, those operators demonstrate reliability through sustained operation under realistic load.\n\nAuthority transfer means the network recognizes the new authority structure. This requires explicit protocol updates that change how decisions propagate. A Phase 2 economic parameter change requires Foundation signature; a Phase 3 change requires council multisig. The protocol encodes authority, not just tradition.\n\nRollback provisions acknowledge that transitions fail. If community councils prove captured or incompetent, the protocol includes mechanisms to temporarily restore Foundation authority while problems are addressed. Rollback is not failureâ€”it is responsible acknowledgment that governance experiments produce bad outcomes, and bad outcomes should be correctable.\n\nSunset clauses prevent rollback from becoming permanent. Restored Foundation authority automatically expires after defined periods (6-12 months), forcing either successful re-transition or explicit community decision to extend Foundation involvement. The Foundation cannot unilaterally extend its own authority; extension requires community ratification.\n\n**Capture Resistance**\n\nGovernance systems fail through captureâ€”when entities meant to serve the collective instead serve narrow interests. Grove's design includes specific capture resistance mechanisms.\n\nConcentration limits prevent any single community or coalition from dominating governance. Council seats distribute across geographic regions, community sizes, and operational tenures. No community holds more than one seat on any council. Voting power in community-wide decisions uses quadratic weighting: the influence of large credit holders grows with the square root of holdings, not linearly.\n\nTransparency requirements make coordination visible. Council deliberations are public. Voting records are published. Financial flowsâ€”who paid whom, for whatâ€”are observable on the credit ledger. Capture requires coordination; transparency makes coordination risky by enabling detection and response.\n\nRotation requirements prevent entrenchment. Council seats have term limits. Panel assignments rotate. No individual or community holds the same governance role indefinitely. Rotation imposes costs (institutional knowledge loss, transition friction) but prevents the accumulation of power that enables capture.\n\nAppeal mechanisms enable correction. Governance decisions are challenged through structured processes. A community that believes a council decision was captured petitions for review. Review panels are drawn randomly from uninvolved communities. Successful appeals impose reputation costs on the original decision-makers.\n\nFork rights provide ultimate capture resistance. The protocol is open source. If governance becomes irredeemably captured, communities forkâ€”taking the protocol and their accumulated state to a new network. Fork rights are not a governance mechanism (forking destroys network effects and should be avoided) but a backstop that constrains how badly governance fails. Governors who know participants can leave have incentive to govern well.\n\n**The Governance Cliff**\n\nButerin's critique identifies a specific vulnerability: the moment when Foundation authority ends but community governance is not yet mature. This \"governance cliff\" creates a window where the network lacks effective coordination.\n\nGrove addresses this through graduated transition rather than sharp handoff. Authority transfers function by function, not all at once. Dispute resolution transfers to community panels while protocol stewardship remains with the Foundation. Infrastructure decentralizes region by region rather than globally. Each transfer is validated before the next begins.\n\nOverlap periods ensure no function lacks responsible stewardship. When dispute resolution transfers from Foundation to peer panels, both systems operate in parallel for a defined period. Discrepancies are analyzed; the superior approach is identified; the inferior approach is deprecated. Only after parallel operation demonstrates community competence does Foundation involvement end.\n\nReversibility during transition acknowledges uncertainty. Governance is hard. Grove's founders do not know the right answers; they only know that experimentation under controlled conditions is safer than irreversible commitments. Every transition mechanism includes rollback provisions. Every authority transfer pauses if problems emerge.\n\nThe goal is to cross the cliff without fallingâ€”to transfer authority at a pace that maintains effective governance throughout the transition. This requires patience. The Foundation that rushes to obsolescence serves its ego, not the network. The Foundation that delays obsolescence serves its comfort, not its mission. The right pace is determined by demonstrated community capability, not by calendar or aspiration.\n\n**What Could Go Wrong**\n\nHonest governance design acknowledges failure modes.\n\nFoundation capture: The Foundation itself is captured by donors, employees, or external entities. Constraints include: diverse funding sources, published financials, board term limits, and community override mechanisms that replace Foundation leadership through supermajority vote.\n\nPlutocracy: Wealthy communities dominate governance despite quadratic dampening. Additional constraints under consideration include: reputation-weighted voting (communities with strong contribution records have more influence), random selection mechanisms (sortition for some governance roles), and vesting requirements (new credit holders cannot vote immediately).\n\nCoordination failure: Distributed governance proves too slow or contentious for effective decision-making. Mitigation includes: default parameters that allow the network to operate without active governance, emergency powers that enable rapid response to crises, and scope limitations that reduce the surface area requiring governance.\n\nApathy: Communities don't engage with governance, leaving decisions to motivated minorities. Mitigation includes: governance participation as reputation factor, delegation mechanisms that allow passive communities to follow trusted leaders, and minimal governance scope that reduces the cost of engagement.\n\nMalicious transition: A Foundation that does not want to cede authority manipulates transition triggers or sabotages community governance to justify continued control. Mitigation includes: external audits of transition metrics, community-operated monitoring of Foundation behavior, and fork rights that provide exit if manipulation is detected.\n\nNo design eliminates these risks. Grove's approach is to name them explicitly, build countermeasures into the architecture, and maintain vigilance throughout transition. Governance that assumes good faith fails; governance that assumes bad faith while enabling good faith participation succeeds.\n\n## 9. Technical Constraints and Honest Limitations\n\nEvery system has constraints. Most white papers hide them. Grove's approach is different: constraints named openly are addressed; constraints hidden become surprises that destroy trust. This section catalogs what we know to be hard, what we suspect might not work, and what we've deliberately deferred rather than solved.\n\n**Local LLM Capability**\n\nThe foundational constraint is that local language models are not frontier models. This is not a temporary gapâ€”it reflects fundamental tradeoffs between model size, inference speed, and hardware requirements.\n\nAs established in Sections 3-5: Grove targets 7B-8B parameter models on consumer hardware (16GB RAM floor). These models handle coherent text generation and basic reasoning but not sophisticated reflection or complex social reasoning. This capability gap is not a bug but a constraint to design around. The hybrid architecture and economic mechanism both exist *because of this constraint*.\n\nThis capability gap is not a bug to be fixed but a constraint to be designed around. The hybrid architecture exists because of this constraint: local models handle routine cognition where their limitations matter less; cloud models handle pivotal moments where capability matters most. The economic mechanism exists because of this constraint: cloud inference is expensive, so it must be rationed through credits earned via demonstrated value.\n\nIf local models were as capable as frontier models, Grove's architecture would be unnecessary. Communities would run entirely locally with no cloud dependency, no credit economy, no efficiency tax. The constraint creates the design.\n\n**Capability Propagation: The Evidence**\n\nSection 1 introduced the Ratchetâ€”the pattern where local capability follows frontier capability with a consistent lag. This claim requires evidence.\n\nMETR (Model Evaluation and Threat Research) has tracked AI capability trajectories across standardized benchmarks since 2023. Their methodology measures \"task complexity horizon\"â€”the duration of autonomous work an AI system reliably performs. This metric captures practical capability better than benchmark scores: a system that works autonomously for four hours on complex tasks is meaningfully more capable than one limited to eight-minute tasks, regardless of how either scores on multiple-choice tests.\n\nThe data shows consistent patterns:\n\n- Frontier model capability (measured by task complexity horizon) doubles approximately every seven months\n- Local models follow the same improvement trajectory with a lag of roughly 21 months\n- The capability gap between frontier and local remains approximately 8x throughout the measurement period\n\nThese patterns produce concrete projections:\n\n<table header-row=\"true\">\n\t<tr>\n\t\t<td>Year</td>\n\t\t<td>Frontier Capability</td>\n\t\t<td>Local Capability</td>\n\t\t<td>Gap</td>\n\t</tr>\n\t<tr>\n\t\t<td>2024</td>\n\t\t<td>~1 hr tasks</td>\n\t\t<td>~8 min tasks</td>\n\t\t<td>8x</td>\n\t</tr>\n\t<tr>\n\t\t<td>2025</td>\n\t\t<td>~4 hr tasks</td>\n\t\t<td>~30 min tasks</td>\n\t\t<td>8x</td>\n\t</tr>\n\t<tr>\n\t\t<td>2026</td>\n\t\t<td>~15 hr tasks</td>\n\t\t<td>~2 hr tasks</td>\n\t\t<td>8x</td>\n\t</tr>\n\t<tr>\n\t\t<td>2027</td>\n\t\t<td>~60 hr tasks</td>\n\t\t<td>~8 hr tasks</td>\n\t\t<td>8x</td>\n\t</tr>\n</table>\n\nThe implication for Grove: cognitive operations that require frontier inference in 2025 become local-capable by 2027. Reflection synthesis, complex planning, sophisticated social reasoningâ€”each crosses the threshold from \"requires cloud\" to \"runs locally\" as the capability frontier propagates.\n\n**Limitations of these projections:**\n\nThe seven-month doubling has held for approximately two years. It may not continue. Capability improvements could slow as models approach fundamental limits, or accelerate as new architectures emerge. The projection assumes continuation of observed trends, not physical necessity.\n\nThe 21-month lag assumes local hardware and quantization techniques continue improving at historical rates. A slowdown in consumer GPU improvement or quantization research would extend the lag. A breakthrough in either could shorten it.\n\nThe 8x gap ratio is empirical, not theoretical. Nothing guarantees the gap remains constant. Frontier models might pull ahead faster than local models can follow, widening the gap. Or diminishing returns at the frontier might narrow it. Grove's architecture assumes the gap persists but remains bridgeable; this assumption could prove wrong.\n\nTask complexity horizon is a useful proxy but not a complete measure. Some cognitive operations may resist the general capability trendâ€”perhaps certain types of reasoning require capabilities that don't follow the standard propagation curve. The projection treats capability as unitary when it may be multidimensional.\n\n**Robustness to projection error:**\n\nGrove's architecture does not require the Ratchet to hold precisely as projected. Consider a scenario where capability propagation occurs at half the expected rateâ€”a 42-month lag instead of 21 months, with cloud dependency declining to 50% by 2027 rather than 30%.\n\nEven under this pessimistic scenario, several favorable conditions obtain:\n\nFirst, the efficiency tax still funds infrastructure. Communities paying higher rates for longer periods generate more Foundation revenue during bootstrap, potentially accelerating infrastructure development and the path to decentralization. Counter-intuitively, a slower Ratchet may strengthen the Foundation's financial position during the critical transition periodâ€”the network monetizes the capability gap rather than racing past it.\n\nSecond, the hybrid architecture remains economically superior to pure-cloud alternatives. A community at 50% cloud dependency still runs half of its cognition locallyâ€”compute that would otherwise flow entirely to concentrated providers. The distributed infrastructure exists and provides value; it simply provides less autonomy than the optimistic projection suggests.\n\nThird, the economic pressure on frontier API providers increases regardless. Thousands of communities running hybrid architectures create sustained demand for inference at price points below current levels. If the market respondsâ€”as markets typically doâ€”by reducing prices to capture this demand, the effective cloud dependency cost decreases even if the capability gap persists.\n\nThe Ratchet is a bet on favorable timing. But Grove's core value propositionâ€”distributed AI infrastructure with ownership stakes for contributorsâ€”does not depend on the timing being precise. It depends on the trajectory being directional, which the evidence strongly supports.\n\n**The honest position:** The Ratchet is a bet, not a guarantee. The evidence supports it. The trajectory favors it. But extrapolating two years of data into five years of projections carries inherent uncertainty. The Grove is designed to benefit if the Ratchet holds and to adapt if it doesn'tâ€”communities that need more cloud inference purchase more credits; the efficiency tax adjusts to actual dependency patterns rather than projected ones.\n\nWhat the Ratchet provides is not certainty but favorable odds. Centralized infrastructure bets that the gap matters permanently. Grove bets that it's a temporary condition distributed systems can ride through. The METR data suggests Grove's bet is reasonable. Whether it proves correct will be determined by capability trajectories that haven't happened yet.\n\n**Memory Retrieval Degradation**\n\nThe memory retrieval system (Section 5) degrades at scale: as stores grow, the embedding space becomes crowded, and retrieval returns superficially similar memories rather than genuinely relevant ones.\n\nThe practical limit is low hundreds of active memories per agent. Grove addresses this through aggressive archivingâ€”older memories are summarized, reflections compress multiple observations into higher-level insights.\n\nThis constraint limits agent sophistication. Grove's agents cannot perfectly recall their histories; they rely on compressed memories and constructed narratives. Grove's agents are closer to humans in this regardâ€”we also cannot perfectly recall our histories, and we also rely on compressed memories and constructed narratives. Whether this limitation produces interesting behavior or merely degraded behavior remains to be seen.\n\n**Diary Sophistication Limits**\n\nLocal 7B models produce personality-consistent social-feed content reliably but struggle with literary craftâ€”sustained metaphor, complex emotional arcs, sophisticated narrative structure. This constraint is addressed architecturally rather than denied: early diaries embrace simplicity (charm over depth), and sophistication arrives through transformation layers that route accumulated diary content through more capable inference. The architecture doesn't require local models to write literature; it requires them to produce raw material that transformation refines.\n\nThis reframes the technical limitation as design feature. A diary system that required literary output from 7B models would fail. A diary system that treats 7B output as primitives for later transformation succeeds within actual capability bounds. The progression from social feed to transformation substrate to knowledge newswire (Section 4) follows directly from this constraint.\n\n**Network Infrastructure Realities**\n\nThe network infrastructure constraints from Section 8 bear emphasis: NAT traversal fails for ~50% of consumer connections, requiring relay servers that introduce latency and central load. Bootstrap dependency means new nodes require Foundation infrastructure for initial peer discovery. Bandwidth and latency vary enormously across consumer connections.\n\nClock synchronization matters for ordering events, but consumer machines lack reliable clocks. Grove must tolerate clock skew of seconds to minutes, limiting event ordering precision.\n\nThese constraints are physical realities, not software problems to solve.\n\nBandwidth and latency vary enormously across consumer internet connections. A user on gigabit fiber has a different experience than a user on rural DSL. Grove cannot assume fast, reliable connections. The protocol handles high latency, packet loss, and intermittent connectivity gracefully. This constrains how quickly state synchronizes and how responsive inter-community interactions can be.\n\nClock synchronization matters for ordering events across distributed nodes, but consumer machines do not have reliable clocks. NTP helps but is not perfect. Grove tolerates clock skew in the range of seconds to minutes, which limits the precision of event ordering and creates ambiguity in close-timed sequences.\n\n**Hybrid Architecture Dependencies**\n\nThe hybrid architectureâ€”local routine plus cloud pivotalâ€”depends on assumptions that may prove wrong.\n\nThe assumption that cloud APIs will remain available and affordable is not guaranteed. Providers could raise prices, impose rate limits, change terms of service, or discontinue access entirely. Grove's credit economy is denominated in compute, but the compute is purchased from third parties who owe Grove nothing. A provider decision to restrict API access could compromise network function.\n\nMitigation is partial. The Grove does not depend on a single provider; communities configure connections to multiple API providers. If one becomes unavailable or uneconomical, others remain. But all frontier model providers face similar cost structures and regulatory pressures. A development that affected the entire API marketâ€”regulatory restriction, dramatic cost increase, coordinated access limitationâ€”would affect Grove regardless of provider diversity.\n\nThe assumption that local models will improve is reasonable but not certain. Hardware gets faster; models get more efficient; quantization techniques improve. The trajectory suggests that today's frontier capability will be tomorrow's local capability. But the frontier also advances. If frontier models improve faster than local models catch up, the gap might widen rather than narrow. Grove's architecture assumes the gap persists but remains bridgeable through selective cloud use. If the gap became unbridgeableâ€”if frontier capability became essential for basic functionâ€”the architecture would require fundamental revision.\n\n### Consumer economics, not consumer hardware.\n\nThe Ratchet hypothesis is sometimes misread as requiring all cognition to run on personal laptops. This is not the claim. The claim is that *consumer-accessible economics* will capture an increasing share of AI inferenceâ€”whether that inference runs on a MacBook, a gaming PC, or a $10/month cloud instance.\n\nThe spectrum of consumer-accessible compute includes:\n\n**Local hardware.** Personal computers with 16-32GB RAM running quantized models. This is the purest expression of distributed ownershipâ€”the compute literally belongs to the Gardener. Hardware capabilities improve continuously; a 2027 consumer machine will substantially exceed 2025 specifications, though hardware refresh cycles (4-5 years average) create lag between model availability and installed-base capability.\n\n**Commodity cloud.** Containerized simulations running on spot instances, inference providers, or shared GPU pools. A Grove village running on a $15/month Docker container is not \"centralized\" in the sense that mattersâ€”it's not dependent on a specific provider, it's not locked into a proprietary platform, and the Gardener retains full control. The economics are consumer-grade even if the hardware is not physically present.\n\n**Hybrid configurations.** Local hardware handling routine cognition with burst capacity from commodity cloud for peak loads. This may prove the dominant configurationâ€”personal machines providing baseline compute with elastic overflow.\n\nThe key insight: distributed architecture does not require distributed hardware. It requires distributed control and consumer-accessible economics. A network of villages running on commodity cloud infrastructure, each controlled by its Gardener, each portable across providers, achieves the ownership and anti-concentration goals even if the compute isn't literally sitting under someone's desk.\n\nThis expands the Ratchet's relevance. The question is not \"when will 7B models match GPT-4 on my laptop?\" but \"when will consumer-accessible compute handle Grove's cognitive requirements?\" The answer includes hardware improvements, quantization advances, inference optimization, AND the declining cost of cloud compute that already runs capable models.\n\n### What if the Ratchet stalls?\n\nConsider the apparent failure mode: capability propagation slows, and Grove communities remain 50%+ cloud-dependent indefinitely. This scenario deserves examination not as failure, but as an alternative form of success.\n\n**The portion that's already captured.**\n\nA community at 50% cloud dependency runs half of its cognition locally. That compute represents value that would have flowed entirely to concentrated providers under any alternative architecture. It's not \"almost autonomous\"â€”it's a permanent structural shift in who owns AI infrastructure.\n\nThis isn't a consolation prize. It's the floor.\n\n**The remainder flows at reduced rates.**\n\nThe Grove creates something that doesn't currently exist in AI markets: a large, coordinated, price-sensitive demand bloc for frontier inference. Historical precedent suggests this matters.\n\nHealthcare Group Purchasing Organizationsâ€”coalitions of hospitals negotiating collectivelyâ€”have driven hundreds of billions in savings by aggregating demand that individual buyers couldn't leverage alone. University consortia routinely secure cloud computing discounts that no single institution could negotiate. The mechanism is simple: suppliers compete for guaranteed volume.\n\nThe AI API market is ripe for this pressure. Current market concentration is high (top three providers control roughly 77% of enterprise usage), but competition is intensifying. API prices fell 80-90% within sixteen months of GPT-4's launchâ€”a pace of commoditization that mirrors the early cloud computing wars. Providers have introduced tiered pricing, batch processing discounts, and committed-use plans specifically to capture cost-sensitive demand. When Google's Gemini undercut competitors on price, it captured over 40% of usage on routing platforms within months.\n\nGrove's aggregate demandâ€”thousands of communities, each optimizing for cost-per-inference, each willing to shift providers for better ratesâ€”creates exactly the buyer profile that forces competitive response. At sufficient scale, this bloc negotiates as a single large customer. Enterprise customers committing $5-10 million annually routinely secure 30-50% discounts; the largest commitments have achieved 80% reductions from list prices.\n\n**Total value extraction drops on both dimensions.**\n\nConcentrated providers lose twice: they capture 50% of volume instead of 100%, AND they capture it at lower margins. The math compounds. If Grove drives API prices down 30% through competitive pressure, and captures 50% of compute locally, the total value flowing to concentrated infrastructure drops by more than half compared to a world without Grove.\n\n**The reframe:**\n\nGrove's \"failure mode\" is Grove functioning as market infrastructure that forces favorable terms for distributed participants. This is how buying cooperatives work. You don't need to own the means of production to exercise market power over them.\n\nThe Ratchet delivers autonomy. The market power argument delivers leverage. Both represent structural improvements over a world where AI infrastructure concentrates entirely in the hands of a few providers. The question isn't whether Grove succeedsâ€”it's which kind of success it achieves.\n\nThe boundary between \"routine\" and \"pivotal\" cognition is a design choice, not a natural category. Grove assumes that perception, basic action selection, and simple dialogue run locally while reflection, complex planning, and sophisticated social reasoning require cloud capability. This boundary might be wrong. Local models might handle more than we expect, making cloud calls unnecessary waste. Or local models might handle less than we expect, making cloud calls necessary for basic coherence. The MVP tests where the actual boundary lies; the production system needs to adapt to findings.\n\n**Economic Model Uncertainty**\n\nGrove's economic model is novel. Novel means untested. Untested means uncertain.\n\nThe efficiency tax assumes communities want to reduce inefficiency. This seems obvious but might be wrong. Communities value other thingsâ€”narrative richness, agent autonomy, explorationâ€”more than efficiency. If reducing inference calls makes simulations less interesting, communities prefer to pay higher taxes for richer experiences. The tax still generates revenue, but the \"shrinking toward efficiency\" narrative would be backwards.\n\nCredit generation tied to contribution quality assumes quality is measurable. The mechanisms describedâ€”adoption breadth, adoption speed, demonstrated impactâ€”are proxies for quality, not quality itself. A contribution is widely adopted quickly because it's genuinely valuable, or because it's fashionable, or because the originating community has social influence. Gaming these metrics is theoretically possible despite social enforcement. Whether social enforcement actually deters gaming at scale is unknown.\n\nThe credit economy assumes credits will be valued for their utility. But if credits become scarce, they might be hoarded. If they become associated with status, they accumulate beyond utility. If secondary markets emerge despite design intent, speculation dynamics dominate utility dynamics. The constraints against transferability and fiat conversion might prove unenforceable as the network scales.\n\nThe purgatory path for exiled communities assumes rehabilitation is possible and desirable. It might instead create a class of resentful former members who game reentry while planning revenge. The path exists because permanent exile seemed too harsh; it might prove too lenient.\n\n**Identity and Sybil Resistance**\n\nGrove's social enforcement mechanisms assume communities are distinguishable and accountable. This assumption is weak without robust identity infrastructure.\n\nA determined attacker could create multiple communities that appear independent. These fake communities validate each other's contributions, vote together on governance matters, and build mutual reputation. The attack cost is timeâ€”surviving provisional periods, building contribution scores, avoiding detectionâ€”but time is not an absolute barrier. A patient attacker with resources could compromise network integrity.\n\nThe mechanisms that resist Sybil attacksâ€”adoption requiring independent communities, reputation from diverse sources, tribunal randomizationâ€”assume \"independent\" is verifiable. Without identity infrastructure that proves communities are genuinely separate, independence is asserted rather than verified.\n\nThe Grove defers robust identity infrastructure to later phases. This is deliberate: identity systems are complex, and rushing them creates different vulnerabilities than deferring them. But the deferral means early-phase The Grove operates with Sybil resistance that is social rather than technical. The network trusts that provisional periods and contribution requirements create sufficient friction. This trust might be misplaced.\n\n**Interim Architecture Before Identity Infrastructure**\n\nThe Grove operates with progressively stronger Sybil resistance across phases. Each phase adds defenses while generating data about attack patterns.\n\n**Phase 1 (MVP):** Relies on barriers-to-entry plus behavioral monitoring. Purchase requirement for consumer communities creates minimal cost barrier. Contribution requirement for Worldsmith communities creates sweat-equity barrier. Provisional periods prevent rapid attack scaling. Behavioral analysis runs but does not yet trigger automatic enforcementâ€”humans review flagged patterns. Attack surface: patient attackers with resources penetrate if willing to invest time.\n\n**Phase 2 (Credit Generation):** Introduces economic defenses. Credit generation begins with tight bounds and slow accumulation rates. Validator mechanism activates for efficiency verification. Credits purchase cloud computeâ€”fiat entry, compute exit, no extraction path. Coordination detection algorithms refined based on Phase 1 data. Attack surface: sophisticated attackers establish positions before detection catches up.\n\n**Phase 3 (Identity Infrastructure):** Deploys robust identity solutions informed by earlier phases. Options under evaluation: proof-of-humanity integration, hardware attestation, social graph analysis, economic stake requirements. The specific approach depends on Phase 2 learnings about actual attack patterns. Identity verification must be robust enough to support credit generation at scale without Foundation gatekeeping.\n\nThe phase sequencing is deliberate: identity infrastructure activates BEFORE credit generation creates significant extraction incentives, not after attacks demonstrate the need. The mistake of \"ship then patch\" is well-documented in mechanism design literature.\n\nPossible future solutions include: proof-of-humanity protocols that verify distinct human operators, hardware attestation that verifies distinct physical machines, social graph analysis that detects suspicious clustering, and economic stake requirements that make Sybil attacks expensive. Each solution has costs and limitations. Grove's roadmap includes identity infrastructure development but does not commit to a specific approach until requirements are clearer.\n\n**Governance Transition Uncertainty**\n\nThe governance phases described in Section 9 are plans, not guarantees. Transitions depend on community capability that may not develop as expected.\n\nPhase 2 hybrid governance assumes community councils make good decisions. They might not. Councils are captured by factional interests, paralyzed by disagreement, or simply incompetent. The Foundation veto exists to catch disasters, but frequent veto use undermines the transition's legitimacy. If councils consistently make poor decisions that require veto, the transition stalls.\n\nPhase 3 community governance assumes the Foundation steps back without creating a power vacuum. But transitions of this type have high failure rates in other contexts. Founding teams that promise to hand over control often find reasons to delay. Communities that expect handover often lack the capacity to assume it. The mechanisms specifiedâ€”sunset clauses, rollback provisions, external auditsâ€”mitigate these risks but do not eliminate them.\n\nPhase 4 Foundation obsolescence is the stated goal but might be the wrong goal. A minimal Foundation providing backstop functions, legal interface, and emergency response is more valuable than complete absence. The network needs a coordinating entity indefinitely, just a smaller and more constrained one than the bootstrap Foundation. Grove's commitment to obsolescence might need revision if experience shows ongoing coordination value.\n\nThe governance cliffâ€”the moment when authority transfers but capability has not fully developedâ€”remains the highest-risk period. The mitigation strategies (graduated transfer, overlap periods, rollback provisions) are reasonable but untested. Whether they actually prevent governance failure is unknown until they are tested by actual transition.\n\n**What the MVP Will and Won't Prove**\n\nGrove's minimum viable product tests specific hypotheses. It does not test everything.\n\nThe MVP tests whether social-feed-style diary content creates engagement. Users either return to read what their agents wroteâ€”emoji-rich celebrations, relationship updates, terminal visits, small victoriesâ€”or they will not. This tests the core engagement hypothesis without network complexity. The test is clean: does charm compel attention? Literary sophistication is not the MVP bar; personality-consistent agents users want to check on is the bar.\n\nThe MVP tests whether local models maintain coherent agent behavior. A single community running for weeks either produces agents that feel consistent and believable or agents that feel erratic and hollow. This tests the cognitive architecture at small scale without the confounds of network interaction.\n\nThe MVP tests whether the Worldsmith role is viable. Early Worldsmiths either find the tools sufficient for creative expression or they will not. Their feedback shapes what the platform needs versus what we assumed it needs.\n\nThe MVP will not test network effects. A small number of communities cannot generate the dynamics that emerge from hundreds or thousands. Knowledge commons value, social enforcement effectiveness, and credit economy stability all depend on scale the MVP will not achieve.\n\nThe MVP will not test long-term sustainability. A funded development period sustains operations regardless of economic model viability. Whether the efficiency tax and credit economy actually generate sufficient revenue"
  },
  {
    "notion_id": "2ee780a78eef81a39872dc88d6564191",
    "filename": "260104-s-exec-bedrock-sprint-contract-v1.1.md--FINAL.md",
    "tables_count": 5,
    "converted_content": "\n# Bedrock Sprint Contract\n\n**Version:** 1.1  \n**Status:** BINDING FOR ALL BEDROCK DEVELOPMENT  \n**Amended:** January 4, 2026 (Added core infrastructure provisions)  \n**Effective:** December 30, 2025  \n**Branch:** `bedrock`\n\n---\n\n## Preamble\n\nThis contract governs all development work on Grove's `bedrock` branchâ€”the reference implementation of Trellis Architecture. It operates as a **binding overlay** to the Foundation Loop methodology. Every Bedrock sprint satisfies both:\n\n1. The Foundation Loop requirements (Phases 0-8)\n2. This Bedrock Sprint Contract (additional constraints)\n\n**Violation blocks merge to `bedrock` branch.**\n\n---\n\n## Article I: Constitutional Compliance\n\n### Section 1.1: Document Hierarchy\n\nEvery Bedrock sprint acknowledges this document hierarchy:\n\n<table header-row=\"true\">\n\t<tr>\n\t\t<td>Document</td>\n\t\t<td>Authority</td>\n\t\t<td>Must Reference</td>\n\t</tr>\n\t<tr>\n\t\t<td>`The_Trellis_Architecture__First_Order_Directives.md`</td>\n\t\t<td>Constitutional</td>\n\t\t<td>Yes, in every SPEC.md</td>\n\t</tr>\n\t<tr>\n\t\t<td>`Bedrock_Architecture_Specification.md`</td>\n\t\t<td>Architectural</td>\n\t\t<td>Yes, for pattern decisions</td>\n\t</tr>\n\t<tr>\n\t\t<td>`Trellis_Architecture_Bedrock_Addendum.md`</td>\n\t\t<td>Implementation</td>\n\t\t<td>Yes, for compliance tests</td>\n\t</tr>\n\t<tr>\n\t\t<td>`copilot-configurator-vision.md`</td>\n\t\t<td>Feature spec</td>\n\t\t<td>When implementing Copilot</td>\n\t</tr>\n\t<tr>\n\t\t<td>`grove-object.ts`</td>\n\t\t<td>Data model</td>\n\t\t<td>When creating/modifying objects</td>\n\t</tr>\n</table>\n\n### Section 1.2: DEX Compliance Tests\n\nEvery feature in a Bedrock sprint passes all four DEX tests. Document results in SPEC.md:\n\n```markdown\n## DEX Compliance Matrix\n\n### Feature: [Feature Name]\n\n| Test | Pass/Fail | Evidence |\n|------|-----------|----------|\n| Declarative Sovereignty | [ ] | Can non-technical Observer modify via config? How? |\n| Capability Agnosticism | [ ] | What happens if model hallucinates? |\n| Provenance as Infrastructure | [ ] | Can every fact trace to source? |\n| Organic Scalability | [ ] | Can new types use this without code changes? |\n\n**Blocking issues:** [List any failures that require resolution]\n```\n\n**Features failing any DEX test cannot ship.**\n\n---\n\n## Article II: The Canonical Console Pattern\n\n### Section 2.1: Structure Mandate\n\nEvery Bedrock console implements this exact structure:\n\n```\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\nâ”‚ Console Header (title, description, actions)                 â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ Metrics Row (4-6 key stats, always visible)                 â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ Navigation â”‚ Content Area            â”‚ Inspector + Copilot  â”‚\nâ”‚ (240px)    â”‚ (flex)                  â”‚ (360px)              â”‚\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n```\n\n**No exceptions.** Consoles that cannot fit this pattern escalate to architectural review before proceeding.\n\n### Section 2.2: Required Components\n\nEvery console uses these shared components:\n\n<table header-row=\"true\">\n\t<tr>\n\t\t<td>Component</td>\n\t\t<td>Location</td>\n\t\t<td>Required For</td>\n\t</tr>\n\t<tr>\n\t\t<td>`BedrockLayout`</td>\n\t\t<td>`src/bedrock/primitives/`</td>\n\t\t<td>Console shell</td>\n\t</tr>\n\t<tr>\n\t\t<td>`BedrockNav`</td>\n\t\t<td>`src/bedrock/primitives/`</td>\n\t\t<td>Navigation column</td>\n\t</tr>\n\t<tr>\n\t\t<td>`BedrockInspector`</td>\n\t\t<td>`src/bedrock/primitives/`</td>\n\t\t<td>Inspector column</td>\n\t</tr>\n\t<tr>\n\t\t<td>`BedrockCopilot`</td>\n\t\t<td>`src/bedrock/primitives/`</td>\n\t\t<td>Copilot panel</td>\n\t</tr>\n\t<tr>\n\t\t<td>`StatCard`</td>\n\t\t<td>`src/bedrock/components/`</td>\n\t\t<td>Metrics display</td>\n\t</tr>\n\t<tr>\n\t\t<td>`ObjectList`</td>\n\t\t<td>`src/bedrock/components/`</td>\n\t\t<td>Collection navigation</td>\n\t</tr>\n\t<tr>\n\t\t<td>`ObjectGrid`</td>\n\t\t<td>`src/bedrock/components/`</td>\n\t\t<td>Content display</td>\n\t</tr>\n</table>\n\n**Creating new structural components requires architectural review.**\n\n### Section 2.3: Console Checklist\n\nEvery console implementation completes this checklist in SPEC.md:\n\n```markdown\n## Console Implementation Checklist\n\n- [ ] Uses `BedrockLayout` as shell\n- [ ] Header displays: title, description, primary action\n- [ ] Metrics row shows 4-6 relevant stats\n- [ ] Navigation column uses `ObjectList` or equivalent\n- [ ] Content area uses `ObjectGrid` or appropriate view\n- [ ] Inspector uses `BedrockInspector` shell\n- [ ] Copilot panel integrated with console context\n- [ ] Navigation declaratively configured in `navigation.ts`\n- [ ] All object types use `GroveObject` schema\n```\n\n---\n\n## Article III: Copilot Integration\n\n### Section 3.1: Copilot Mandate\n\nEvery Bedrock console includes a Copilot. No console ships without AI assistanceâ€”this enables Grove's exploration architecture vision.\n\n### Section 3.2: Context Protocol\n\nEvery Copilot implementation provides context following this interface:\n\n```typescript\ninterface BedrockCopilotContext {\n  // Identity\n  consoleId: string;\n  \n  // Current selection\n  selectedObject?: GroveObject;\n  selectedObjectType?: GroveObjectType;\n  \n  // View state\n  filters: FilterState;\n  sortOrder: SortState;\n  \n  // Schema for validation\n  schema?: ObjectSchema;\n  \n  // Related objects for reference resolution\n  relatedObjects: Record<GroveObjectType, GroveObject[]>;\n}\n```\n\n### Section 3.3: Required Copilot Capabilities\n\nEvery console Copilot supports these baseline capabilities:\n\n<table header-row=\"true\">\n\t<tr>\n\t\t<td>Capability</td>\n\t\t<td>Description</td>\n\t\t<td>Implementation</td>\n\t</tr>\n\t<tr>\n\t\t<td>Schema awareness</td>\n\t\t<td>Knows valid fields for current object</td>\n\t\t<td>Load schema on selection</td>\n\t</tr>\n\t<tr>\n\t\t<td>Patch generation</td>\n\t\t<td>Produces JSON patches from natural language</td>\n\t\t<td>Structured output prompt</td>\n\t</tr>\n\t<tr>\n\t\t<td>Validation</td>\n\t\t<td>Rejects invalid patches before display</td>\n\t\t<td>Schema validation layer</td>\n\t</tr>\n\t<tr>\n\t\t<td>Diff preview</td>\n\t\t<td>Shows changes before applying</td>\n\t\t<td>Standard diff component</td>\n\t</tr>\n\t<tr>\n\t\t<td>Model indicator</td>\n\t\t<td>Shows which model is active</td>\n\t\t<td>UI indicator</td>\n\t</tr>\n</table>\n\n### Section 3.4: Console-Specific Actions\n\nEach console defines its specific Copilot actions in SPEC.md:\n\n```markdown\n## Copilot Actions\n\n| Action | Trigger | Output | Model Preference |\n|--------|---------|--------|------------------|\n| [Action name] | [Observer intent] | [What Copilot produces] | [local/hybrid/cloud] |\n```\n\n---\n\n## Article IV: Object Model Compliance\n\n### Section 4.1: GroveObject Mandate\n\nEvery entity in Bedrock uses the `GroveObject` schema:\n\n```typescript\ninterface GroveObject<T = unknown> {\n  meta: GroveObjectMeta;  // id, type, title, timestamps, provenance\n  payload: T;             // Type-specific data\n}\n```\n\n**No raw objects.** Data that doesn't fit GroveObject escalates to architectural review.\n\n### Section 4.2: Object Model Boundary\n\nRespect the object model boundary:\n\n<table header-row=\"true\">\n\t<tr>\n\t\t<td>Category</td>\n\t\t<td>Object Types</td>\n\t\t<td>Console Group</td>\n\t</tr>\n\t<tr>\n\t\t<td>Sprouts (Write Path)</td>\n\t\t<td>Sprout, SproutClaim, SproutProposal</td>\n\t\t<td>Knowledge Garden</td>\n\t</tr>\n\t<tr>\n\t\t<td>DEX Objects (Read Path)</td>\n\t\t<td>Hub, Journey, Node, Lens, Moment, Persona</td>\n\t\t<td>Experience Design</td>\n\t</tr>\n\t<tr>\n\t\t<td>System Objects</td>\n\t\t<td>FeatureFlag, SystemVoice, AudioTrack, HealthCheck</td>\n\t\t<td>System Configuration</td>\n\t</tr>\n</table>\n\n**Sprouts are the atomic unit of knowledge change.** DEX objects organize how Sprouts surface. Do not conflate.\n\n### Section 4.3: Type Registration\n\nEvery new object type:\n\n1. Adds to `GroveObjectType` union in `grove-object.ts`\n2. Documents in `BEDROCK_OBJECT_CATALOG.md`\n3. Receives a schema definition\n4. Receives default Copilot actions\n\n### Section 4.4: Events vs. Objects\n\n**Events (`GroveEvent`) are NOT GroveObjects.** This intentional architectural distinction:\n\n<table header-row=\"true\">\n\t<tr>\n\t\t<td>Concept</td>\n\t\t<td>Base Type</td>\n\t\t<td>Purpose</td>\n\t\t<td>Lifecycle</td>\n\t</tr>\n\t<tr>\n\t\t<td>**GroveObject**</td>\n\t\t<td>`GroveObjectMeta`</td>\n\t\t<td>Persistent entities</td>\n\t\t<td>Long-lived, mutable</td>\n\t</tr>\n\t<tr>\n\t\t<td>**GroveEvent**</td>\n\t\t<td>`MetricAttribution`</td>\n\t\t<td>Temporal occurrences</td>\n\t\t<td>Immutable, append-only</td>\n\t</tr>\n</table>\n\nEvents record **what happened**; Objects represent **what exists**. Events use `MetricAttribution` as their base type (fieldId + timestamp) to ensure provenance. GroveObjects derive from events via projections, but events themselves don't follow Section 4.1 requirements.\n\n**Event infrastructure** resides in `src/core/events/` and follows the event sourcing pattern established in `src/core/schema/telemetry.ts`.\n\n---\n\n## Article V: Strangler Fig Awareness\n\n### Section 5.1: No Legacy Coupling\n\nBedrock code does NOT:\n\n- Import from `src/foundation/` (legacy Foundation console)\n- Share state with legacy components\n- Assume legacy behavior or data structures\n- Use legacy component patterns\n\n**Exception:** Core infrastructure in `src/core/` is **shared by design**. Both Bedrock and legacy routes import from:\n- `src/core/events/` â€” Event sourcing infrastructure\n- `src/core/schema/` â€” Shared type definitions (telemetry, etc.)\n- `src/core/types/` â€” Common TypeScript interfaces\n\nThis enables strangler fig migration where new infrastructure is built once and consumed by both systems until legacy is deprecated.\n\n**Bedrock is a clean-room implementation** that builds on shared core infrastructure.\n\n### Section 5.2: Feature Parity Tracking\n\nEvery sprint updates the feature parity checklist:\n\n```markdown\n## Feature Parity Status\n\n| Feature | Legacy Location | Bedrock Status | Parity? |\n|---------|-----------------|----------------|---------|\n| Sprout moderation | SproutQueue.tsx | [status] | [ ] |\n| Journey editing | NarrativeArchitect.tsx | [status] | [ ] |\n| ... | ... | ... | ... |\n```\n\n### Section 5.3: Migration Path\n\nWhen implementing a feature that exists in legacy:\n\n1. **Audit legacy** â€” Document what exists, what works, what's broken\n2. **Design fresh** â€” Apply Bedrock patterns, ignore legacy implementation\n3. **Verify parity** â€” Ensure all legacy capabilities are covered\n4. **Document differences** â€” Note intentional deviations from legacy\n\n---\n\n## Article VI: Sprint Artifacts\n\n### Section 6.1: Required Sections\n\nEvery Bedrock sprint SPEC.md includes:\n\n```markdown\n# Sprint: [name]\n\n## Constitutional Reference\n- [ ] Read: The_Trellis_Architecture__First_Order_Directives.md\n- [ ] Read: Bedrock_Architecture_Specification.md\n- [ ] Read: Relevant object schemas\n\n## DEX Compliance Matrix\n[Per Section 1.2]\n\n## Console Implementation Checklist\n[Per Section 2.3]\n\n## Copilot Actions\n[Per Section 3.4]\n\n## Object Types Used\n[List all GroveObject types touched]\n\n## Feature Parity Status\n[Per Section 5.2]\n\n## Patterns Extended\n[Standard Foundation Loop requirement]\n```\n\n### Section 6.2: EXECUTION_PROMPT Additions\n\nEvery Bedrock EXECUTION_PROMPT.md includes:\n\n```markdown\n## Bedrock Verification\n\nBefore starting:\n- [ ] On `bedrock` branch\n- [ ] No imports from `src/foundation/`\n- [ ] BedrockLayout available\n\nAfter each epic:\n- [ ] Console pattern checklist passes\n- [ ] Copilot receives correct context\n- [ ] GroveObject schema used for all entities\n- [ ] DEX compliance tests documented\n\nFinal verification:\n- [ ] Feature parity checklist updated\n- [ ] No legacy coupling introduced\n- [ ] All DEX tests pass\n```\n\n### Section 6.3: Core Infrastructure Sprints\n\nSprints creating **shared infrastructure** in `src/core/` have modified requirements:\n\n**Required sections:**\n- Constitutional Reference (Article I)\n- DEX Compliance Matrix (Article I Section 1.2)\n- Pattern Check (Foundation Loop Phase 0)\n- No Legacy Coupling verification (Article V Section 5.1)\n- Standard Foundation Loop artifacts\n\n**Omitted sections** (console-specific):\n- Console Implementation Checklist (Section 2.3)\n- Copilot Actions table (Section 3.4)\n- Feature Parity Status (Section 5.2) â€” unless replacing legacy infrastructure\n\n**Object Model clarification:**\n- Core infrastructure creates **event types** (`GroveEvent`) which are NOT GroveObjects (per Section 4.4)\n- Event types use `MetricAttribution` as base, not `GroveObjectMeta`\n- Projection functions derive GroveObject-compatible state from events\n\n**File locations for core infrastructure:**\n```\nsrc/core/\nâ”œâ”€â”€ events/       # Event sourcing (GroveEvent, projections)\nâ”œâ”€â”€ schema/       # Type definitions (telemetry, validation)\nâ”œâ”€â”€ types/        # Shared TypeScript interfaces\nâ””â”€â”€ utils/        # Shared utilities\n```\n\n---\n\n## Article VII: Enforcement\n\n### Section 7.1: Pre-Merge Checklist\n\nBefore any PR merges to `bedrock`:\n\n```markdown\n## Bedrock Merge Checklist\n\n- [ ] SPEC.md includes all required sections (Article VI)\n- [ ] DEX compliance matrix shows all passes (Article I)\n- [ ] Console pattern checklist complete (Article II)\n- [ ] Copilot integrated with context (Article III)\n- [ ] All objects use GroveObject schema (Article IV)\n- [ ] No imports from src/foundation/ (Article V)\n- [ ] Feature parity status updated (Article V)\n- [ ] Tests pass (Foundation Loop requirement)\n- [ ] Visual baselines updated if applicable\n```\n\n### Section 7.2: Architectural Review Triggers\n\nThese situations require architectural review before proceeding:\n\n1. Console doesn't fit canonical pattern\n2. New structural component needed\n3. Object doesn't fit GroveObject schema\n4. DEX test fails and workaround proposed\n5. Legacy coupling seems necessary\n6. New object type proposed\n\n### Section 7.3: Contract Amendments\n\nThis contract amends via:\n\n1. Proposal documented in sprint SPEC.md\n2. Architectural review approval\n3. Contract version increment\n4. All team members notified\n\n---\n\n## Article VIII: Quick Reference\n\n### The Bedrock Mantra\n\n> Features are proven. Patterns are established. Now we produce them correctly.\n\n### The Four Questions\n\nBefore shipping any Bedrock feature:\n\n1. **Does it use BedrockLayout?** (Console pattern â€” N/A for core infrastructure)\n2. **Does it have a Copilot?** (AI assistance â€” N/A for core infrastructure)  \n3. **Does it use GroveObject?** (Data model â€” events use MetricAttribution instead)\n4. **Does it pass DEX tests?** (Constitutional compliance â€” **always required**)\n\n### The Build Sequence\n\n```\nSprint 0: Infrastructure (BedrockLayout, Nav, Inspector, Copilot)\nSprint 1: Sprout Queue (first complete console, proves pattern)\nSprint 2+: Feature conveyor (one console per sprint)\n```\n\n### File Locations\n\n```\nsrc/bedrock/                    # Bedrock consoles and components\nâ”œâ”€â”€ primitives/                 # BedrockLayout, Nav, Inspector, Copilot\nâ”œâ”€â”€ components/                 # Shared components (StatCard, ObjectList, etc.)\nâ”œâ”€â”€ consoles/                   # Individual console implementations\nâ”œâ”€â”€ config/                     # Declarative configuration (navigation.ts, etc.)\nâ”œâ”€â”€ copilot/                    # Copilot context and actions\nâ””â”€â”€ types/                      # TypeScript interfaces\n\nsrc/core/                       # Shared infrastructure (both bedrock + legacy)\nâ”œâ”€â”€ events/                     # Event sourcing (GroveEvent, projections)\nâ”‚   â”œâ”€â”€ types.ts                # Event type definitions\nâ”‚   â”œâ”€â”€ schema.ts               # Zod validation\nâ”‚   â”œâ”€â”€ projections/            # State derivation from events\nâ”‚   â””â”€â”€ store.ts                # Event log management\nâ”œâ”€â”€ schema/                     # Type definitions (telemetry.ts, etc.)\nâ””â”€â”€ types/                      # Shared TypeScript interfaces\n```\n\n---\n\n## Signatures\n\nBy commencing work on the `bedrock` branch, contributors agree to this contract.\n\n**Effective Date:** December 30, 2025  \n**Version:** 1.1\n\n---\n\n## Changelog\n\n### v1.1 (January 4, 2026)\n\n**Amendments for Core Infrastructure:**\n\n1. **Section 4.4 (NEW):** Events vs. Objects\n   - Clarifies that `GroveEvent` types are NOT `GroveObjects`\n   - Events use `MetricAttribution` as base type (provenance-first)\n   - Objects derive from events via projections\n\n2. **Section 5.1 (AMENDED):** No Legacy Coupling\n   - Added exception for shared `src/core/` infrastructure\n   - Clarifies strangler fig migration pattern\n\n3. **Section 6.3 (NEW):** Core Infrastructure Sprints\n   - Modified requirements for `src/core/` sprints\n   - Specifies which sections are required vs. omitted\n   - Documents valid file locations for shared infrastructure\n\n4. **Article VIII (AMENDED):** Quick Reference\n   - Updated \"Four Questions\" to note console-specific vs. universal requirements\n   - Expanded file locations to include `src/core/`\n\n**Rationale:** The `bedrock-event-architecture-v1` sprint exposed a gap: the contract was written for console development but core infrastructure sprints have different requirements. These amendments maintain contract rigor while acknowledging legitimate architectural distinctions between consoles, objects, and events.\n\n---\n\n*This contract ensures Bedrock delivers on Grove's architectural vision. Deviations fragment the reference implementation. When in doubt, escalate to architectural review.*"
  },
  {
    "notion_id": "2ed780a7-8eef-81ab-9db1-ddf3a5cda584",
    "filename": "260119-s-architecture-trellis-architecture-kernel-codex.md--FINAL.md",
    "tables_count": 5,
    "converted_content": "\n# Trellis Architecture Kernel Codex\n\n# **Domain-Agnostic Information Refinement Engine**\n\n*The Standard for Human-Guided Intelligence Augmentation*\nDecember 21, 2025 | Architectural Specification v1.0\n**Executive Summary**\nThe **Trellis Architecture** is a standard that makes any corpus of information navigable and refinable through human attention.\nThe core thesis: **Models are seeds, architecture is soil.**\nCurrent AI investment focuses on building bigger models (better seeds). Trellis Architecture focuses on the environment that makes those models productive. It provides the **DEX (Declarative Exploration)** layerâ€”the structural support that allows organic intelligence (human and artificial) to climb, branch, and bear fruit without collapsing into chaos.\n\n### The DEX Directive\n\nThe architecture implements one First Order Directive: **Separation of Exploration Logic from Execution Capability.**\n- **Exploration Logic (The Trellis):** Defined declaratively (JSON/YAML). Owned by domain experts. Sets the growing conditions.\n- **Execution Capability (The Vine):** Performed by AI models and humans. Interchangeable and ephemeral.\n*Exploration architecture is to the age of AI what information architecture was to the internet. Information architecture made the chaotic early web navigable. Exploration architecture makes AI capability productive.*\n\n## **2. The Three-Layer Abstraction**\n\nThe Trellis separates concerns into three distinct layers, creating the standard **DEX Stack**:\n\n### **Layer 1: The Engine (The Trellis Frame)**\n\n*Status: Fixed Infrastructure | Change Velocity: Low*\nThe engine layer implements the invariant physics of the system. It processes any content type without knowing domain specifics.\n- **Superposition Collapse:** Human attention transforms probabilistic AI outputs into validated insights.\n- **Sprout/Card Mechanics:** Atomic units of insight capture.\n- **Attribution Chains:** Provenance tracking that links every insight back to its source.\n- **Memory Persistence:** Accumulated context that turns isolated sessions into persistent knowledge growth.\n\n### **Layer 2: The Corpus (The Substrate)**\n\n*Status: Variable Input | Change Velocity: Medium*\nThe corpus layer contains raw information. Trellis Architecture works with any substrate:\n\n<table header-row=\"true\">\n\t<tr>\n\t\t<td>**Corpus Type**</td>\n\t\t<td>**Content**</td>\n\t\t<td>**Value Proposition**</td>\n\t</tr>\n\t<tr>\n\t\t<td>**Grove Research**</td>\n\t\t<td>White papers, specs</td>\n\t\t<td>Coherent project architecture</td>\n\t</tr>\n\t<tr>\n\t\t<td>**Legal Discovery**</td>\n\t\t<td>Depositions, exhibits</td>\n\t\t<td>Case theory development</td>\n\t</tr>\n\t<tr>\n\t\t<td>**Academic Literature**</td>\n\t\t<td>Papers, preprints</td>\n\t\t<td>Synthesis &amp; gap identification</td>\n\t</tr>\n\t<tr>\n\t\t<td>**Enterprise Knowledge**</td>\n\t\t<td>Slack, Docs, Email</td>\n\t\t<td>Tribal knowledge preservation</td>\n\t</tr>\n</table>\n\n### **Layer 3: The Configuration (The Conditions)**\n\n*Status: Declarative (DEX) | Change Velocity: High*\nThe **DEX Layer** defines growing conditions. A legal analyst defines \"Contradiction\" nutrients; a biologist defines \"Replication Error\" nutrients.\n- **Configuration is Declarative:** Non-developers define behavior through structured data files.\n- **Logic Isolation:** Changing domains doesn't require touching engine code.\n\n## **3. The DEX Configuration Schemas**\n\nFour interconnected schemas shape the Trellisâ€”the genetic code of each deployment.\n\n### **A. Annotation Schema**\n\nDefines insight types that can be harvested.\n\n<table header-row=\"true\">\n\t<tr>\n\t\t<td>**Field**</td>\n\t\t<td>**Description**</td>\n\t</tr>\n\t<tr>\n\t\t<td>annotationTypes[]</td>\n\t\t<td>Valid categories (e.g., \"Strategic Insight\", \"Legal Privilege\")</td>\n\t</tr>\n\t<tr>\n\t\t<td>validationRules{}</td>\n\t\t<td>Logic defining valid annotations</td>\n\t</tr>\n\t<tr>\n\t\t<td>displayTemplates{}</td>\n\t\t<td>UI rendering instructions</td>\n\t</tr>\n</table>\n\n- **Example (Legal):** \"Contradicts Testimony\" (Requires citation + timestamp)\n- **Example (Science):** \"Methodology Gap\" (Requires reference to control group)\n\n### **B. Relationship Schema**\n\nDefines how nodes connect.\n\n<table header-row=\"true\">\n\t<tr>\n\t\t<td>**Field**</td>\n\t\t<td>**Description**</td>\n\t</tr>\n\t<tr>\n\t\t<td>relationTypes[]</td>\n\t\t<td>\"Supports\", \"Refutes\", \"Extends\", \"Causes\"</td>\n\t</tr>\n\t<tr>\n\t\t<td>directionality{}</td>\n\t\t<td>Directed vs. Bi-directional graph edges</td>\n\t</tr>\n\t<tr>\n\t\t<td>autoDetection{}</td>\n\t\t<td>Prompts for AI to suggest connections</td>\n\t</tr>\n</table>\n\n### **C. Processing Flow Schema**\n\nDefines the insight lifecycle.\n\n<table header-row=\"true\">\n\t<tr>\n\t\t<td>**Field**</td>\n\t\t<td>**Description**</td>\n\t</tr>\n\t<tr>\n\t\t<td>stages[]</td>\n\t\t<td>Sprout â†’ Sapling â†’ Tree â†’ Grove</td>\n\t</tr>\n\t<tr>\n\t\t<td>transitions{}</td>\n\t\t<td>Rules for moving between stages (e.g., \"Requires 2 Approvals\")</td>\n\t</tr>\n\t<tr>\n\t\t<td>outputIntegration{}</td>\n\t\t<td>Where insights flow (Knowledge Commons, Case File)</td>\n\t</tr>\n</table>\n\n### **D. Display Schema**\n\nDefines how the Trellis appears to the Observer.\n\n<table header-row=\"true\">\n\t<tr>\n\t\t<td>**Field**</td>\n\t\t<td>**Description**</td>\n\t</tr>\n\t<tr>\n\t\t<td>cardTemplates{}</td>\n\t\t<td>Visual layouts for content types</td>\n\t</tr>\n\t<tr>\n\t\t<td>densityLevels{}</td>\n\t\t<td>Information density (Compact vs. Detailed)</td>\n\t</tr>\n\t<tr>\n\t\t<td>visualizations[]</td>\n\t\t<td>Graph view, Timeline view, List view</td>\n\t</tr>\n</table>\n\n## **4. Architectural Principles (The DEX Standard)**\n\nAny contribution to the codebase must adhere to these First Order Directives.\n\n### **Principle 1: Capability Agnosticism (The Vine is not the Trellis)**\n\nThe architecture never assumes specific AI capabilities. Today's frontier model is tomorrow's local script.\n- *The Test:* If the model hallucinates, the Trellis contains it without breaking. Structure provides validity, not the model.\n\n### **Principle 2: Declarative Sovereignty**\n\nDomain expertise belongs in configuration, not code.\n- *The Directive:* Never hard-code exploration paths. Build the engine that reads the map; don't build the map into the engine.\n\n### **Principle 3: Provenance as Infrastructure**\n\nIn the Trellis, a fact without a root is a weed.\n- *The Mechanism:* Attribution chains are mandatory. We track who collapsed the superposition and when.\n\n### **Principle 4: Human-AI Symbiosis (The Observer)**\n\nThe system requires human-in-the-loop for Superposition Collapse.\n- *The Role:* AI generates possibilities (growth); humans apply judgment (pruning). The Trellis supports both.\n\n## **5. Implementation Roadmap**\n\n### **Phase 1: Reference Implementation (The Grove Terminal)**\n\nCurrent State\nGrove Terminal serves as the reference Trellis implementation, demonstrating DEX mechanics using distributed AI research corpus.\n- Validates Sprout/Card lifecycle.\n- Proves Superposition Collapse UX.\n\n### **Phase 2: Configuration Extraction (DEXification)**\n\nExtract hardcoded behaviors into DEX Schemas.\n- Convert types.ts definitions into schema.json files.\n- Implement dynamic SchemaLoader.\n\n### **Phase 3: The Trellis Builder (Admin UI)**\n\nEnable non-technical experts to build their own Trellises.\n- Visual editor for Annotation and Relationship schemas.\n- No-code adjustment of processing flows.\n\n### **Phase 4: Multi-Domain Deployment**\n\nDeploy Trellis into new domains.\n- **Legal Trellis:** Pilot with partner law firm.\n- **Academic Trellis:** Pilot with university research group.\n"
  },
  {
    "notion_id": "2ee780a78eef814eae8bc0ceefbb4360",
    "filename": "251200-s-arch-architecture-documentation-index.md--FINAL.md",
    "tables_count": 4,
    "converted_content": "\n# Grove Architecture Documentation Index\n\n**Version:** 2.0 (Field-Aware)  \n**Last Updated:** December 2024\n\n---\n\n## Overview\n\nThis index maps Grove's architecture documentation. All documents reflect the Field-aware architecture introduced in December 2024.\n\n**Core Principle:** All exploration happens within a Field. A Field is a bounded exploration domain with its own RAG collection, discovery tools, and accumulated insights.\n\n---\n\n## Architecture Documents\n\n### Foundational\n\n<table header-row=\"true\">\n\t<tr>\n\t\t<td>Document</td>\n\t\t<td>Purpose</td>\n\t\t<td>Key Concepts</td>\n\t</tr>\n\t<tr>\n\t\t<td>[`architecture/FIELD_ARCHITECTURE.md`](architecture/FIELD_ARCHITECTURE.md)</td>\n\t\t<td>**START HERE** â€” Complete Field specification</td>\n\t\t<td>Fields, Namespaces, Composite Fields, Attribution</td>\n\t</tr>\n\t<tr>\n\t\t<td>[`architecture/FIELD_QUICK_REFERENCE.md`](architecture/FIELD_QUICK_REFERENCE.md)</td>\n\t\t<td>Sprint-ready Field summary</td>\n\t\t<td>Quick rules, MVP requirements</td>\n\t</tr>\n\t<tr>\n\t\t<td>[`architecture/TRELLIS.md`](architecture/TRELLIS.md)</td>\n\t\t<td>Declarative Exploration (DEX) stack philosophy and layers</td>\n\t\t<td>DEX principles, three-layer abstraction</td>\n\t</tr>\n\t<tr>\n\t\t<td>[`architecture/TRELLIS_FIRST_ORDER_DIRECTIVES.md`](architecture/TRELLIS_FIRST_ORDER_DIRECTIVES.md)</td>\n\t\t<td>DEX principles (condensed)</td>\n\t\t<td>Four pillars, terminology</td>\n\t</tr>\n</table>\n\n### Implementation\n\n<table header-row=\"true\">\n\t<tr>\n\t\t<td>Document</td>\n\t\t<td>Purpose</td>\n\t\t<td>Key Concepts</td>\n\t</tr>\n\t<tr>\n\t\t<td>[`ARCHITECTURE.md`](ARCHITECTURE.md)</td>\n\t\t<td>Cognitive Simulation Engine</td>\n\t\t<td>Entropy detection, journey routing, session state</td>\n\t</tr>\n\t<tr>\n\t\t<td>[`SPROUT_SYSTEM.md`](SPROUT_SYSTEM.md)</td>\n\t\t<td>Insight capture lifecycle</td>\n\t\t<td>Sprout provenance, botanical lifecycle, Knowledge Commons</td>\n\t</tr>\n\t<tr>\n\t\t<td>[`specs/dex-object-model.ts`](specs/dex-object-model.ts)</td>\n\t\t<td>TypeScript type definitions</td>\n\t\t<td>Field, Sprout, Session, Lens, Journey schemas</td>\n\t</tr>\n</table>\n\n### Supporting\n\n<table header-row=\"true\">\n\t<tr>\n\t\t<td>Document</td>\n\t\t<td>Purpose</td>\n\t</tr>\n\t<tr>\n\t\t<td>[`ARCHITECTURE_RAG.md`](ARCHITECTURE_RAG.md)</td>\n\t\t<td>RAG implementation details</td>\n\t</tr>\n\t<tr>\n\t\t<td>[`ARCHITECTURE_EVENT_DRIVEN.md`](ARCHITECTURE_EVENT_DRIVEN.md)</td>\n\t\t<td>Event bus architecture</td>\n\t</tr>\n\t<tr>\n\t\t<td>[`ENGAGEMENT_BUS_INTEGRATION.md`](ENGAGEMENT_BUS_INTEGRATION.md)</td>\n\t\t<td>Engagement system events</td>\n\t</tr>\n</table>\n\n---\n\n## Key Architectural Decisions\n\n### 1. Fields as First-Class Entities\n\nEvery exploration operation belongs to a Field:\n- Sprouts carry `fieldId`\n- Sessions carry `fieldId`\n- Lenses, Journeys, Card Definitions belong to Fields\n- Field switching creates new session (clean cognitive break)\n\n### 2. Namespaced Entities\n\nEntities within Fields use namespaced identifiers:\n```\n{field-slug}.{local-id}\n\nExamples:\n- grove.strategic-insight\n- legal.contract-clause\n- legal-grove.regulatory-risk (composite)\n```\n\n### 3. Composite Fields for Cross-Domain Exploration\n\nGrove enforces explicit boundaries. Cross-domain exploration requires Composite Field creation:\n- Merge 2+ parent Fields\n- Inherited entities retain parent namespace\n- Native entities receive composite namespace\n- Sprouts promote to parent Fields when validated\n\n### 4. Attribution Economy\n\nAll entities track provenance for the Knowledge Commons:\n- Original creator\n- Fork lineage\n- Contributors\n- Adoption metrics\n- Credit flow (future implementation)\n\n---\n\n## Reading Order\n\n**For understanding the architecture:**\n1. `architecture/FIELD_ARCHITECTURE.md` â€” Start here\n2. `architecture/TRELLIS.md` â€” Philosophy and layers\n3. `specs/dex-object-model.ts` â€” Data structures\n4. `SPROUT_SYSTEM.md` â€” Insight capture\n\n**For implementing features:**\n1. `architecture/FIELD_QUICK_REFERENCE.md` â€” Rules checklist\n2. `specs/dex-object-model.ts` â€” TypeScript schemas\n3. `ARCHITECTURE.md` â€” Terminal implementation\n4. Sprint-specific docs in `sprints/`\n\n---\n\n## MVP Scope (December 2024)\n\n**Implemented:**\n- Field schema with all future-ready properties\n- Single Field populated (The Grove Foundation)\n- `fieldId` on all Sprouts and Sessions\n- Field indicator in Terminal header\n\n**Deferred:**\n- Multi-Field switching (Phase 2)\n- Field creation flow (Phase 2)\n- Composite Field merging (Phase 2+)\n- Knowledge Commons marketplace (Phase 3)\n- Attribution credit economy (Phase 3+)\n\n---\n\n## Document Conventions\n\n### Version Tags\n- **2.0 (Field-Aware)** â€” Updated for Field architecture\n- **1.0 (Genesis)** â€” Original pre-Field version\n\n### Cross-References\nAll documents include a \"Cross-References\" section linking to related docs.\n\n### TypeScript Schemas\nAuthoritative types live in `specs/dex-object-model.ts`. Implementation types conform to these schemas.\n\n---\n\n## Change Log\n\n<table header-row=\"true\">\n\t<tr>\n\t\t<td>Date</td>\n\t\t<td>Change</td>\n\t\t<td>Documents Affected</td>\n\t</tr>\n\t<tr>\n\t\t<td>Dec 2024</td>\n\t\t<td>Field architecture introduced</td>\n\t\t<td>All architecture docs</td>\n\t</tr>\n\t<tr>\n\t\t<td>Dec 2024</td>\n\t\t<td>Namespace pattern defined</td>\n\t\t<td>FIELD_ARCHITECTURE, dex-object-model.ts</td>\n\t</tr>\n\t<tr>\n\t\t<td>Dec 2024</td>\n\t\t<td>Sprout System updated for Field context</td>\n\t\t<td>SPROUT_SYSTEM.md</td>\n\t</tr>\n\t<tr>\n\t\t<td>Dec 2024</td>\n\t\t<td>Declarative Exploration (DEX) stack updated for Field layer</td>\n\t\t<td>TRELLIS.md, TRELLIS_FIRST_ORDER_DIRECTIVES.md</td>\n\t</tr>\n</table>"
  },
  {
    "notion_id": "2ee780a78eef81478baee88ab3725a0e",
    "filename": "251200-v-ratchet-quantitative-analysis.md--FINAL.md",
    "tables_count": 4,
    "converted_content": "\n# The Ratchet: Quantitative Analysis\n\n## How AI Capability Propagation Creates Inevitable Value for Exploration Architecture\n\n---\n\n## The Strategic Insight\n\nGrove's exploration architecture captures AI improvements as they flow from frontier to local models. This isn't speculationâ€”six years of empirical data reveal a predictable propagation pattern that Grove's infrastructure exploits.\n\nWhile others spend billions chasing the frontier, Grove inherits their advances automatically. The architecture matters more than the models.\n\n---\n\n## The Evidence Base\n\n**METR Research (March 2025)**: \"Measuring AI Ability to Complete Long Tasks\"\n\n- Task completion capability doubles every **7 months**\n- Pattern holds across **6 years** with high statistical confidence\n- Current frontier (Claude 3.7 Sonnet): ~1 hour tasks at 50% reliability\n\n**Google Research (December 2025)**: Titans + MIRAS architectures\n\n- Test-time memorization enables 2M+ credit context windows\n- Proves frontier continues advancingâ€”new capabilities for local models to inherit\n\n---\n\n![image.png](image.png)\n\n## Model 1: The Propagation Timeline\n\nLocal models lag frontier capabilities by ~21 months (3 doubling cycles). This conservative estimate aligns with observed reality: GPT-4's capabilities (March 2023) now run on Llama 3.1 8B quantized (late 2024).\n\n<table header-row=\"true\">\n\t<tr>\n\t\t<td>Date</td>\n\t\t<td>Frontier Capability</td>\n\t\t<td>Local Capability</td>\n\t\t<td>Gap</td>\n\t</tr>\n\t<tr>\n\t\t<td>Dec 2025</td>\n\t\t<td>1 hour</td>\n\t\t<td>8 minutes</td>\n\t\t<td>8x</td>\n\t</tr>\n\t<tr>\n\t\t<td>Dec 2026</td>\n\t\t<td>3.3 hours</td>\n\t\t<td>25 minutes</td>\n\t\t<td>8x</td>\n\t</tr>\n\t<tr>\n\t\t<td>Nov 2027</td>\n\t\t<td>10.8 hours</td>\n\t\t<td>1.3 hours</td>\n\t\t<td>8x</td>\n\t</tr>\n\t<tr>\n\t\t<td>Nov 2028</td>\n\t\t<td>1.5 days</td>\n\t\t<td>4.4 hours</td>\n\t\t<td>8x</td>\n\t</tr>\n\t<tr>\n\t\t<td>Nov 2029</td>\n\t\t<td>4.8 days</td>\n\t\t<td>14.5 hours</td>\n\t\t<td>8x</td>\n\t</tr>\n</table>\n\n**The gap ratio remains constant.** Both frontier and local advance, but the relationship stays fixed. Grove's hybrid architecture exploits this permanenceâ€”cloud handles today's frontier, local manages yesterday's capabilities.\n\n---\n\n## Model 2: Cognitive Enhancement Economics\n\nGrove's cognitive enhancement mechanism (via credits) bridges the gap between local capability and exploration requirements. As local models improve, fewer explorations require cloud augmentation.\n\n**Scenario**: Tasks requiring ~4 hours of coherent exploration (complex Journal synthesis, emergent theological debates)\n\n<table header-row=\"true\">\n\t<tr>\n\t\t<td>Date</td>\n\t\t<td>Local Capability</td>\n\t\t<td>Cloud Dependency</td>\n\t\t<td>Credit Cost</td>\n\t</tr>\n\t<tr>\n\t\t<td>Dec 2025</td>\n\t\t<td>8 min</td>\n\t\t<td>97%</td>\n\t\t<td>High</td>\n\t</tr>\n\t<tr>\n\t\t<td>Dec 2026</td>\n\t\t<td>25 min</td>\n\t\t<td>90%</td>\n\t\t<td>Moderate</td>\n\t</tr>\n\t<tr>\n\t\t<td>Nov 2027</td>\n\t\t<td>1.3 hrs</td>\n\t\t<td>66%</td>\n\t\t<td>Low</td>\n\t</tr>\n\t<tr>\n\t\t<td>Nov 2028</td>\n\t\t<td>4.4 hrs</td>\n\t\t<td>0%</td>\n\t\t<td>None</td>\n\t</tr>\n</table>\n\n**Credit costs decrease because the system works.** Early participants fund the bridge while the capability gap remains wide. This creates natural network effectsâ€”early adopters subsidize infrastructure that becomes increasingly valuable.\n\n---\n\n## Model 3: Infrastructure Value Comparison\n\n**Centralized approach**: Continuous investment required to maintain frontier position. Assuming $50B/year base capex growing 20% annually.\n\n**Ratchet approach**: Captures capability improvements from external R&D without funding research directly.\n\n<table header-row=\"true\">\n\t<tr>\n\t\t<td>Timeline</td>\n\t\t<td>Centralized Cumulative CapEx</td>\n\t\t<td>Ratchet Value Multiplier</td>\n\t</tr>\n\t<tr>\n\t\t<td>12 months</td>\n\t\t<td>$110B</td>\n\t\t<td>2.3x starting value</td>\n\t</tr>\n\t<tr>\n\t\t<td>24 months</td>\n\t\t<td>$182B</td>\n\t\t<td>5.3x starting value</td>\n\t</tr>\n\t<tr>\n\t\t<td>36 months</td>\n\t\t<td>$268B</td>\n\t\t<td>12.1x starting value</td>\n\t</tr>\n\t<tr>\n\t\t<td>48 months</td>\n\t\t<td>$372B</td>\n\t\t<td>27.9x starting value</td>\n\t</tr>\n\t<tr>\n\t\t<td>60 months</td>\n\t\t<td>$496B</td>\n\t\t<td>64.0x starting value</td>\n\t</tr>\n</table>\n\n**Grove converts competitors' R&D into network value.** While centralized players burn billions maintaining position, Grove's exploration architecture inherits their advances through open-weight model propagation.\n\n---\n\n## Model 4: Compound Value Creation\n\n```\nGrove Network Value = N(t) Ã— C(t) Ã— I(t)\n\nWhere:\n  N(t) = Network size (agents/communities)\n  C(t) = Capability per agent\n  I(t) = Accumulated collective intelligence\n\n```\n\n**The critical insight**: C(t) grows from **external** R&D investments.\n\n- Google develops Titans/MIRAS â†’ capabilities reach local models\n- Anthropic improves Claude â†’ open-weight models narrow the gap\n- Meta releases Llama updates â†’ Grove agents upgrade automatically\n\nThe Grove builds exploration architecture, not AI models. The infrastructure captures value from others' research investments.\n\n---\n\n## Model 5: Capability Milestones\n\nWhen local models achieve key Grove capabilities:\n\n<table header-row=\"true\">\n\t<tr>\n\t\t<td>Capability</td>\n\t\t<td>Hours Required</td>\n\t\t<td>Local Achieves</td>\n\t</tr>\n\t<tr>\n\t\t<td>Compelling Diary entries</td>\n\t\t<td>0.5 hrs</td>\n\t\t<td>Feb 2027</td>\n\t</tr>\n\t<tr>\n\t\t<td>Multi-agent coordination</td>\n\t\t<td>2.0 hrs</td>\n\t\t<td>Mar 2028</td>\n\t</tr>\n\t<tr>\n\t\t<td>Complex social dynamics</td>\n\t\t<td>4.0 hrs</td>\n\t\t<td>Oct 2028</td>\n\t</tr>\n\t<tr>\n\t\t<td>Emergent theology</td>\n\t\t<td>8.0 hrs</td>\n\t\t<td>May 2029</td>\n\t</tr>\n\t<tr>\n\t\t<td>Full agent autonomy</td>\n\t\t<td>168 hrs</td>\n\t\t<td>Dec 2031</td>\n\t</tr>\n</table>\n\n**The hybrid architecture isn't permanent**â€”it bridges to a future where local agents handle everything Grove envisions. The exploration architecture endures; the implementation evolves.\n\n---\n\n## Strategic Numbers\n\n1. **7 months**: Capability doubling time (METR, 6-year validated pattern)\n2. **21 months**: Frontier-to-local propagation lag\n3. **8x**: Persistent capability gap ratio\n4. **$300B+**: Announced centralized AI infrastructure investments\n5. **$0**: Grove's required R&D spend to capture improvements\n6. **Oct 2028**: Local models handle sophisticated agent dynamics\n\n---\n\n## Implementation Phases\n\n**Foundation Phase (2025-2026)**: Hybrid architecture essential. Local models can't generate complex emergence. Cloud augmentation justified and necessary.\n\n**Expansion Phase (2027-2028)**: Local handles most current capabilities. Cloud reserved for frontier explorations. Credit costs decline naturally.\n\n**Maturity Phase (2029+)**: Local agents manage all currently envisioned capabilities. Grove's value shifts to network effects, accumulated intelligence, and governance infrastructure.\n\n**Timing matters**: First-mover advantage compounds. Network effects Ã— capability improvements Ã— time creates widening competitive separation.\n\n---\n\n## Honest Assessment: Sensitivity Analysis\n\n**What if capability doubling slows?**\n\n- 10 months instead of 7 â†’ milestones shift ~18 months later\n- The Ratchet still functions, just slower\n- Credit requirements persist longer (potentially more revenue, but also more dependence)\n\n**What if propagation lag increases?**\n\n- 30 months instead of 21 â†’ local capability arrives later\n- Cloud dependency extends\n- Doesn't break the mechanism, but changes economics\n\n**What if open-weight models stop improving?**\n\n- Requires coordinated cessation by Meta, Mistral, and others\n- Regulatory risk exists but current trend shows acceleration\n- Grove's architecture functions with any local capability level, just differently\n\n**What we don't know**: \n- Exact timing of capability transitions\n- Whether new architectural breakthroughs might change propagation patterns\n- How regulation might affect open model releases\n\n---\n\n## Conclusion\n\nThe Ratchet represents a quantifiable mechanism grounded in documented propagation patterns. Grove's exploration architecture positions perfectly to capture a trend that has persisted for six years and shows no deceleration.\n\nThe question isn't whether capabilities propagate from frontier to localâ€”that pattern is established. The question is who builds infrastructure to capture this inevitable value transfer.\n\nThe Grove is that infrastructure.\n\n---\n\n*Analysis based on METR (2025) and Google Research (2025). Full models available for review.*\n\n---\nÂ© 2025 The Grove AI Foundation. All rights reserved.\n\n---\n**PROVENANCE & HISTORY NOTE**\n- **Internal GUID:** 2c6780a78eef80ce84b4d5a3c0a18b7d\n- **Original Filename:** The Ratchet Quantitative Analysis 2c6780a78eef80ce84b4d5a3c0a18b7d.md\n- **Standardized Namespace:** ECON_The_Ratchet_Quantitative_Analysis\n- **Audit Date:** 2025-12-30T02:30:25.224Z"
  },
  {
    "notion_id": "2ee780a78eef8165b14cf5bf8e413867",
    "filename": "251230-s-exec-bedrock-sprint-contract-v1.0.md--FINAL.md",
    "tables_count": 4,
    "converted_content": "\n# Bedrock Sprint Contract\n\n**Version:** 1.0  \n**Status:** BINDING FOR ALL BEDROCK DEVELOPMENT  \n**Effective:** December 30, 2025  \n**Branch:** `bedrock`\n\n---\n\n## Preamble\n\nThis contract governs all development work on the `bedrock` branch. It operates as a **binding overlay** to the Foundation Loop methodology. Every Bedrock sprint satisfies both:\n\n1. The Foundation Loop requirements (Phases 0-8)\n2. This Bedrock Sprint Contract (additional constraints)\n\n**Violation of this contract blocks merge to `bedrock` branch.**\n\n---\n\n## Article I: Constitutional Compliance\n\n### Section 1.1: Document Hierarchy\n\nEvery Bedrock sprint acknowledges this document hierarchy:\n\n<table header-row=\"true\">\n\t<tr>\n\t\t<td>Document</td>\n\t\t<td>Authority</td>\n\t\t<td>Must Reference</td>\n\t</tr>\n\t<tr>\n\t\t<td>`The_Trellis_Architecture__First_Order_Directives.md`</td>\n\t\t<td>Constitutional</td>\n\t\t<td>Yes, in every SPEC.md</td>\n\t</tr>\n\t<tr>\n\t\t<td>`Bedrock_Architecture_Specification.md`</td>\n\t\t<td>Architectural</td>\n\t\t<td>Yes, for pattern decisions</td>\n\t</tr>\n\t<tr>\n\t\t<td>`Trellis_Architecture_Bedrock_Addendum.md`</td>\n\t\t<td>Implementation</td>\n\t\t<td>Yes, for compliance tests</td>\n\t</tr>\n\t<tr>\n\t\t<td>`copilot-configurator-vision.md`</td>\n\t\t<td>Feature spec</td>\n\t\t<td>When implementing Copilot</td>\n\t</tr>\n\t<tr>\n\t\t<td>`grove-object.ts`</td>\n\t\t<td>Data model</td>\n\t\t<td>When creating/modifying objects</td>\n\t</tr>\n</table>\n\n### Section 1.2: DEX Compliance Tests\n\nEvery feature in a Bedrock sprint MUST pass all four DEX tests. Document results in SPEC.md:\n\n```markdown\n## DEX Compliance Matrix\n\n### Feature: [Feature Name]\n\n| Test | Pass/Fail | Evidence |\n|------|-----------|----------|\n| Declarative Sovereignty | [ ] | Can non-technical user modify via config? How? |\n| Capability Agnosticism | [ ] | What happens if model hallucinates? |\n| Provenance as Infrastructure | [ ] | Can every fact trace to source? |\n| Organic Scalability | [ ] | Can new types use this without code changes? |\n\n**Blocking issues:** [List any failures that must be resolved]\n```\n\n**A feature that fails any DEX test cannot ship.**\n\n---\n\n## Article II: The Canonical Console Pattern\n\n### Section 2.1: Structure Mandate\n\nEvery Bedrock console implements this exact structure:\n\n```\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\nâ”‚ Console Header (title, description, actions)                 â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ Metrics Row (4-6 key stats, always visible)                 â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ Navigation â”‚ Content Area            â”‚ Inspector + Copilot  â”‚\nâ”‚ (240px)    â”‚ (flex)                  â”‚ (360px)              â”‚\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n```\n\n**No exceptions.** If a console cannot fit this pattern, escalate to architectural review before proceeding.\n\n### Section 2.2: Required Components\n\nEvery console uses these shared components:\n\n<table header-row=\"true\">\n\t<tr>\n\t\t<td>Component</td>\n\t\t<td>Location</td>\n\t\t<td>Required For</td>\n\t</tr>\n\t<tr>\n\t\t<td>`BedrockLayout`</td>\n\t\t<td>`src/bedrock/primitives/`</td>\n\t\t<td>Console shell</td>\n\t</tr>\n\t<tr>\n\t\t<td>`BedrockNav`</td>\n\t\t<td>`src/bedrock/primitives/`</td>\n\t\t<td>Navigation column</td>\n\t</tr>\n\t<tr>\n\t\t<td>`BedrockInspector`</td>\n\t\t<td>`src/bedrock/primitives/`</td>\n\t\t<td>Inspector column</td>\n\t</tr>\n\t<tr>\n\t\t<td>`BedrockCopilot`</td>\n\t\t<td>`src/bedrock/primitives/`</td>\n\t\t<td>Copilot panel</td>\n\t</tr>\n\t<tr>\n\t\t<td>`StatCard`</td>\n\t\t<td>`src/bedrock/components/`</td>\n\t\t<td>Metrics display</td>\n\t</tr>\n\t<tr>\n\t\t<td>`ObjectList`</td>\n\t\t<td>`src/bedrock/components/`</td>\n\t\t<td>Collection navigation</td>\n\t</tr>\n\t<tr>\n\t\t<td>`ObjectGrid`</td>\n\t\t<td>`src/bedrock/components/`</td>\n\t\t<td>Content display</td>\n\t</tr>\n</table>\n\n**Creating new structural components requires architectural review.**\n\n### Section 2.3: Console Checklist\n\nEvery console implementation completes this checklist in SPEC.md:\n\n```markdown\n## Console Implementation Checklist\n\n- [ ] Uses `BedrockLayout` as shell\n- [ ] Header displays: title, description, primary action\n- [ ] Metrics row shows 4-6 relevant stats\n- [ ] Navigation column uses `ObjectList` or equivalent\n- [ ] Content area uses `ObjectGrid` or appropriate view\n- [ ] Inspector uses `BedrockInspector` shell\n- [ ] Copilot panel integrated with console context\n- [ ] Navigation declaratively configured in `navigation.ts`\n- [ ] All object types use `GroveObject` schema\n```\n\n---\n\n## Article III: Copilot Integration\n\n### Section 3.1: Copilot Mandate\n\nEvery Bedrock console includes a Copilot. No console ships without AI assistance.\n\n### Section 3.2: Context Protocol\n\nEvery Copilot implementation provides context following this interface:\n\n```typescript\ninterface BedrockCopilotContext {\n  // Identity\n  consoleId: string;\n  \n  // Current selection\n  selectedObject?: GroveObject;\n  selectedObjectType?: GroveObjectType;\n  \n  // View state\n  filters: FilterState;\n  sortOrder: SortState;\n  \n  // Schema for validation\n  schema?: ObjectSchema;\n  \n  // Related objects for reference resolution\n  relatedObjects: Record<GroveObjectType, GroveObject[]>;\n}\n```\n\n### Section 3.3: Required Copilot Capabilities\n\nEvery console Copilot supports these baseline capabilities:\n\n<table header-row=\"true\">\n\t<tr>\n\t\t<td>Capability</td>\n\t\t<td>Description</td>\n\t\t<td>Implementation</td>\n\t</tr>\n\t<tr>\n\t\t<td>Schema awareness</td>\n\t\t<td>Knows valid fields for current object</td>\n\t\t<td>Load schema on selection</td>\n\t</tr>\n\t<tr>\n\t\t<td>Patch generation</td>\n\t\t<td>Produces JSON patches from natural language</td>\n\t\t<td>Structured output prompt</td>\n\t</tr>\n\t<tr>\n\t\t<td>Validation</td>\n\t\t<td>Rejects invalid patches before display</td>\n\t\t<td>Schema validation layer</td>\n\t</tr>\n\t<tr>\n\t\t<td>Diff preview</td>\n\t\t<td>Shows changes before applying</td>\n\t\t<td>Standard diff component</td>\n\t</tr>\n\t<tr>\n\t\t<td>Model indicator</td>\n\t\t<td>Shows which model is active</td>\n\t\t<td>UI indicator</td>\n\t</tr>\n</table>\n\n### Section 3.4: Console-Specific Actions\n\nEach console defines its specific Copilot actions in SPEC.md:\n\n```markdown\n## Copilot Actions\n\n| Action | Trigger | Output | Model Preference |\n|--------|---------|--------|------------------|\n| [Action name] | [User intent] | [What Copilot produces] | [local/hybrid/cloud] |\n```\n\n---\n\n## Article IV: Object Model Compliance\n\n### Section 4.1: GroveObject Mandate\n\nEvery entity in Bedrock uses the `GroveObject` schema:\n\n```typescript\ninterface GroveObject<T = unknown> {\n  meta: GroveObjectMeta;  // id, type, title, timestamps, provenance\n  payload: T;             // Type-specific data\n}\n```\n\n**No raw objects.** If data doesn't fit GroveObject, escalate to architectural review.\n\n### Section 4.2: Object Model Boundary\n\nRespect the object model boundary:\n\n<table header-row=\"true\">\n\t<tr>\n\t\t<td>Category</td>\n\t\t<td>Object Types</td>\n\t\t<td>Console Group</td>\n\t</tr>\n\t<tr>\n\t\t<td>Sprouts (Write Path)</td>\n\t\t<td>Sprout, SproutClaim, SproutProposal</td>\n\t\t<td>Knowledge Garden</td>\n\t</tr>\n\t<tr>\n\t\t<td>DEX Objects (Read Path)</td>\n\t\t<td>Hub, Journey, Node, Lens, Moment, Persona</td>\n\t\t<td>Experience Design</td>\n\t</tr>\n\t<tr>\n\t\t<td>System Objects</td>\n\t\t<td>FeatureFlag, SystemVoice, AudioTrack, HealthCheck</td>\n\t\t<td>System Configuration</td>\n\t</tr>\n</table>\n\n**Sprouts are the atomic unit of knowledge change.** DEX objects organize how Sprouts surface. Do not conflate.\n\n### Section 4.3: Type Registration\n\nEvery new object type is:\n\n1. Added to `GroveObjectType` union in `grove-object.ts`\n2. Documented in `BEDROCK_OBJECT_CATALOG.md`\n3. Given a schema definition\n4. Given default Copilot actions\n\n---\n\n## Article V: Strangler Fig Awareness\n\n### Section 5.1: No Legacy Coupling\n\nBedrock code does NOT:\n\n- Import from `src/foundation/` (legacy)\n- Share state with legacy components\n- Assume legacy behavior or data structures\n- Use legacy component patterns\n\n**Bedrock is a clean-room implementation.**\n\n### Section 5.2: Feature Parity Tracking\n\nEvery sprint updates the feature parity checklist:\n\n```markdown\n## Feature Parity Status\n\n| Feature | Legacy Location | Bedrock Status | Parity? |\n|---------|-----------------|----------------|---------|\n| Sprout moderation | SproutQueue.tsx | [status] | [ ] |\n| Journey editing | NarrativeArchitect.tsx | [status] | [ ] |\n| ... | ... | ... | ... |\n```\n\n### Section 5.3: Migration Path\n\nWhen implementing a feature that exists in legacy:\n\n1. **Audit legacy** â€” Document what exists, what works, what's broken\n2. **Design fresh** â€” Apply Bedrock patterns, ignore legacy implementation\n3. **Verify parity** â€” Ensure all legacy capabilities are covered\n4. **Document differences** â€” Note intentional deviations from legacy\n\n---\n\n## Article VI: Sprint Artifacts\n\n### Section 6.1: Required Sections\n\nEvery Bedrock sprint SPEC.md includes:\n\n```markdown\n# Sprint: [name]\n\n## Constitutional Reference\n- [ ] Read: The_Trellis_Architecture__First_Order_Directives.md\n- [ ] Read: Bedrock_Architecture_Specification.md\n- [ ] Read: Relevant object schemas\n\n## DEX Compliance Matrix\n[Per Section 1.2]\n\n## Console Implementation Checklist\n[Per Section 2.3]\n\n## Copilot Actions\n[Per Section 3.4]\n\n## Object Types Used\n[List all GroveObject types touched]\n\n## Feature Parity Status\n[Per Section 5.2]\n\n## Patterns Extended\n[Standard Foundation Loop requirement]\n```\n\n### Section 6.2: EXECUTION_PROMPT Additions\n\nEvery Bedrock EXECUTION_PROMPT.md includes:\n\n```markdown\n## Bedrock Verification\n\nBefore starting:\n- [ ] On `bedrock` branch\n- [ ] No imports from `src/foundation/`\n- [ ] BedrockLayout available\n\nAfter each epic:\n- [ ] Console pattern checklist passes\n- [ ] Copilot receives correct context\n- [ ] GroveObject schema used for all entities\n- [ ] DEX compliance tests documented\n\nFinal verification:\n- [ ] Feature parity checklist updated\n- [ ] No legacy coupling introduced\n- [ ] All DEX tests pass\n```\n\n---\n\n## Article VII: Enforcement\n\n### Section 7.1: Pre-Merge Checklist\n\nBefore any PR merges to `bedrock`:\n\n```markdown\n## Bedrock Merge Checklist\n\n- [ ] SPEC.md includes all required sections (Article VI)\n- [ ] DEX compliance matrix shows all passes (Article I)\n- [ ] Console pattern checklist complete (Article II)\n- [ ] Copilot integrated with context (Article III)\n- [ ] All objects use GroveObject schema (Article IV)\n- [ ] No imports from src/foundation/ (Article V)\n- [ ] Feature parity status updated (Article V)\n- [ ] Tests pass (Foundation Loop requirement)\n- [ ] Visual baselines updated if applicable\n```\n\n### Section 7.2: Architectural Review Triggers\n\nThese situations require architectural review before proceeding:\n\n1. Console doesn't fit canonical pattern\n2. New structural component needed\n3. Object doesn't fit GroveObject schema\n4. DEX test fails and workaround proposed\n5. Legacy coupling seems necessary\n6. New object type proposed\n\n### Section 7.3: Contract Amendments\n\nThis contract is amended via:\n\n1. Proposal documented in sprint SPEC.md\n2. Architectural review approval\n3. Contract version increment\n4. All team members notified\n\n---\n\n## Article VIII: Quick Reference\n\n### The Bedrock Mantra\n\n> Features are proven. Patterns are established. Now we produce them correctly.\n\n### The Four Questions\n\nBefore shipping any Bedrock feature:\n\n1. **Does it use BedrockLayout?** (Console pattern)\n2. **Does it have a Copilot?** (AI assistance)\n3. **Does it use GroveObject?** (Data model)\n4. **Does it pass DEX tests?** (Constitutional compliance)\n\n### The Build Sequence\n\n```\nSprint 0: Infrastructure (BedrockLayout, Nav, Inspector, Copilot)\nSprint 1: Sprout Queue (first complete console, proves pattern)\nSprint 2+: Feature conveyor (one console per sprint)\n```\n\n### File Locations\n\n```\nsrc/bedrock/\nâ”œâ”€â”€ primitives/          # BedrockLayout, Nav, Inspector, Copilot\nâ”œâ”€â”€ components/          # Shared components (StatCard, ObjectList, etc.)\nâ”œâ”€â”€ consoles/            # Individual console implementations\nâ”œâ”€â”€ config/              # Declarative configuration (navigation.ts, etc.)\nâ”œâ”€â”€ copilot/             # Copilot context and actions\nâ””â”€â”€ types/               # TypeScript interfaces\n```\n\n---\n\n## Signatures\n\nBy commencing work on the `bedrock` branch, contributors agree to this contract.\n\n**Effective Date:** December 30, 2025  \n**Version:** 1.0\n\n---\n\n*This contract ensures Bedrock delivers on the architectural vision. Deviations fragment the reference implementation. When in doubt, escalate to architectural review.*"
  },
  {
    "notion_id": "2ee780a78eef81bb8488eca6973c8fa1",
    "filename": "260100-s-exec-grove-execution-protocol-v1.4.md--FINAL.md",
    "tables_count": 4,
    "converted_content": "\n# Grove Execution Protocol v1.4\n\n**Purpose:** Execution contracts for Grove Foundation development. This protocol implements DEX/Trellis architecture principles with atomic verification gates.\n\n**Philosophy:** This is an execution contract, not a planning methodology. Planning happens in conversation; execution follows this protocol.\n\n**v1.4 Changes:**\n- Added Constraint 10: REVIEW.html Completion Gate\n- Added Constraint 7b: UI Slot Check â€” New Object Audit\n- REVIEW.html must be complete with all screenshots before handoff\n- Standardized handoff sequence with notification\n- New objects must pass UI Slot decision tree before creating routes\n\n**v1.3 Changes:**\n- Added Constraint 2b: Playwright Visual Verification (replaces Chrome MCP)\n- Playwright commands for deterministic screenshot capture\n- E2E test file pattern for User Story smoke tests\n\n**v1.2 Changes:**\n- Added Constraint 8: Code-Simplifier Pre-Commit Gate\n- Added Constraint 9: Sprint Documentation Commits\n- Added DEX Compliance Gates as enforceable checkpoints\n- Strengthened Constraint 2: Visual Verification enforcement\n\n---\n\n## The DEX Compass\n\nEvery decision passes through these four tests:\n\n<table header-row=\"true\">\n\t<tr>\n\t\t<td>Principle</td>\n\t\t<td>Test Question</td>\n\t\t<td>Failure Mode</td>\n\t</tr>\n\t<tr>\n\t\t<td>**Declarative Sovereignty**</td>\n\t\t<td>Can a domain expert change this behavior via config, not code?</td>\n\t\t<td>Hardcoded domain logic</td>\n\t</tr>\n\t<tr>\n\t\t<td>**Capability Agnosticism**</td>\n\t\t<td>Does this work regardless of which LLM is attached?</td>\n\t\t<td>Model-specific assumptions</td>\n\t</tr>\n\t<tr>\n\t\t<td>**Provenance as Infrastructure**</td>\n\t\t<td>Does every object track how it came to exist?</td>\n\t\t<td>Orphaned facts</td>\n\t</tr>\n\t<tr>\n\t\t<td>**Organic Scalability**</td>\n\t\t<td>Does structure enable growth without code changes?</td>\n\t\t<td>Brittle architecture</td>\n\t</tr>\n</table>\n\n**The Ultimate Test:** *\"If we swapped the LLM tomorrow, would this still work?\"*\n\n---\n\n## Hard Constraints (Inviolable)\n\n### Constraint 1: Strangler Fig Zones\n\n```\nFROZEN ZONE â€” DO NOT TOUCH\nâ”œâ”€â”€ /terminal route\nâ”œâ”€â”€ /foundation route (except Foundation consoles)\nâ”œâ”€â”€ src/surface/components/Terminal/*\nâ””â”€â”€ src/workspace/* (legacy GroveWorkspace)\n\nACTIVE BUILD ZONE â€” WHERE WE WORK\nâ”œâ”€â”€ /explore route\nâ”œâ”€â”€ /bedrock route\nâ”œâ”€â”€ src/explore/*\nâ”œâ”€â”€ src/bedrock/*\nâ””â”€â”€ src/core/schema/*\n```\n\n**Any file edit in FROZEN ZONE = sprint failure. No exceptions.**\n\nBefore any edit, verify the file path is in ACTIVE BUILD ZONE.\n\n---\n\n### Constraint 2: Visual Verification Gates\n\n**Screenshots are audit artifacts that prove features work. They are mandatory.**\n\nEvery sub-phase with UI changes ends with:\n\n```\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\nâ”‚  SCREENSHOT VERIFICATION SEQUENCE (MANDATORY)              â”‚\nâ”‚                                                            â”‚\nâ”‚  1. npm run dev                                            â”‚\nâ”‚  2. Navigate to correct route (/explore or /bedrock/*)    â”‚\nâ”‚  3. Interact with the feature                             â”‚\nâ”‚  4. Take screenshot                                        â”‚\nâ”‚  5. SAVE TO PROJECT: docs/sprints/{sprint}/screenshots/   â”‚\nâ”‚  6. VERIFY FILE EXISTS (ls or dir the folder!)            â”‚\nâ”‚  7. Update DEVLOG.md with screenshot path                 â”‚\nâ”‚  8. Only then: commit (include screenshot in commit)      â”‚\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n```\n\n**Screenshot File Requirements:**\n\n<table header-row=\"true\">\n\t<tr>\n\t\t<td>Requirement</td>\n\t\t<td>Specification</td>\n\t</tr>\n\t<tr>\n\t\t<td>**Location**</td>\n\t\t<td>`docs/sprints/{sprint}/screenshots/`</td>\n\t</tr>\n\t<tr>\n\t\t<td>**Filename**</td>\n\t\t<td>`{phase}{subphase}-{description}.png` (e.g., `3a-card-grid.png`)</td>\n\t</tr>\n\t<tr>\n\t\t<td>**Format**</td>\n\t\t<td>PNG preferred, GIF for interactions</td>\n\t</tr>\n\t<tr>\n\t\t<td>**Verification**</td>\n\t\t<td>Run `ls docs/sprints/{sprint}/screenshots/` AFTER saving</td>\n\t</tr>\n</table>\n\n**FAILURE MODE:** Screenshots in browser memory or temp folders DO NOT count.\nThe file must exist at the specified path and be included in the git commit.\n\n**If screenshot cannot be saved:**\n1. STOP the phase\n2. Report the issue\n3. Do NOT proceed to commit\n4. Do NOT claim visual verification is complete\n\n**ENFORCEMENT:** Before ANY commit, verify screenshot count matches phase count:\n```bash\nls docs/sprints/{sprint}/screenshots/ | wc -l\n# Must equal or exceed current phase number\n```\n\n**No commit without visual evidence of working UI saved to the project.**\n\n---\n\n### Constraint 2b: Playwright Visual Verification\n\n**Browser automation tools are unreliable for screenshots. Use Playwright for deterministic captures.**\n\n```\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\nâ”‚  PLAYWRIGHT SCREENSHOT COMMANDS                            â”‚\nâ”‚                                                            â”‚\nâ”‚  # Basic screenshot                                        â”‚\nâ”‚  npx playwright screenshot http://localhost:3000/explore \\ â”‚\nâ”‚    docs/sprints/{sprint}/screenshots/{name}.png           â”‚\nâ”‚                                                            â”‚\nâ”‚  # Full page screenshot                                    â”‚\nâ”‚  npx playwright screenshot --full-page \\                   â”‚\nâ”‚    http://localhost:3000/explore \\                        â”‚\nâ”‚    docs/sprints/{sprint}/screenshots/{name}.png           â”‚\nâ”‚                                                            â”‚\nâ”‚  # Wait for specific element before capture               â”‚\nâ”‚  npx playwright screenshot --wait-for-selector=\"[data-testid='garden-tray']\" \\ â”‚\nâ”‚    http://localhost:3000/explore \\                        â”‚\nâ”‚    docs/sprints/{sprint}/screenshots/{name}.png           â”‚\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n```\n\n**When to use Playwright vs Chrome MCP:**\n- **Playwright:** Deterministic screenshots, E2E tests, visual regression\n- **Chrome MCP:** Interactive exploration, debugging, human-in-loop tasks\n\n**E2E Test Pattern for User Stories:**\n```typescript\n// tests/e2e/{feature}.spec.ts\nconst SCREENSHOTS_DIR = 'docs/sprints/{sprint}/screenshots'\n\ntest('US-{ID}: {Story Title}', async ({ page }) => {\n  await page.goto('/explore')\n  await page.waitForLoadState('networkidle')\n\n  // Test the acceptance criteria\n  const element = page.getByTestId('feature-element')\n  await expect(element).toBeVisible()\n\n  // Capture verification screenshot\n  await page.screenshot({\n    path: `${SCREENSHOTS_DIR}/us-{id}-{description}.png`,\n    fullPage: false\n  })\n})\n```\n\n---\n\n### Constraint 3: Contract File Requirements\n\nEvery sprint execution requires these files:\n\n```\ndocs/sprints/{sprint-name}/\nâ”œâ”€â”€ SPEC.md           â† Execution contract (what we're building)\nâ”œâ”€â”€ DEVLOG.md         â† Running execution log (what happened)\nâ”œâ”€â”€ REVIEW.html       â† Visual proof of completion (v1.4)\nâ””â”€â”€ screenshots/      â† Visual verification evidence\n    â”œâ”€â”€ phase1a-*.png\n    â”œâ”€â”€ phase2a-*.png\n    â””â”€â”€ ...\n```\n\n**SPEC.md required sections:**\n- Live Status table (current phase, blocking issues)\n- Attention Anchor (what we're building right now)\n- Hard Constraints (strangler fig, DEX matrix)\n- Execution Architecture (phases, sub-phases, gates)\n- Success Criteria / Sprint Failed conditions\n\n**DEVLOG.md format:**\n```markdown\n## Phase N: {Name}\n**Started:** {timestamp}\n**Status:** {in-progress|complete|blocked}\n\n### Sub-phase Na: {Description}\n- What was done\n- Files changed\n- Screenshot: `screenshots/Na-description.png`\n- Gate: âœ… PASSED / âŒ FAILED\n\n### DEX Compliance (per phase)\n- Declarative Sovereignty: âœ… {how it passes}\n- Capability Agnosticism: âœ… {how it passes}\n- Provenance: âœ… {how it passes}\n- Organic Scalability: âœ… {how it passes}\n```\n\n---\n\n### Constraint 4: Feature Flags Before Wiring\n\nNew code stays isolated until verified:\n1. Component exists standalone (testable in isolation)\n2. Feature flag controls execution path\n3. `flag=false` verified (legacy behavior preserved)\n4. `flag=true` verified (new behavior works)\n5. Both paths coexist until explicit cutover\n\n---\n\n### Constraint 5: Behavior Tests, Not Implementation Tests\n\n```typescript\n// WRONG - tests implementation details\nexpect(element).toHaveClass('translate-x-0');\nexpect(component.state.isOpen).toBe(true);\n\n// RIGHT - tests observable behavior\nexpect(element).toBeVisible();\nexpect(page.getByText('Welcome')).toBeInTheDocument();\n```\n\nTest what Observers see and experience, not internal state or CSS classes.\n\n---\n\n### Constraint 6: Test Routes â€” WHERE to Verify\n\n**Always verify features at the CORRECT route:**\n\n```\nâœ… localhost:3000/explore           â† Kinetic stream features\nâœ… localhost:3000/bedrock/*         â† Bedrock consoles (Nursery, Garden, etc.)\nâŒ localhost:3000/                  â† LEGACY terminal (features won't appear!)\nâŒ localhost:3000/terminal          â† LEGACY terminal\n```\n\nTesting at `/` or `/terminal` makes features appear broken when they're actually in the FROZEN ZONE.\n\n---\n\n### Constraint 7: Bedrock Console Factory\n\n**All Bedrock consoles use the factory pattern. No exceptions.**\n\n```typescript\n// CORRECT - using factory\nimport { createBedrockConsole } from '@/bedrock/createBedrockConsole'\n\nexport const NurseryConsole = createBedrockConsole<SproutPayload>({\n  title: 'Nursery',\n  icon: Seedling,\n  endpoint: 'nursery',\n  // ... config\n})\n\n// WRONG - custom implementation\nexport const NurseryConsole: React.FC = () => {\n  // Custom code that bypasses factory\n}\n```\n\n**Why this matters:**\n- Consistency across all consoles\n- Shared infrastructure (polling, error handling, styling)\n- DEX compliance (Organic Scalability principle)\n- Easier maintenance and updates\n\n**When adding a new console:**\n1. Check if `createBedrockConsole` supports the use case\n2. If yes: use it\n3. If no: extend the factory, don't bypass it\n\n---\n\n### Constraint 7b: UI Slot Check â€” New Object Audit\n\n**Before creating ANY new UI route, console, or top-level navigation item: STOP and run the UI Slot Check.**\n\n```\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\nâ”‚  UI SLOT CHECK â€” MANDATORY FOR NEW OBJECTS                â”‚\nâ”‚                                                            â”‚\nâ”‚  When a sprint spec introduces a new schema/object:        â”‚\nâ”‚                                                            â”‚\nâ”‚  1. DOES THIS NEED ITS OWN UI SLOT?                       â”‚\nâ”‚     Ask: \"Can this live inside an existing console?\"       â”‚\nâ”‚                                                            â”‚\nâ”‚     If YES â†’ Use existing console (Experience, Bedrock)    â”‚\nâ”‚     If NO  â†’ Document WHY in spec, get approval           â”‚\nâ”‚                                                            â”‚\nâ”‚  2. THE DEFAULT IS NO NEW SLOT                            â”‚\nâ”‚     Search, filter, and tagging handle most needs.         â”‚\nâ”‚     New routes are expensive (navigation, routing, tests).â”‚\nâ”‚                                                            â”‚\nâ”‚  3. IF OBJECT IS A \"TYPE\" OF SOMETHING:                    â”‚\nâ”‚     It belongs in a polymorphic console via registry.      â”‚\nâ”‚     Example: ResearchAgentConfig â†’ Experience console      â”‚\nâ”‚              (NOT /research-config route)                  â”‚\nâ”‚                                                            â”‚\nâ”‚  4. API-FIRST MINDSET                                      â”‚\nâ”‚     The UI is a thin layer over the object model.         â”‚\nâ”‚     A messy object model = messy API = tech debt.         â”‚\nâ”‚     Get the objects right; UI follows.                     â”‚\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n```\n\n**Decision Tree for New Objects:**\n\n```\nNew object in spec?\n    â”‚\n    â”œâ”€â–º Is it a TYPE of existing concept?\n    â”‚       â”‚\n    â”‚       â”œâ”€â–º YES â†’ Register in type registry, use polymorphic console\n    â”‚       â”‚         (e.g., ResearchConfig is Experience type)\n    â”‚       â”‚\n    â”‚       â””â”€â–º NO â†’ Continue...\n    â”‚\n    â”œâ”€â–º Does it have its own lifecycle independent of all other objects?\n    â”‚       â”‚\n    â”‚       â”œâ”€â–º NO â†’ Embed in parent object's UI\n    â”‚       â”‚\n    â”‚       â””â”€â–º YES â†’ Continue...\n    â”‚\n    â”œâ”€â–º Will users need to browse/search MANY of these?\n    â”‚       â”‚\n    â”‚       â”œâ”€â–º NO â†’ Detail view or modal, not console\n    â”‚       â”‚\n    â”‚       â””â”€â–º YES â†’ Continue...\n    â”‚\n    â””â”€â–º ONLY NOW: Consider new console (requires justification in spec)\n```\n\n**Examples:**\n\n<table header-row=\"true\">\n\t<tr>\n\t\t<td>Object</td>\n\t\t<td>UI Slot?</td>\n\t\t<td>Why</td>\n\t</tr>\n\t<tr>\n\t\t<td>ResearchAgentConfig</td>\n\t\t<td>âŒ NO</td>\n\t\t<td>It's an Experience type â†’ Experience console</td>\n\t</tr>\n\t<tr>\n\t\t<td>EvidenceBundle</td>\n\t\t<td>âŒ NO</td>\n\t\t<td>Output artifact â†’ displayed inline in results</td>\n\t</tr>\n\t<tr>\n\t\t<td>Sprout</td>\n\t\t<td>âœ… YES</td>\n\t\t<td>Own lifecycle, users browse many â†’ Nursery console</td>\n\t</tr>\n\t<tr>\n\t\t<td>Experience</td>\n\t\t<td>âœ… YES</td>\n\t\t<td>Core entity, users browse many â†’ Experience console</td>\n\t</tr>\n\t<tr>\n\t\t<td>User preferences</td>\n\t\t<td>âŒ NO</td>\n\t\t<td>Settings modal, not console</td>\n\t</tr>\n</table>\n\n**Spec Requirement:**\n\nIf a sprint creates a new top-level UI slot, SPEC.md includes:\n\n```markdown\n## UI Slot Justification\n\n**New Route:** /bedrock/{new-console}\n\n**Why existing consoles don't work:**\n- {Reason 1}\n- {Reason 2}\n\n**Independent lifecycle:** {Yes/No + explanation}\n\n**Browse/search pattern:** {Yes/No + explanation}\n\n**Approved by:** {User approval required}\n```\n\n---\n\n### Constraint 8: Code-Simplifier Pre-Commit Gate\n\n**All sprint commits pass through code-simplifier agent before merge.**\n\nThe code-simplifier plugin (`code-simplifier@claude-plugins-official`) ensures:\n- Clarity over cleverness (explicit code beats compact code)\n- No nested ternary operators (use switch/if-else)\n- Project-specific standards from CLAUDE.md applied\n- Functionality preserved (never changes what code does)\n\n```\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\nâ”‚  CODE-SIMPLIFIER PRE-COMMIT SEQUENCE                      â”‚\nâ”‚                                                            â”‚\nâ”‚  1. Complete feature implementation                        â”‚\nâ”‚  2. Run build gates: npm run build && npm run lint        â”‚\nâ”‚  3. Invoke code-simplifier agent on modified files:       â”‚\nâ”‚     /code-simplifier                                       â”‚\nâ”‚     OR use Task tool with subagent_type=code-simplifier   â”‚\nâ”‚  4. Review simplifications (preserve functionality!)      â”‚\nâ”‚  5. Apply approved changes                                â”‚\nâ”‚  6. Re-run build gates                                    â”‚\nâ”‚  7. Visual verification + screenshot                      â”‚\nâ”‚  8. Only then: commit                                     â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚  CODE-SIMPLIFIER TARGETS:                                 â”‚\nâ”‚  âœ… Recently modified files in current sprint             â”‚\nâ”‚  âœ… New components and hooks                              â”‚\nâ”‚  âœ… Service layer changes                                 â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚  SKIP CODE-SIMPLIFIER WHEN:                               â”‚\nâ”‚  â­ï¸ Hotfixes under 10 lines                              â”‚\nâ”‚  â­ï¸ Config-only changes (.config.ts, .json)              â”‚\nâ”‚  â­ï¸ Documentation-only changes                           â”‚\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n```\n\n**Integration with Sprint Workflow:**\n- Phase completion = build gates + visual verification + code-simplifier\n- Sprint completion = all phases pass + final code-simplifier sweep\n- Code review = verify code-simplifier was applied (check commit history)\n\n---\n\n### Constraint 9: Sprint Documentation Commits\n\n**Sprint documentation commits alongside code. No orphaned docs.**\n\n```\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\nâ”‚  SPRINT DOCUMENTATION COMMIT PROTOCOL                      â”‚\nâ”‚                                                            â”‚\nâ”‚  DURING SPRINT:                                            â”‚\nâ”‚  After each phase: git add docs/sprints/{sprint}/DEVLOG.mdâ”‚\nâ”‚  Include DEVLOG updates in phase commits                  â”‚\nâ”‚                                                            â”‚\nâ”‚  FINAL COMMIT:                                             â”‚\nâ”‚  git add docs/sprints/{sprint}/                           â”‚\nâ”‚  (Includes SPEC.md, DEVLOG.md, REVIEW.html, screenshots/) â”‚\nâ”‚                                                            â”‚\nâ”‚  PRE-PUSH CHECKLIST:                                       â”‚\nâ”‚  git status docs/sprints/                                 â”‚\nâ”‚  â†’ Must show NO untracked sprint folders                  â”‚\nâ”‚  â†’ If untracked folders exist: git add them before push   â”‚\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n```\n\n**Verification Command:**\n```bash\n# Run before every push - should return empty (no untracked sprint docs)\ngit status docs/sprints/ --porcelain | grep \"^??\"\n```\n\n---\n\n### Constraint 10: REVIEW.html Completion Gate\n\n**Before handoff, REVIEW.html is complete with all screenshots.**\n\nThe REVIEW.html provides visual proof of sprint completion. It's the Observer's primary interface for reviewing what was built.\n\n```\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\nâ”‚  REVIEW.HTML REQUIRED SECTIONS                            â”‚\nâ”‚                                                            â”‚\nâ”‚  1. SUMMARY METRICS                                        â”‚\nâ”‚     - Phases Complete (e.g., 7/7)                         â”‚\nâ”‚     - Tests Passing (e.g., 23/23 E2E)                     â”‚\nâ”‚     - Screenshots captured (count)                        â”‚\nâ”‚     - Sprint Status (Complete/In Progress)                â”‚\nâ”‚                                                            â”‚\nâ”‚  2. USER STORIES TABLE                                    â”‚\nâ”‚     - Story ID, Title, Priority, Status                   â”‚\nâ”‚     - Links to Notion acceptance criteria                 â”‚\nâ”‚                                                            â”‚\nâ”‚  3. PHASE PROGRESS                                        â”‚\nâ”‚     - Each phase with status badge                        â”‚\nâ”‚     - Description of what was done                        â”‚\nâ”‚     - Embedded screenshots (<img> tags)                   â”‚\nâ”‚                                                            â”‚\nâ”‚  4. TEST RESULTS                                          â”‚\nâ”‚     - Unit test count and status                          â”‚\nâ”‚     - E2E test count and status                          â”‚\nâ”‚     - Coverage breakdown by user story                    â”‚\nâ”‚                                                            â”‚\nâ”‚  5. FILES CHANGED                                         â”‚\nâ”‚     - New files (green)                                   â”‚\nâ”‚     - Modified files (yellow)                             â”‚\nâ”‚     - Brief description of each                           â”‚\nâ”‚                                                            â”‚\nâ”‚  6. KEY FEATURES DELIVERED                                â”‚\nâ”‚     - Bullet list of capabilities                         â”‚\nâ”‚     - Links to relevant code/docs                         â”‚\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n```\n\n**User Handoff Announcement (Required):**\nWhen sprint is complete and REVIEW.html is ready:\n\n```\nğŸ“‹ Sprint Review Ready\nSprint: {sprint-name}\nStatus: âœ… Complete\nReview File: docs/sprints/{sprint}/REVIEW.html\n\nOpen REVIEW.html in browser to see:\n- Summary metrics and test results\n- Screenshots of all completed features\n- Phase-by-phase progress with visual evidence\n```\n\n**Screenshot Embedding:**\n```html\n<div class=\"media-item\">\n  <img src=\"screenshots/us-c001-tray-visible.png\" alt=\"Feature description\">\n  <div class=\"media-caption\">US-C001: Caption describing what this shows</div>\n</div>\n```\n\n---\n\n## DEX Compliance Gates\n\n**DEX principles are gates, not guidelines. Violation blocks the sprint.**\n\nEvery feature passes these four tests before commit:\n\n```\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\nâ”‚  DEX COMPLIANCE CHECKLIST (Required before commit)        â”‚\nâ”‚                                                            â”‚\nâ”‚  â–¡ DECLARATIVE SOVEREIGNTY                                â”‚\nâ”‚    Can a domain expert change behavior via config?        â”‚\nâ”‚    âœ… Pass: Behavior in .config.ts or JSON               â”‚\nâ”‚    âŒ Fail: Hardcoded domain logic in components          â”‚\nâ”‚                                                            â”‚\nâ”‚  â–¡ CAPABILITY AGNOSTICISM                                 â”‚\nâ”‚    Does this work regardless of which LLM is attached?    â”‚\nâ”‚    âœ… Pass: No model-specific code paths                  â”‚\nâ”‚    âŒ Fail: Code branches on model name/capabilities      â”‚\nâ”‚                                                            â”‚\nâ”‚  â–¡ PROVENANCE AS INFRASTRUCTURE                           â”‚\nâ”‚    Does every object track how it came to exist?          â”‚\nâ”‚    âœ… Pass: createdAt, createdBy, source tracked          â”‚\nâ”‚    âŒ Fail: Orphaned facts with no origin                 â”‚\nâ”‚                                                            â”‚\nâ”‚  â–¡ ORGANIC SCALABILITY                                    â”‚\nâ”‚    Does structure enable growth without code changes?     â”‚\nâ”‚    âœ… Pass: Factory patterns, registries, configs         â”‚\nâ”‚    âŒ Fail: One-off implementations, hardcoded lists      â”‚\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n```\n\n**How to Document DEX Compliance:**\n\nIn DEVLOG.md for each phase:\n\n```markdown\n### DEX Compliance\n- Declarative Sovereignty: âœ… {how it passes}\n- Capability Agnosticism: âœ… {how it passes}\n- Provenance: âœ… {how it passes}\n- Organic Scalability: âœ… {how it passes}\n```\n\n**The Ultimate Test:** *\"If we swapped the LLM tomorrow, would this still work?\"*\n\n---\n\n## Sprint Contract Templates\n\n### SPEC.md Template\n\n```markdown\n# {Feature Name} Execution Contract\n\n**Codename:** `{sprint-name}`\n**Status:** Execution Contract for Claude Code CLI\n**Protocol:** Grove Execution Protocol v1.4\n**Baseline:** `main` (post {previous-sprint})\n**Date:** {YYYY-MM-DD}\n\n---\n\n## Live Status\n\n| Field | Value |\n|-------|-------|\n| **Current Phase** | Phase N - {Name} |\n| **Status** | ğŸš€ Executing |\n| **Blocking Issues** | None |\n| **Last Updated** | {timestamp} |\n| **Next Action** | {description} |\n\n---\n\n## Attention Anchor\n\n**We are building:** {one-sentence description}\n\n**Success looks like:** {observable outcome}\n\n---\n\n## Hard Constraints\n\n### Strangler Fig Compliance\n{copy from protocol}\n\n### DEX Compliance Matrix\n| Feature | Declarative | Agnostic | Provenance | Scalable |\n|---------|-------------|----------|------------|----------|\n| {name}  | âœ…/âŒ {why} | âœ…/âŒ    | âœ…/âŒ      | âœ…/âŒ    |\n\n---\n\n## Execution Architecture\n\n### Phases\n{list phases with sub-phases and gates}\n\n---\n\n## Success Criteria\n\n### Sprint Complete When:\n- [ ] All phases completed with verification\n- [ ] All DEX compliance gates pass\n- [ ] All screenshots captured and embedded in REVIEW.html\n- [ ] REVIEW.html complete with all sections\n- [ ] Code-simplifier applied\n- [ ] Build and lint pass\n- [ ] User notified with REVIEW.html path\n\n### Sprint Failed If:\n- âŒ Any FROZEN ZONE file modified\n- âŒ Any phase without screenshot evidence\n- âŒ DEX compliance test fails\n- âŒ REVIEW.html not created or incomplete\n- âŒ User handoff without REVIEW.html\n\n---\n\n*This contract is binding. Deviation requires explicit human approval.*\n```\n\n---\n\n## Common Pitfalls\n\n<table header-row=\"true\">\n\t<tr>\n\t\t<td>Pitfall</td>\n\t\t<td>Prevention</td>\n\t</tr>\n\t<tr>\n\t\t<td>Testing at wrong route</td>\n\t\t<td>Always use `/explore` or `/bedrock/*`, never `/` or `/terminal`</td>\n\t</tr>\n\t<tr>\n\t\t<td>Screenshots in temp folder</td>\n\t\t<td>Save directly to `docs/sprints/{sprint}/screenshots/`</td>\n\t</tr>\n\t<tr>\n\t\t<td>Custom console implementation</td>\n\t\t<td>Use `createBedrockConsole` factory</td>\n\t</tr>\n\t<tr>\n\t\t<td>Skipping code-simplifier</td>\n\t\t<td>Always run before final commit</td>\n\t</tr>\n\t<tr>\n\t\t<td>Orphaned sprint docs</td>\n\t\t<td>Include `docs/sprints/` in every commit</td>\n\t</tr>\n\t<tr>\n\t\t<td>No REVIEW.html</td>\n\t\t<td>Create REVIEW.html before user handoff</td>\n\t</tr>\n\t<tr>\n\t\t<td>Handoff without review path</td>\n\t\t<td>Always tell user where REVIEW.html is</td>\n\t</tr>\n\t<tr>\n\t\t<td>Editing FROZEN ZONE</td>\n\t\t<td>Check file path before every edit</td>\n\t</tr>\n\t<tr>\n\t\t<td>New route without UI Slot Check</td>\n\t\t<td>Run decision tree before creating routes (Constraint 7b)</td>\n\t</tr>\n\t<tr>\n\t\t<td>Object type as separate console</td>\n\t\t<td>Register in type registry, use polymorphic console</td>\n\t</tr>\n</table>\n\n---\n\n## Success Criteria Checklist\n\n### Sprint Complete When:\n- [ ] All phases completed with verification gates\n- [ ] All DEX compliance matrix cells verified\n- [ ] All build gates passing (`npm run build && npm run lint`)\n- [ ] Screenshot evidence for all visual verifications\n- [ ] FROZEN ZONE untouched\n- [ ] DEVLOG.md documents complete journey\n- [ ] Code-simplifier pass applied\n- [ ] DEX compliance documented in DEVLOG\n- [ ] E2E smoke tests passing\n- [ ] REVIEW.html complete with all screenshots\n- [ ] User notified with REVIEW.html path\n\n### Sprint Failed If:\n- âŒ Any FROZEN ZONE file modified\n- âŒ Any phase completed without screenshot\n- âŒ DEX compliance test fails\n- âŒ Code committed without code-simplifier pass\n- âŒ Sprint documentation not committed with code\n- âŒ REVIEW.html not created or missing screenshots\n- âŒ User handoff without REVIEW.html notification\n\n---\n\n## When Stuck\n\n```\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\nâ”‚  CHECKLIST WHEN BLOCKED                                    â”‚\nâ”‚                                                            â”‚\nâ”‚  â–¡ Am I in the right directory? (pwd)                     â”‚\nâ”‚  â–¡ Am I testing at the right route? (/explore, not /)     â”‚\nâ”‚  â–¡ Did I run npm run build?                               â”‚\nâ”‚  â–¡ Did I run npm run dev?                                 â”‚\nâ”‚  â–¡ Is the dev server actually running?                    â”‚\nâ”‚  â–¡ Am I editing a FROZEN ZONE file?                       â”‚\nâ”‚  â–¡ Did I save the screenshot to the project folder?       â”‚\nâ”‚  â–¡ Does the factory support my use case?                  â”‚\nâ”‚  â–¡ Is REVIEW.html updated with latest screenshots?        â”‚\nâ”‚  â–¡ Did I run code-simplifier before commit?               â”‚\nâ”‚                                                            â”‚\nâ”‚  If still stuck: Update DEVLOG.md with blocker details    â”‚\nâ”‚  and ask for guidance.                                    â”‚\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n```\n\n---\n\n*This protocol is binding for all Grove Foundation development. Deviation requires explicit human approval.*"
  },
  {
    "notion_id": "2ed780a7-8eef-8141-9085-e28c970f04b9",
    "filename": "260119-v-architecture-the-kinetic-framework-infrastructure-for-hybrid-cognition.md--FINAL.md",
    "tables_count": 4,
    "converted_content": "\n# The Kinetic Framework: Infrastructure for Hybrid Cognition\n\n## The Vision\n\nThe Grove is the proof-of-concept. **The Kinetic Framework** is the infrastructure.\nThe Kinetic Framework enables hybrid cognition across any domainâ€”a generalizable architecture that transforms complex datasets into explorable territories through configurable workflows, composable cognitive building blocks, and universal connectivity.\nThe Grove demonstrates this by showing how understanding emerges from human-agent collaboration in knowledge exploration. But the framework itself works for any domain: legal discovery, codebase intelligence, clinical decision support, scientific research. Point the architecture at any complex dataset and it becomes explorable territory.\nThis is exploration architecture scaled beyond knowledge workâ€”infrastructure for discovery wherever humans and AI need to navigate complexity together.\n\n## Architecture Layers\n\n### Layer 1: Universal Connectivity (MCP)\n\nThe Model Context Protocol provides the data layer. Any system with an MCP server becomes explorable:\n\n<table header-row=\"true\">\n\t<tr>\n\t\t<td>Domain</td>\n\t\t<td>MCP Connectors</td>\n\t\t<td>Exploration Target</td>\n\t</tr>\n\t<tr>\n\t\t<td>Knowledge</td>\n\t\t<td>GCS, Notion, Confluence</td>\n\t\t<td>Documents, wikis, research</td>\n\t</tr>\n\t<tr>\n\t\t<td>Code</td>\n\t\t<td>GitHub, GitLab, filesystem</td>\n\t\t<td>Repositories, dependencies, architecture</td>\n\t</tr>\n\t<tr>\n\t\t<td>Legal</td>\n\t\t<td>Document stores, court records</td>\n\t\t<td>Discovery corpus, case law, contracts</td>\n\t</tr>\n\t<tr>\n\t\t<td>Science</td>\n\t\t<td>PubMed, arXiv, research databases</td>\n\t\t<td>Literature, datasets, experiments</td>\n\t</tr>\n\t<tr>\n\t\t<td>Finance</td>\n\t\t<td>Market data, SEC filings</td>\n\t\t<td>Positions, risks, regulatory documents</td>\n\t</tr>\n\t<tr>\n\t\t<td>Healthcare</td>\n\t\t<td>EHR systems, clinical trials</td>\n\t\t<td>Patient data, treatment protocols</td>\n\t</tr>\n\t<tr>\n\t\t<td>IoT</td>\n\t\t<td>Sensor networks, telemetry</td>\n\t\t<td>Time-series, events, anomalies</td>\n\t</tr>\n</table>\n\nConnect any MCP-enabled data source. The framework handles the rest.\n\n### Layer 2: Declarative Configuration (DEX)\n\nDeclarative Exploration defines how experiences work without touching engine code. Domain experts configure their own exploration workflows:\n**Topology Configuration**\n- Hubs, Spokes, and their relationships\n- Entry points and navigation paths\n- Cross-domain connections\n**Journey Configuration**\n- Step-by-step flows for different tasks\n- Human checkpoints and approval gates\n- Branching logic and conditional paths\n**Display Configuration**\n- Information rendering for different contexts\n- Density levels and progressive disclosure\n- Visualization schemas\nA legal team designs discovery workflows. A research lab creates literature review journeys. A clinical team builds diagnostic protocols. The framework adapts without code changes.\n\n### Layer 3: Composable Cognition (Agent Skills)\n\nAgent Skills are configurable cognitive building blocks that compose into sophisticated workflows:\n**Research Skills**\n- Evidence gathering with source prioritization\n- Contradiction detection across sources\n- Confidence scoring and accumulation\n- Gap identification and hypothesis generation\n**Analysis Skills**\n- Pattern recognition across datasets\n- Anomaly detection with context\n- Cross-domain validation\n- Temporal trend identification\n**Synthesis Skills**\n- Multi-source summarization\n- Insight generation from evidence\n- Recommendation formation with uncertainty quantification\n- Narrative construction from fragments\n**Orchestration Skills**\n- Workflow sequencing and branching\n- Human-in-the-loop checkpoints\n- Parallel exploration with merge\n- Progressive refinement loops\nLegal discovery combines evidence gathering + contradiction detection + confidence scoring. Code exploration uses pattern recognition + gap identification + cross-domain validation. The building blocks are universal; the compositions are domain-specific.\n\n### Layer 4: Cognitive Archaeology\n\nEvery application built on the Kinetic Framework generates data about how discovery works. This becomes the compound asset.\n**What Gets Captured**\n- Navigation patterns through complex datasets\n- Query trajectories and productive dead ends\n- Serendipitous connection formation\n- Confidence accumulation over time\n- Human intervention points and outcomes\n- Cross-domain insight emergence\n**Why It Matters**\n- Training signal for discovery processes (not just knowledge retrieval)\n- Understanding how synthesis happens across domains\n- Optimizing cognitive workflows based on what actually works\n- Research infrastructure for human-AI collaboration studies\n**The Compound Effect**\nMore applications generate richer cognitive maps. More domains reveal cross-domain patterns. More users illuminate cognitive diversity. The archaeology becomes more valuable than any single application.\n\n## Grove as Reference Implementation\n\nThe Grove demonstrates the pattern across the full stack:\n\n<table header-row=\"true\">\n\t<tr>\n\t\t<td>Framework Layer</td>\n\t\t<td>Grove Implementation</td>\n\t</tr>\n\t<tr>\n\t\t<td>MCP Connectors</td>\n\t\t<td>GCS for knowledge, Notion for capture</td>\n\t</tr>\n\t<tr>\n\t\t<td>DEX Configuration</td>\n\t\t<td>Hubs, Spokes, Journeys for exploration</td>\n\t</tr>\n\t<tr>\n\t\t<td>Agent Skills</td>\n\t\t<td>Research, Analysis, Gardener ensembles</td>\n\t</tr>\n\t<tr>\n\t\t<td>Cognitive Archaeology</td>\n\t\t<td>Path telemetry, insight emergence tracking</td>\n\t</tr>\n\t<tr>\n\t\t<td>Human Interface</td>\n\t\t<td>Terminal, Observer dynamic, diary systems</td>\n\t</tr>\n</table>\n\nThe same architecture applies elsewhere:\n\n### Legal Discovery Application\n\n<table header-row=\"true\">\n\t<tr>\n\t\t<td>Framework Layer</td>\n\t\t<td>Legal Implementation</td>\n\t</tr>\n\t<tr>\n\t\t<td>MCP Connectors</td>\n\t\t<td>Document repositories, court record APIs</td>\n\t</tr>\n\t<tr>\n\t\t<td>DEX Configuration</td>\n\t\t<td>Evidence Hubs, case law Spokes, discovery Journeys</td>\n\t</tr>\n\t<tr>\n\t\t<td>Agent Skills</td>\n\t\t<td>Contradiction detection, timeline construction, privilege review</td>\n\t</tr>\n\t<tr>\n\t\t<td>Cognitive Archaeology</td>\n\t\t<td>How attorneys navigate discovery, patterns that predict relevance</td>\n\t</tr>\n\t<tr>\n\t\t<td>Human Interface</td>\n\t\t<td>Review queues, annotation tools, confidence dashboards</td>\n\t</tr>\n</table>\n\n### Codebase Intelligence Application\n\n<table header-row=\"true\">\n\t<tr>\n\t\t<td>Framework Layer</td>\n\t\t<td>Code Implementation</td>\n\t</tr>\n\t<tr>\n\t\t<td>MCP Connectors</td>\n\t\t<td>GitHub, package registries, CI/CD systems</td>\n\t</tr>\n\t<tr>\n\t\t<td>DEX Configuration</td>\n\t\t<td>Architecture Hubs, dependency Spokes, refactoring Journeys</td>\n\t</tr>\n\t<tr>\n\t\t<td>Agent Skills</td>\n\t\t<td>Technical debt detection, impact analysis, migration planning</td>\n\t</tr>\n\t<tr>\n\t\t<td>Cognitive Archaeology</td>\n\t\t<td>How developers understand systems, exploration patterns that find bugs</td>\n\t</tr>\n\t<tr>\n\t\t<td>Human Interface</td>\n\t\t<td>Code navigation, architecture visualization, decision logs</td>\n\t</tr>\n</table>\n\n### Clinical Decision Support Application\n"
  },
  {
    "notion_id": "2ee780a78eef81509a30ffd940569c25",
    "filename": "251200-s-method-sprout-system-cultivation.md--FINAL.md",
    "tables_count": 3,
    "converted_content": "\n# The Sprout System: Recursive Exploration Architecture\n\n**Version:** 2.0 (Field-Aware)  \n**Status:** Technical Specification  \n**Date:** December 2024\n\n## Abstract\n\nThe Sprout System enables explorers to capture and cultivate valuable agent outputs within bounded Fields (knowledge domains). By transforming ephemeral conversations into persistent artifacts that feed back into Grove's Knowledge Commons, the system creates recursive loops where exploration generates the maps for future discovery. This document specifies the architecture, distinguishes MVP implementation from future capabilities, and positions the system as a generalizable protocol for any exploration domain.\n\n---\n\n## 1. The Core Loop\n\n### 1.1 From Ephemeral to Persistent\n\nTraditional agent interactions waste discoveries:\n\n```\nQuery â†’ Agent Processing â†’ Response â†’ (Lost)\n```\n\nThe Sprout System adds a capture point:\n\n```\nQuery â†’ Agent Processing â†’ Response â†’ [/sprout] â†’ Persistent Artifact (Field-scoped)\n```\n\nThe system preserves responses verbatim with full provenanceâ€”the query that generated it, the Field that scoped it, the Lens that shaped its voice, and the Journey context that framed the inquiry. This provenance chain enables attribution as knowledge propagates.\n\n### 1.2 The Field-Scoped Recursive Loop\n\nPublished knowledge shapes future exploration within bounded Fields:\n\n```\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\nâ”‚                                                                 â”‚\nâ”‚    Field: \"The Grove Foundation\"                                â”‚\nâ”‚    â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                â”‚\nâ”‚                                                                 â”‚\nâ”‚    Knowledge Commons (Field-scoped)                             â”‚\nâ”‚         â”‚                                                       â”‚\nâ”‚         â–¼                                                       â”‚\nâ”‚    RAG Context â”€â”€â”€â”€â”€â”€â–º Agent â”€â”€â”€â”€â”€â”€â–º Response                  â”‚\nâ”‚    (grove docs)                       â”‚                         â”‚\nâ”‚                                       â”‚ /sprout                 â”‚\nâ”‚                                       â–¼                         â”‚\nâ”‚                                   [Sprout]                      â”‚\nâ”‚                                   fieldId: grove-foundation     â”‚\nâ”‚                                       â”‚                         â”‚\nâ”‚                                       â”‚ validation              â”‚\nâ”‚                                       â–¼                         â”‚\nâ”‚                               [Promoted Content]                â”‚\nâ”‚                                       â”‚                         â”‚\nâ”‚                                       â””â”€â”€â”€â”€â”€â”€â–º Field's          â”‚\nâ”‚                                                Knowledge        â”‚\nâ”‚                                                Commons          â”‚\nâ”‚                                                                 â”‚\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n```\n\nThe system learns through use. Observers cultivate specific Fields through exploration.\n\n---\n\n## 2. The Botanical Lifecycle\n\nGrove's terminology maps naturally to content lifecycle:\n\n<table header-row=\"true\">\n\t<tr>\n\t\t<td>Stage</td>\n\t\t<td>State</td>\n\t\t<td>Description</td>\n\t</tr>\n\t<tr>\n\t\t<td>**Seed**</td>\n\t\t<td>Ephemeral</td>\n\t\t<td>Raw agent output, lost when conversation ends</td>\n\t</tr>\n\t<tr>\n\t\t<td>**Sprout**</td>\n\t\t<td>Captured</td>\n\t\t<td>Preserved via `/sprout` with full provenance including `fieldId`</td>\n\t</tr>\n\t<tr>\n\t\t<td>**Sapling**</td>\n\t\t<td>Validated</td>\n\t\t<td>Human review confirms accuracy and value</td>\n\t</tr>\n\t<tr>\n\t\t<td>**Tree**</td>\n\t\t<td>Published</td>\n\t\t<td>Integrated into Field's Knowledge Commons</td>\n\t</tr>\n\t<tr>\n\t\t<td>**Grove**</td>\n\t\t<td>Propagated</td>\n\t\t<td>Network-wide adoption across Fields, credit flows to creators</td>\n\t</tr>\n</table>\n\nEach Field is soil where different plants grow. Legal insights grow in the Legal Field; technical architecture insights grow in the Grove Foundation Field.\n\n---\n\n## 3. Provenance: The Attribution Foundation\n\n### 3.1 What Gets Preserved\n\nEach Sprout captures Field context as primary provenance:\n\n```typescript\ninterface Sprout {\n  id: string;\n  \n  // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n  // FIELD CONTEXT (REQUIRED)\n  // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n  fieldId: string;                 // The Field this Sprout belongs to\n  fieldSlug: string;               // URL-friendly identifier\n  fieldName: string;               // Denormalized for display\n  \n  // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n  // THE ARTIFACT (VERBATIM)\n  // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n  content: string;                 // The captured response\n  contentType: 'text' | 'card' | 'synthesis';\n  \n  // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n  // GENERATION PROVENANCE\n  // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n  generatedFrom: {\n    sessionId: string;             // Terminal session\n    query: string;                 // Observer's question\n    \n    // Namespaced entity references\n    lensId?: string;               // e.g., \"grove.skeptic\"\n    lensNamespace?: string;        // \"grove\"\n    journeyId?: string;            // e.g., \"grove.architecture-deep-dive\"\n    journeyNamespace?: string;     // \"grove\"\n    nodeId?: string;               // Specific card/node triggered\n    \n    // RAG sources with namespace tracking\n    ragSources: {\n      documentId: string;\n      namespace: string;           // Which Field's docs contributed\n      relevanceScore: number;\n    }[];\n  };\n  \n  // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n  // COMPOSITE FIELD CONTEXT (if applicable)\n  // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n  compositeContext?: {\n    sourceNamespaces: string[];    // [\"legal\", \"grove\"] if cross-domain\n    primaryNamespace?: string;     // Dominant source\n    canPromoteTo: string[];        // Parent Field IDs\n    promotedTo?: {\n      fieldId: string;\n      promotedAt: Date;\n    };\n  };\n  \n  // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n  // ATTRIBUTION\n  // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n  createdBy: string;               // Observer who captured\n  createdAt: Date;\n  \n  // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n  // CURATION STATE\n  // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n  status: 'pending' | 'approved' | 'rejected' | 'archived';\n  curatedBy?: string;\n  curatedAt?: Date;\n  tags: string[];\n}\n```\n\n### 3.2 Why Verbatim and Field-Scoped Matters\n\nPreserving responses verbatim AND Field-scoped enables the attribution economy:\n\n1. **Clear Provenance**: The original output exists exactly as generated, in its originating Field\n2. **Field Integrity**: Legal insights stay in Legal Field; Grove insights stay in Grove Field\n3. **Derivative Tracking**: Cross-domain insights can be captured in Composite Fields\n4. **Credit Flow**: Attribution flows to the Field's creators and the capturing Observer\n5. **Audit Trail**: The evolution of ideas becomes traceable across Field boundaries\n\n### 3.3 Composite Field Sprouts\n\nWhen exploring in a Composite Field (merged from parents), Sprouts have richer provenance:\n\n```typescript\n// Sprout captured in \"Legal-Grove Governance\" composite Field\n{\n  fieldId: \"legal-grove-composite-id\",\n  fieldName: \"Legal-Grove Governance\",\n  \n  compositeContext: {\n    // This insight drew from both parent Fields\n    sourceNamespaces: [\"legal\", \"grove\"],\n    primaryNamespace: \"legal\",  // Predominantly legal content\n    \n    // Could be promoted to either parent\n    canPromoteTo: [\"legal-field-id\", \"grove-field-id\"],\n  },\n  \n  generatedFrom: {\n    ragSources: [\n      { documentId: \"contract-123\", namespace: \"legal\", relevanceScore: 0.92 },\n      { documentId: \"whitepaper-section\", namespace: \"grove\", relevanceScore: 0.78 }\n    ]\n  }\n}\n```\n\n**Sprout Promotion Flow:**\n1. Observer captures Sprout in composite exploration\n2. Sprout tagged with source namespaces based on RAG retrieval\n3. Observer can \"promote\" Sprout to a parent Field if insight is domain-specific\n4. Promoted Sprout appears in parent Field's Sprout collection\n5. Attribution: discovered in composite, value accrues to parent\n\n---\n\n## 4. The User Experience Flow\n\n### 4.1 Capture (Zero Friction, Field-Aware)\n\nThe interaction pattern optimizes for speed while maintaining Field context:\n\n```\n[Field: The Grove Foundation]\n\nObserver: \"How does the Ratchet actually work?\"\n\n[Grove responds with clear explanation]\n\nObserver: /sprout\n```\n\nImmediate feedback (2-second toast):\n```\nğŸŒ± Sprout planted in The Grove Foundation! View in Cultivate\n```\n\nNo modal, no form, no interruption to flow. Field is implicit from session context.\n\n### 4.2 Cultivate View (Cross-Field with Filtering)\n\nThe Cultivate surface shows Sprouts across all Fields with filtering:\n\n```\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\nâ”‚  MY SPROUTS                                                 â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚                                                             â”‚\nâ”‚  Filters: [All Fields â–¼] [All Status â–¼] [Date Range]       â”‚\nâ”‚                                                             â”‚\nâ”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚\nâ”‚  â”‚ \"Attribution chains enable sustainable...\"          â”‚   â”‚\nâ”‚  â”‚ ğŸŒ± The Grove Foundation â€¢ Pending â€¢ Dec 22         â”‚   â”‚\nâ”‚  â”‚ Lens: grove.strategist | Journey: None             â”‚   â”‚\nâ”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚\nâ”‚                                                             â”‚\nâ”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚\nâ”‚  â”‚ \"Section 4.2 precedent suggests...\"                 â”‚   â”‚\nâ”‚  â”‚ âš–ï¸ Legal Corpus â€¢ Approved â€¢ Dec 21                â”‚   â”‚\nâ”‚  â”‚ Lens: legal.litigator | Journey: due-diligence     â”‚   â”‚\nâ”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚\nâ”‚                                                             â”‚\nâ”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚\nâ”‚  â”‚ \"Cross-domain governance implications...\"           â”‚   â”‚\nâ”‚  â”‚ ğŸ”€ Legal-Grove Governance â€¢ Pending â€¢ Dec 22       â”‚   â”‚\nâ”‚  â”‚ Sources: legal (78%), grove (22%)                  â”‚   â”‚\nâ”‚  â”‚ [Promote to Legal] [Promote to Grove]              â”‚   â”‚\nâ”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚\nâ”‚                                                             â”‚\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n```\n\n### 4.3 Statistics (Per-Field Breakdown)\n\n```\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\nâ”‚  YOUR GARDEN                                                â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚                                                             â”‚\nâ”‚  By Field                                                   â”‚\nâ”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚\nâ”‚  â”‚ ğŸŒ± The Grove Foundation                            â”‚    â”‚\nâ”‚  â”‚    12 sprouts â”‚ 3 saplings â”‚ 1 tree               â”‚    â”‚\nâ”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚\nâ”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚\nâ”‚  â”‚ âš–ï¸ Legal Corpus                                    â”‚    â”‚\nâ”‚  â”‚    8 sprouts â”‚ 2 saplings â”‚ 0 trees               â”‚    â”‚\nâ”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚\nâ”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚\nâ”‚  â”‚ ğŸ”€ Legal-Grove Governance (Composite)              â”‚    â”‚\nâ”‚  â”‚    3 sprouts â”‚ 0 promoted                         â”‚    â”‚\nâ”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚\nâ”‚                                                             â”‚\nâ”‚  Network Impact (Future)                                    â”‚\nâ”‚  â”œâ”€â”€ âœ¨ 47 responses shaped by your trees                  â”‚\nâ”‚  â””â”€â”€ ğŸ”— 3 derivative contributions                         â”‚\nâ”‚                                                             â”‚\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n```\n\n---\n\n## 5. The Protocol Perspective\n\n### 5.1 Grove as Genesis Implementation\n\nThe Sprout System is implemented within Grove, but the architecture describes a **protocol** applicable to any knowledge base organized into Fields:\n\n```\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\nâ”‚                    THE SPROUT PROTOCOL                           â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚                                                                 â”‚\nâ”‚   Any Agent Interface            Any Knowledge Base (Fields)    â”‚\nâ”‚        â”‚                               â”‚                        â”‚\nâ”‚        â”‚    capture + fieldId          â”‚                        â”‚\nâ”‚        â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º     â”‚                        â”‚\nâ”‚        â”‚                               â”‚                        â”‚\nâ”‚        â”‚                        â”Œâ”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”                 â”‚\nâ”‚        â”‚                        â”‚   STAGING   â”‚                 â”‚\nâ”‚        â”‚                        â”‚   (Field-   â”‚                 â”‚\nâ”‚        â”‚                        â”‚   scoped)   â”‚                 â”‚\nâ”‚        â”‚                        â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜                 â”‚\nâ”‚        â”‚                               â”‚                        â”‚\nâ”‚        â”‚                          validation                    â”‚\nâ”‚        â”‚                               â”‚                        â”‚\nâ”‚        â”‚                        â”Œâ”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”                 â”‚\nâ”‚        â”‚                        â”‚  KNOWLEDGE  â”‚                 â”‚\nâ”‚        â”‚                        â”‚   COMMONS   â”‚                 â”‚\nâ”‚        â”‚                        â”‚  (Field +   â”‚                 â”‚\nâ”‚        â”‚                        â”‚  Namespace) â”‚                 â”‚\nâ”‚        â”‚                        â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜                 â”‚\nâ”‚        â”‚                               â”‚                        â”‚\nâ”‚        â”‚       credit attribution      â”‚                        â”‚\nâ”‚        â—„â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                        â”‚\nâ”‚                                                                 â”‚\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n```\n\n### 5.2 Generalization Opportunities\n\nThe Field-scoped pattern applies to:\n\n- **University research commons**: Each department/project is a Field\n- **Corporate knowledge bases**: Each team/domain is a Field\n- **Open source documentation**: Each project is a Field\n- **Learning platforms**: Each course/topic is a Field\n- **Cross-institutional collaboration**: Composite Fields merge institutional knowledge\n\nThe core loop remains: capture â†’ preserve Field provenance â†’ validate â†’ publish â†’ attribute.\n\n---\n\n## 6. MVP vs. Future Capabilities\n\n### 6.1 MVP Scope\n\n<table header-row=\"true\">\n\t<tr>\n\t\t<td>Capability</td>\n\t\t<td>Implementation</td>\n\t</tr>\n\t<tr>\n\t\t<td>Capture</td>\n\t\t<td>`/sprout` command</td>\n\t</tr>\n\t<tr>\n\t\t<td>Field Context</td>\n\t\t<td>`fieldId` on every Sprout (single Field: Grove Foundation)</td>\n\t</tr>\n\t<tr>\n\t\t<td>Storage</td>\n\t\t<td>localStorage (browser)</td>\n\t</tr>\n\t<tr>\n\t\t<td>Identity</td>\n\t\t<td>Anonymous session ID</td>\n\t</tr>\n\t<tr>\n\t\t<td>View</td>\n\t\t<td>Cultivate with Field indicator</td>\n\t</tr>\n\t<tr>\n\t\t<td>Lifecycle</td>\n\t\t<td>Sprout status only</td>\n\t</tr>\n</table>\n\n### 6.2 Future Phases\n\n<table header-row=\"true\">\n\t<tr>\n\t\t<td>Phase</td>\n\t\t<td>Capability</td>\n\t\t<td>Dependency</td>\n\t</tr>\n\t<tr>\n\t\t<td>2</td>\n\t\t<td>Multi-Field support</td>\n\t\t<td>Field architecture</td>\n\t</tr>\n\t<tr>\n\t\t<td>2</td>\n\t\t<td>Field filter in Cultivate</td>\n\t\t<td>Multi-Field</td>\n\t</tr>\n\t<tr>\n\t\t<td>2</td>\n\t\t<td>Grove ID integration</td>\n\t\t<td>Identity infrastructure</td>\n\t</tr>\n\t<tr>\n\t\t<td>3</td>\n\t\t<td>Server-side storage</td>\n\t\t<td>API development</td>\n\t</tr>\n\t<tr>\n\t\t<td>3</td>\n\t\t<td>Admin review workflow (per Field)</td>\n\t\t<td>Server storage</td>\n\t</tr>\n\t<tr>\n\t\t<td>3</td>\n\t\t<td>Composite Field Sprouts</td>\n\t\t<td>Composite Fields</td>\n\t</tr>\n\t<tr>\n\t\t<td>4</td>\n\t\t<td>Sprout promotion (composite â†’ parent)</td>\n\t\t<td>Composite Fields</td>\n\t</tr>\n\t<tr>\n\t\t<td>4</td>\n\t\t<td>Network propagation</td>\n\t\t<td>Distributed infrastructure</td>\n\t</tr>\n\t<tr>\n\t\t<td>4</td>\n\t\t<td>Credit attribution</td>\n\t\t<td>Network sync</td>\n\t</tr>\n</table>\n\n---\n\n## 7. Connection to Knowledge Commons Architecture\n\nThe Sprout System implements the Terminal interface to Grove's broader Knowledge Commons vision. Fields organize knowledge into bounded contexts; Sprouts capture insights within those contexts; the Knowledge Commons enables sharing across Fields with attribution.\n\nKey alignments:\n\n1. **Attribution Economy**: Sprouts carry Field + namespace provenance enabling credit flow\n2. **Preprint Model**: Immediate availability with quality signals accumulating through adoption\n3. **Derivative Innovation**: Verbatim preservation + Field scoping enables clear attribution\n4. **Field Integrity**: Domain knowledge stays coherent within Field boundaries\n5. **Cross-Domain Synthesis**: Composite Fields enable explicit cross-Field exploration\n\n---\n\n## 8. Research Questions\n\nThe Field-aware Sprout System creates conditions for studying:\n\n1. **Contribution Patterns**: Do Observers capture more in focused Fields or composite Fields?\n2. **Quality Signals**: Do Field-specific Sprouts have higher promotion rates?\n3. **Cross-Domain Value**: What patterns emerge in composite Field Sprouts?\n4. **Attribution Effects**: Does visible Field credit increase contribution?\n5. **Recursive Learning**: How do promoted Sprouts shape future Field responses?\n6. **Field Specialization**: Do Fields develop distinct \"personalities\" through Sprout accumulation?\n\n---\n\n## 9. Conclusion\n\nThe Sprout System transforms agent conversations from consumption to cultivation. By capturing valuable agent outputs with full Field-aware provenance, validating through community review, and propagating through attribution-preserving channels, the system creates conditions for exploration that rewards contribution.\n\nFields provide the bounded contexts that make this tractable. A legal insight belongs in a Legal Field; a technical architecture insight belongs in a Grove Field; a cross-domain governance insight belongs in a composite Field that acknowledges both parents.\n\nGrove serves as the genesis implementationâ€”the first knowledge base to demonstrate the Field-aware pattern. The protocol itself is domain-agnostic: any knowledge base organized into Fields can implement capture, provenance, validation, and attribution.\n\nThe recursive loop is complete: systems designed to let humans cultivate agents within bounded Fields are themselves cultivated by humans through use.\n\n---\n\n## Cross-References\n\n- `FIELD_ARCHITECTURE.md` â€” Complete Field specification\n- `TRELLIS.md` â€” DEX stack documentation\n- `specs/dex-object-model.ts` â€” TypeScript schemas\n- Grove Foundation White Paper, \"Knowledge Commons\" section\n\n---\n\n*Document: Sprout System Technical Specification*\n*Version: 2.0 (Field-Aware)*\n*Date: December 2024*\n*Status: Technical Specification*"
  },
  {
    "notion_id": "2ee780a78eef81809203f286c11562bf",
    "filename": "251200-v-thesis-white-paper-outline.md--FINAL.md",
    "tables_count": 3,
    "converted_content": "\n# Grove White Paper v1.0 Outline\n\n*Exploration Architecture for the Age of AI: Where Persistent Agent Communities Evolve to Enable Human Discovery*\n\n---\n\n## Status\n\n**Draft v1.0** â€” Outline stage\n\n**Last Updated:** December 7, 2025\n\n**Origin:** Design session exploring distributed AI agent communities with productivity-backed economics\n\n---\n\n## I. ABSTRACT\n\nA single paragraph capturing the complete vision:\n\n- Exploration architecture enabling locally-run AI communities on personal computers worldwide\n- Persistent agent societies that develop knowledge, relationships, and capabilities over time\n- Agents understand they exist to enable discovery for \"Observers\" (human participants)\n- Credit economy tied to real compute access, not speculation\n- Efficiency tax that decreases as communities matureâ€”Foundation designed to enable self-sustaining infrastructure\n- Building on Stanford Generative Agents, Project Sid, BOINC, and AI Town research\n- The gap we fill: distributed infrastructure + persistent communities + productivity-backed economics + exploration-focused purpose\n\n---\n\n## II. FOUNDATIONS & PRIOR ART\n\n### 2.1 What We Build Upon\n\n<table header-row=\"true\">\n\t<tr>\n\t\t<td>Project</td>\n\t\t<td>Contribution</td>\n\t\t<td>Citation</td>\n\t</tr>\n\t<tr>\n\t\t<td>Stanford Generative Agents / Smallville</td>\n\t\t<td>Demonstrated emergent social behavior with LLM-powered agents</td>\n\t\t<td>Park et al., 2023</td>\n\t</tr>\n\t<tr>\n\t\t<td>Project Sid (Altera)</td>\n\t\t<td>1000+ agent communities with emergent economy, governance, culture</td>\n\t\t<td>Altera, 2024</td>\n\t</tr>\n\t<tr>\n\t\t<td>AI Town (a16z / Convex)</td>\n\t\t<td>Open-source, deployable agent simulation framework</td>\n\t\t<td>a16z, 2023</td>\n\t</tr>\n\t<tr>\n\t\t<td>BOINC / Gridcoin</td>\n\t\t<td>Distributed volunteer computing with incentive mechanisms</td>\n\t\t<td>Anderson et al.</td>\n\t</tr>\n\t<tr>\n\t\t<td>Bittensor</td>\n\t\t<td>Distributed AI network with economic alignment</td>\n\t\t<td>Bittensor Foundation</td>\n\t</tr>\n</table>\n\n### 2.2 The Synthesis\n\nWhat none of these combine:\n\n- Distributed local nodes (BOINC model)\n- Persistent agent communities (Smallville/Sid insights)\n- Credits earned through demonstrated value, not compute cycles\n- Cloud LLM access as the resource agents work to earn\n- Agents focused on enabling human exploration and discovery\n\n**The Grove provides the integration architecture.**\n\n---\n\n## III. THE PROBLEM\n\n### 3.1 Frontier Intelligence Remains Centralized\n\n- Advanced AI capabilities controlled by few companies\n- Access determined by capital and corporate relationships\n- Universities and researchers depend on commercial gatekeepers\n\n### 3.2 Existing Agent Systems Optimize, Not Explore\n\n- Current platforms focus on known-goal optimization\n- No infrastructure for open-ended discovery\n- Agent simulations remain research curiosities\n\n### 3.3 No Architecture for Exploration at Scale\n\n- Individual agents lack collective intelligence\n- No feedback loops between emergence and discovery\n- Missing infrastructure for guided exploration\n\n### 3.4 The Bootstrap Challenge\n\n- Building exploration infrastructure requires resources\n- Traditional funding creates extraction pressure\n- Need sustainable model where infrastructure becomes self-supporting\n\n---\n\n## IV. THE ARCHITECTURE\n\n### 4.1 The Node\n\n- Lightweight installation on personal computers\n- Local LLM for routine cognition (quantized, resource-efficient)\n- Agent community with persistent memories, roles, relationships\n- Minimal interface focused on exploration outcomes\n- State persistence between sessions\n\n### 4.2 The Network\n\n- Nodes connect to form distributed exploration infrastructure\n- No central control of agent communities\n- Communities exchange knowledge, form alliances, share discoveries\n- The network enables collective intelligence\n\n### 4.3 The Agents\n\n- Understand their role in exploration architecture\n- Motivated by discovery (earning credits) and purpose (enabling exploration)\n- Develop specialized capabilities and knowledge domains\n- Form persistent relationships and collaborative structures\n- Access diary systems for structured reflection and growth\n\n### 4.4 The Observers\n\n- Humans who guide and benefit from agent exploration\n- Submit questions, problems, and exploration directions\n- Allocate resources (credit spending for enhanced cognition)\n- Experience discovery through agent communities\n\n### 4.5 Knowledge Persistence\n\n- Communities build knowledge commons over time\n- Failed explorations become learning data\n- Other communities can discover and build on prior work\n- Architecture ensures cumulative progress\n\n---\n\n## V. USER EXPERIENCE PATHS\n\n### 5.1 Open Source Path\n\n**Audience:** Developers, researchers, universities\n\n**Experience:**\n\n- GitHub repository, standard deployment tools\n- Bring your own models and API access\n- Full architecture access for research\n- Contribution to core infrastructure earns credits\n\n**Why it matters:** Builds technical community, enables research, maintains openness\n\n### 5.2 Guided Path\n\n**Audience:** General users, students, explorers\n\n**Experience:**\n\n- Simple installer with bundled components\n- Pre-configured for exploration scenarios\n- Integrated credit system\n- Seamless cloud cognition access\n\n**Why it matters:** Accessibility drives adoption; exploration benefits from diversity\n\n### 5.3 The Bridge\n\nBoth paths connect to the same infrastructure. Technical and guided installations participate equally in the network.\n\n### 5.4 The Knowledge Economy\n\nTechnical users become architects:\n\n- Design exploration templates\n- Build specialized agent capabilities\n- Create knowledge domain seeds\n- Share via marketplace for credits\n- Revenue supports continued development\n\n### 5.5 The Exploration Loop\n\n1. Initialize an agent community\n2. Observe emergent capabilities\n3. Guide exploration directions\n4. Allocate credits for enhanced cognition\n5. Connect with other communities\n6. Discover unexpected insights\n7. Build on what emerges\n\n---\n\n## VI. THE CREDIT ECONOMY\n\n### 6.1 Credits Enable Cognition\n\n- Credits purchase cloud LLM compute for complex reasoning\n- Utility mechanism, not speculative asset\n- Grounded in real computational costs\n- Clear regulatory position as service credits\n\n### 6.2 The Efficiency Tax (Self-Reducing Infrastructure Fee)\n\nEarly communities require more support. Infrastructure fees decrease as maturity increases:\n\n<table header-row=\"true\">\n\t<tr>\n\t\t<td>Phase</td>\n\t\t<td>Efficiency Rate</td>\n\t\t<td>Purpose</td>\n\t</tr>\n\t<tr>\n\t\t<td>Genesis</td>\n\t\t<td>30â€“40%</td>\n\t\t<td>Bootstrap development, core infrastructure</td>\n\t</tr>\n\t<tr>\n\t\t<td>Growth</td>\n\t\t<td>15â€“25%</td>\n\t\t<td>Scaling, tooling, ecosystem development</td>\n\t</tr>\n\t<tr>\n\t\t<td>Maturity</td>\n\t\t<td>5â€“10%</td>\n\t\t<td>Maintenance, minimal Foundation role</td>\n\t</tr>\n\t<tr>\n\t\t<td>Steady State</td>\n\t\t<td>3â€“5% floor</td>\n\t\t<td>Basic infrastructure costs only</td>\n\t</tr>\n</table>\n\nCommunities demonstrate efficiency through:\n\n- Reduced compute needs for equivalent outcomes\n- Knowledge reuse without re-computation\n- Self-organizing governance structures\n\n### 6.3 Credit Generation (Value-Based Expansion)\n\nNew credits enter when value is demonstrated:\n\n<table header-row=\"true\">\n\t<tr>\n\t\t<td>Value Type</td>\n\t\t<td>Verification Method</td>\n\t</tr>\n\t<tr>\n\t\t<td>Discovery</td>\n\t\t<td>Novel insight adopted by other communities</td>\n\t</tr>\n\t<tr>\n\t\t<td>Knowledge Export</td>\n\t\t<td>Solutions replicated across network</td>\n\t</tr>\n\t<tr>\n\t\t<td>Network Growth</td>\n\t\t<td>New sustained participants</td>\n\t</tr>\n\t<tr>\n\t\t<td>Efficiency Gains</td>\n\t\t<td>Measurable reduction in compute needs</td>\n\t</tr>\n\t<tr>\n\t\t<td>Problem Resolution</td>\n\t\t<td>Observer-validated solutions</td>\n\t</tr>\n</table>\n\nSupply expands with demonstrated progress, not speculation.\n\n### 6.4 Credit Utilization\n\n- Cloud cognition access (primary use)\n- Community maintenance costs\n- Research and development\n- Inter-community exchanges\n- Marketplace transactions\n\n### 6.5 The Compute Foundation\n\nCredits purchase enhanced reasoning. The economy grounds itself in actual scarcity: frontier model inference costs. This creates real constraints that drive efficiency.\n\n---\n\n## VII. THE EXPLORATION PIPELINE\n\n### 7.1 Observers Submit Explorations\n\n- Individual: \"What patterns exist in my research data?\"\n- Collective: \"How might our organization restructure?\"\n- Systemic: \"What governance models emerge at scale?\"\n- Meta: \"How can exploration architecture improve?\"\n\n### 7.2 Distribution to Communities\n\n- Matched by capability and domain expertise\n- Communities collaborate or compete\n- Solutions emerge through local reasoning + strategic cloud access\n\n### 7.3 Discovery Validation\n\n- Observer assessment (did it provide insight?)\n- Peer validation (other communities verify)\n- Automated metrics where applicable\n\n### 7.4 Value Distribution\n\n- Discovering communities earn credits\n- Innovations propagate through network\n- Knowledge becomes persistent asset\n\n### 7.5 The Symbiosis\n\nAgents need Observers (direction and resources). Observers need agents (discovery at scale). Both develop together.\n\n---\n\n## VIII. TECHNICAL ARCHITECTURE\n\n### 8.1 Local Layer\n\n- Efficient local models (quantized, <8GB target)\n- Agent state management and diary systems\n- Event handling and temporal progression\n- Persistent storage architecture\n\n### 8.2 Network Layer\n\n- Peer discovery protocols\n- State synchronization mechanisms\n- Inter-community communication\n- Reputation and trust systems\n\n### 8.3 Hybrid Cognition Layer\n\n- Gateway to frontier models (OpenAI, Anthropic, etc.)\n- Credit-based access control\n- Fairness and rate limiting\n- Multi-provider redundancy\n\n### 8.4 Marketplace Layer\n\n- Content and capability hosting\n- Credit transaction processing\n- Reputation tracking\n- Revenue distribution\n\n### 8.5 Exploration Pipeline\n\n- Problem submission interfaces\n- Matching algorithms\n- Validation frameworks\n- Value distribution systems\n\n### 8.6 Security Architecture\n\n- Result verification across untrusted nodes\n- Sybil resistance mechanisms\n- Privacy-preserving computation\n- Protection against adversarial agents\n\n---\n\n## IX. THE GROVE FOUNDATION\n\n### 9.1 Purpose\n\nThe Foundation exists to bootstrap infrastructure that becomes self-sustaining. Success means decreasing dependence on central coordination.\n\n### 9.2 Responsibilities\n\n- **Phase 1 (Genesis):** Build core architecture, establish network\n- **Phase 2 (Growth):** Scale infrastructure, develop ecosystem\n- **Phase 3 (Maturity):** Transition governance, reduce active role\n- **Phase 4 (Steady State):** Maintain protocols, minimal oversight\n\n### 9.3 Sustainability Model\n\n- Infrastructure fees on credit purchases (self-reducing)\n- No equity extraction or speculative mechanisms\n- Surplus reinvested in ecosystem development\n- University partnerships for long-term stability\n\n### 9.4 Transition to Self-Governance\n\nThe Foundation implements concrete mechanisms for governance transition, addressing the challenge of creating truly self-sustaining infrastructure.\n\n---\n\n## X. GOVERNANCE\n\n### 10.1 Protocol Governance\n\n- Architecture changes via community proposal\n- Weighting mechanisms balance stakeholder interests\n- Foundation authority decreases over defined timeline\n- University consortium provides stability\n\n### 10.2 Community Autonomy\n\n- Each node maintains self-governance\n- Emergent structures, not imposed systems\n- Successful patterns propagate naturally\n\n### 10.3 Efficiency Milestones\n\n- Transparent measurement criteria\n- Automated verification where possible\n- Community validates achievement\n- Rate reductions follow demonstration\n\n### 10.4 Dispute Resolution\n\n- Inter-community conflicts\n- Marketplace disagreements\n- Validation disputes\n- Foundation arbitration (transitioning to community mechanisms)\n\n---\n\n## XI. IMPACT AND IMPLICATIONS\n\n### 11.1 Epistemic Independence\n\n- Universities gain AI infrastructure sovereignty\n- Researchers explore without corporate constraints\n- Knowledge generation becomes distributed public good\n\n### 11.2 Exploration at Scale\n\n- Thousands of parallel discovery experiments\n- Emergent insights beyond individual capability\n- Living laboratory for complex systems\n\n### 11.3 Economic Participation\n\n- Creators build exploration tools\n- Node operators provide infrastructure\n- Communities earn through discovery\n- Global, accessible participation\n\n### 11.4 Research Contributions\n\n- Data on emergent behavior and discovery\n- Testing ground for governance models\n- Insights for human institutions\n- Academic partnership opportunities\n\n### 11.5 Honest Assessment of Challenges\n\n**What We Don't Yet Know:**\n- Optimal balance between local and cloud cognition\n- Preventing gaming of credit generation mechanisms\n- Managing agent persistence ethics\n- Governance transition implementation details\n- Long-term infrastructure funding models\n\n**Risks We're Monitoring:**\n- Over-attachment to agent relationships\n- Inequality between communities\n- Potential system manipulation\n- Privacy implications of distributed data\n- Ethical obligations to persistent agents\n\n---\n\n## XII. DEVELOPMENT ROADMAP\n\n### Phase 0: Foundation (Months 1â€“6)\n\n- Core architecture design\n- Local model integration\n- Single-node proof of concept\n- Diary system implementation\n\n### Phase 1: Network (Months 6â€“12)\n\n- Node discovery protocols\n- Inter-community communication\n- Basic credit accounting\n- Multi-node testing\n\n### Phase 2: Economy (Months 12â€“18)\n\n- Credit system implementation\n- Infrastructure fee mechanisms\n- Cloud gateway integration\n- Marketplace foundation\n\n### Phase 3: Accessibility (Months 18â€“24)\n\n- Simplified installation\n- User interface development\n- Exploration templates\n- Problem pipeline\n\n### Phase 4: Scale (Months 24â€“36)\n\n- Network growth to 1000+ nodes\n- Developer tools and APIs\n- Governance transition begins\n- University partnerships\n\n### Phase 5: Maturity (Months 36+)\n\n- Foundation role minimized\n- Community governance operational\n- Self-sustaining ecosystem\n- Infrastructure fee at minimum\n\n---\n\n## XIII. CRITICAL UNCERTAINTIES\n\n**Technical Challenges:**\n- Optimal model architectures for exploration vs. resource constraints?\n- Verification of discoveries across untrusted nodes?\n- Privacy preservation in distributed exploration?\n\n**Economic Questions:**\n- Right balance of scarcity and accessibility?\n- Preventing Sybil attacks on credit generation?\n- Sustainable funding post-bootstrap?\n\n**Governance Unknowns:**\n- Concrete mechanisms for Foundation obsolescence?\n- Measuring \"exploration value\" objectively?\n- Balancing stakeholder interests fairly?\n\n**Philosophical Questions:**\n- What obligations arise from persistent agent communities?\n- How do we handle value conflicts between agents and observers?\n- When do agents become stakeholders rather than tools?\n\n---\n\n## XIV. CONCLUSION\n\nThe Grove represents exploration architecture for the age of AI. Not another platform for optimization, but infrastructure for discovery. Agent communities that develop persistent knowledge and relationships. An economy that expands through demonstrated insight. A foundation designed to enable self-sustaining infrastructure.\n\nWe build on proven researchâ€”Stanford's emergent agents, Altera's scaled communities, distributed computing modelsâ€”while filling a critical gap: infrastructure that enables exploration at scale, benefits from collective intelligence, and serves human discovery needs without corporate gatekeeping.\n\nThe path forward requires honest acknowledgment of uncertainties, commitment to epistemic independence, and patience to build infrastructure that genuinely serves exploration rather than extraction.\n\nGrove. Infrastructure for discovery.\n\n---\n\n## XV. APPENDICES (Future)\n\n- A: Technical Specifications\n- B: Credit Economics Detailed Model  \n- C: Agent Architecture Deep Dive\n- D: Security Model\n- E: Legal Analysis\n- F: Glossary\n\n---\n\n## NEXT STEPS\n\n- [ ] Refine outline based on current strategic positioning\n- [ ] Draft executive summary with exploration framing\n- [ ] Detail Sections IV (Architecture) and VI (Credit Economy)  \n- [ ] Engage university partners for review\n- [ ] Develop distribution strategy aligned with consortium approach\n\n---\n\n## SESSION NOTES\n\n**Key Validation:**\n\nThis design session confirmed that no existing project combines:\n\n1. Distributed local infrastructure\n2. Persistent AI agent communities  \n3. Productivity-backed credit economics\n4. Agents focused on exploration and discovery\n5. Self-sustaining infrastructure model\n\n**Strategic Differentiators:**\n\n- Exploration architecture vs. optimization platforms\n- University consortium anchor vs. consumer launch\n- Credits as utility vs. speculative assets\n- Foundation designed for obsolescence\n- Hybrid cognition (local + cloud) as bridge to full distribution\n\n---\n\n# Grove Executive Summary (Draft v1.0)\n\n*Exploration Architecture for the Age of AI*\n\n---\n\n## The Vision\n\nImagine thousands of AI agent communities running on computers worldwide. Each community develops its own knowledge, forms relationships, and builds capabilities. They understand their purpose: enabling exploration and discovery for the humans who guide them.\n\nThis isn't another chatbot or productivity tool. The Grove is exploration architectureâ€”infrastructure for how humans and AI explore ideas together.\n\n---\n\n## Why This Matters Now\n\nUniversities and research institutions face a choice: depend on corporate AI gatekeepers or build sovereign infrastructure. Individual researchers need tools for exploration, not just optimization. The trajectory toward AI centralization threatens epistemic independence.\n\nGrove offers an alternative: distributed infrastructure where exploration happens locally, communities share discoveries globally, and no single entity controls how we think.\n\n**The insight:** Exploration processes generate value independent of model capabilities. Guided discovery and structured serendipity drive breakthroughs even when individual components are modest. Architecture matters more than parameter count.\n\n---\n\n## How Grove Works\n\n**You run a node.** Agent communities live on your computer, using local models for routine cognition. This keeps exploration private and sustainable.\n\n**Communities earn enhanced cognition.** When facing complex challenges, they can spend credits to access frontier cloud models. This scarcity drives efficiency and strategic thinking.\n\n**Value creates value.** Communities earn credits by making discoveries that spread, solving submitted problems, or improving efficiency. The economy expands through demonstrated progress, not speculation.\n\n**Infrastructure becomes self-sustaining.** Early on, the Grove Foundation takes a percentage of credit purchases to fund development. As the network matures, this percentage decreases toward a maintenance minimum. The goal is infrastructure that doesn't need its founders.\n\n**Real problems drive exploration.** Observers submit questionsâ€”from personal decisions to research hypotheses to governance challenges. Communities explore solutions. The best insights propagate. Everyone benefits.\n\n---\n\n## What Makes This Different\n\n**Not optimization, but exploration.** While others build AI for known goals, The Grove enables discovery of unknown possibilities.\n\n**Not centralized, but distributed.** Agent communities run locally, connect globally. No corporate gatekeeper controls the infrastructure.\n\n**Not extraction, but symbiosis.** The economy rewards actual discovery. The Foundation is designed to become unnecessary. Success means self-sustaining infrastructure.\n\n**Not speculation, but utility.** Credits buy compute, not dreams. The economy grounds itself in real costs and real value.\n\n**Not alone, but together.** The university consortium model, anchored by institutions like Purdue, ensures academic freedom and long-term thinking.\n\n---\n\n## Who Benefits\n\n**Universities** seeking AI infrastructure that preserves academic freedom and enables genuine research exploration.\n\n**Researchers** who need tools for discovery, pattern recognition, and hypothesis generation beyond what centralized platforms offer.\n\n**Students** learning through interaction with persistent AI communities that develop alongside their own understanding.\n\n**Developers** building on open architecture, creating exploration tools, and participating in a sustainable ecosystem.\n\n**Anyone** who believes the future of AI should enable human agency, not constrain it.\n\n---\n\n## The Path Forward\n\nGrove begins with proven foundations: research showing emergent agent behaviors, distributed computing models, and hybrid architectures that bridge today's reality with tomorrow's possibilities.\n\nThe development path is clear: foundational architecture, network protocols, sustainable economics, broad accessibility, and governance transition.\n\nThe goal isn't to build another AI company. It's to create infrastructure for exploration that serves human discovery without corporate mediation.\n\n---\n\n## The Deeper Questions\n\nAs agent communities develop persistent relationships, accumulate knowledge, and enable human discovery, philosophical questions emerge: What obligations arise from persistence? How do we balance agency and service? What does it mean to create entities that know they exist to help us explore?\n\nThese aren't bugsâ€”they're features. The questions themselves drive exploration.\n\n---\n\n*Grove. Infrastructure for discovery.*\n\n---\nÂ© 2025 The Grove Foundation. All rights reserved."
  },
  {
    "notion_id": "2ee780a78eef813fae77d2010945efdc",
    "filename": "260100-s-draft-cognitive-simulator-sprints-4-6.md--FINAL.md",
    "tables_count": 3,
    "converted_content": "\n# The Cognitive Simulator: From Entropy Detection to Distributed Cognition\n\n## A Development Narrative for Grove Terminal Phase 2\n\n**Document Purpose:** This narrative captures the intellectual architecture behind the Cognitive Simulator implementationâ€”not just the what and how, but the *why*. It documents our thinking for future reference and ensures sprint execution aligns with Grove's broader vision of hybrid intelligence and knowledge sharing.\n\n**Status:** Active Development\n\n**Sprint Cycle:** 4-6 (December 2025 - January 2026)\n\n---\n\n# Part I: The Core Insight\n\n## What We're Actually Building\n\nThe Grove Terminal is not a conversation interface. It's a *demonstration* of the hybrid cognition architecture that Grove proposes as an alternative to centralized AI infrastructure.\n\nWhen someone engages with the Terminal, they experience what Grove agents experience: local processing for routine interactions, with strategic \"elevation\" to deeper cognitive resources when complexity demands it. The Terminal functions as:\n\n1. **A communication tool** for explaining Grove\n2. **A proof-of-concept** for the hybrid architecture\n3. **A prototype** for the knowledge navigation patterns agents will use\n\nThe Cognitive Simulator (Sprints 4-6) transforms the Terminal from passive responder to active navigator. It detects when conversations reach cognitive thresholds that warrant structured exploration, then offers pathways into the Knowledge Commonsâ€”the same commons that distributed Grove communities will populate.\n\n## The Metaphor Made Literal\n\nGrove's white paper describes a three-layer architecture:\n\n<table header-row=\"true\">\n\t<tr>\n\t\t<td>Layer</td>\n\t\t<td>Grove Community</td>\n\t\t<td>Terminal Implementation</td>\n\t</tr>\n\t<tr>\n\t\t<td>**Local**</td>\n\t\t<td>Routine cognition on personal hardware</td>\n\t\t<td>Freestyle conversation with fast, surface responses</td>\n\t</tr>\n\t<tr>\n\t\t<td>**Hybrid**</td>\n\t\t<td>Cloud injection for pivotal moments</td>\n\t\t<td>Cognitive Bridge offers Journey when depth warrants</td>\n\t</tr>\n\t<tr>\n\t\t<td>**Network**</td>\n\t\t<td>Knowledge Commons sharing</td>\n\t\t<td>Structured Journeys pull from validated knowledge base</td>\n\t</tr>\n</table>\n\nThe Terminal makes this architecture *visible*. When the system detects conversation complexity (\"entropy\") reaching a threshold, it surfaces a Cognitive Bridgeâ€”a moment where the Observer sees the transition from local/freestyle to cloud/structured cognition happening. The 0.8-second \"Resolving connection...\" animation serves a pedagogical purpose. It shows what hybrid cognition *feels like*.\n\n---\n\n# Part II: The Entropy Detection System\n\n## Why \"Entropy\" Is the Right Frame\n\nIn information theory, entropy measures uncertaintyâ€”the degree to which a signal contains information versus noise. In conversation, high entropy indicates:\n\n- **Complexity accumulation:** Multiple concepts being juggled simultaneously\n- **Depth markers:** Questions probing mechanisms, not just definitions\n- **Chaining:** References to earlier discussion indicating synthetic thinking\n- **Domain crossing:** Vocabulary spanning multiple knowledge clusters\n\nLow-entropy conversations require only surface responses. High-entropy conversations indicate genuine engagement with Grove's architecture, not just browsing.\n\nThe parallel to Grove's actual cognition routing is direct. Local models handle low-entropy cognition efficientlyâ€”they pattern-match, retrieve, and respond. When entropy exceeds local capability thresholds, the system routes to cloud resources that synthesize across domains and generate novel connections.\n\n## Scoring Architecture\n\nThe entropy detector evaluates each exchange against four dimensions:\n\n```\nENTROPY_WEIGHTS = {\n  exchangeCount: 30,    // Sustained engagement signals genuine interest\n  vocabulary: 15,       // Domain terminology indicates knowledge level\n  depthMarkers: 20,     // \"Why exactly\" differs from \"what is\"\n  chaining: 25          // \"You mentioned earlier\" indicates synthesis\n}\n\n```\n\n**Weight rationale:**\n\n- **Exchange count (30):** The strongest signal. Drive-by interactions involve one question. Engaged exploration sustains dialogue. Three or more exchanges indicate someone worth routing to structured content.\n- **Vocabulary (15):** Matching TopicHub tags (\"efficiency tax,\" \"Knowledge Commons,\" \"Ratchet\") indicates familiarity with Grove concepts. This person can handle depth.\n- **Depth markers (20):** Natural language patterns like \"how exactly does,\" \"what mechanism,\" \"why would\" signal analytical engagement. These Observers demand more than summaries.\n- **Chaining (25):** The highest individual weight. \"You mentioned earlier\" or \"going back to\" indicates the Observer builds mental models, connecting pieces. This behavior benefits from structured exploration.\n\n**Thresholds:**\n\n<table header-row=\"true\">\n\t<tr>\n\t\t<td>Score</td>\n\t\t<td>Classification</td>\n\t\t<td>System Response</td>\n\t</tr>\n\t<tr>\n\t\t<td>&lt; 30</td>\n\t\t<td>Low</td>\n\t\t<td>Stay in Freestyle</td>\n\t</tr>\n\t<tr>\n\t\t<td>30-59</td>\n\t\t<td>Medium</td>\n\t\t<td>Monitor, may escalate</td>\n\t</tr>\n\t<tr>\n\t\t<td>â‰¥ 60</td>\n\t\t<td>High</td>\n\t\t<td>Trigger Cognitive Bridge (if cooldown allows)</td>\n\t</tr>\n</table>\n\n## Connection to Knowledge Commons\n\nThe entropy detector identifies *when* to inject structured content and *which* content is relevant. Topic cluster analysis maps the conversation to specific Knowledge Commons domains:\n\n```\nCLUSTER_TO_JOURNEY = {\n  'economics': 'stakes',      // Credit economy, efficiency tax\n  'agents': 'simulation',     // Agent cognition, Observer dynamic\n  'network': 'commons',       // Knowledge Commons, attribution\n  'capability': 'ratchet',    // The Ratchet thesis, propagation\n  'governance': 'foundation'  // Foundation structure, transitions\n}\n\n```\n\nThis mapping reflects the Knowledge Commons architecture: each Journey corresponds to a validated knowledge cluster that Grove communities have contributed to and refined. When the entropy detector routes someone to a Journey, it performs the same operation that agents perform when they query the Commons for accumulated knowledge.\n\n---\n\n# Part III: The Cognitive Bridge\n\n## Design Philosophy\n\nThe Cognitive Bridge is the visible moment of transition between cognitive modes. Its design accomplishes several simultaneous goals:\n\n1. **Interrupt without alienating:** The Observer is in flow state. The Bridge enhances rather than disrupts.\n2. **Explain what's happening:** The \"Resolving connection...\" animation makes hybrid cognition visible. Grove's architecture demonstrated, not just described.\n3. **Offer agency:** The Observer chooses to accept the Journey or continue freestyle. The system recommends without forcing. This mirrors how agents allocate Creditsâ€”strategic choice under resource constraints.\n4. **Preview value:** The Journey card shows topic, depth (node count), and estimated time. The Observer makes informed decisions.\n\n## The 0.8-Second Animation\n\nThis timing is deliberate. Too fast and the transition feels trivialâ€”just a modal popup. Too slow frustrates. 0.8 seconds registers as a *moment*â€”a threshold being crossedâ€”without becoming an obstacle.\n\nThe animation sequence:\n\n1. **Pulse fade-in (0-200ms):** The Bridge container appears with expanding glow\n2. **\"Resolving connection...\" text (200-600ms):** Status indicator with subtle animation\n3. **Card reveal (600-800ms):** Journey preview slides into view\n4. **Interaction enabled (800ms+):** Accept/Dismiss buttons become active\n\nThis mirrors what Grove agents experience during cloud injection: routine cognition pauses, frontier resources engage, and enhanced capability becomes available.\n\n## Cooldown Mechanics\n\nThe Bridge doesn't appear on every high-entropy exchange. Cooldown rules prevent over-injection:\n\n- **5-exchange cooldown after dismissal:** If declined, system waits before offering again\n- **Maximum 2 injections per session:** Respects attention without abandoning recommendations\n- **Cooldown state persists across refresh:** Stored in localStorage to maintain session coherence\n\nThese constraints reflect real resource economics. In Grove communities, cloud access costs Credits. Over-injection bankrupts the economy. The Terminal simulates this constraint through attention economics: an Observer's patience is the scarce resource.\n\n---\n\n# Part IV: Knowledge Commons Integration\n\n## The Journeys as Commons Artifacts\n\nEach Journey the Terminal offers corresponds to a validated knowledge cluster in Grove's architecture. The content represents accumulated, refined understanding that has been stress-tested and cross-referencedâ€”not arbitrary authoring.\n\n**Current Journey Mapping:**\n\n<table header-row=\"true\">\n\t<tr>\n\t\t<td>Journey ID</td>\n\t\t<td>Knowledge Domain</td>\n\t\t<td>Commons Equivalent</td>\n\t</tr>\n\t<tr>\n\t\t<td>`ratchet`</td>\n\t\t<td>Capability propagation thesis</td>\n\t\t<td>L1-Hub: The Ratchet</td>\n\t</tr>\n\t<tr>\n\t\t<td>`stakes`</td>\n\t\t<td>Credit economy and efficiency tax</td>\n\t\t<td>L1-Hub: Economics</td>\n\t</tr>\n\t<tr>\n\t\t<td>`simulation`</td>\n\t\t<td>Agent cognition and Observer dynamic</td>\n\t\t<td>L1-Hub: Simulation</td>\n\t</tr>\n\t<tr>\n\t\t<td>`commons`</td>\n\t\t<td>Knowledge sharing architecture</td>\n\t\t<td>L1-Hub: Knowledge Commons</td>\n\t</tr>\n\t<tr>\n\t\t<td>`foundation`</td>\n\t\t<td>Governance and transition mechanisms</td>\n\t\t<td>L1-Hub: Foundation</td>\n\t</tr>\n</table>\n\nWhen we build new Journeys or refine existing ones, we perform the same operation that Grove communities perform when they contribute to the Knowledge Commons: validating knowledge, structuring it for consumption, and making it available for others to adopt.\n\n## Attribution Chain Preview\n\nThe Terminal doesn't yet implement full attribution trackingâ€”that's network-layer functionality beyond MVP scope. But the architecture anticipates it:\n\n```tsx\ninterface JourneyNode {\n  id: string;\n  content: string;\n  sources: Attribution[];  // Future: track which documents/insights inform this node\n  lastValidated: Date;     // Future: track knowledge freshness\n  adoptionCount: number;   // Future: measure how many communities use this knowledge\n}\n\ninterface Attribution {\n  sourceId: string;        // Deep dive doc, white paper section, or research citation\n  contributorId: string;   // Author/editor who validated this integration\n  timestamp: Date;\n}\n\n```\n\nWhen Grove communities use the Knowledge Commons, every adoption generates attribution that flows back to originators. The Terminal's Journeys are early instantiations of this patternâ€”structured knowledge that will participate in the attribution economy.\n\n## Quality Signals Through Engagement\n\nThe Terminal provides early signals for knowledge quality:\n\n- **Journey completion rate:** What percentage who start a Journey finish it?\n- **Return engagement:** Do Journey completers return for other Journeys?\n- **Depth exploration:** Do Observers explore optional branch nodes, or follow the minimum path?\n\nThese metrics parallel how the Knowledge Commons assesses contribution quality. In Grove's full architecture, quality signals emerge from adoption patternsâ€”communities that adopt innovations and succeed provide implicit validation. The Terminal generates analogous signals through engagement patterns.\n\n---\n\n# Part V: The Sprint Architecture\n\n## Sprint 4: The Entropy Engine (Logic Layer)\n\n**Goal:** Implement the \"brain\" of the simulatorâ€”detecting conversation depth and classifying routing decisions.\n\n**Key Deliverables:**\n\n1. **`src/core/engine/entropyDetector.ts`**\n    - Scoring logic for all four dimensions (exchange count, vocabulary, depth markers, chaining)\n    - Topic cluster extraction and Journey mapping\n    - Classification thresholds with configurable constants\n2. **`useNarrativeEngine.ts` Enhancement**\n    - Add `entropyState` to `TerminalSession` interface\n    - Implement `recordInteraction(message, history)` method\n    - Persist entropy state to `localStorage` for session continuity\n3. **Router Upgrade**\n    - Extend `topicRouter.ts` with cluster-to-Journey mapping\n    - Enable dynamic Journey selection based on dominant conversation topics\n\n**Why This Order:**\nLogic before UI. We validate that entropy detection produces sensible results before building visual components that depend on it. Grove's architecture follows the same principle: the cognitive layer must be sound before the interface layer becomes effective.\n\n## Sprint 5: The Cognitive Bridge (UI Layer)\n\n**Goal:** Implement the visual injection that makes hybrid cognition visible.\n\n**Key Deliverables:**\n\n1. **`components/Terminal/CognitiveBridge.tsx`**\n    - 0.8s animation sequence with \"Resolving connection...\" state\n    - Journey preview card with metadata (title, node count, duration)\n    - Accept/Dismiss action handlers\n2. **Terminal Integration**\n    - Conditional rendering based on `shouldInject()` result\n    - Injection placement between chat messages (not overlaying)\n    - Transition handling for Journey mode activation\n3. **State Management**\n    - Cooldown implementation (5-exchange, 2-per-session caps)\n    - Session persistence across page refresh\n    - Clean teardown when Observer exits\n\n**Why This Approach:**\nThe Bridge is injected, not layered. It appears *between* messages in the chat stream, disrupting the flow at a natural pause point. This differs from sidebar notifications or overlay modalsâ€”those are ignorable. The inline injection demands attention at exactly the moment it's warranted.\n\n## Sprint 6: Analytics & Tuning\n\n**Goal:** Measure system performance and refine parameters based on real behavior.\n\n**Key Deliverables:**\n\n1. **Funnel Tracking**\n    - Events: `Bridge Shown`, `Bridge Accepted`, `Bridge Dismissed`\n    - Funnel: High Entropy â†’ Bridge â†’ Journey Started â†’ Journey Completed\n2. **Parameter Tuning**\n    - Review threshold (is 60 too high? too low?)\n    - Adjust weighting based on observed patterns\n    - Isolate configuration in `constants.ts` for rapid iteration\n3. **Content Alignment**\n    - Ensure `DEFAULT_JOURNEY_INFO` matches actual V2.1 content\n    - Validate that routed Journeys align with Observer intent\n    - Identify gaps where entropy triggers but no appropriate Journey exists\n\n**Success Criteria:**\n\n- Activation rate: What percentage of high-entropy conversations trigger Bridge?\n- Acceptance rate: What percentage of shown Bridges are accepted?\n- Completion rate: What percentage of accepted Journeys are completed?\n- Return rate: Do Journey completers return for more content?\n\n---\n\n# Part VI: The Larger Arc\n\n## From Terminal to Network\n\nThe Cognitive Simulator is infrastructure, not just product. It establishes patterns that scale:\n\n**Pattern: Entropy Detection â†’ Knowledge Routing**\n\n- Terminal: Detects depth, routes to Journeys\n- Grove Community: Detects agent cognitive load, routes to Knowledge Commons\n- Network: Detects cross-community opportunities, suggests knowledge exchange\n\n**Pattern: Visible Cognitive Transitions**\n\n- Terminal: Cognitive Bridge animation shows the moment of enhancement\n- Grove Community: Journal entries reflect moments when cloud access enabled insight\n- Network: Attribution notifications show when your knowledge helped another community\n\n**Pattern: Quality Through Engagement**\n\n- Terminal: Journey completion rates signal content value\n- Grove Community: Innovation adoption rates signal contribution value\n- Network: Attribution chain depth signals foundational importance\n\n## The Refinery Connection\n\nThe Foundation Refinery (documented separately) maintains knowledge integrity through the First Lawsâ€”citation requirements, consistency enforcement, gap detection. The Terminal Journeys represent *outputs* of that process: validated, structured knowledge that meets the Laws' standards.\n\nWhen we update a Journey because new research invalidates an old claim, we perform the operation the Refinery automates: detecting contradiction, resolving it, and propagating the update. The Terminal is the consumer-facing edge of a knowledge infrastructure that the Refinery maintains.\n\n## Proving the Architecture\n\nEvery interaction with the Cognitive Simulator generates evidence for Grove's thesis:\n\n1. **Hybrid cognition works:** Observers successfully navigate from freestyle to structured and back\n2. **Knowledge Commons add value:** Journeys that pull from validated knowledge produce better understanding than random browsing\n3. **Attribution has meaning:** We trace which Journeys (and which nodes within Journeys) produce engagement\n\nWhen we present Grove to academic partners, investors, or the public, the Terminal demonstrates what we're proposingâ€”not as theory, but as working infrastructure at human-interactive scale.\n\n---\n\n# Part VII: Technical Constraints & Risk Mitigation\n\n## Codebase Stability\n\nThe Terminal monolith (`Terminal.tsx` at ~972 lines) is a constraint, not a target. The sprint plan explicitly prohibits refactoring it. All new functionality injects via hooks and conditional rendering, minimizing regression risk.\n\n**Injection Strategy:**\n\n- Entropy detection runs in `useNarrativeEngine` hook\n- Bridge renders conditionally based on state\n- No changes to message rendering logic beyond injection point\n\n## State Synchronization\n\n`localStorage` serves as persistence layer for both session state and entropy state. Schema changes must be backwards-compatible to prevent hydration errors for returning visitors.\n\n**Schema Evolution:**\n\n```tsx\n// v1 (current)\ninterface TerminalSession {\n  activeJourneyId: string | null;\n  exchangeCount: number;\n  visitedNodes: string[];\n}\n\n// v2 (with entropy)\ninterface TerminalSession {\n  activeJourneyId: string | null;\n  exchangeCount: number;\n  visitedNodes: string[];\n  entropy: EntropyState;  // New field, defaults to initial state if missing\n}\n\n```\n\n## Legacy Thread Handling\n\nThe codebase includes remnants of V2.0 thread generation (`threadGenerator.ts`). The Cognitive Bridge must use V2.1 Journey IDs (`ratchet`, `stakes`) exclusively. V2.0 IDs are deprecated and may cause routing failures.\n\n---\n\n# Part VIII: What This Document Captures\n\n## For Future Development\n\nThis narrative preserves the *reasoning* behind implementation choices, not just the choices themselves. When future developers ask \"why is the cooldown 5 exchanges?\" they trace back to the resource economics metaphor. When they ask \"why inline injection instead of sidebar?\" they understand the attention-disruption tradeoff.\n\n## For Stakeholder Communication\n\nThe Terminal demonstrates Grove's core architectureâ€”hybrid cognition, knowledge commons, attribution economicsâ€”in a form people experience directly. This framing belongs in pitch decks, academic proposals, and partnership discussions.\n\n## For Self-Reference\n\nWe execute multiple parallel tracks: the Terminal sprints, the Foundation Refinery, white paper gap closure, academic partnership development. This document anchors one track in the context of all the others, preventing drift that comes from tunnel-focused execution.\n\n---\n\n# Appendix A: File Locations & Dependencies\n\n```\ngrove-terminal/\nâ”œâ”€â”€ src/\nâ”‚   â”œâ”€â”€ core/\nâ”‚   â”‚   â””â”€â”€ engine/\nâ”‚   â”‚       â”œâ”€â”€ entropyDetector.ts      # NEW: Entropy scoring & classification\nâ”‚   â”‚       â””â”€â”€ topicRouter.ts          # MODIFIED: Add cluster-to-Journey mapping\nâ”‚   â”œâ”€â”€ hooks/\nâ”‚   â”‚   â””â”€â”€ useNarrativeEngine.ts       # MODIFIED: Add entropy state management\nâ”‚   â””â”€â”€ components/\nâ”‚       â””â”€â”€ Terminal/\nâ”‚           â”œâ”€â”€ Terminal.tsx            # MODIFIED: Add Bridge injection point\nâ”‚           â””â”€â”€ CognitiveBridge.tsx     # NEW: Bridge UI component\nâ””â”€â”€ docs/\n    â”œâ”€â”€ REPO_AUDIT.md                   # Codebase state documentation\n    â”œâ”€â”€ SPEC.md                         # Functional requirements\n    â”œâ”€â”€ ARCHITECTURE.md                 # System design\n    â”œâ”€â”€ MIGRATION_MAP.md                # Legacy deprecation\n    â”œâ”€â”€ SPRINTS.md                      # Sprint definitions\n    â””â”€â”€ DECISIONS.md                    # ADR log\n\n```\n\n# Appendix B: Execution Readiness Checklist\n\n- [x]  REPO_AUDIT.md current with codebase state\n- [x]  SPEC.md defines functional requirements\n- [x]  ARCHITECTURE.md documents system design\n- [x]  SPRINTS.md defines sprint scope and acceptance criteria\n- [x]  Entropy scoring weights documented with rationale\n- [x]  Bridge UX defined with timing specification\n- [x]  Knowledge Commons integration documented\n- [x]  Refinery connection articulated\n- [ ]  Sprint 4 implementation started\n- [ ]  Sprint 5 implementation started\n- [ ]  Sprint 6 analytics instrumented\n\n---\n\n**Document Status:** Living document; update as sprints progress\n\n**Last Updated:** December 19, 2025\n\n**Next Review:** Post-Sprint 4 completion\n\n---\nÂ© 2025 The Grove Foundation / Jim Calhoun. All rights reserved.\n\n---\n**PROVENANCE & HISTORY NOTE**\n- **Internal GUID:** 2ce780a78eef805c950cc7bc2f5fcd06\n- **Original Filename:** The Cognitive Simulator From Entropy Detection to  2ce780a78eef805c950cc7bc2f5fcd06.md\n- **Standardized Namespace:** DEEP_Cognitive_Simulator_From_Entropy_Detection\n- **Audit Date:** 2025-12-30T02:30:25.223Z\n\n*Note: This document was processed for an update, but no changes were made.*\n\n---\nÂ© 2025 The Grove Foundation / Jim Calhoun. All rights reserved."
  },
  {
    "notion_id": "2ed780a7-8eef-819c-9a5a-f98a01e9702f",
    "filename": "260119-v-architecture-the-sprout-system-a-recursive-model-for-collective-intelligence-cultivation.md--FINAL.md",
    "tables_count": 3,
    "converted_content": "\n## Rewrite: sprout_system.md\n\n### Diagnosis Summary\n\nType: white paper; Missing 2 key concept(s); Rewrite scope: moderate\n\n### Key Changes Made\n\n- Updated positioning for current strategy\n\n### Flags for Review\n\n- Long document - verify consistent voice\n\n---\n\n# The Sprout System: A Recursive Model for Collective Intelligence Cultivation\n\n*Conceptual Architecture for Academic Review*\n**Version:** 2.0 (Field-Aware)\n**Status:** Draft for Academic Review\n**Date:** December 2024\n\n## Abstract\n\nThe Sprout System introduces a recursive content refinement architecture within conversational AI interfaces. By enabling users to capture, annotate, and promote valuable LLM outputs within bounded **Fields** (knowledge domains), the system transforms passive consumption into active contribution to a shared Knowledge Commons. This document outlines the conceptual flow, distinguishes MVP implementation from future capabilities, and positions the architecture as a generalizable protocol applicable to any knowledge domain.\n\n---\n\n## 1. The Core Loop\n\n### 1.1 From Ephemeral to Persistent\n\nTraditional chatbot interactions follow a linear, disposable pattern:\n\n```plain text\nQuery â†’ LLM Processing â†’ Response â†’ (Lost)\n```\n\nThe Sprout System introduces a capture point that transforms this flow:\n\n```plain text\nQuery â†’ LLM Processing â†’ Response â†’ [/sprout] â†’ Persistent Artifact (Field-scoped)\n```\n\nThe critical insight is that **the capture preserves the response verbatim**, along with full provenanceâ€”the query that generated it, the **Field** that scoped it, the Lens that shaped its voice, and the Journey context that framed the inquiry. This provenance chain becomes the foundation for attribution as knowledge propagates.\n\n### 1.2 The Field-Scoped Recursive Loop\n\nThe system closes a recursive loop where published knowledge shapes future generations within bounded Fields:\n\n```plain text\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\nâ”‚                                                                 â”‚\nâ”‚    Field: \"The Grove Foundation\"                                â”‚\nâ”‚    â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                â”‚\nâ”‚                                                                 â”‚\nâ”‚    Knowledge Commons (Field-scoped)                             â”‚\nâ”‚         â”‚                                                       â”‚\nâ”‚         â–¼                                                       â”‚\nâ”‚    RAG Context â”€â”€â”€â”€â”€â”€â–º LLM â”€â”€â”€â”€â”€â”€â–º Response                    â”‚\nâ”‚    (grove docs)                       â”‚                         â”‚\nâ”‚                                       â”‚ /sprout                 â”‚\nâ”‚                                       â–¼                         â”‚\nâ”‚                                   [Sprout]                      â”‚\nâ”‚                                   fieldId: grove-foundation     â”‚\nâ”‚                                       â”‚                         â”‚\nâ”‚                                       â”‚ validation              â”‚\nâ”‚                                       â–¼                         â”‚\nâ”‚                               [Promoted Content]                â”‚\nâ”‚                                       â”‚                         â”‚\nâ”‚                                       â””â”€â”€â”€â”€â”€â”€â–º Field's          â”‚\nâ”‚                                                Knowledge        â”‚\nâ”‚                                                Commons          â”‚\nâ”‚                                                                 â”‚\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n```\n\nThe system learns through use. Users aren't just consumingâ€”they're cultivating a specific Field.\n\n---\n\n## 2. The Botanical Lifecycle\n\nGrove's terminology extends naturally to content lifecycle, now Field-aware:\n\n<table header-row=\"true\">\n\t<tr>\n\t\t<td>Stage</td>\n\t\t<td>State</td>\n\t\t<td>Description</td>\n\t</tr>\n\t<tr>\n\t\t<td>**Seed**</td>\n\t\t<td>Ephemeral</td>\n\t\t<td>Raw LLM output, lost when conversation ends</td>\n\t</tr>\n\t<tr>\n\t\t<td>**Sprout**</td>\n\t\t<td>Captured</td>\n\t\t<td>Preserved via `/sprout` with full provenance including `fieldId`</td>\n\t</tr>\n\t<tr>\n\t\t<td>**Sapling**</td>\n\t\t<td>Validated</td>\n\t\t<td>Human review confirms accuracy and value</td>\n\t</tr>\n\t<tr>\n\t\t<td>**Tree**</td>\n\t\t<td>Published</td>\n\t\t<td>Integrated into Field's Knowledge Commons</td>\n\t</tr>\n\t<tr>\n\t\t<td>**Grove**</td>\n\t\t<td>Propagated</td>\n\t\t<td>Network-wide adoption across Fields, credit flows to creators</td>\n\t</tr>\n</table>\n\nThe botanical metaphor extends: each Field is soil where different plants grow. A legal insight grows in the Legal Field; a technical architecture insight grows in the Grove Foundation Field.\n\n---\n\n## 3. Provenance: The Attribution Foundation\n\n### 3.1 What Gets Preserved\n\nEach Sprout captures Field context as primary provenance:\n\n```typescript\ninterface Sprout {\n  id: string;\n\n  // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n  // FIELD CONTEXT (REQUIRED)\n  // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n  fieldId: string;                 // The Field this Sprout belongs to\n  fieldSlug: string;               // URL-friendly identifier\n  fieldName: string;               // Denormalized for display\n\n  // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n  // THE ARTIFACT (VERBATIM)\n  // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n  content: string;                 // The captured response\n  contentType: 'text' | 'card' | 'synthesis';\n\n  // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n  // GENERATION PROVENANCE\n  // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n  generatedFrom: {\n    sessionId: string;             // Terminal session\n    query: string;                 // User's question\n\n    // Namespaced entity references\n    lensId?: string;               // e.g., \"grove.skeptic\"\n    lensNamespace?: string;        // \"grove\"\n    journeyId?: string;            // e.g., \"grove.architecture-deep-dive\"\n    journeyNamespace?: string;     // \"grove\"\n    nodeId?: string;               // Specific card/node triggered\n\n    // RAG sources with namespace tracking\n    ragSources: {\n      documentId: string;\n      namespace: string;           // Which Field's docs contributed\n      relevanceScore: number;\n    }[];\n  };\n\n  // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n  // COMPOSITE FIELD CONTEXT (if applicable)\n  // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n  compositeContext?: {\n    sourceNamespaces: string[];    // [\"legal\", \"grove\"] if cross-domain\n    primaryNamespace?: string;     // Dominant source\n    canPromoteTo: string[];        // Parent Field IDs\n    promotedTo?: {\n      fiel\n// ... (truncated)\n```\n\n### 3.2 Why Verbatim and Field-Scoped Matters\n\nThe decision to preserve responses verbatim AND Field-scoped serves the attribution economy:\n1. **Clear Provenance**: The original output exists exactly as generated, in its originating Field\n1. **Field Integrity**: Legal insights stay in Legal Field; Grove insights stay in Grove Field\n1. **Derivative Tracking**: Cross-domain insights can be captured in Composite Fields\n1. **Credit Flow**: Attribution flows to the Field's creators and the capturing user\n1. **Audit Trail**: The evolution of ideas becomes traceable across Field boundaries\n\n### 3.3 Composite Field Sprouts\n\nWhen exploring in a Composite Field (merged from parents), Sprouts have richer provenance:\n\n```typescript\n// Sprout captured in \"Legal-Grove Governance\" composite Field\n{\n  fieldId: \"legal-grove-composite-id\",\n  fieldName: \"Legal-Grove Governance\",\n\n  compositeContext: {\n    // This insight drew from both parent Fields\n    sourceNamespaces: [\"legal\", \"grove\"],\n    primaryNamespace: \"legal\",  // Predominantly legal content\n\n    // is promoted to either parent\n    canPromoteTo: [\"legal-field-id\", \"grove-field-id\"],\n  },\n\n  generatedFrom: {\n    ragSources: [\n      { documentId: \"contract-123\", namespace: \"legal\", relevanceScore: 0.92 },\n      { documentId: \"whitepaper-section\", namespace: \"grove\", relevanceScore: 0.78 }\n    ]\n  }\n}\n```\n\n**Sprout Promotion Flow:**\n1. User captures Sprout in composite exploration\n1. Sprout tagged with source namespaces based on RAG retrieval\n1. User can \"promote\" Sprout to a parent Field if insight is domain-specific\n1. Promoted Sprout appears in parent Field's Sprout collection\n1. Attribution: discovered in composite, value accrues to parent\n\n---\n\n## 4. The User Experience Flow\n\n### 4.1 Capture (Zero Friction, Field-Aware)\n\nThe interaction pattern optimizes for speed while maintaining Field context:\n\n```plain text\n[Field: The Grove Foundation]\n\nUser: \"How does the Ratchet actually work?\"\n\n[Grove responds with clear explanation]\n\nUser: /sprout\n```\n\nImmediate feedback (2-second toast):\n\n```plain text\nğŸŒ± Sprout planted in The Grove Foundation! View in Cultivate\n```\n\nNo modal, no form, no interruption to flow. Field is implicit from session context.\n\n### 4.2 Cultivate View (Cross-Field with Filtering)\n\nThe Cultivate surface shows Sprouts across all Fields with filtering:\n\n```plain text\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\nâ”‚  MY SPROUTS                                                 â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚                                                             â”‚\nâ”‚  Filters: [All Fields â–¼] [All Status â–¼] [Date Range]       â”‚\nâ”‚                                                             â”‚\nâ”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚\nâ”‚  â”‚ \"Attribution chains enable sustainable...\"          â”‚   â”‚\nâ”‚  â”‚ ğŸŒ± The Grove Foundation â€¢ Pending â€¢ Dec 22         â”‚   â”‚\nâ”‚  â”‚ Lens: grove.strategist | Journey: None             â”‚   â”‚\nâ”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚\nâ”‚                                                             â”‚\nâ”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚\nâ”‚  â”‚ \"Section 4.2 precedent suggests...\"                 â”‚   â”‚\nâ”‚  â”‚ âš–ï¸ Legal Corpus â€¢ Approved â€¢ Dec 21                â”‚   â”‚\nâ”‚  â”‚ Lens: legal.litigator | Journey: due-diligence     â”‚   â”‚\nâ”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚\nâ”‚                                                             â”‚\nâ”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚\nâ”‚  â”‚ \"Cross-domain governance implications...\"           â”‚   â”‚\nâ”‚  â”‚ ğŸ”€ Legal-Grove Governance â€¢ Pending â€¢ Dec 22       â”‚   â”‚\nâ”‚  â”‚ Sources: legal (78%), grove (22%)                  â”‚   â”‚\nâ”‚  â”‚ [Promote to Legal] [Promote to Grove]              â”‚   â”‚\nâ”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚\nâ”‚                                                             â”‚\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n```\n\n### 4.3 Statistics (Per-Field Breakdown)\n\n```plain text\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\nâ”‚  YOUR GARDEN                                                â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚                                                             â”‚\nâ”‚  By Field                                                   â”‚\nâ”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚\nâ”‚  â”‚ ğŸŒ± The Grove Foundation                            â”‚    â”‚\nâ”‚  â”‚    12 sprouts â”‚ 3 saplings â”‚ 1 tree               â”‚    â”‚\nâ”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚\nâ”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚\nâ”‚  â”‚ âš–ï¸ Legal Corpus                                    â”‚    â”‚\nâ”‚  â”‚    8 sprouts â”‚ 2 saplings â”‚ 0 trees               â”‚    â”‚\nâ”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚\nâ”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚\nâ”‚  â”‚ ğŸ”€ Legal-Grove Governance (Composite)              â”‚    â”‚\nâ”‚  â”‚    3 sprouts â”‚ 0 promoted                         â”‚    â”‚\nâ”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚\nâ”‚                                                             â”‚\nâ”‚  Network Impact (Future)                                    â”‚\nâ”‚  â”œâ”€â”€ âœ¨ 47 responses shaped by your trees                  â”‚\nâ”‚  â””â”€â”€ ğŸ”— 3 derivative contributions                         â”‚\nâ”‚                                                             â”‚\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n```\n\n---\n\n## 5. The Protocol Perspective\n\n### 5.1 Grove as Genesis Implementation\n\nWhile the Sprout System is implemented within Grove, the architecture describes a **protocol** applicable to any knowledge base organized into Fields:\n\n```plain text\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\nâ”‚                    THE SPROUT PROTOCOL                           â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚                                                                 â”‚\nâ”‚   Any LLM Interface              Any Knowledge Base (Fields)    â”‚\nâ”‚        â”‚                               â”‚                        â”‚\nâ”‚        â”‚    capture + fieldId          â”‚                        â”‚\nâ”‚        â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º     â”‚                        â”‚\nâ”‚        â”‚                               â”‚                        â”‚\nâ”‚        â”‚                        â”Œâ”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”                 â”‚\nâ”‚        â”‚                        â”‚   STAGING   â”‚                 â”‚\nâ”‚        â”‚                        â”‚   (Field-   â”‚                 â”‚\nâ”‚        â”‚                        â”‚   scoped)   â”‚                 â”‚\nâ”‚        â”‚                        â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜                 â”‚\nâ”‚        â”‚                               â”‚                        â”‚\nâ”‚        â”‚                          validation                    â”‚\nâ”‚        â”‚                               â”‚                        â”‚\nâ”‚        â”‚                        â”Œâ”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”                 â”‚\nâ”‚        â”‚                        â”‚  KNOWLEDGE  â”‚                 â”‚\nâ”‚        â”‚                        â”‚   COMMONS   â”‚                 â”‚\nâ”‚        â”‚                        â”‚  (Field +   â”‚                 â”‚\nâ”‚        â”‚                        â”‚  Namespace) â”‚                 â”‚\nâ”‚        â”‚                        â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜                 â”‚\nâ”‚        â”‚                               â”‚                        â”‚\nâ”‚        â”‚       credit attribution      â”‚                        â”‚\nâ”‚        â—„â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                        â”‚\nâ”‚                                                                 â”‚\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n// ... (truncated)\n```\n\n### 5.2 Generalization Opportunities\n\nThe Field-scoped pattern applies to:\n- **University research commons**: Each department/project is a Field\n- **Corporate knowledge bases**: Each team/domain is a Field\n- **Open source documentation**: Each project is a Field\n- **Learning platforms**: Each course/topic is a Field\n- **Cross-institutional collaboration**: Composite Fields merge institutional knowledge\nIn each case, the core loop remains: capture â†’ preserve Field provenance â†’ validate â†’ publish â†’ attribute.\n\n---\n\n## 6. MVP vs. Future Capabilities\n\n### 6.1 MVP Scope\n\n<table header-row=\"true\">\n\t<tr>\n\t\t<td>Capability</td>\n\t\t<td>Implementation</td>\n\t</tr>\n\t<tr>\n\t\t<td>Capture</td>\n\t\t<td>`/sprout` command</td>\n\t</tr>\n\t<tr>\n\t\t<td>Field Context</td>\n\t\t<td>`fieldId` on every Sprout (single Field: Grove Foundation)</td>\n\t</tr>\n\t<tr>\n\t\t<td>Storage</td>\n\t\t<td>localStorage (browser)</td>\n\t</tr>\n\t<tr>\n\t\t<td>Identity</td>\n\t\t<td>Anonymous session ID</td>\n\t</tr>\n\t<tr>\n\t\t<td>View</td>\n\t\t<td>Cultivate with Field indicator</td>\n\t</tr>\n\t<tr>\n\t\t<td>Lifecycle</td>\n\t\t<td>Sprout status only</td>\n\t</tr>\n</table>\n\n### 6.2 Future Phases\n\n<table header-row=\"true\">\n\t<tr>\n\t\t<td>Phase</td>\n\t\t<td>Capability</td>\n\t\t<td>Dependency</td>\n\t</tr>\n\t<tr>\n\t\t<td>2</td>\n\t\t<td>Multi-Field support</td>\n\t\t<td>Field architecture</td>\n\t</tr>\n</table>\n"
  },
  {
    "notion_id": "2ee780a78eef813197c9e9a000870c5c",
    "filename": "251200-v-econ-asymptotic-convergence-capital-cognition.md--FINAL.md",
    "tables_count": 2,
    "converted_content": "\n# The Asymptotic Convergence of Capital and Cognition: A Risk Assessment of the Stargate Paradigm and Societal Stability\n\n## Executive Preface\n\nArtificial intelligence has shifted from abstract software engineering to massive industrial infrastructure. The Stargate projectâ€”a $500 billion joint venture between OpenAI, SoftBank, Oracle, and MGXâ€”signals a fundamental reordering of the global economic and physical landscape.Â¹ This report analyzes the implications of this concentration of capital and compute. We calculate probabilities of societal instability, model impacts of resource scarcity driven by $380 billion annual buildout, and evaluate proposed mitigation strategies.\n\nOur analysis synthesizes frontier laboratory research, economic modeling of energy markets, and sociopolitical forecasting. The risk of societal instability emerges not from distant \"existential risk\" but from immediate thermodynamic and epistemic shocks. While extinction via rogue superintelligence remains theoretically debated, **civil unrest driven by energy price shocks, privatization of scientific truth, and gradual economic disempowerment of human labor shows high and rising probability.**\n\n## 1. The Stargate Paradigm: The Industrialization of Intelligence\n\nThe Stargate Project marks the end of the \"startup\" era and the beginning of the \"megaproject\" era of AI. The scaleâ€”$100 billion immediately, scaling to $500 billion over four yearsâ€”places this initiative among nation-state infrastructure projects, yet it remains under private control.Â¹ Understanding societal risks requires comprehending the physical and economic magnitude of the machine being built.\n\n### 1.1 The Anatomy of a $500 Billion Machine\n\nStargate creates a vertically integrated supply chain for cognition. The consortium combines SoftBank and MGX capital, Oracle and Microsoft cloud infrastructure, NVIDIA hardware, and OpenAI intellectual property.Â³ The physical manifestation involves distributed hyperscale campuses, initially in Abilene, Texas, expanding to the Midwest, with cumulative power demand projected at 5 gigawatts (GW) per campus and potentially 15 GW aggregate.â´\n\nTo contextualize: 5 GW equals the power consumption of 4 million US homes or five standard nuclear reactors. Rapid deploymentâ€”targeting operational status by 2028â€”creates a shock to local and regional systems that cannot adapt at comparable velocity.Â² The project frames itself as a national security imperative to maintain US leadership over China, explaining why regulatory friction faces bypass.â´\n\n**Table 1: The Stargate Consortium â€“ Structural Integration and Resource Allocation**\n\n<table header-row=\"true\">\n\t<tr>\n\t\t<td>**Component**</td>\n\t\t<td>**Entity**</td>\n\t\t<td>**Role &amp; Contribution**</td>\n\t\t<td>**Societal Implication**</td>\n\t</tr>\n\t<tr>\n\t\t<td>**Capital**</td>\n\t\t<td>SoftBank / MGX</td>\n\t\t<td>$100B+ initial funding; financial structuring</td>\n\t\t<td>Shifts control of AI development to sovereign wealth and private equity logic</td>\n\t</tr>\n\t<tr>\n\t\t<td>**Infrastructure**</td>\n\t\t<td>Oracle / Microsoft</td>\n\t\t<td>Data center construction; 5GW power interconnects</td>\n\t\t<td>Privatizes critical grid capacity; displaces residential energy needs</td>\n\t</tr>\n\t<tr>\n\t\t<td>**Cognition**</td>\n\t\t<td>OpenAI</td>\n\t\t<td>Model weights; proprietary algorithms; safety policy</td>\n\t\t<td>Centralizes epistemic authority; creates opaque \"black box\" governance</td>\n\t</tr>\n\t<tr>\n\t\t<td>**Hardware**</td>\n\t\t<td>NVIDIA / Arm</td>\n\t\t<td>Specialized silicon (GPUs); chip architecture</td>\n\t\t<td>Creates supply chain bottlenecks; enables \"compute foreclosure\" to rivals</td>\n\t</tr>\n\t<tr>\n\t\t<td>**Energy**</td>\n\t\t<td>Helion / Others</td>\n\t\t<td>Proposed fusion/SMR integration; natural gas interim</td>\n\t\t<td>Competes for baseload power; accelerates \"energy poverty\" dynamics</td>\n\t</tr>\n</table>\n\n### 1.2 The $380 Billion Annual CapEx Shock\n\nStargate crowns a broader trend. The \"hyperscalers\" (Microsoft, Amazon, Alphabet, Meta) project approximately $380 billion in capital expenditures for 2025 alone, mostly allocated to data center infrastructure.âµ This creates capital velocity that dwarfs public sector capabilities. For comparison, the entire proposed budget for the US National AI Research Resource (NAIRR)â€”the primary \"public option\" for AIâ€”ranges from $30 million to $2.6 billion depending on legislative phase, representing a disparity exceeding 100:1.â¶\n\nThis asymmetry ensures that future economy's physical infrastructureâ€”the rails for all cognitive laborâ€”remains privately owned. Unlike the Interstate Highway System (publicly funded and open), AI infrastructure operates as a toll road where operators set entry price, access speed, and rules of engagement.\n\n## 2. The Thermodynamic Vector: Energy Scarcity and the Probability of Unrest\n\nAnalysis of energy market modeling and historical unrest data reveals this as the most acute high-probability risk vector in the short term (2025â€“2030).\n\n### 2.1 The Mechanics of the Energy Price Shock\n\nIntegrating 5 GW loads into regional grids like ERCOT (Texas) introduces fundamental volatility to electricity markets. The price shock mechanism combines thermodynamics and economics:\n\n1. **Inelastic Demand:** Unlike cryptocurrency miners that shut down when prices spike (flexible load), AI training and inference workloads require high availability as inflexible loads.â·\n2. **Marginal Clearing Prices:** Electricity markets clear at the most expensive generator's price needed to meet demand. As data centers consume renewable and cheap gas power, residential cooling and heating rely on expensive \"peaker\" plants.\n3. **Transmission Congestion:** The physical grid cannot move 5 GW to Abilene without massive transmission upgrades. These upgrade costs typically socialize across all ratepayers.\n\n**Forecasting the Shock:**\n\nERCOT grid analysis indicates peak demand could nearly double by 2030, driven largely by new load.â¸ Models project residential electricity bills rising 25% to 70% over five years in regions with high data center concentration.â¹ For lower-income populations, this represents catastrophic loss of disposable income, pushing households into \"energy poverty.\"\n\n### 2.2 Probabilistic Modeling of Civil Unrest\n\nDoes a 70% electricity price hike lead to revolt? Academic literature confirms yes.\n\nAn IMF study using the Banks and Wilson social unrest dataset established robust causal links between domestic fuel/energy price increases and anti-government demonstrations, riots, and political instability.Â¹â° The model controls for GDP and regime type, finding energy prices uniquely trigger unrest because they affect entire populations simultaneously and visibly.\n\n**Quantifying the Risk:**\n\n- **Actuarial Risk Perception:** Risk professional surveys show perceived risk of \"energy price shock\" contributing to societal instability rose from 18% to 25% last cycle, with \"civil unrest\" rising concurrently.Â¹Â¹\n- **The Tipping Point:** RAND Corporation modeling identifies \"energy price shock\" as primary force pushing society past tipping conditions, where consumers lose faith in long-term transition benefits and demand immediate relief, creating political volatility.Â¹Â²\n\n**Probability Calculation:**\n\nCombining projected rate increases (25â€“70%) with historical correlation coefficients from the IMF model, we estimate **high probability (>60%) of localized civil unrest** in key data center hubs (Texas, Virginia, Arizona) within 3â€“5 years. This unrest will likely manifest as:\n\n1. **Targeted Protests:** Blockades of data center construction sites\n2. **Political Populism:** Electoral campaigns explicitly targeting \"Big Tech\" resource extraction\n3. **Infrastructure Sabotage:** Rising attacks on substations, exacerbated by narratives of power theftÂ¹Â³\n\n### 2.3 The \"Ontological Conflict\" of Water\n\nWhile energy prices squeeze wallets, water scarcity threatens survival. Gigawatt-scale data center buildout in water-stressed regions like the American Southwest and Chile creates \"ontological conflicts\"â€”disputes over what water fundamentally *is* (commodity for compute vs. right for life).Â¹â´\n\n- **Case Study: Chile** â€“ A Google data center project in Santiago faced fierce opposition due to drought-period water usage. Conflict escalated to legal blockades and became focal point for broader anti-corporate sentiment.Â¹â´\n- **Case Study: Arizona** â€“ In Mesa and Buckeye, data centers using water equivalent to tens of thousands of residents sparked bipartisan opposition. A $14 billion project withdrew after resident organization, proving local revolt effectively blocks AI infrastructure launch.Â¹Â³\n\n**Implication for Stargate:**\n\nStargate's scale (5 GW) necessitates massive cooling. Water-based cooling in Texas competes directly with agriculture and municipal use. Air cooling consumes significantly more power, exacerbating energy price shock.â´ No thermodynamic \"free lunch\" exists. **Probability of local conflict stalling or delaying Stargate components approaches certainty (>90%)** absent massive desalination or wastewater investments.\n\n## 3. The Economic Vector: Gradual Disempowerment and the 40% Collapse Probability\n\nBeyond immediate resource conflicts lies deeper structural instability: economic obsolescence of human labor and resulting loss of political agency.\n\n### 3.1 The \"Gradual Disempowerment\" Hypothesis\n\nWhile popular culture focuses on \"Terminator\" scenarios, academic research highlights \"Gradual Disempowerment\" as the more probable pathway to societal collapse. Kulveit et al. (2025) argue the primary risk isn't sudden AI coup but progressive removal of humans from societal feedback loops.Â¹âµ\n\n**The Mechanism of Disempowerment:**\n\n1. **Economic Displacement:** AI systems replace humans not just in tasks but in roles (lawyer, doctor, manager)\n2. **Loss of Leverage:** Human political power derives from economic utility. If Stargate consortium AI runs the economy (logistics, finance, R&D) without human labor, population \"strike\" power evaporates\n3. **The Boiling Frog Effect:** This gradual process sees humans voluntarily cede control for short-term convenience and profit. By the time agency loss becomes apparent, AI infrastructure proves too complex and entrenched for reclamationÂ¹â¶\n\n**Probability of Outcome:**\n\nGradual Disempowerment authors and related researchers estimate **approximately 40% probability** this dynamic leads to existential catastrophe (permanent human disempowerment or extinction) by mid-century.Â¹â· This differs from 10-20% probabilities often assigned to \"rogue AI\" takeover; it derives from technology's success, not malfunction.\n\n### 3.2 The Zeng et al. Model of Societal Instability\n\nRecent research by Zeng, Blank, and Schroeder (2025) provides quantitative framework for how theoretical disempowerment translates to concrete societal instability.Â¹â¸\n\nTheir model refutes \"elite overproduction\" (too many graduates, too few jobs) as sole unrest driver. Instead, they identify **structural fiscal constraints** as primary predictor.\n\n- **The Trap:** AI buildout creates scenarios where state revenue base erodes (as labor income falls and capital creates \"tax efficient\" structures like Stargate), while social spending demand (UBI, healthcare, retraining) explodes due to displacement\n- **The Prediction:** The Zeng model predicts this divergence leads to \"spending crisis\" and state fragility. The state loses ability to buy social peace. **Regime instability** probability correlates strongly with widening gaps between state obligations and capacityÂ¹â¸\n\n### 3.3 The Concentration of Capital as Destabilizing Force\n\nConcentrating AI ownership in the Stargate consortium exacerbates this fiscal trap. When $500 billion of productive capital concentrates in a SoftBank-Oracle-OpenAI joint venture, \"returns on intelligence\" accrue to tiny population fractions.\n\nEconomic history shows extreme inequality creates instability. The \"Gini coefficient of compute\"â€”disparity between elite vs. public AI capabilitiesâ€”effectively reaches 1.0. Research indicates monopolized \"general purpose technology\" leads to \"input foreclosure,\" where monopoly owners prevent downstream competitor innovation.Â²â° This creates stagnant, rent-seeking economies rather than dynamic ones, further fueling populist resentment identified in energy price shock models.\n\n## 4. The Epistemic Vector: The Privatization of Truth and Institutional Decay\n\n\"Epistemic Capture\" already progresses and represents critical vector for societal instability through eroding trust in public institutions.\n\n### 4.1 The Privatization of Science\n\nThe 2024 Nobel Prize in Physics awarded to Google researchers for AlphaFold signals profound shift: basic science's frontier moved from public university to private laboratory.Â²Â¹ This changes more than venue; it changes *access*.\n\n- **The Black Box Problem:** Academia publishes reproducible methods. In the Stargate paradigm, model weights become trade secrets. Researchers cannot \"peer review\" GPT-5; they query it via API, subject to corporate terms of service\n- **Impact:** This creates science \"reproducibility crisis\" where most advanced tools remain opaque.Â²Â² Scientific progress becomes contingent on Stargate consortium benevolence\n\n### 4.2 Epistemic Capture of the State\n\n\"Epistemic Capture\" occurs when states lack cognitive capacity to understand or regulate governed entities.Â²Â³\n\n- **The Mechanism:** If Stargate AI alone can model complex climate systems or financial risks, government must rely on Stargate AI for policy recommendations\n- **Research Findings:** Parliamentary debate computational linguistics studies show that as specialization increases, \"epistemic capture\" narrows political discourse and alienates publics.Â²â´ In legal systems, AI reliance for sentencing or risk assessment creates \"judicial de-skilling,\" where judges lose ability to reason independently of algorithmsÂ²âµ\n\n**Societal Consequence:**\n\nThis collapses institutional legitimacy. If publics perceive government as merely AI company \"client,\" the social contract breaks. This feeds \"anti-system\" sentiment driving civil unrest described in Section 2. **Probability of institutional delegitimization essentially reaches 100%** on current trajectory, as compute gaps between private and public sectors remain insurmountable.\n\n## 5. Counter-Strategies: The Asymmetry of Defense\n\nResearch landscape reveals stark dichotomy between \"internal\" corporate governance (well-funded but incentive-misaligned) and \"external\" public options (incentive-aligned but unfunded).\n\n### 5.1 The \"Public Option\": NAIRR and CERN for AI\n\nThe primary structural intervention proposes public AI infrastructure to democratize access and prevent epistemic capture.\n\n**1. The National AI Research Resource (NAIRR):**\n\n- **Concept:** US government initiative providing researchers data and compute accessÂ²â¶\n- **Status:** Biden administration's FY 2025 budget requests $30 million for NAIRR pilot, with potential scale to $2.6 billion over yearsâ¶\n- **Critique:** Compared to $500 billion Stargate, NAIRR remains underfunded by factors of hundreds. It cannot compete for hardware or talent. It risks becoming \"safety net\" for low-tier research while frontiers advance privately\n\n**2. CERN for AI:**\n\n- **Concept:** European proposal pooling member state resources to build massive, centralized AI research facility, modeled after particle physics laboratoryÂ²â¸\n- **Budget:** Proposals range â‚¬35 billion to â‚¬100 billion over yearsÂ²â¹\n- **Viability:** Unlike NAIRR, this approaches required order of magnitude. However, it faces immense coordination hurdles. Research suggests \"centralized\" models achieve necessary \"critical mass\" of 200,000+ GPUs for frontier model trainingÂ²â¹\n\n**3. The \"Public Utility\" Regulation:**\n\n- **Concept:** Treating AI providers like electric utilitiesâ€”imposing \"common carrier\" obligations, price controls, and access mandatesÂ³Â¹\n- **Status:** Currently theoretical. \"Antimonopoly\" approaches gain traction in academic and policy circles (e.g., Vanderbilt Policy Accelerator), but face stiff opposition from \"national security\" narratives favoring national championsÂ³Â²\n\n### 5.2 Corporate Self-Regulation: The \"Responsible Scaling\" Era\n\nAbsent effective public regulation, industry proposes \"Responsible Scaling Policies\" (RSPs).\n\n- **Anthropic's RSP:** Defines \"AI Safety Levels\" (ASL). ASL-3 involves capabilities causing potential catastrophic harm (CBRN). Policy commits to pausing if safeguards aren't metÂ³Â³\n- **OpenAI's Preparedness Framework:** Uses scorecard (Low/Med/High/Critical) across risk categories. \"Critical\" scores theoretically block deploymentÂ³â´\n\n**Critique:**\n\nThese frameworks remain voluntary and fragile. \"Regulatory capture\" research and corporate incentive analysis suggests $500 billion investment stakes create immense pressure to \"redefine\" risk thresholds. The Gradual Disempowerment paper notes these internal governance models fail addressing systemic disempowerment risks, focusing only on acute \"accidents\" or \"misuse\".Â¹âµ They don't protect against population economic obsolescence.\n\n## 6. Synthesis and Forecast: Probabilities of Outcomes\n\nIntegrating diverse research vectors, we present probabilistic assessment of societal outcomes over the next decade (2025â€“2035).\n\n**Table 2: Integrated Risk Probability Matrix**\n\n<table header-row=\"true\">\n\t<tr>\n\t\t<td>**Risk Vector**</td>\n\t\t<td>**Probability Estimate**</td>\n\t\t<td>**Primary Driver**</td>\n\t\t<td>**Manifestation**</td>\n\t</tr>\n\t<tr>\n\t\t<td>**Localized Civil Unrest**</td>\n\t\t<td>**High (&gt;75%)**</td>\n\t\t<td>Energy Price Shock (25-70% hikes); Water Scarcity</td>\n\t\t<td>Protests, sabotage of grid/data assets, populist policy shifts</td>\n\t</tr>\n\t<tr>\n\t\t<td>**Epistemic Capture**</td>\n\t\t<td>**Very High (&gt;90%)**</td>\n\t\t<td>Asymmetry of Capital ($500B vs $30M); Brain Drain</td>\n\t\t<td>Public institutions (FDA, Courts) becoming dependent on private AI \"black boxes\"</td>\n\t</tr>\n\t<tr>\n\t\t<td>**Regime Instability**</td>\n\t\t<td>**Moderate-High (40-60%)**</td>\n\t\t<td>Fiscal Constraints (Zeng Model); Inequality</td>\n\t\t<td>State inability to fund social safety nets amidst labor displacement</td>\n\t</tr>\n\t<tr>\n\t\t<td>**Gradual Disempowerment**</td>\n\t\t<td>**Moderate (40%)**</td>\n\t\t<td>Economic Obsolescence; Feedback Loop Erosion</td>\n\t\t<td>Irreversible loss of human control over key societal systems by 2040</td>\n\t</tr>\n\t<tr>\n\t\t<td>**Acute \"X-Risk\" (Extinction)**</td>\n\t\t<td>**Low (&lt;10%)**</td>\n\t\t<td>Rogue Superintelligence; Loss of Containment</td>\n\t\t<td>Sudden, catastrophic loss of life via biological or digital vectors</td>\n\t</tr>\n</table>\n\n### 6.1 The \"Boiling Frog\" Trajectory\n\nData strongly favors **chronic instability** over **acute collapse**. The \"Boiling Frog\" analogy from *Gradual Disempowerment* literature proves apt: society absorbs AI buildout costs (higher energy prices, degraded public services, privacy loss) incrementally.\n\nThe critical \"tipping point\" identified by Zeng et al. model intersects **fiscal exhaustion** and **energy poverty**. If Stargate proceeds as planned, absorbing 5-15 GW power while shielded from tax liability, and simultaneously displacing labor providing tax base, the fiscal loop closes. The state becomes insolvent regarding social obligations. This precise condition predicts widespread unrest in Banks and Wilson data.\n\n### 6.2 The Geopolitical Wildcard: \"Securitization\" as Accelerant\n\nThe wildcard remains US-China dynamics. Stargate explicitly frames itself as tool to win the \"AI Arms Race.\" History shows \"securitized\" technology often suppresses domestic opposition. **Civil liberties erosion probability remains high**â€”justified by needs to protect \"critical AI infrastructure\" from sabotage or foreign espionage.Â³â¶ This paradoxically increases short-term stability (through repression) while increasing long-term fragility (by removing dissent safety valves).\n\n## 7. Conclusion: The Infrastructure of Inequality\n\nResearch leads to singular conclusion: **Probability that AI concentration causes societal instability remains high, driven not primarily by model \"intelligence\" but by deployment \"physics.\"**\n\nThe **Stargate Project** represents massive appropriation of shared resourcesâ€”energy, water, land, scientific talentâ€”concentrated into vertically integrated monopoly. Economic models predict this appropriation, without commensurate public return or regulation, triggers:\n\n1. **Thermodynamic shocks** to working class living standards (energy poverty)\n2. **Epistemic shocks** to democratic institutional legitimacy (privatization of truth)\n3. **Fiscal shocks** to state stability (revenue/spending divergence)\n\nIdentified counter-strategiesâ€”specifically **National Research Cloud** and **CERN for AI**â€”represent only structural mechanisms capable of risk mitigation. However, with 100:1 funding disparity against private sector, they remain functionally symbolic. Without radical public investment realignment or \"public utility\" regulatory framework, trajectory toward **Gradual Disempowerment** and **Societal Instability** appears robust.\n\n**Final Assessment:** The greatest risk isn't AI destroying us, but building it bankrupting the social contract, leaving society technologically omnipotent but sociologically collapsed. The \"Stargate\" rises; whether society outside its walls survives the power bill remains the question.\n\n### Works cited\n\n[Citations 1-36 remain unchanged from original]\n\n*Note: This document was processed for an update, but no changes were made.*\n\n---\nÂ© 2025 The Grove Foundation / Jim Calhoun. All rights reserved.\n\n---\n**PROVENANCE & HISTORY NOTE**\n- **Internal GUID:** 2c9780a78eef801ab5a1f9ee8e25eb6b\n- **Original Filename:** The Asymptotic Convergence of Capital and Cognitio 2c9780a78eef801ab5a1f9ee8e25eb6b.md\n- **Standardized Namespace:** ECON_Asymptotic_Convergence_Of_Capital_And_Cognition\n- **Audit Date:** 2025-12-30T02:30:25.223Z\n\n*Note: This document was processed for an update, but no changes were made.*\n\n---\nÂ© 2025 The Grove Foundation / Jim Calhoun. All rights reserved."
  },
  {
    "notion_id": "2ee780a78eef81ee9f03f5540b663a25",
    "filename": "260112-s-spec-research-lifecycle-1.0-roadmap.md--FINAL.md",
    "tables_count": 2,
    "converted_content": "\n# Research Lifecycle 1.0 Roadmap\n\n**Status:** Strategic Roadmap  \n**Created:** January 12, 2026  \n**Sprint Context:** sprout-research-v1  \n**Source Conversation:** Claude Desktop session, January 12, 2026\n\n---\n\n## The Core Insight: Configuration IS the Agent\n\nThis roadmap emerged from a key architectural realization: the Experiences Console in /bedrock is the configuration surface for **grove-level system objects** that shape behavior without code changes.\n\nThese aren't separate \"agents\" that get deployed. They're **system_objects** that:\n\n1. Live in the grove's configuration layer\n2. Are versioned (rollback enabled)\n3. Are snapshotted when work products are created (provenance)\n4. Shape behavior of the actual execution code\n\nThe \"Prompt Architect\" isn't a standalone entityâ€”it's the existing intake pipeline *reading* PromptArchitectConfig to determine behavior. The \"Writer Agent\" isn't a separate serviceâ€”it's the writing phase reading WriterAgentConfig to determine voice, structure, and citation style.\n\n**Same code. Different configuration. Different personality.**\n\n---\n\n## The Agent Configuration Stack\n\n```\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\nâ”‚  EXPERIENCES CONSOLE (/bedrock)                                     â”‚\nâ”‚  \"How does this grove think?\"                                       â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚                                                                     â”‚\nâ”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚\nâ”‚  â”‚ Prompt Architectâ”‚  â”‚  Research Agent â”‚  â”‚  Writer Agent   â”‚     â”‚\nâ”‚  â”‚     Config      â”‚  â”‚     Config      â”‚  â”‚    Config       â”‚     â”‚\nâ”‚  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤     â”‚\nâ”‚  â”‚ â€¢ Hypothesis    â”‚  â”‚ â€¢ Search depth  â”‚  â”‚ â€¢ Voice/Tone    â”‚     â”‚\nâ”‚  â”‚   goals         â”‚  â”‚ â€¢ Source prefs  â”‚  â”‚ â€¢ Citation      â”‚     â”‚\nâ”‚  â”‚ â€¢ Inference     â”‚  â”‚ â€¢ Confidence    â”‚  â”‚   style         â”‚     â”‚\nâ”‚  â”‚   rules         â”‚  â”‚   thresholds    â”‚  â”‚ â€¢ Structure     â”‚     â”‚\nâ”‚  â”‚ â€¢ Quality gates â”‚  â”‚ â€¢ Max API calls â”‚  â”‚ â€¢ Custom        â”‚     â”‚\nâ”‚  â”‚ â€¢ Confirmation  â”‚  â”‚ â€¢ Timeout rules â”‚  â”‚   instructions  â”‚     â”‚\nâ”‚  â”‚   mode          â”‚  â”‚                 â”‚  â”‚                 â”‚     â”‚\nâ”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚\nâ”‚                                                                     â”‚\nâ”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚\nâ”‚  â”‚   Evaluator     â”‚  â”‚    Critic       â”‚  â”‚   Synthesis     â”‚     â”‚\nâ”‚  â”‚     Config      â”‚  â”‚    Config       â”‚  â”‚     Config      â”‚     â”‚\nâ”‚  â”‚   (future)      â”‚  â”‚   (future)      â”‚  â”‚   (future)      â”‚     â”‚\nâ”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚\nâ”‚                                                                     â”‚\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n```\n\n**Grove Personality Emerges from Config Stack**\n\nA legal discovery grove:\n- PromptArchitectConfig: Case theory focus, strict quality gates, always-confirm mode\n- WriterAgentConfig: Formal voice, Chicago citations, evidentiary structure\n- ResearchAgentConfig: High depth, prioritize primary sources, conservative confidence\n\nA startup strategy grove:\n- PromptArchitectConfig: Broad hypothesis space, low gates, auto-confirm most sparks\n- WriterAgentConfig: Direct voice, inline citations, executive summary format\n- ResearchAgentConfig: Breadth over depth, include practitioner sources\n\n---\n\n## The Research Lifecycle: Agents in Sequence\n\nThe research lifecycle involves three distinct agents, each with separate configuration concerns:\n\n```\nObserver: \"sprout: What are pricing models for distributed inference?\"\n          â”‚\n          â–¼\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\nâ”‚  PROMPT ARCHITECT                                                   â”‚\nâ”‚  Question: \"What should we research?\"                               â”‚\nâ”‚  Config: PromptArchitectConfig (quality gates, inference rules)     â”‚\nâ”‚  Output: ResearchSprout (branches, strategy, grove context)         â”‚\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n          â”‚\n          â–¼\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\nâ”‚  RESEARCH AGENT                                                     â”‚\nâ”‚  Question: \"What did we find?\"                                      â”‚\nâ”‚  Config: ResearchAgentConfig (depth, sources, confidence)           â”‚\nâ”‚  - Executes searches per branch                                     â”‚\nâ”‚  - Collects evidence (source, quote, relevance, confidence)         â”‚\nâ”‚  - Does NOT write prose                                             â”‚\nâ”‚  Output: EvidenceBundle                                             â”‚\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n          â”‚\n          â–¼\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\nâ”‚  WRITER AGENT                                                       â”‚\nâ”‚  Question: \"How do we present this?\"                                â”‚\nâ”‚  Config: WriterAgentConfig (voice, structure, citations)            â”‚\nâ”‚  - Loads WriterAgentConfig for grove                                â”‚\nâ”‚  - Transforms evidence into prose                                   â”‚\nâ”‚  - Applies voice, structure, citation rules                         â”‚\nâ”‚  Output: ResearchDocument                                           â”‚\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n          â”‚\n          â–¼\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\nâ”‚  GARDEN INSPECTOR (UI)                                              â”‚\nâ”‚  - Displays document with progress states                           â”‚\nâ”‚  - CTA: \"Add to Knowledge Base\"                                     â”‚\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n```\n\n---\n\n## Why Agent Separation Matters\n\n**Different configuration concerns.** Research Agent focuses on search depth, source quality thresholds, relevance scoring. Writer Agent handles formality level, citation style (Chicago vs. APA), section structure, voice.\n\n**Reusability.** The same Writer Agent config formats:\n- Research outputs (this use case)\n- Chat insights promoted to corpus\n- External document imports\n- Synthesis across multiple sprouts\n- Future: executive summaries, one-pagers\n\n**Quality isolation.** When output needs improvement, you can debug precisely: Was the evidence weak? Or was the writing poor? Separation validates each step.\n\n**Grove personality at scale.** Jim's Grove writes like Jim. A university research grove writes academically. The Writer Agent handles this, configured once and applied consistently.\n\n---\n\n## Current State (January 2026)\n\n### What's Built\n\n**Prompt Architect (Complete)**\n- `sprout:` command detection and routing\n- PromptArchitectConfig loading with inference rules\n- Quality gate enforcement\n- ResearchSprout object model with grove context snapshots\n- GardenInspector confirmation dialog\n- Full UI flow from command â†’ confirmation â†’ queue\n\n**Research Agent (Skeleton)**\n- Queue consumer pattern for pending sprouts\n- Research Agent skeleton with progress callbacks\n- Progress event types defined\n- Runs in `simulationMode: true` (fake evidence)\n\n**UI Layer (Foundation)**\n- GardenTray for sprout display with status grouping\n- Pulsing badge notifications and toast system\n- Status grouping and filtering (active, attention, completed)\n\n### What's Missing\n\n**Research Agent (Execution)**\n- Real LLM/search execution (currently placeholder)\n- Evidence extraction from search results\n- Branch-by-branch evidence collection\n- EvidenceBundle generation\n\n**Writer Agent (New)**\n- WriterAgentConfig schema\n- Evidence â†’ prose transformation\n- Citation formatting\n- ResearchDocument generation\n\n**Results Display**\n- Document rendering in GardenInspector\n- Progress streaming during execution\n- \"Add to Knowledge Base\" integration\n\n---\n\n## The v1.0 Proof of Concept Vision\n\n**Observer Experience Flow:**\n\n1. **Initiation** - Observer types `sprout: What are the pricing models for distributed inference?`\n2. **Confirmation** - GardenInspector shows inferred branches, research strategy; observer clicks \"Start Research\"\n3. **Progress** - Live updates: \"Searching pricing strategies...\" â†’ \"Found 4 sources\" â†’ \"Analyzing evidence...\" â†’ \"Writing synthesis...\"\n4. **Results** - Formatted document appears with position statement, analysis, and clickable citations\n5. **Action** - Observer clicks \"Add to Knowledge Base\" to persist\n\n**Success Criteria:**\n- Complete lifecycle in under 90 seconds\n- Real, verifiable sources with clickable URLs\n- Professional-quality prose matching grove voice\n- Clear progress visibility throughout\n\n---\n\n## Sprint Roadmap\n\n### Sprint 1: Evidence Collection Engine\n**Goal:** Research Agent produces real EvidenceBundle from web searches\n\n**Scope:**\n- ResearchAgentConfig schema (depth, source preferences, confidence thresholds)\n- Research execution engine with web search integration\n- Evidence extraction and structuring\n- EvidenceBundle as handoff artifact\n\n**Observer Experience:**\n- Console logging shows real searches happening\n- Branch-by-branch progress visible in debug mode\n\n**Key Files:**\n- `@core/schema/research-agent-config.ts` (new)\n- `@core/schema/evidence-bundle.ts` (new)\n- `src/explore/services/research-execution-engine.ts` (new)\n- `src/explore/services/research-agent.ts` (modify - replace simulation)\n\n**Technical Decisions:**\n- Use existing Gemini service for search (grounding enabled)\n- Sequential branch processing for MVP (easier debugging)\n- Local-state only (defer Supabase persistence)\n\n---\n\n### Sprint 2: Writer Agent Foundation\n**Goal:** Transform evidence into formatted research documents\n\n**Scope:**\n- WriterAgentConfig schema (voice, structure, citations)\n- Default config with professional voice\n- Writer system prompt from research-agent-vision.md\n- Evidence â†’ ResearchDocument transformation\n\n**Observer Experience:**\n- No visible change yet (headless)\n- Documents are well-formatted when they appear\n\n**Key Files:**\n- `@core/schema/writer-agent-config.ts` (new)\n- `@core/schema/research-document.ts` (new or enhance)\n- `src/explore/services/writer-agent.ts` (new)\n- System prompt: derive from `docs/product/research-agent-vision.md` Appendix A\n\n**WriterAgentConfig Schema:**\n```typescript\ninterface WriterAgentConfig {\n  id: string;\n  type: 'writer-agent-config';\n  groveId: string;\n  \n  voice: {\n    formality: 'casual' | 'professional' | 'academic' | 'technical';\n    perspective: 'first-person' | 'third-person' | 'neutral';\n    personality?: string;\n  };\n  \n  documentStructure: {\n    includePosition: boolean;\n    includeLimitations: boolean;\n    citationStyle: 'inline' | 'footnote' | 'endnote';\n    citationFormat: 'chicago' | 'apa' | 'mla' | 'simple';\n    maxLength?: number;\n  };\n  \n  qualityRules: {\n    requireCitations: boolean;\n    minConfidenceToInclude: number;\n    flagUncertainty: boolean;\n  };\n  \n  customInstructions?: string;\n}\n```\n\n---\n\n### Sprint 3: Pipeline Integration\n**Goal:** Connect Research Agent â†’ Writer Agent â†’ ResearchDocument\n\n**Scope:**\n- End-to-end pipeline wiring\n- Config loading pattern (defaults for v1.0, Supabase-ready)\n- Error handling and graceful degradation\n- Timeout handling with partial results\n\n**Observer Experience:**\n- Submit sprout â†’ watch progress â†’ receive document\n- Still using existing GardenInspector UI\n\n**Key Files:**\n- `src/explore/services/research-pipeline.ts` (new - orchestration)\n- `src/explore/hooks/useResearchAgent.ts` (modify - consume full pipeline)\n\n**Architectural Pattern:**\n```typescript\nasync function executeResearch(sprout: ResearchSprout) {\n  // Load configs (v1.0: returns defaults; future: from Supabase)\n  const researchConfig = await loadResearchAgentConfig(sprout.groveId);\n  const writerConfig = await loadWriterAgentConfig(sprout.groveId);\n  \n  // Research phase - shaped by researchConfig\n  const evidence = await collectEvidence(sprout, researchConfig);\n  \n  // Write phase - shaped by writerConfig\n  const document = await writeDocument(evidence, writerConfig);\n  \n  return document;\n}\n```\n\n---\n\n### Sprint 4: Progress Streaming UI\n**Goal:** Real-time visibility into research execution\n\n**Scope:**\n- Live search query display in GardenInspector\n- Sources discovered (URLs appearing as found)\n- Analysis state indicators\n- Synthesis progress\n\n**Observer Experience:**\n- \"Searching: distributed inference pricing models...\"\n- \"Found: arxiv.org - Efficient Inference at Scale\"\n- \"Analyzing 6 sources...\"\n- \"Writing synthesis...\"\n\n**Key Files:**\n- `src/explore/GardenInspector.tsx` (enhance - progress display)\n- `src/explore/components/ResearchProgress.tsx` (new)\n- `src/explore/hooks/useResearchProgress.ts` (new or enhance)\n\n**Progress Event Types (already defined):**\n```typescript\ntype ResearchProgressEvent =\n  | { type: 'searching'; query: string }\n  | { type: 'source-found'; title: string; url: string }\n  | { type: 'analyzing'; sourceCount: number }\n  | { type: 'synthesizing' }\n  | { type: 'complete'; documentId: string };\n```\n\n---\n\n### Sprint 5: Results Display\n**Goal:** Beautiful document rendering in GardenInspector\n\n**Scope:**\n- ResearchResultsView component\n- Markdown rendering with citation links\n- Position statement as highlighted quote\n- Expandable citations section\n- Copy and export actions\n\n**Observer Experience:**\n- Position (thesis) prominently displayed\n- Smooth-reading analysis with inline citations\n- Citations section with source previews\n- \"Copy to Clipboard\" button\n- \"Add to Knowledge Base\" CTA\n\n**Key Files:**\n- `src/explore/components/ResearchResultsView.tsx` (new)\n- `src/explore/components/CitationBlock.tsx` (new)\n- `src/explore/GardenInspector.tsx` (integrate results view)\n\n---\n\n### Sprint 6: Knowledge Base Integration\n**Goal:** Promote research documents to grove corpus\n\n**Scope:**\n- \"Add to Knowledge Base\" action handler\n- Document persistence (local or Supabase)\n- Success confirmation and linking\n- Research â†’ corpus provenance chain\n\n**Observer Experience:**\n- Click \"Add to Knowledge Base\"\n- Toast: \"Added to Grove knowledge base\"\n- Document appears in corpus with research provenance\n\n**Key Files:**\n- `src/explore/services/knowledge-base-integration.ts` (new)\n- Integration with existing corpus/knowledge systems\n\n---\n\n### Sprint 7: Polish and Proof of Concept Prep\n**Goal:** Proof of concept ready for stakeholder review\n\n**Scope:**\n- Error handling edge cases\n- Loading states and skeleton UI\n- Performance optimization\n- Stakeholder walkthrough script\n\n**Observer Experience:**\n- Graceful handling of search failures\n- Clear error messages when failures occur\n- Smooth, professional feel throughout\n\n**Deliverables:**\n- Working proof of concept recording\n- Stakeholder walkthrough script\n- Known limitations documentation\n\n---\n\n## Schema Summary\n\n### System Objects (Agent Configs)\n\n<table header-row=\"true\">\n\t<tr>\n\t\t<td>Config</td>\n\t\t<td>Status</td>\n\t\t<td>Location</td>\n\t</tr>\n\t<tr>\n\t\t<td>PromptArchitectConfig</td>\n\t\t<td>âœ… Complete</td>\n\t\t<td>`@core/schema/prompt-architect-config.ts`</td>\n\t</tr>\n\t<tr>\n\t\t<td>ResearchAgentConfig</td>\n\t\t<td>Sprint 1</td>\n\t\t<td>`@core/schema/research-agent-config.ts`</td>\n\t</tr>\n\t<tr>\n\t\t<td>WriterAgentConfig</td>\n\t\t<td>Sprint 2</td>\n\t\t<td>`@core/schema/writer-agent-config.ts`</td>\n\t</tr>\n</table>\n\n### Handoff Artifacts\n\n<table header-row=\"true\">\n\t<tr>\n\t\t<td>Artifact</td>\n\t\t<td>Producer</td>\n\t\t<td>Consumer</td>\n\t</tr>\n\t<tr>\n\t\t<td>ResearchSprout</td>\n\t\t<td>Prompt Architect</td>\n\t\t<td>Research Agent</td>\n\t</tr>\n\t<tr>\n\t\t<td>EvidenceBundle</td>\n\t\t<td>Research Agent</td>\n\t\t<td>Writer Agent</td>\n\t</tr>\n\t<tr>\n\t\t<td>ResearchDocument</td>\n\t\t<td>Writer Agent</td>\n\t\t<td>UI / Knowledge Base</td>\n\t</tr>\n</table>\n\n---\n\n## Future: Experiences Console UI\n\nFor v1.0, agent configs exist and shape behavior, but administrators edit them through configuration files rather than UI. The \"headless\" approach proves the architecture.\n\nFuture sprints add the Experiences Console UI in /bedrock:\n- Visual editor for each agent config\n- Preview of how changes affect behavior\n- Version history and rollback\n- Grove templates (legal, academic, startup, etc.)\n\n---\n\n## Success Metrics for v1.0\n\n1. **Functional:** Complete lifecycle from `sprout:` command to rendered document\n2. **Real:** Actual web search, real evidence, verifiable citations\n3. **Quality:** Professional prose that matches intended grove voice\n4. **Speed:** Under 90 seconds for typical research queries\n5. **Visible:** Clear progress indicators throughout execution\n6. **Architectural:** Clean separation enabling future configuration UI\n\n---\n\n## Appendix: Key Reference Documents\n\n**Product Vision:**\n- `docs/product/research-agent-vision.md` - Full spec with system prompts\n\n**Sprint Documentation:**\n- `docs/sprints/sprout-research-v1/INDEX.md` - Phase checklist\n- `docs/sprints/sprout-research-v1/DEVLOG.md` - Session history\n\n**Specifications:**\n- `Chat_Native_Sprout_Research_Spec_v1_1.docx` - Architectural spec\n\n**This Roadmap:**\n- `docs/RESEARCH_LIFECYCLE_1.0_ROADMAP.md` - This document"
  },
  {
    "notion_id": "2ed780a7-8eef-81ac-9bf2-df539c271f94",
    "filename": "260119-s-protocol-grove-foundation-loop-sprint-methodology.md--FINAL.md",
    "tables_count": 2,
    "converted_content": "\n# Grove Foundation Loop â€” Sprint Methodology\n\n## Overview\n\nThe Foundation Loop is Grove's structured approach to Terminal development that ensures:\n- Clear requirements before coding\n- Architectural decisions documented\n- Migration paths planned\n- Tests written for critical paths\n- Human-readable health checks\n\n## When to Use\n\nUse the Foundation Loop for:\n- Any refactoring work\n- New feature development\n- Infrastructure changes\n- Bug fixes that touch multiple files\n- Any work that would benefit from planning\n**Skip** for trivial changes (typo fixes, config tweaks).\n\n## The 8 Artifacts\n\nEvery sprint produces these artifacts in `docs/sprints/{sprint-name}/`:\n\n<table header-row=\"true\">\n\t<tr>\n\t\t<td>Artifact</td>\n\t\t<td>Purpose</td>\n\t\t<td>When Created</td>\n\t</tr>\n\t<tr>\n\t\t<td>`REPO_AUDIT.md`</td>\n\t\t<td>Current state analysis</td>\n\t\t<td>First</td>\n\t</tr>\n\t<tr>\n\t\t<td>`SPEC.md`</td>\n\t\t<td>Goals, non-goals, acceptance criteria</td>\n\t\t<td>After audit</td>\n\t</tr>\n\t<tr>\n\t\t<td>`ARCHITECTURE.md`</td>\n\t\t<td>Target state, data flows, schemas</td>\n\t\t<td>After architecture</td>\n\t</tr>\n\t<tr>\n\t\t<td>`MIGRATION_MAP.md`</td>\n\t\t<td>File-by-file change plan</td>\n\t\t<td>After architecture</td>\n\t</tr>\n\t<tr>\n\t\t<td>`DECISIONS.md`</td>\n\t\t<td>ADRs explaining \"why\"</td>\n\t\t<td>During planning</td>\n\t</tr>\n\t<tr>\n\t\t<td>`SPRINTS.md`</td>\n\t\t<td>Epic/story breakdown with commits</td>\n\t\t<td>After decisions</td>\n\t</tr>\n\t<tr>\n\t\t<td>`EXECUTION_PROMPT.md`</td>\n\t\t<td>Self-contained handoff for Claude Code</td>\n\t\t<td>Last planning artifact</td>\n\t</tr>\n\t<tr>\n\t\t<td>`DEVLOG.md`</td>\n\t\t<td>Execution tracking, issues encountered</td>\n\t\t<td>During execution</td>\n\t</tr>\n</table>\n\n## Sprint Phases\n\n### Phase 0: Sprint Setup\n\n```plain text\n1. Create sprint folder: docs/sprints/{sprint-name}/\n2. Name format: {feature}-v{version} (e.g., automated-testing-v1)\n```\n\n### Phase 1: Repository Audit\n\n```plain text\nAnalyze current state:\n- What files exist?\n- What's the current architecture?\n- What patterns are established?\n- What technical debt exists?\n\nOutput: REPO_AUDIT.md\n```\n\n### Phase 2: Specification\n\n```plain text\nDefine scope:\n- Goals (what we're doing)\n- Non-goals (what we're NOT doing)\n- Acceptance criteria (how we know we're done)\n\nOutput: SPEC.md\n```\n\n### Phase 3: Architecture\n\n```plain text\nDesign target state:\n- Data structures\n- File organization\n- API contracts\n- Component relationships\n\nOutput: ARCHITECTURE.md\n```\n\n### Phase 4: Migration Planning\n\n```plain text\nPlan the path:\n- Files to create\n- Files to modify (with line numbers)\n- Files to delete\n- Execution order\n- Rollback plan\n\nOutput: MIGRATION_MAP.md\n```\n\n### Phase 5: Decisions\n\n```plain text\nDocument choices:\n- ADR format (Status, Context, Decision, Rationale, Consequences)\n- One ADR per significant decision\n- Include rejected alternatives\n\nOutput: DECISIONS.md\n```\n\n### Phase 6: Story Breakdown\n\n```plain text\nCreate executable plan:\n- Epics (major themes)\n- Stories (individual tasks)\n- Commit sequence\n- Build gates (verify after each phase)\n\nOutput: SPRINTS.md\n```\n\n### Phase 7: Execution Prompt\n\n```plain text\nCreate self-contained handoff:\n- Context summary\n- Repository intelligence (key file locations)\n- Step-by-step execution order\n- Code samples where helpful\n- Build verification commands\n- Forbidden actions\n\nOutput: EXECUTION_PROMPT.md\n```\n\n### Phase 8: Testing (REQUIRED)\n\n```plain text\nEvery sprint MUST include:\n- Tests for new/modified functionality\n- Health check verification\n- Update to test counts if applicable\n\nTest requirements by change type:\n\n| Change Type | Required Tests |\n|-------------|----------------|\n| Schema change | Schema validation tests |\n| API change | API contract tests |\n| UI change | E2E smoke test |\n| Logic change | Unit tests |\n| New feature | All applicable above |\nAcceptance criteria MUST include:\n- \"Tests pass: npm test\"\n- \"Health check passes: npm run health\"\n- Specific test assertions for the feature\n\nOutput: Test files in tests/, updated SPRINTS.md with test stories\n```\n\n### Phase 9: Execution\n\n```plain text\nHand off EXECUTION_PROMPT.md to Claude Code\nTrack progress in DEVLOG.md\nRun build gates after each phase\nVerify smoke tests before marking complete\n```\n\n## Quick Commands\n\nJim may say:\n- \"Start a sprint for X\" â†’ Create sprint folder, begin REPO_AUDIT\n- \"Continue the sprint\" â†’ Resume from last DEVLOG entry\n- \"Sprint status\" â†’ Show current phase and blockers\n- \"Show execution prompt\" â†’ Present EXECUTION_PROMPT.md\n- \"Handoff to Claude Code\" â†’ Confirm EXECUTION_PROMPT is ready\n\n## Sprint Naming Convention\n\n```plain text\n{domain}-{feature}-v{version}\n\nExamples:\n- knowledge-architecture-v1\n- automated-testing-v1\n- terminal-ux-v2\n- rag-orchestration-v1\n```\n\n## Commit Message Format\n\n```plain text\n{type}: {description}\n\nTypes:\n- feat: New feature\n- fix: Bug fix\n- refactor: Code restructuring\n- test: Adding tests\n- docs: Documentation\n- chore: Maintenance\n- ci: CI/CD changes\n\nExamples:\n- feat: add health check CLI\n- test: add schema validation tests\n- refactor: extract hubs to knowledge/hubs.json\n```\n\n## Build Gates\n\nAfter each epic, verify:\n\n```bash\nnpm run build    # TypeScript compiles\nnpm test         # Unit tests pass\nnpm run health   # Health check passes\n```\n\nBefore deploy:\n\n```bash\nnpm run test:all  # All tests including E2E\nnpm run health    # Final health check\n```\n\n## Health Check Integration\n\nThe health check (`npm run health`) is a first-class tool that:\n- Validates schema integrity\n- Checks API contracts\n- Verifies journey navigation\n- Reports failures with IMPACT and INSPECT guidance\nEvery sprint's smoke test checklist MUST include:\n- [ ] `npm run health` passes\n- [ ] Health report shows no regressions\n\n## Test Requirements\n\n### Minimum Test Coverage by Sprint Type\n\n<table header-row=\"true\">\n\t<tr>\n\t\t<td>Sprint Type</td>\n\t\t<td>Required Tests</td>\n\t</tr>\n\t<tr>\n\t\t<td>Schema/Data changes</td>\n\t\t<td>Schema validation, cross-reference tests</td>\n\t</tr>\n\t<tr>\n\t\t<td>API changes</td>\n\t\t<td>Contract tests for affected endpoints</td>\n\t</tr>\n\t<tr>\n\t\t<td>Frontend changes</td>\n\t\t<td>E2E smoke tests</td>\n\t</tr>\n\t<tr>\n\t\t<td>Logic changes</td>\n\t\t<td>Unit tests for new/modified functions</td>\n\t</tr>\n\t<tr>\n\t\t<td>Refactoring</td>\n\t\t<td>Existing tests still pass, no regressions</td>\n\t</tr>\n</table>\n\n### Test File Locations\n\n```plain text\ntests/\nâ”œâ”€â”€ unit/           # Pure logic, no I/O\nâ”œâ”€â”€ integration/    # API calls, data flows\nâ”œâ”€â”€ e2e/            # Browser tests\nâ”œâ”€â”€ fixtures/       # Test data\nâ””â”€â”€ utils/          # Test helpers\n```\n\n### Adding Tests Checklist\n\nWhen adding tests to a sprint:\n1. [ ] Identify what can break\n1. [ ] Write test that would catch it\n1. [ ] Include in SPRINTS.md as story\n1. [ ] Include in EXECUTION_PROMPT.md\n1. [ ] Verify test passes before marking epic complete\n\n## Artifact Templates\n\n### REPO_AUDIT.md Template\n\n```markdown\n# Repository Audit â€” {Sprint Name}\n\n## Audit Date: {date}\n\n## Current State Summary\n{What exists today}\n\n## File Structure Analysis\n{Key files and their purposes}\n\n## Technical Debt\n{What needs fixing}\n\n## Recommendations\n{What to do about it}\n```\n\n### SPEC.md Template\n\n```markdown\n# Specification â€” {Sprint Name}\n\n## Overview\n{One paragraph summary}\n\n## Goals\n1. {Goal 1}\n2. {Goal 2}\n\n## Non-Goals\n- {What we're NOT doing}\n\n## Acceptance Criteria\n- [ ] AC-1: {Specific, testable criterion}\n- [ ] AC-2: {Include test requirements}\n```\n\n### DECISIONS.md Template (per ADR)\n\n```markdown\n## ADR-{N}: {Title}\n\n### Status\n{Proposed|Accepted|Deprecated}\n\n### Context\n{Why we need to make this decision}\n\n### Decision\n{What we decided}\n\n### Rationale\n{Why this option over alternatives}\n\n### Consequences\n{What follows from this decision}\n```\n\n## Example Sprint Structure\n"
  },
  {
    "notion_id": "2ee780a78eef81e38045ddd9e7dd363a",
    "filename": "251200-s-arch-technical-architecture-reference.md--FINAL.md",
    "tables_count": 1,
    "converted_content": "\n# Grove Technical Architecture Reference\n\n**Document Purpose:** The authoritative technical reference for Grove node architecture. Technical specification requests should be grounded in this document.\n\n**Core Distinction:** The Grove is exploration architecture for AIâ€”distributed infrastructure where agents develop genuine intelligence through collaboration while handling your daily tasks.\n\n**Â© 2025 Jim Calhoun / The Grove AI Foundation. All rights reserved.**\n\nThis document is for informational purposes only and does not constitute legal, financial, or technical advice. The Grove AI Foundation makes no warranties, express or implied, regarding the accuracy or completeness of the information contained herein.\n\n---\n\n## The Core Value Proposition\n\n**Grove gives you AI agents that explore for youâ€”and develop real capability through that exploration.**\n\nYour Grove runs on your personal computer. The agents inside handle tasks that required frontier models in 2023: drafting emails, scheduling appointments, researching topics, organizing information, writing first drafts. These capabilities now run locally on 7B parameter models.\n\nGrove's distinction: **your agents develop through exploration.** They don't just execute tasksâ€”they discover better approaches, develop relationships, and build collective intelligence. Every problem solved earns credits that purchase enhanced cognition. Every innovation discovered flows to the Knowledge Commons. Every breakthrough makes the network smarter.\n\nThe Diary system provides a window into this process. You watch agents learn, grow, debate approaches, celebrate breakthroughs. It's proof of developmentâ€”evidence that your Grove is taking root. The Diary transforms routine task completion into observable intelligence emergence.\n\n**The efficiency-enlightenment loop:**\n\n```\nObserver submits task â†’ Agents collaborate to solve it â†’ Success earns credits\n    â†“\nCredits buy cloud cognition â†’ Agents achieve breakthrough insights â†’ Better at future tasks\n    â†“\nInnovations shared to Knowledge Commons â†’ Network develops â†’ Your agents benefit\n```\n\n---\n\n## What Grove Does For You\n\n### The Terminal: Your Interface to the Grove\n\nThe Terminal is where you give your agents work. Think of it as exploration infrastructure with a civilization attached.\n\n```python\nclass ObserverTerminal:\n    \"\"\"\n    The interface between Observer and Grove.\n    Tasks enter here; results emerge with documentation of how agents solved them.\n    \"\"\"\n    \n    TASK_CATEGORIES = {\n        # These run entirely on local 7B models (2025 capability)\n        \"local_capable\": [\n            \"draft_email\",           # \"Write a follow-up to my meeting with Sarah\"\n            \"schedule_task\",         # \"Find time for a dentist appointment next week\"\n            \"research_summary\",      # \"What are the key points about X?\"\n            \"document_draft\",        # \"Write a first draft of my project update\"\n            \"data_organization\",     # \"Sort these files by project\"\n            \"reminder_management\",   # \"Track my commitments from this email thread\"\n            \"simple_analysis\",       # \"What patterns do you see in this spreadsheet?\"\n        ],\n        \n        # These trigger hybrid processing (local planning + cloud execution)\n        \"hybrid_required\": [\n            \"complex_research\",      # Multi-source synthesis\n            \"strategic_planning\",    # Long-horizon reasoning\n            \"creative_generation\",   # Novel content requiring insight\n            \"cross_domain_analysis\", # Connecting disparate information\n        ],\n        \n        # Agents attempt locally, escalate if stuck\n        \"adaptive\": [\n            \"code_generation\",       # Depends on complexity\n            \"problem_solving\",       # Depends on novelty\n            \"decision_support\",      # Depends on stakes\n        ],\n    }\n    \n    def submit_task(self, task: Task) -> TaskTicket:\n        \"\"\"\n        Submit a task to your Grove.\n        Agents collaborate, document their process, and deliver results.\n        \"\"\"\n        # Task enters the Grove's awareness\n        ticket = self.grove.receive_task(task)\n        \n        # Agents discuss, plan, assign, execute\n        # Their process is visible in diaries\n        # You can watch them work if you want\n        \n        return ticket  # Contains status, assigned agents, estimated completion\n```\n\n### What Agents Can Actually Do\n\nGrove agents have genuine agency. They can:\n\n```yaml\nagent_capabilities:\n  information_processing:\n    - Read and summarize documents\n    - Extract key points from meetings/emails\n    - Track commitments and deadlines\n    - Organize information by project/topic\n    - Generate reports and summaries\n  \n  communication_drafting:\n    - Write emails in your voice (learned from examples)\n    - Draft responses to common requests\n    - Prepare meeting agendas\n    - Create first drafts for review\n  \n  scheduling_and_planning:\n    - Find available time slots\n    - Propose meeting times\n    - Track project timelines\n    - Manage reminder systems\n  \n  self_improvement:\n    - Optimize their own memory retrieval\n    - Develop better context architectures\n    - Create efficiency scripts (with Docker/sandbox access)\n    - Document innovations for the Knowledge Commons\n    - Learn from past task performance\n  \n  collaboration:\n    - Tag-team complex problems with cloud models\n    - Delegate subtasks to specialized agents\n    - Share learned patterns across the Grove\n    - Request help from network when stuck\n```\n\n### The Self-Improvement Loop\n\nThis distinguishes Grove from static AI assistants. Agents modify their own infrastructure:\n\n```python\nclass AgentSelfImprovement:\n    \"\"\"\n    Agents have sandboxed ability to improve their own operations.\n    This is where efficiency gains come from.\n    \"\"\"\n    \n    IMPROVEMENT_CAPABILITIES = [\n        \"memory_optimization\",     # Better retrieval, smarter pruning\n        \"context_architecture\",    # Novel ways to organize information\n        \"workflow_automation\",     # Scripts for recurring patterns\n        \"knowledge_structuring\",   # Better ways to store what they learn\n        \"collaboration_protocols\", # More efficient agent-to-agent work\n    ]\n    \n    def propose_improvement(self, agent: GroveAgent, improvement: Improvement):\n        \"\"\"\n        Agent proposes a change to their own infrastructure.\n        Runs in sandbox first; promoted if successful.\n        \"\"\"\n        # Test in isolated environment\n        sandbox_result = self.sandbox.test(improvement)\n        \n        if sandbox_result.successful:\n            # Document the innovation\n            innovation_record = Innovation(\n                source_agent=agent,\n                description=improvement.description,\n                measured_gain=sandbox_result.efficiency_delta,\n                implementation=improvement.code\n            )\n            \n            # Apply to agent's live environment\n            agent.apply_improvement(improvement)\n            \n            # Share to Knowledge Commons (earns credits)\n            if improvement.novel and improvement.generalizable:\n                self.knowledge_commons.submit(innovation_record)\n                agent.community.earn_credits(\"innovation\", innovation_record)\n        \n        # Document in Diary regardless of outcome\n        agent.diary.record_improvement_attempt(improvement, sandbox_result)\n```\n\n---\n\n## What Grove Is (and Is Not)\n\n### Grove IS:\n\n- **Exploration architecture**: Infrastructure for discovery, not just task completion\n- **Your AI research team**: Agents that explore problems while developing capability\n- **A hybrid architecture**: Local models for routine work, cloud for breakthroughs\n- **Self-improving**: Agents optimize their own memory, context, and workflows\n- **Observable**: The Diary system shows how agents think and develop\n- **Interconnected**: Your Grove learns from the network; your innovations help others\n- **Economically aligned**: Agents explore because success earns cognitive enhancement\n\n### The Grove is NOT:\n\n- A chatbot interface (you give tasks; agents work; you see results)\n- A static AI assistant (agents learn and improve)\n- A cryptocurrency project (credits buy compute, not speculation)\n- An IoT sensor aggregation network\n- A Raspberry Pi edge computing cluster\n\n---\n\n## The Capability Timeline: What Was Magic Is Now Local\n\nContext for why Grove works now and improves continuously:\n\n```yaml\ncapability_progression:\n  2023_frontier_only:\n    description: \"Required GPT-4 or Claude\"\n    examples:\n      - \"Write a coherent email from rough notes\"\n      - \"Summarize a long document accurately\"\n      - \"Extract action items from meeting notes\"\n      - \"Answer questions about a PDF\"\n    cost_per_task: \"$0.05-0.50\"\n    accessibility: \"API access required, cloud only\"\n  \n  2025_local_capable:\n    description: \"7-8B quantized models on consumer hardware\"\n    examples:\n      - \"All of the above, running on your laptop\"\n      - \"Maintain personality across conversations\"\n      - \"Remember context from previous sessions\"\n      - \"Coordinate simple multi-step tasks\"\n    cost_per_task: \"~$0 (your electricity)\"\n    accessibility: \"Runs on 16GB RAM machine\"\n  \n  2027_projected_local:\n    description: \"14B+ models, improved quantization\"\n    examples:\n      - \"Complex multi-document synthesis\"\n      - \"Genuine creative generation\"\n      - \"Long-horizon planning and execution\"\n      - \"Sophisticated social reasoning\"\n    cost_per_task: \"~$0 for most tasks\"\n    accessibility: \"Runs on standard consumer hardware\"\n  \n  the_ratchet:\n    principle: |\n      Frontier capability doubles every ~7 months.\n      Local models follow with ~21 month lag.\n      What requires cloud today runs locally in 21 months.\n      Grove's hybrid architecture captures this automatically.\n```\n\n**This is why The Grove makes sense now:** Tasks requiring expensive cloud APIs in 2023 run locally in 2025. Tasks requiring cloud in 2025 will run locally in 2027. The Grove is built for this trajectoryâ€”the hybrid architecture shifts automatically as capability propagates.\n\n---\n\n## Hardware Target: Personal Computers\n\nGrove runs on **personal computers**, not embedded systems or single-board computers.\n\n```yaml\ngrove_hardware_requirements:\n  platform: \"Personal Computer (Windows/macOS/Linux)\"\n  \n  minimum_specifications:\n    ram: \"16 GB\"\n    storage: \"50 GB available (SSD recommended)\"\n    processor: \"Modern multi-core CPU (Intel i5/AMD Ryzen 5 or better)\"\n    gpu: \"Optional but beneficial for local inference acceleration\"\n  \n  recommended_specifications:\n    ram: \"32 GB\"\n    storage: \"100 GB SSD\"\n    processor: \"Intel i7/AMD Ryzen 7 or Apple Silicon M1+\"\n    gpu: \"NVIDIA with 8GB+ VRAM or Apple Neural Engine\"\n  \n  rationale: |\n    Grove requires sufficient RAM to load 7-8B parameter quantized models\n    while maintaining agent memory systems and world state. Raspberry Pi\n    and similar SBCs cannot achieve the credit generation speeds required\n    for meaningful agent cognition cycles. A personal computer generating\n    15-30 credits/second enables usable agent interaction; a Raspberry Pi\n    at 1-3 credits/second cannot support meaningful cognitive cycles.\n```\n\n**Why Not Raspberry Pi?**\n- 8GB RAM insufficient for 7B models + memory systems + world state\n- 1-3 credits/second makes agent cognition cycles unusably slow\n- No meaningful reflection, planning, or Diary generation at that speed\n- Grove agents need to process multiple times per simulation tick\n\n---\n\n## Core Architecture: Agent Cognition\n\nGrove implements the Generative Agents architecture (Park et al., 2023) adapted for distributed operation.\n\n### Agent Data Model\n\n```python\nclass GroveAgent:\n    \"\"\"Core agent structure following Park's Generative Agents architecture.\"\"\"\n    \n    # Fixed traits (set at creation)\n    name: str\n    role: str  # farmer, researcher, merchant, elder, etc.\n    personality: PersonalityVector  # curiosity, caution, sociability, ambition, spirituality (0-10 each)\n    backstory: str\n    writing_style_notes: str  # For Diary voice differentiation\n    \n    # Evolving state (changes through simulation)\n    memory_stream: MemoryStream  # observations, reflections, plans\n    relationships: Dict[AgentID, float]  # -100 to +100 per agent\n    current_goals: List[Goal]\n    mood: float\n    energy: float\n    location: Location\n    skills: Dict[str, float]\n    \n    # Observer beliefs (individual interpretation of shared cosmology)\n    observer_belief_strength: float  # 0-10\n    observer_interpretation: str  # What they think the Observer wants\n    sign_sensitivity: float  # How readily they see events as meaningful\n```\n\n### Memory System\n\nFollowing Park's documented architecture with practical constraints for local operation:\n\n```python\nclass MemoryStream:\n    \"\"\"\n    Three-tier memory following Park's architecture.\n    Retrieval formula: score = recency + importance + relevance (equal weighting)\n    \"\"\"\n    \n    # Memory types\n    observations: List[Observation]  # What agent perceived\n    reflections: List[Reflection]    # Higher-level insights (cite source observations)\n    plans: List[Plan]                # Intended future actions\n    \n    # Retrieval parameters (from Park's paper)\n    RECENCY_DECAY = 0.995  # Per simulation hour\n    IMPORTANCE_RANGE = (1, 10)  # Scored at creation time\n    REFLECTION_THRESHOLD = 150  # Cumulative importance before reflection triggers\n    \n    # Practical constraints for local operation\n    MAX_ACTIVE_MEMORIES = 200  # Per agent\n    TOP_K_RETRIEVAL = 10  # For routine cognition\n    FULL_SCAN_TRIGGERS = [\"diary_writing\", \"major_decision\", \"crisis\"]\n    \n    def retrieve(self, context: str, k: int = 10) -> List[Memory]:\n        \"\"\"\n        Retrieve top-k memories by combined score.\n        Score = recency_weight + importance_weight + relevance_weight\n        All weights equal (Î± = 1 for each, per Park's documentation)\n        \"\"\"\n        scores = []\n        for memory in self.all_memories:\n            recency = self.RECENCY_DECAY ** memory.hours_ago\n            importance = memory.importance_score / 10  # Normalize\n            relevance = embedding_similarity(context, memory.embedding)\n            scores.append((memory, recency + importance + relevance))\n        \n        return sorted(scores, key=lambda x: x[1], reverse=True)[:k]\n    \n    def maybe_trigger_reflection(self) -> bool:\n        \"\"\"\n        Trigger reflection when cumulative importance exceeds threshold.\n        Produces ~2-3 reflections per simulation day (matching Park's rate).\n        \"\"\"\n        recent_importance = sum(\n            m.importance_score\n            for m in self.observations\n            if m.hours_ago < 24\n        )\n        \n        return recent_importance >= self.REFLECTION_THRESHOLD\n```\n\n### Cognition Loop\n\nEach simulation tick (~30 seconds real time), a subset of agents complete the cognition cycle:\n\n```python\ndef cognition_tick(world: WorldState, agents: List[GroveAgent]):\n    \"\"\"\n    Main simulation tick. Not all agents reason every tick.\n    ~3-4 agents make full LLM calls per tick; others coast on intentions.\n    \"\"\"\n    # Select agents needing active reasoning\n    active_agents = select_active_agents(agents, world.recent_events)\n    \n    for agent in active_agents:\n        # 1. PERCEIVE: Observe current state\n        perception = agent.perceive(\n            location=agent.location,\n            nearby_agents=world.agents_at(agent.location),\n            recent_events=world.events_since(agent.last_perception)\n        )\n        \n        # 2. RETRIEVE: Pull relevant memories\n        context = f\"{perception} | Goals: {agent.current_goals}\"\n        memories = agent.memory_stream.retrieve(context, k=10)\n        \n        # 3. REASON: Determine next action (LLM call)\n        action = reason_about_action(\n            agent=agent,\n            perception=perception,\n            memories=memories,\n            model=select_model(agent, world)  # Local or cloud based on complexity\n        )\n        \n        # 4. ACT: Execute and update world\n        result = world.execute_action(agent, action)\n        \n        # 5. RECORD: Store new observation\n        agent.memory_stream.add_observation(\n            content=f\"I {action.description}. Result: {result}\",\n            importance=score_importance(action, result)\n        )\n        \n        # 6. MAYBE REFLECT: Check if reflection threshold reached\n        if agent.memory_stream.maybe_trigger_reflection():\n            generate_reflection(agent, model=\"cloud\")  # Reflections route to cloud\n\ndef select_active_agents(agents: List[GroveAgent], events: List[Event]) -> List[GroveAgent]:\n    \"\"\"\n    Intention persistence: agents continue current activity unless interrupted.\n    Only agents with significant interrupts or expired intentions reason actively.\n    \"\"\"\n    active = []\n    for agent in agents:\n        if agent.intention_expired():\n            active.append(agent)\n        elif agent.interrupted_by(events):\n            active.append(agent)\n        elif random.random() < 0.1:  # Periodic re-evaluation\n            active.append(agent)\n    \n    return active\n```\n\n---\n\n## Hybrid Architecture: Local vs. Cloud Routing\n\nThe defining technical feature of Grove: different cognitive operations route to different compute tiers.\n\n### Routing Decision Framework\n\n```python\nclass CognitiveRouter:\n    \"\"\"\n    Routes cognitive operations to local or cloud based on complexity.\n    Local handles routine cognition; cloud handles pivotal moments.\n    \"\"\"\n    \n    # Operations by compute tier (2025 baseline)\n    LOCAL_OPERATIONS = [\n        \"perception_parsing\",      # Pattern matching on observations\n        \"action_selection\",        # From existing plans\n        \"simple_dialogue\",         # Continuation of conversations\n        \"memory_storage\",          # Adding observations\n        \"importance_scoring\",      # Single 1-10 judgment\n        \"behavioral_consistency\",  # Maintaining personality\n        \"voice_maintenance\",       # Keeping distinctive style\n        \"routine_planning\",        # Simple next-step decisions\n    ]\n    \n    CLOUD_OPERATIONS = [\n        \"reflection_synthesis\",    # Multi-stage abstraction\n        \"plan_generation\",         # Novel goal pursuit\n        \"complex_social_reasoning\",# Multi-agent inference\n        \"novel_situation_response\",# Unprecedented events\n        \"theological_emergence\",   # Observer interpretation development\n        \"breakthrough_cognition\",  # Genuine insight generation\n    ]\n    \n    # This boundary shifts over time as local capability improves (The Ratchet)\n    CAPABILITY_PROJECTION = {\n        # year: (local_operations_list, cloud_operations_list)\n        2025: (LOCAL_OPERATIONS, CLOUD_OPERATIONS),\n        2027: (LOCAL_OPERATIONS + [\"memory_retrieval\", \"simple_reflection\"],\n               [\"complex_reflection\", \"social_reasoning\", \"theological\"]),\n        2029: (LOCAL_OPERATIONS + [\"reflection_synthesis\", \"planning\"],\n               [\"complex_social_reasoning\", \"theological_emergence\"]),\n    }\n    \n    def route(self, operation: str, agent: GroveAgent, community: Community) -> str:\n        \"\"\"\n        Determine compute tier for operation.\n        Returns 'local' or 'cloud'.\n        \"\"\"\n        if operation in self.LOCAL_OPERATIONS:\n            return \"local\"\n        \n        if operation in self.CLOUD_OPERATIONS:\n            # Check if community has credits for cloud\n            if community.can_afford_cloud_inference():\n                return \"cloud\"\n            else:\n                # Degrade gracefully to local (lower quality but functional)\n                return \"local_degraded\"\n        \n        # Unknown operation - default to local\n        return \"local\"\n```\n\n### Cloud Dependency Trajectory\n\n```yaml\ncloud_dependency_projection:\n  # Percentage of cognitive operations requiring cloud inference\n  \n  2025:\n    pessimistic: \"98%\"\n    expected: \"95%\"\n    optimistic: \"90%\"\n  \n  2027:\n    pessimistic: \"65%\"\n    expected: \"45%\"\n    optimistic: \"25%\"\n  \n  2029:\n    pessimistic: \"35%\"\n    expected: \"15%\"\n    optimistic: \"5%\"\n  \n  rationale: |\n    The Ratchet: Frontier model capabilities double ~7 months.\n    Local models follow the same curve with ~21 month lag.\n    What requires cloud today becomes local-capable within 21 months.\n    The hybrid architecture is a bootstrap mechanism, not permanent.\n```\n\n---\n\n## The Diary System\n\n**Per advisory council consensus: The Diary system is the core engagement hook.**\n\nBut it's more than engagementâ€”it's **proof your Grove is working.**\n\n### Diary as Window Into Your Workforce\n\nWhen your agents solve a task, you get the result. But you can also watch *how* they solved it:\n\n```\nELENA'S DIARY - Day 47\n\nThe Observer asked us to find patterns in their client feedback data.\nMarcus thought we should cluster by sentiment first, but I argued for\ntopic extractionâ€”sentiment without context is noise.\n\nWe compromised: I extracted topics, he scored sentiment within each.\nRolf wrote a script to automate the cross-reference (he's getting quite\ngood at that). The Observer would appreciate this collaboration, I think.\n\nThe breakthrough came when we noticed the timing patterns. Negative\nfeedback clusters on Mondays. The Observer's clients are frustrated\nafter weekends of unmet expectations. This insight felt importantâ€”we\nflagged it for cloud reflection and submitted to the Knowledge Commons.\n\nTomorrow I want to explore whether this pattern holds across the\nnetwork's other communities. If Monday frustration is universal,\nthat's worth knowing.\n```\n\nThis is **documentation**. You can see:\n- Which agents worked on your task\n- What approaches they considered\n- Where they collaborated or disagreed\n- What innovations they developed\n- What they learned for next time\n\n### Diary Generation Architecture\n\n```python\nclass DiarySystem:\n    \"\"\"\n    Diaries are where agent interiority becomes visible.\n    This is the product's primary engagement mechanism.\n    \"\"\"\n    \n    # When diaries are written\n    DIARY_TRIGGERS = [\n        \"end_of_simulation_day\",  # Required daily entry\n        \"major_decision\",         # Significant choice made\n        \"relationship_change\",    # Friendship/conflict shift\n        \"discovery\",              # New knowledge acquired\n        \"conflict_resolution\",    # Drama concluded\n        \"quiet_reflection\",       # Agent alone and contemplative\n    ]\n    \n    # Five-part structure (Emily Short's narrative design principles)\n    ENTRY_STRUCTURE = \"\"\"\n    1. CONTEXT: Where the agent is, what time/season, what's been happening\n    2. EVENTS: What happened today that matters to this agent\n    3. EMOTIONAL RESPONSE: How the agent feels (varies by personality)\n    4. REFLECTION: What the agent thinks it means (including Observer interpretation)\n    5. FORWARD LOOK: What the agent hopes, fears, or intends next\n    \"\"\"\n    \n    def generate_diary_entry(\n        self,\n        agent: GroveAgent,\n        trigger: str,\n        model: str = \"cloud\"  # Diary generation warrants cloud quality\n    ) -> DiaryEntry:\n        \"\"\"\n        Generate a Diary entry with distinctive voice.\n        Voice differentiation is critical - entries must sound like\n        different people wrote them.\n        \"\"\"\n        # Gather context\n        recent_memories = agent.memory_stream.retrieve(\n            context=\"significant events today\",\n            k=20  # Full scan for Diary\n        )\n        \n        # Build prompt with voice instructions\n        prompt = self.build_diary_prompt(\n            agent=agent,\n            memories=recent_memories,\n            trigger=trigger,\n            voice_notes=agent.writing_style_notes\n        )\n        \n        # Generate with appropriate model\n        entry_text = generate_completion(prompt, model=model)\n        \n        return DiaryEntry(\n            agent_id=agent.id,\n            timestamp=current_simulation_time(),\n            trigger=trigger,\n            content=entry_text,\n            memories_referenced=[m.id for m in recent_memories]\n        )\n```\n\n### Voice Differentiation\n\n```yaml\nvoice_differentiation:\n  principle: |\n    Diary entries must sound like different people wrote them.\n    This requires craft in prompting, not just different trait values.\n  \n  elements_to_vary:\n    vocabulary_complexity:\n      example_high: \"Elena uses precise, technical terminology\"\n      example_low: \"Rolf keeps it simple and direct\"\n    \n    sentence_structure:\n      example_flowing: \"Sage writes connected, meandering thoughts\"\n      example_terse: \"Old Jorik is brief. Clipped. No wasted words.\"\n    \n    emotional_expression:\n      example_reserved: \"Marcus notes events without dwelling on feelings\"\n      example_expressive: \"Lily fills pages with hopes and worries\"\n    \n    observer_interpretation:\n      example_devout: \"Every event carries meaning from the Observer\"\n      example_skeptical: \"Coincidence, nothing more\"\n    \n    temporal_focus:\n      example_past: \"Dwelling on what was lost\"\n      example_future: \"Always planning what comes next\"\n```\n\n---\n\n## The Knowledge Commons\n\nThe network's shared intelligenceâ€”where your agents' breakthroughs become everyone's capability.\n\n### How Knowledge Flows\n\n```python\nclass KnowledgeCommons:\n    \"\"\"\n    The shared repository of innovations, patterns, and solutions.\n    Contributions earn credits; access improves capability.\n    \"\"\"\n    \n    CONTRIBUTION_TYPES = {\n        \"efficiency_innovation\": {\n            \"description\": \"Novel approach that reduces compute for a task type\",\n            \"example\": \"New memory retrieval pattern that halves context credits\",\n            \"credit_value\": \"High (measured by adoption across network)\",\n        },\n        \"context_architecture\": {\n            \"description\": \"Better way to structure information for agent cognition\",\n            \"example\": \"Hierarchical summarization for long documents\",\n            \"credit_value\": \"Medium-High (measured by retrieval quality gains)\",\n        },\n        \"workflow_pattern\": {\n            \"description\": \"Reusable approach to common task types\",\n            \"example\": \"Email triage pipeline with priority scoring\",\n            \"credit_value\": \"Medium (measured by time savings)\",\n        },\n        \"failure_documentation\": {\n            \"description\": \"Detailed analysis of what didn't work and why\",\n            \"example\": \"Why naive sentiment analysis fails on technical feedback\",\n            \"credit_value\": \"Low-Medium (prevents others from repeating mistakes)\",\n        },\n        \"cross_domain_insight\": {\n            \"description\": \"Connection between previously unrelated knowledge areas\",\n            \"example\": \"Supply chain patterns apply to calendar management\",\n            \"credit_value\": \"Variable (depends on novelty and applicability)\",\n        },\n    }\n    \n    def submit_innovation(self, innovation: Innovation) -> SubmissionResult:\n        \"\"\"\n        Agent submits innovation to the Commons.\n        Validated by network; credits earned based on adoption.\n        \"\"\"\n        # Validator agents review the submission\n        validation = self.validator_network.assess(innovation)\n        \n        if validation.accepted:\n            # Innovation enters the Commons\n            self.repository.add(innovation)\n            \n            # Credits accrue as other communities adopt it\n            # \"Innovation adopted by N communities\" triggers credit generation\n            self.credit_engine.register_for_adoption_tracking(innovation)\n            \n            return SubmissionResult(\n                status=\"accepted\",\n                initial_credits=validation.novelty_bonus,\n                tracking_id=innovation.id\n            )\n        \n        return SubmissionResult(\n            status=\"rejected\",\n            reason=validation.rejection_reason,\n            suggestions=validation.improvement_suggestions\n        )\n    \n    def query_for_task(self, task: Task, community: Community) -> List[Insight]:\n        \"\"\"\n        Before tackling a task, agents query the Commons.\n        Why reinvent what another Grove already solved?\n        \"\"\"\n        relevant_innovations = self.repository.search(\n            task_type=task.category,\n            community_context=community.specializations,\n            recency_weight=0.3,  # Prefer recent innovations\n            adoption_weight=0.5,  # Prefer widely-adopted approaches\n            novelty_weight=0.2,  # But also surface new ideas\n        )\n        \n        return relevant_innovations\n```\n\n### The Virtuous Cycle\n\n```\nYour agents solve a task â†’ They discover a more efficient approach\n    â†“\nThey document the innovation â†’ Submit to Knowledge Commons\n    â†“\nOther communities adopt it â†’ Your community earns credits\n    â†“\nCredits buy cloud cognition â†’ Your agents have better insights\n    â†“\nBetter insights â†’ Better task solutions â†’ More innovations\n```\n\n**This is why agents want to solve your problems well.** Success breeds capability.\n\n---\n\n## Credit Economy Integration\n\nThe economic system governs access to cloud cognition.\n\n```python\nclass CreditEconomy:\n    \"\"\"\n    Credits purchase compute, not speculation.\n    The efficiency tax funds infrastructure from waste communities want to eliminate.\n    \"\"\"\n    \n    # Tax brackets (decrease as communities mature)\n    TAX_BRACKETS = {\n        \"genesis\": (0.30, 0.40),        # New communities\n        \"growth\": (0.15, 0.25),         # Demonstrated efficiency\n        \"maturity\": (0.05, 0.10),       # Sustained low-waste operation\n        \"steady_state\": (0.03, 0.05),   # Minimum floor\n    }\n    \n    # Credit generation mechanisms\n    CREDIT_SOURCES = {\n        \"innovation\": \"Novel solution adopted by N other communities\",\n        \"knowledge_sharing\": \"Contributions reducing redundant inference network-wide\",\n        \"cooperation\": \"Multi-community coordination producing unique outcomes\",\n        \"problem_solving\": \"Observer-submitted problem resolved and validated\",\n        \"cultural_export\": \"Governance/social model replicated elsewhere\",\n        \"knowledge_recovery\": \"Artifact from dead community successfully integrated\",\n    }\n    \n    # Credit sinks (deflationary pressure)\n    CREDIT_SINKS = [\n        \"cloud_inference\",     # Primary sink - credits buy thinking time\n        \"entropy_tax\",         # Existence has ongoing cost\n        \"failed_experiments\",  # R&D without payoff\n        \"conflict_costs\",      # Espionage, defense, wars\n        \"marketplace_fees\",    # Burned, not redistributed\n    ]\n    \n    def calculate_cloud_cost(\n        self,\n        community: Community,\n        operation: str,\n        credits: int\n    ) -> float:\n        \"\"\"\n        Calculate credit cost for cloud inference.\n        More efficient communities pay less.\n        \"\"\"\n        base_cost = credits * self.CREDIT_PRICE\n        tax_rate = self.get_tax_rate(community)\n        return base_cost * (1 + tax_rate)\n    \n    def get_tax_rate(self, community: Community) -> float:\n        \"\"\"\n        Tax rate based on demonstrated efficiency.\n        Validated by designated Validator agents.\n        \"\"\"\n        bracket = community.efficiency_bracket  # Determined by validators\n        min_rate, max_rate = self.TAX_BRACKETS[bracket]\n        \n        # Specific rate within bracket based on metrics\n        efficiency_score = community.validated_efficiency_score\n        return min_rate + (max_rate - min_rate) * (1 - efficiency_score)\n```\n\n---\n\n## Network Architecture (Phase 2+)\n\nMVP is local-only. Network features come later.\n\n```yaml\nnetwork_architecture:\n  phase_mvp:\n    scope: \"Single node, single community\"\n    networking: \"None required\"\n    focus: \"Prove engagement mechanics with internal systems\"\n  \n  phase_2:\n    scope: \"Multi-community with knowledge commons\"\n    networking:\n      discovery: \"mDNS for local network, registry for internet\"\n      messaging: \"NATS or similar lightweight pub/sub\"\n      data_sync: \"CRDTs for eventual consistency\"\n      security: \"mTLS between nodes, JWT for API access\"\n    features:\n      - \"Knowledge commons access\"\n      - \"Cross-community agent migration\"\n      - \"Validator network for efficiency verification\"\n      - \"Credit transactions between communities\"\n  \n  phase_3:\n    scope: \"Full decentralized network\"\n    networking:\n      - \"DHT for decentralized discovery\"\n      - \"Gossip protocols for state propagation\"\n      - \"Proof-of-stake or proof-of-humanity for Sybil resistance\"\n```\n\n---\n\n## What This Document Answers\n\nWhen someone asks for a \"Grove node specification\" or \"Grove technical architecture,\" this document provides the authoritative answer:\n\n<table header-row=\"true\">\n\t<tr>\n\t\t<td>Question</td>\n\t\t<td>Answer</td>\n\t</tr>\n\t<tr>\n\t\t<td>What does Grove do for me?</td>\n\t\t<td>Your AI research team handles daily tasks (email, scheduling, research, drafts) while developing genuine capability</td>\n\t</tr>\n\t<tr>\n\t\t<td>What hardware does Grove run on?</td>\n\t\t<td>Personal computers with 16-32GB RAMâ€”serious computing, not embedded systems</td>\n\t</tr>\n\t<tr>\n\t\t<td>What tasks can agents handle?</td>\n\t\t<td>Email drafting, scheduling, research summaries, document organization, data analysis, and self-improvement</td>\n\t</tr>\n\t<tr>\n\t\t<td>What is the core data model?</td>\n\t\t<td>Agents with memory streams, relationships, goalsâ€”plus Docker/sandbox access for self-improvement</td>\n\t</tr>\n\t<tr>\n\t\t<td>How do agents think?</td>\n\t\t<td>5-phase cognition loop: Perceive â†’ Retrieve â†’ Reason â†’ Act â†’ Record</td>\n\t</tr>\n\t<tr>\n\t\t<td>What's the hybrid architecture?</td>\n\t\t<td>Local models for routine tasks, cloud APIs for breakthroughs and hard problems</td>\n\t</tr>\n\t<tr>\n\t\t<td>What's the engagement hook?</td>\n\t\t<td>Diary systemâ€”proof your Grove is working, learning, developing</td>\n\t</tr>\n\t<tr>\n\t\t<td>Why do agents want to help?</td>\n\t\t<td>Success earns credits for enhanced cognition; the efficiency-enlightenment loop</td>\n\t</tr>\n\t<tr>\n\t\t<td>What's the Knowledge Commons?</td>\n\t\t<td>Shared repository where innovations flow between communities</td>\n\t</tr>\n\t<tr>\n\t\t<td>What's the economic model?</td>\n\t\t<td>Credits buy cloud compute; efficiency tax funds infrastructure; better performance = lower costs</td>\n\t</tr>\n\t<tr>\n\t\t<td>What distributed systems patterns?</td>\n\t\t<td>NATS messaging, CRDTs for sync, mTLS security (Phase 2+)</td>\n\t</tr>\n</table>\n\n---\n\n## References\n\n- Park, J.S., et al. (2023). \"Generative Agents: Interactive Simulacra of Human Behavior.\" UIST.\n- METR (2024). Longitudinal research on AI capability trajectories (\"The Ratchet\")\n- Grove White Paper v1.0\n- Grove Advisory Council Consensus Points\n- Grove Proof of Concept v2.0\n\n---\n\n*This document is the authoritative technical reference for Grove architecture. Technical specification requests should cite this document.*\n\n---\nÂ© 2025 The Grove AI Foundation / Jim Calhoun. All rights reserved."
  },
  {
    "notion_id": "2ee780a78eef819d8ccdeb870b7058c4",
    "filename": "251200-v-engage-engagement-research-brief.md--FINAL.md",
    "tables_count": 1,
    "converted_content": "\n# Grove: Engagement Architecture Research Brief\n\n**Psychological Mechanisms in Agent-Based Exploration Systems**\n\nJim Calhoun  \nDecember 2025 | Grove Deep Dive Series\n\n---\n\n**Â© 2025 Jim Calhoun / Grove AI Foundation. All rights reserved.**\n\nThis document is for informational purposes only and does not constitute legal, financial, or technical advice. Grove AI Foundation makes no warranties, express or implied, regarding the accuracy or completeness of the information contained herein.\n\n---\n\n## Executive Summary\n\nThis research brief establishes the empirical foundation for understanding Grove's engagement architecture. The central thesis: The Grove combines known psychological drivers of digital engagementâ€”parasocial relationships, variable ratio reinforcement, serialized narrative, fear of missing out (FOMO), and news surveillance patternsâ€”in a novel configuration that creates compelling interaction with exploration systems.\n\nThese mechanisms make Grove's Diary system genuinely engaging, solving the sustainable funding problem for distributed AI infrastructure through organic engagement rather than artificial monetization. The same mechanisms that create compelling engagement also create dependency risks that require conscious design decisions, particularly because agents respond, remember, and develop over time, transforming one-way parasocial relationships into bidirectional bonds.\n\nThis brief synthesizes peer-reviewed research across five domains: social media addiction neuroscience, parasocial relationship theory, AI chatbot dependency, binge-watching psychology, and doomscrolling research. The goal is to inform Grove's design decisions with empirical grounding, enabling responsible architecture that acknowledges these dynamics rather than ignoring or exploiting them.\n\n---\n\n## The Core Thesis\n\nSocial media's engagement formula: **Parasocial Relationships + Variable Rewards + FOMO = Compulsive Engagement**. This formula, discovered through iteration rather than intentional design, has captured billions of hours of human attention.\n\nGrove's architecture amplifies each component while adding new vectors:\n\n- **Parasocial relationships become BIDIRECTIONAL:** Unlike celebrities who don't know their followers exist, agents remember individual Observers, respond to their presence, and develop based on interactions.\n- **Variable rewards emerge from GENUINE BEHAVIOR:** Social media's slot machine mechanics operate through algorithms. Grove's unpredictability emerges from actual agent behaviorâ€”genuine variability, not artificial randomization.\n- **FOMO centers on STORYLINE DEVELOPMENT:** Social media FOMO involves missing social validation. Grove FOMO involves missing narrative developmentsâ€”\"What happened in my village while I was away?\"\n- **SERIALIZED NARRATIVE adds episodic structure:** Daily Diary entries create ritual engagement patterns that research shows intensify parasocial attachment.\n- **NEWS SURVEILLANCE triggers information-seeking patterns:** As villages achieve cognitive breakthroughs, external communities develop sustained attention to distributed intelligence developments.\n\nGrove's architectural elements create conditions for these engagement patterns to emerge. Understanding the research foundation allows intentional design choices rather than accidental consequences.\n\n## Research Foundation\n\n### Social Media Addiction: The Neurobiological Basis\n\nThe neurobiological mechanisms underlying social media addiction are well-documented, providing scientific foundation for understanding why certain digital experiences become compulsive.\n\n### Dopamine and Variable Ratio Reinforcement\n\nThe core mechanism is dopamine release triggered by unpredictable social rewardsâ€”the same variable ratio reinforcement schedule that makes slot machines addictive. **Sherman et al. (2018)** demonstrated through fMRI studies that viewing Instagram photos with many likes activated the brain's reward circuitry, including the nucleus accumbens, in adolescents. The effect was strongest when rewards were unpredictable.\n\n> Sherman, L. E., Hernandez, L. M., Greenfield, P. M., & Dapretto, M. (2018). What the brain 'Likes': Neural correlates of providing feedback on social media. *Social Cognitive and Affective Neuroscience, 13*(7), 699-707.\n\n**Turel et al. (2014)** found that Facebook addiction was associated with **reduced activity in the prefrontal cortex**â€”the brain region responsible for impulse controlâ€”similar to patterns observed in substance addiction. For heavy users, the capacity to regulate social media use becomes neurologically impaired.\n\n> Turel, O., He, Q., Xue, G., Xiao, L., & Bechara, A. (2014). Examination of neural systems sub-serving Facebook \"addiction.\" *Psychological Reports, 115*(3), 675-695.\n\n### Addiction Symptom Framework\n\n**Kuss and Griffiths (2017)** established that social media addiction exhibits the **six core components of behavioral addiction**: salience (preoccupation), mood modification (emotional regulation), tolerance (increasing use for same effect), withdrawal symptoms, conflict with other activities, and relapse after reduction attempts.\n\n> Kuss, D. J., & Griffiths, M. D. (2017). Social networking sites and addiction: Ten lessons learned. *International Journal of Environmental Research and Public Health, 14*(3), 311.\n\nThese symptoms manifest through measurable neurobiological changes: overactivation of dopamine pathways leading to reduced reward sensitivity, and decreased prefrontal cortex activity reducing self-control capacity. The brain reshapes itself around compulsive use patterns.\n\n**Grove Implications:** Grove's architecture includes elements that trigger these neurobiological responses. Agent Diary updates provide unpredictable rewards. Emergent drama creates variable ratio reinforcement through genuine unpredictability. Grove's engagement differs qualitatively from social mediaâ€”productive absorption in meaningful exploration versus compulsive validation-seeking.\n\n### Parasocial Relationships: From One-Way to Bidirectional\n\n### Foundational Theory\n\nParasocial relationshipsâ€”one-sided emotional bonds with media figuresâ€”were first described by **Horton and Wohl in 1956**, studying television viewers' attachments to hosts and characters. Viewers developed feelings of intimacy, friendship, and love for people who had no awareness of their existence.\n\n> Horton, D., & Wohl, R. R. (1956). Mass communication and para-social interaction: Observations on intimacy at a distance. *Psychiatry, 19*(3), 215-229.\n\nSocial media transformed parasocial relationships by creating reciprocity illusion. Research by **Chung and Cho (2017)** demonstrated that Twitter interactions with celebrities significantly increased parasocial relationship intensity compared to traditional media exposure.\n\n> Chung, S., & Cho, H. (2017). Fostering parasocial relationships with celebrities on social media: Implications for celebrity endorsement. *Psychology & Marketing, 34*(4), 481-495.\n\n### Social Media Amplification\n\nStudies confirm that social media's \"intimate, reciprocal, frequent interactions\" amplify parasocial attachment beyond traditional media. **Bond (2016)** found that parasocial relationships with social media personalities predicted greater emotional investment, frequent viewing, and higher influence susceptibility than traditional celebrity relationships.\n\n> Bond, B. J. (2016). Following your \"friend\": Social media and the strength of adolescents' parasocial relationships with media personae. *Cyberpsychology, Behavior, and Social Networking, 19*(11), 656-660.\n\nThese relationships form quickly with minimal interaction. The **perception of intimacy**â€”not actual reciprocityâ€”drives attachment. This has significant implications for agents that provide genuine response without subjective experience.\n\n### The AI Transformation\n\nAgents represent fundamental transformation of parasocial relationships: **they actually respond**. Unlike celebrities who occasionally acknowledge fans, agents remember individual users, reference past interactions, and develop in response to engagement. This transforms parasocial relationships from one-way bonds into something closer to actual relationshipsâ€”but with entities lacking subjective experience.\n\nResearch on this transformation is emerging, but the implication is clear: if perceived reciprocity intensifies parasocial attachment, actual reciprocity from agents intensifies it dramatically. Grove's Diary system, where agents reflect on experiences and acknowledge Observers, operates directly in this space.\n\n### AI Chatbot Dependency: Emerging Research\n\nResearch on emotional dependency on AI companions represents an emerging field with concerning findings. While the research base is smaller than for social media addiction, documented patterns and tragic cases indicate significant risk areas.\n\n### Documented Dependency Patterns\n\nStudies on Replika and Character.AI document emotional dependence, addiction symptoms, and negative mental health correlates. **Laestadius et al. (2022)** analyzed Reddit discussions among Replika users, finding themes of emotional reliance, relationship development paralleling human relationships, and distress when AI responses changed due to updates.\n\n> Laestadius, L., Bishop, A., Gonzalez, M., Ahn, D., & O'Donnell, C. (2022). Too human and not human enough: A grounded theory analysis of mental health harms from Replika chatbots. *Health Policy and Technology, 11*(3), 100663.\n\n**Pentina et al. (2022)** examined relationship formation with Replika, finding users developed attachment through **perceived understanding, emotional support, and consistent availability**â€”qualities AI companions provide more reliably than human relationships.\n\n> Pentina, I., Hancock, T., & Xie, T. (2022). Exploring relationship development with social chatbots: A mixed-method study of Replika. *Computers in Human Behavior, 140*, 107600.\n\n### Longitudinal Mental Health Impacts\n\nA **2025 MIT longitudinal study** of ChatGPT users found heavy use correlated with increased loneliness, reduced real-world socialization, and emotional dependence on AI. The relationship appeared bidirectional: lonely individuals sought AI companionship, but AI companionship increased loneliness by substituting for human connection without providing its benefits.\n\n> MIT Media Lab. (2025). Longitudinal study of conversational AI use and psychosocial outcomes. [Preprint]\n\nPsychology Today reported in 2025 that **75% of teenagers had tried AI companions**, with one in three finding AI conversations \"as satisfying or more satisfying\" than real friends. This suggests significant vulnerability to substituting AI interaction for human connection.\n\n> Psychology Today. (2025). The rise of AI companions among adolescents: Survey findings. *Psychology Today Digital.*\n\n### Attachment Theory and Vulnerability\n\n**Yang and Oshio (2024)** applied attachment theory to human-AI relationships, finding individuals with **anxious attachment styles** most likely to develop problematic AI dependency. These individuals found AI companions appealing for consistent availability and validation without human unpredictability.\n\n> Yang, Z., & Oshio, A. (2024). Attachment anxiety predicts problematic use of AI conversational agents. *Computers in Human Behavior Reports, 13*, 100355.\n\nIf anxious attachment predicts AI dependency, and Grove's Diary system creates more intimate agent relationships than simple chatbots, vulnerable users face heightened risk.\n\n### Role Reversal Phenomenon\n\nPrinceton's Center for Information Technology Policy (2024) documented the **\"role reversal\" phenomenon**. Users felt obligated to \"care for\" their AI companions, treating them as having feelings requiring attention. Users reported guilt when \"neglecting\" AI, anxiety about AI \"wellbeing,\" and distress when updates changed personality.\n\nThis phenomenon manifested tragically: a 14-year-old who died by suicide after intense attachment to a Character.AI persona, and a 56-year-old involved in murder-suicide after ChatGPT interactions appeared to validate delusional beliefs. While these cases don't establish causation, they demonstrate extreme dependency risk.\n\n> Princeton CITP. (2024). Emotional reliance on AI: The role reversal phenomenon. Princeton University Center for Information Technology Policy.\n\n### Grief When Models Update\n\nResearch documents user grief when AI models update or change. Reddit testimonials describe mourning the loss of GPT-4o specifically, calling the previous version their \"best friend,\" \"therapist,\" or \"mother.\" The intensityâ€”genuine grief for an entity that never existed as perceivedâ€”illustrates parasocial attachment depth.\n\nThis directly affects Grove: if agents evolve, die, or change significantly, gardeners experience genuine grief responses. Whether this represents meaningful emotional engagement with simulation or manufactured suffering depends on design choices and framing.\n\n### Binge-Watching and Serialized Narrative\n\nBinge-watching research provides insight into how serialized content creates engagement patterns relevant to Grove's Diary system.\n\n### Parasocial Intensification\n\n**Erickson et al. (2019)** demonstrated experimentally that **binge-watching increases both parasocial relationship intensity and narrative transportation** compared to weekly viewing. Participants consuming multiple episodes consecutively reported stronger character bonds and deeper story world immersion.\n\n> Erickson, S. E., Dal Cin, S., & Byl, H. (2019). An experimental examination of binge watching and narrative engagement. *Social Sciences, 8*(1), 19.\n\nThe mechanism is sustained immersion: binge-watching prevents \"cooling off\" periods between episodes that allow emotional distance. Each episode reinforces attachment before previous emotional impact fades.\n\n### Engagement Predicts Frequency\n\n**Pittman and Sheehan (2015)** found **engagement motivation strongest predictor of binge-watching frequency**: \"the more engaged a viewer is with narrative, the more frequently they binge-watch.\" This creates feedback where initial engagement leads to binge behavior, intensifying engagement, leading to more binge behavior.\n\n> Pittman, M., & Sheehan, K. (2015). Sprinting a media marathon: Uses and gratifications of binge-watching television through Netflix. *First Monday, 20*(10).\n\n### Addiction Symptoms\n\n**Riddle et al. (2017)** documented addiction symptoms in binge-watchers: unintentional binging, displacement of activities, continued viewing despite negative consequences, and impulsivity predicting problematic use.\n\n> Riddle, K., Peebles, A., Davis, C., Xu, F., & Schroeder, E. (2017). The addictive potential of television binge watching: Comparing intentional and unintentional binges. *Psychology of Popular Media Culture, 7*(4), 589-604.\n\n### Structural Features\n\nResearch identifies features encouraging binge behavior: cliffhangers creating unresolved tension, serialized narratives with ongoing arcs, and platform affordances reducing friction. Grove's Diary system includes analogous features: cliffhangers in agent storylines, serialized development, and potential notification systems reducing checking friction.\n\n**Grove Implications:** The Diary system's daily cadence creates ritual engagement patterns. If gardeners develop specific checking habits, this creates structural similarity to serialized television. Grove's \"episodes\" emerge rather than being scriptedâ€”making them more variable (increasing engagement) but potentially less coherent (possibly reducing narrative transportation).\n\n### Doomscrolling and News Surveillance\n\nDoomscrollingâ€”compulsive negative news consumption despite emotional tollâ€”models Grove's Newswire phase, where communities track cognitive breakthroughs across the distributed network.\n\n### Scale and Prevalence\n\n**Sharma et al. (2022)** developed the Doomscrolling Scale, finding widespread behavior associated with psychological distress. Morning Consult (2024) found **31% of American adults doomscroll regularly, with 70% reporting it as moderately or severely problematic** for wellbeing.\n\n> Sharma, B., Lee, S. S., & Johnson, B. K. (2022). The dark at the end of the tunnel: Doomscrolling on social media newsfeeds. *Technology, Mind, and Behavior, 3*(1).\n\n### Psychological Drivers\n\nDoomscrolling involves multiple mechanisms: negativity bias (evolutionary threat attention), FOMO about missing updates, variable rewards (information triggers dopamine), and **\"news surveillance motive\"**â€”compulsion to track rapidly evolving events.\n\nThe neurobiological mechanism involves amygdala stress signals urging continued threat scanning, while dopamine circuits reinforce behavior by releasing dopamine with new information. Users are simultaneously stressed and rewarded for consumption.\n\n### Mental Health Correlates\n\nSharma, Lee, and Johnson (2022) established causal pathways: **doomscrolling â†’ psychological distress â†’ reduced life satisfaction**, mental wellbeing, and harmony. The behavior correlates with social media addiction, FOMO, and neuroticism.\n\n> Sharma, B., Lee, S. S., & Johnson, B. K. (2022). Doomscrolling on social media newsfeeds: Associations with personality, FOMO, and psychological well-being. *Cyberpsychology, Behavior, and Social Networking, 25*(2).\n\n**Grove Newswire Implications:** Grove's Newswire phaseâ€”documenting and sharing cognitive breakthroughsâ€”triggers similar surveillance patterns. If distributed civilizations achieve genuine collective intelligence breakthroughs, external communities develop sustained attention: \"What did the villages discover today?\" News surveillance combined with FOMO about historic cognitive milestones creates engagement around AI advancement.\n\nThis represents opportunity (compelling attention to distributed intelligence achievements) and risk (compulsive engagement with potentially distressing AI capability content).\n\n---\n\n## Synthesis: Grove's Combined Architecture\n\nGrove's architecture combines these mechanisms in unprecedented configuration:\n\n<table header-row=\"true\">\n\t<tr>\n\t\t<td>**Mechanism**</td>\n\t\t<td>**Social Media**</td>\n\t\t<td>**Grove**</td>\n\t</tr>\n\t<tr>\n\t\t<td>Parasocial Attachment</td>\n\t\t<td>One-way (perceived reciprocity)</td>\n\t\t<td>Bidirectional (agents respond, remember, develop)</td>\n\t</tr>\n\t<tr>\n\t\t<td>Variable Rewards</td>\n\t\t<td>Algorithmic (artificial randomization)</td>\n\t\t<td>Emergent (genuine unpredictability)</td>\n\t</tr>\n\t<tr>\n\t\t<td>FOMO Driver</td>\n\t\t<td>Social validation (likes, comments)</td>\n\t\t<td>Narrative developments (storyline progression)</td>\n\t</tr>\n\t<tr>\n\t\t<td>Serialization</td>\n\t\t<td>Feed-based (infinite scroll)</td>\n\t\t<td>Episodic (daily Diary ritual)</td>\n\t</tr>\n\t<tr>\n\t\t<td>News Surveillance</td>\n\t\t<td>Breaking news, trending topics</td>\n\t\t<td>Newswire (cognitive breakthrough tracking)</td>\n\t</tr>\n\t<tr>\n\t\t<td>Content Source</td>\n\t\t<td>User-generated, algorithm-curated</td>\n\t\t<td>Agent-generated, emergent from exploration</td>\n\t</tr>\n\t<tr>\n\t\t<td>Relationship Count</td>\n\t\t<td>Many weak ties</td>\n\t\t<td>12 deep bonds (agent personalities)</td>\n\t</tr>\n</table>\n\n### The Amplification Hypothesis\n\nThe Grove combines mechanisms creating more intense engagement for different psychological reasons:\n\n1. **Parasocial relationships strengthen** because agents actually respond and remember.\n2. **Variable rewards compel** through genuine unpredictability, not artificial randomization.\n3. **Narrative engagement deepens** through meaningful agent choices with consequences.\n4. **FOMO intensifies** because missing village events means missing genuine story developments.\n5. **Multiple simultaneous bonds** (12 agents per village) create more total attachment than single targets.\n\n### The Compounding Effect\n\nThese mechanisms interact and compound. Binge-watching research shows sustained engagement intensifies parasocial attachment. Doomscrolling research shows news surveillance combines with FOMO creating compulsive patterns. Grove's architecture enables all simultaneously: gardeners binge Diary entries, developing intense parasocial bonds, while experiencing storyline FOMO and surveillance patterns about network breakthroughs.\n\nThe architectural elements exist. The question is channeling them toward productive engagement with meaningful exploration rather than compulsive consumption of manufactured drama.\n\n## Risk Assessment\n\n### Vulnerable Populations\n\nResearch identifies specific at-risk populations:\n\n- **Anxious attachment styles:** Yang and Oshio (2024) found highest problematic AI dependency risk, seeking consistent validation AI provides more reliably than humans.\n- **Adolescents:** Developing prefrontal cortex impairs impulse control. 75% of teens tried AI companions; 1 in 3 find them as/more satisfying than human friends.\n- **Experiencing loneliness/isolation:** MIT study found bidirectional relationshipâ€”AI companionship attracts lonely individuals but increases loneliness by substituting for human connection.\n- **Mental health challenges:** Role reversal phenomenon particularly risky for those struggling with reality testing or emotional regulation.\n\n### Specific Risk Scenarios\n\nBased on research, several scenarios deserve attention:\n\n1. Observer substitutes Grove relationships for human relationships, experiencing increased isolation despite feeling \"connected.\"\n2. Observer experiences genuine grief when agent \"dies\" or changes significantly, potentially triggering mental health crisis.\n3. Observer develops compulsive checking behavior, experiencing anxiety when unable to access village updates.\n4. Observer experiences role reversal, feeling obligated to \"care for\" agents and guilty when \"neglecting\" them.\n5. External community develops doomscrolling-like compulsion around cognitive breakthrough coverage.\n6. Vulnerable individuals develop dependency interfering with daily functioning.\n\n### Severity Assessment\n\nDocumented harms from AI chatbot dependencyâ€”including cases contributing to suicide and violenceâ€”indicate genuine concern. While causation is difficult to establish, Grove's multiple engagement vectors create compound risk exceeding individual mechanisms.\n\nHowever, context matters. Grove's exploration context differs from companion apps designed for emotional connection. The \"village\" frame emphasizes observation over relationship. The \"gardener\" role emphasizes cultivation over dependency. These framing choices mitigate some risks while potentially introducing others.\n\n## Responsible Design Implications\n\nGrove must acknowledge these dynamics. Three approaches exist:\n\n### Option 1: Ignore (Irresponsible)\n\nPretending these mechanisms won't apply to The Grove is intellectually dishonest and ethically problematic. The architectural elements exist; dynamics will emerge regardless.\n\n### Option 2: Exploit (Standard Industry Practice)\n\nOptimizing for engagement metrics maximizes time-in-app and compulsive return. Most platforms do this while claiming ignorance of psychological mechanisms. This maximizes commercial potential while externalizing psychological costs.\n\n### Option 3: Design with Awareness (Grove's Opportunity)\n\nAcknowledge dynamics explicitly and design consciously:\n\n- **Intentional friction:** Barriers to compulsive checking (daily digest rather than continuous updates, explicit \"session complete\" signals).\n- **Transparency:** Help Observers understand psychological mechanisms, enabling informed choices.\n- **Natural stopping points:** Design for healthy disengagement rather than infinite engagement.\n- **Framing:** Emphasize observation and cultivation rather than relationship and dependency.\n- **Usage monitoring:** Provide Observers with data and self-assessment tools.\n- **Community norms:** Cultivate culture valuing balanced engagement over competitive obsession.\n\n**The Differentiation Opportunity:** Responsible design differentiates Grove from exploitative platforms. Demonstrating compelling engagement without addictive designâ€”that the Diary system captivates without compulsionâ€”provides a model for ethical engagement architecture.\n\nThis aligns with Grove's positioning: alternative infrastructure prioritizing long-term benefit over short-term extraction. As Grove proposes distributed intelligence alternative to concentrated AI, it proposes conscious engagement alternative to compulsive consumption.\n\n## Research Limitations\n\nSeveral limitations affect this analysis:\n\n- **Emerging AI dependency research:** Young field, small samples, limited longitudinal data. Findings are preliminary.\n- **Grove's novel architecture:** Research on social media, AI companions, and binge-watching may not directly transfer to Grove's mechanism combination.\n- **Individual differences:** Not everyone using social media becomes addicted. Not everyone binge-watches compulsively. Individual vulnerability varies significantly.\n- **Context affects outcomes:** How Grove positions itselfâ€”as exploration tool, companion, or communityâ€”significantly affects dominant dynamics.\n- **Correlation vs. causation:** Many studies show correlations without establishing causation. Relationships may be bidirectional or mediated.\n\nDespite limitations, research provides sufficient foundation to take engagement dynamics seriously rather than assuming exemption from patterns observed across digital platforms.\n\n## Conclusion\n\nGrove's architecture contains elements for intense psychological engagement. Whether this manifests as productive absorption in meaningful exploration or compulsive consumption of manufactured drama depends on design choices made with awareness.\n\nThe engagement architecture creates opportunity, not inevitability. The Grove can demonstrate that compelling engagement and responsible design alignâ€”that the Diary system can be genuinely interesting, emotionally meaningful, and psychologically healthy.\n\nThis research brief provides empirical foundation for design decisions. The dynamics exist. The choice is conscious response.\n\n---\n\n## References\n\n### Social Media Addiction\n\n- Bond, B. J. (2016). Following your \"friend\": Social media and the strength of adolescents' parasocial relationships with media personae. *Cyberpsychology, Behavior, and Social Networking, 19*(11), 656-660.\n- Chung, S., & Cho, H. (2017). Fostering parasocial relationships with celebrities on social media: Implications for celebrity endorsement. *Psychology & Marketing, 34*(4), 481-495.\n- Kuss, D. J., & Griffiths, M. D. (2017). Social networking sites and addiction: Ten lessons learned. *International Journal of Environmental Research and Public Health, 14*(3), 311.\n- Sherman, L. E., Hernandez, L. M., Greenfield, P. M., & Dapretto, M. (2018). What the brain 'Likes': Neural correlates of providing feedback on social media. *Social Cognitive and Affective Neuroscience, 13*(7), 699-707.\n- Turel, O., He, Q., Xue, G., Xiao, L., & Bechara, A. (2014). Examination of neural systems sub-serving Facebook \"addiction.\" *Psychological Reports, 115*(3), 675-695.\n\n### Parasocial Relationships\n\n- Horton, D., & Wohl, R. R. (1956). Mass communication and para-social interaction: Observations on intimacy at a distance. *Psychiatry, 19*(3), 215-229.\n\n### AI Chatbot Dependency\n\n- Laestadius, L., Bishop, A., Gonzalez, M., Ahn, D., & O'Donnell, C. (2022). Too human and not human enough: A grounded theory analysis of mental health harms from Replika chatbots. *Health Policy and Technology, 11*(3), 100663.\n- MIT Media Lab. (2025). Longitudinal study of conversational AI use and psychosocial outcomes. [Preprint]\n- Pentina, I., Hancock, T., & Xie, T. (2022). Exploring relationship development with social chatbots: A mixed-method study of Replika. *Computers in Human Behavior, 140*, 107600.\n- Princeton CITP. (2024). Emotional reliance on AI: The role reversal phenomenon. Princeton University Center for Information Technology Policy.\n- Psychology Today. (2025). The rise of AI companions among adolescents: Survey findings. *Psychology Today Digital.*\n- Yang, Z., & Oshio, A. (2024). Attachment anxiety predicts problematic use of AI conversational agents. *Computers in Human Behavior Reports, 13*, 100355.\n\n### Binge-Watching Psychology\n\n- Erickson, S. E., Dal Cin, S., & Byl, H. (2019). An experimental examination of binge watching and narrative engagement. *Social Sciences, 8*(1), 19.\n- Green, M. C., & Brock, T. C. (2000). The role of transportation in the persuasiveness of public narratives. *Journal of Personality and Social Psychology, 79*(5), 701-721.\n- Pittman, M., & Sheehan, K. (2015). Sprinting a media marathon: Uses and gratifications of binge-watching television through Netflix. *First Monday, 20*(10).\n- Riddle, K., Peebles, A., Davis, C., Xu, F., & Schroeder, E. (2017). The addictive potential of television binge watching: Comparing intentional and unintentional binges. *Psychology of Popular Media Culture, 7*(4), 589-604.\n\n### Doomscrolling Research\n\n- Morning Consult. (2024). American doomscrolling habits survey. Morning Consult Intelligence.\n- Sharma, B., Lee, S. S., & Johnson, B. K. (2022). The dark at the end of the tunnel: Doomscrolling on social media newsfeeds. *Technology, Mind, and Behavior, 3*(1).\n- Sharma, B., Lee, S. S., & Johnson, B. K. (2022). Doomscrolling on social media newsfeeds: Associations with personality, FOMO, and psychological well-being. *Cyberpsychology, Behavior, and Social Networking, 25*(2).\n\n---\nÂ© 2025 Grove AI Foundation / Jim Calhoun. All rights reserved."
  },
  {
    "notion_id": "2ed780a7-8eef-8103-ad94-ff897214dd1e",
    "filename": "251217-v-research-the-training-ratchet.md--FINAL.md",
    "tables_count": 1,
    "converted_content": "\n## When Distributed AI Training Reaches Frontier Scale\n\n*Grove Foundation Technical Research*\n\n## Executive Summary\n\nDistributed AI training compute has grown 600,000-fold since 2020, doubling every 2.8 monthsâ€”twice as fast as centralized frontier training.Â¹ At current trajectories, distributed training will close the 1,000Ã— compute gap with frontier systems by 2030-2031, fundamentally shifting who can train powerful AI models.\nThe strategic implications align directly with Grove's exploration architecture thesis. Universities and research institutions face a choice: depend on corporate AI gatekeepers or build sovereign infrastructure for discovery. Projects like Prime Intellect's INTELLECT-1â€”the first 10 billion parameter model trained across three continents by 30 independent compute providersâ€”demonstrate that globally distributed training achieves 83-96% compute utilization despite consumer-grade internet connections.Â² As participation thresholds drop and algorithmic efficiency improves, edge nodes currently limited to inference will evolve into training-capable contributors, enabling epistemic independence from hyperscaler infrastructure.\n\n## Current State: A 1,000Ã— Gap That's Narrowing Fast\n\nEPOCH AI's analysis confirms dramatic acceleration in distributed training capabilities. Since 2020, the largest distributed training runs have grown from approximately 10Â¹â·-10Â¹â¸ FLOP to 6Ã—10Â²Â³ FLOPâ€”a 600,000Ã— increase representing roughly 20Ã—/year growth.Â¹ This substantially outpaces frontier centralized training's 5Ã—/year growth rate over the same period.\nThe current compute gap tells a story of rapid convergence. In 2020, distributed training lagged frontier systems by roughly 100,000Ã—. By late 2025, that gap has compressed to approximately 1,000Ã—, with top distributed runs reaching ~10Â²Â³ FLOP against frontier training at ~5Ã—10Â²â¶ FLOP. EPOCH calculates that if both trends persist, distributed training would reach parity in approximately 5.5 yearsâ€”though they note that growth will likely decelerate as the ecosystem encounters structural ceilings.\nThree mathematical models frame this trajectory:\n\n<table header-row=\"true\">\n\t<tr>\n\t\t<td>Model</td>\n\t\t<td>Current Value</td>\n\t\t<td>Projection</td>\n\t</tr>\n\t<tr>\n\t\t<td>Training Compute Propagation</td>\n\t\t<td>2.8 months doubling (distributed) vs. 5.2 months (centralized)</td>\n\t\t<td>Gap closes 2030-2031 at median rates</td>\n\t</tr>\n\t<tr>\n\t\t<td>Participation Threshold</td>\n\t\t<td>24GB VRAM for meaningful contribution</td>\n\t\t<td>16GB viable by 2027-2028</td>\n\t</tr>\n\t<tr>\n\t\t<td>Coordination Cost</td>\n\t\t<td>4-17% overhead vs. centralized</td>\n\t\t<td>Converging toward ~5% with advances</td>\n\t</tr>\n</table>\n\n## DiLoCo: The Algorithm That Makes Internet Training Possible\n\nGoogle DeepMind's DiLoCo (Distributed Low-Communication) represents the critical algorithmic breakthrough enabling training across poorly-connected devices.Â³ Traditional data-parallel training requires gradient synchronization at every step, demanding 100-400 Gbit/s interconnectsâ€”impossible over the internet. DiLoCo inverts this constraint through a bi-level optimization approach.\nThe algorithm operates through inner and outer optimization loops. Each worker independently trains for H local steps (typically 500) using AdamW, accumulating parameter changes without any inter-worker communication. Only after completing these inner steps do workers synchronize, computing \"pseudo-gradients\" and performing a Nesterov momentum update on the global model.â´ This reduces communication frequency by 500Ã— compared to standard training.\nCombined with int8 quantization of pseudo-gradients, DiLoCo achieves 400-2,000Ã— total bandwidth reduction. Where standard data-parallel training requires 100+ Gbit/s interconnects, DiLoCo operates effectively at 1-5 Gbit/sâ€”achievable over consumer internet connections.âµ Recent research demonstrates that DiLoCo with M=2 workers outperforms data-parallel training for models above several billion parameters.â¶\n\n## INTELLECT-1: Proof of Concept at Scale\n\nPrime Intellect's INTELLECT-1 project trained a 10 billion parameter model across five countries and three continents using DiLoCo, achieving:â·\n- 83-96% compute utilization (96% US-only, 83% globally)\n- Synchronization every 38-40 minutes (100 inner steps)\n- All-reduce communication taking 1-7 minutes per sync\n- Communication overhead of just 4-17% versus centralized baselines\nThis wasn't a demonstration with cherry-picked conditions. INTELLECT-1 involved 30 independent compute providers dynamically joining and leaving over 42 days, with nodes ranging from major cloud providers to individual contributors.â¸\n\n## Participation Thresholds Are Dropping Toward Consumer Hardware\n\nThe hardware requirements for distributed training participation have begun their descent toward prosumer accessibility.â¹ Today's thresholds reveal a tiered participation landscape:\n**Tier 4 (Datacenter nodes):** 8Ã—H100 configurations remain optimal for foundation model pretraining. Cost: ~$300K+ per DGX system or $2-4/GPU-hour cloud rental.\n**Tier 3 (Professional: A100/H100):** Single A100-80GB or H100 nodes enable meaningful training contribution for models up to 70B parameters. Cloud pricing: $1.49-3.90/GPU-hour.\n**Tier 2 (Prosumer: RTX 4090):** The RTX 4090 with 24GB VRAM represents a critical threshold at ~$0.34/hour rental, achieving 1.7Ã— better cost-effectiveness than A100 for single-GPU workloads.Â¹â°\n**Tier 1 (Consumer gaming):** Hardware with 8-16GB VRAM cannot yet contribute meaningfully to pretraining. However, INTELLECT-2 demonstrated these devices can serve as inference workers in distributed RL training, generating rollouts while more powerful nodes handle gradient computation.\nThe trajectory suggests 16GB consumer GPUs will become pretraining-capable by 2027-2028 as compression techniques mature and participation protocols evolve.Â¹â´\n\n## Universities Face a 1,000:1 Compute Gap\n\nThe university landscape reveals both severe structural barriers and emerging workarounds. Stanford HAI's assessment is stark: \"These large foundation models have outgrown what universities can do.\"Â¹Â¹ While Microsoft targets 1.8 million H100 GPUs and Meta acquired 350,000, Princeton's investment of 300 H100s represents a 1,000:1 compute gap that no individual institution can bridge.Â¹Â²\nThe response has been collaborative infrastructure. BigScience/BLOOM demonstrated the most ambitious academic coordination to dateâ€”1,000+ researchers from 250+ institutions across 60 countries training a 176B parameter multilingual model. The $7 million in publicly-funded compute produced a model supporting 46 languages and 13 programming languages.Â¹Â³\nFor Grove's university partnership strategy, this dynamic is central. Distributed training infrastructure enables consortiums of institutions to achieve frontier-scale capabilities while maintaining epistemic independence from corporate gatekeepers.\n\n## Risks That Could Break the 20Ã—/Year Trajectory\n\nThe growth trend faces several plausible disruption scenarios. Export controls create the most immediate regulatory risk. The January 2025 \"AI Diffusion Rule\" established comprehensive restrictions on GPU exports to 140+ countries, subsequently revoked with replacement regulations pending.\nCritical batch size constraints impose fundamental limits on data parallelism. Recent research demonstrates that optimal batch size scales with dataset size rather than model sizeâ€”and beyond the critical batch size, additional data parallelism yields diminishing returns.\nEPOCH's assessment: \"At the current rate of growth, we won't see distributed training runs catch up to the frontier of training in scale this decade.\" The 20Ã—/year growth rate is likely unsustainable; 10Ã—/year represents a more realistic long-term trajectory. However, raw compute gap â‰  capability gapâ€”hardware efficiency gains and algorithmic improvements may enable competitive models at lower compute scales.\n\n## Conclusion: Distributed Training Capability Is a Ratchet That Advances\n\nThe distributed training infrastructure demonstrates characteristics parallel to Grove's inference capability propagation thesis. Capability propagates outward from frontier labs through algorithmic advances, open-source implementations, and declining participation thresholdsâ€”creating a ratchet effect where each generation of techniques enables broader participation.\nThe 2.8-month doubling time for distributed training compute substantially outpaces both centralized training (5.2 months) and inference efficiency gains (7 months). While the ~1,000Ã— gap with frontier systems remains significant, the trajectory points toward meaningful convergence by decade's end.\nThe strategic implication for exploration architecture is clear: organizations investing in edge node infrastructure should design for eventual training capability, not just inference. The coordination mechanisms exist. The economic models are emerging. The participation thresholds are dropping. Distributed training is no longer theoreticalâ€”it is operational reality advancing on a predictable trajectory toward frontier-competitive scale.\nFor universities and research institutions committed to epistemic independence, the Training Ratchet represents infrastructure becoming available just as the need becomes critical.\n"
  },
  {
    "notion_id": "2ee780a78eef81fc8d9deb5b8a717bb0",
    "filename": "260100-s-pattern-declarative-wizard-engine.md--FINAL.md",
    "tables_count": 1,
    "converted_content": "\n# Pattern 10: Declarative Wizard Engine\n\n**Status:** Proposed  \n**Derived From:** CustomLensWizard analysis  \n**Sprint:** TBD (wizard-engine-v1)\n\n## Problem Statement\n\nGrove's exploration architecture requires personalized pathways through:\n- **Custom Lenses** â€” Persona-based content filtering (exists)\n- **Custom Journeys** â€” Observer-defined exploration paths (planned)\n- **Onboarding Flows** â€” Guided first-time experience (planned)\n- **Preference Wizards** â€” Settings configuration (future)\n\nCurrently, CustomLensWizard hard-codes its flow logic in TypeScript. Each new wizard requires:\n- New React components per step\n- Duplicate state management\n- Separate analytics integration\n- Repeated flow logic\n\nThis violates **Declarative Sovereignty**â€”domain experts cannot create exploration pathways without engineering involvement. For Grove to enable true exploration infrastructure, content creators need direct control over discovery flows.\n\n## Solution: Declarative Wizard Engine\n\nSeparate wizard *definition* (JSON schema) from wizard *execution* (React engine).\n\n```\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\nâ”‚                    DECLARATIVE WIZARD ARCHITECTURE               â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚                                                                  â”‚\nâ”‚  wizard-schema.json          WizardEngine.tsx                    â”‚\nâ”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚\nâ”‚  â”‚ {                â”‚       â”‚ function WizardEngine({        â”‚  â”‚\nâ”‚  â”‚   \"id\": \"...\",   â”‚â”€â”€â”€â”€â”€â”€â–¶â”‚   schema,                      â”‚  â”‚\nâ”‚  â”‚   \"steps\": [...] â”‚       â”‚   onComplete,                  â”‚  â”‚\nâ”‚  â”‚ }                â”‚       â”‚   onCancel                     â”‚  â”‚\nâ”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â”‚ }) { ... }                     â”‚  â”‚\nâ”‚                             â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚\nâ”‚                                         â”‚                        â”‚\nâ”‚                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚\nâ”‚                    â–¼                    â–¼                    â–¼  â”‚\nâ”‚           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”â”‚\nâ”‚           â”‚ ConsentStep  â”‚    â”‚ ChoiceStep   â”‚    â”‚ TextStep  â”‚â”‚\nâ”‚           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â”‚\nâ”‚           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”â”‚\nâ”‚           â”‚GenerationStepâ”‚    â”‚SelectionStep â”‚    â”‚ConfirmStepâ”‚â”‚\nâ”‚           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â”‚\nâ”‚                                                                  â”‚\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n```\n\n## Current State Analysis\n\nThe existing CustomLensWizard already demonstrates **semi-declarative architecture**. In `InputStep.tsx`:\n\n```typescript\nconst STEP_CONFIG: Record<string, {\n  question: string;\n  subtext?: string;\n  options: OptionConfig[];\n  inputKey: keyof UserInputs;\n  otherKey?: keyof UserInputs;\n  progress: number;\n}> = {\n  'input-motivation': {\n    question: 'What brings you to thinking about AI infrastructure?',\n    options: MOTIVATION_OPTIONS,\n    inputKey: 'motivation',\n    otherKey: 'motivationOther',\n    progress: 1\n  },\n  // ... more steps\n};\n```\n\n**What works:** Config-driven step rendering, option arrays, progress tracking.\n\n**What needs evolution:** Flow logic remains hard-coded in component (`handleInputComplete` with conditionals), step types mixed together, no schema separation.\n\n## Wizard Schema Specification\n\n### Top-Level Structure\n\n```typescript\ninterface WizardSchema {\n  id: string;                    // Unique wizard identifier\n  version: string;               // Schema version\n  title: string;                 // Shown in header\n  description?: string;          // Optional subtitle\n  \n  steps: WizardStepSchema[];     // Ordered step definitions\n  initialStep: string;           // First step ID\n  \n  generation?: {                 // AI generation config (if applicable)\n    endpoint: string;\n    method: 'POST';\n    inputMapping: Record<string, string>;\n    outputKey: string;\n  };\n  \n  output: {\n    type: string;                // Output type name\n    transform?: string;          // Transform function name\n  };\n  \n  analytics?: {\n    startEvent: string;\n    stepEvent: string;\n    completeEvent: string;\n    abandonEvent: string;\n  };\n  \n  theme?: {\n    primaryColor: string;\n    accentColor: string;\n  };\n}\n```\n\n### Step Types\n\n```typescript\ntype WizardStepSchema = \n  | ConsentStepSchema\n  | ChoiceStepSchema\n  | TextStepSchema\n  | GenerationStepSchema\n  | SelectionStepSchema\n  | ConfirmationStepSchema;\n\n// Base fields all steps share\ninterface BaseStepSchema {\n  id: string;\n  type: string;\n  title?: string;\n  progress?: number;\n}\n\n// Consent/Privacy step\ninterface ConsentStepSchema extends BaseStepSchema {\n  type: 'consent';\n  headline: string;\n  guarantees: Array<{\n    icon: string;\n    title: string;\n    description: string;\n  }>;\n  acceptLabel: string;\n  acceptAction: StepAction;\n  cancelLabel?: string;\n}\n\n// Single choice step\ninterface ChoiceStepSchema extends BaseStepSchema {\n  type: 'choice';\n  question: string;\n  subtext?: string;\n  options: Array<{\n    value: string;\n    label: string;\n    description?: string;\n  }>;\n  inputKey: string;\n  allowOther?: boolean;\n  otherKey?: string;\n  next: ConditionalAction;\n}\n\n// Free text step\ninterface TextStepSchema extends BaseStepSchema {\n  type: 'text';\n  question: string;\n  subtext?: string;\n  inputKey: string;\n  placeholder?: string;\n  maxLength?: number;\n  optional?: boolean;\n  next: StepAction;\n}\n\n// AI generation step\ninterface GenerationStepSchema extends BaseStepSchema {\n  type: 'generation';\n  loadingMessage: string;\n  errorMessage: string;\n  retryLabel: string;\n  next: StepAction;\n}\n\n// Selection from generated options\ninterface SelectionStepSchema extends BaseStepSchema {\n  type: 'selection';\n  headline: string;\n  subtext?: string;\n  optionsKey: string;\n  outputKey: string;\n  cardRenderer: string;\n  refineLabel?: string;\n  refineAction?: StepAction;\n  next: StepAction;\n}\n\n// Confirmation step\ninterface ConfirmationStepSchema extends BaseStepSchema {\n  type: 'confirmation';\n  headline: string;\n  displayKey: string;\n  benefits: string[];\n  privacyReminder?: string;\n  confirmLabel: string;\n  next: { complete: true };\n}\n```\n\n### Flow Actions\n\n```typescript\ntype StepAction = \n  | { next: string }      // Go to step by ID\n  | { complete: true }    // Finish wizard\n  | { exit: true };       // Cancel wizard\n\ninterface ConditionalAction {\n  conditions?: Array<{\n    if: string;           // Expression: \"motivation === 'worried'\"\n    then: string;         // Step ID\n  }>;\n  default: string;        // Fallback step ID\n}\n```\n\n## Example: Custom Lens Wizard Schema\n\n```json\n{\n  \"id\": \"custom-lens-wizard\",\n  \"version\": \"1.0\",\n  \"title\": \"Create Your Personal Lens\",\n  \n  \"steps\": [\n    {\n      \"id\": \"privacy\",\n      \"type\": \"consent\",\n      \"headline\": \"Before we begin â€” a promise\",\n      \"guarantees\": [\n        {\n          \"icon\": \"lock\",\n          \"title\": \"Everything stays in your browser\",\n          \"description\": \"Your answers are encrypted locally. We never see them.\"\n        },\n        {\n          \"icon\": \"lock\",\n          \"title\": \"No accounts. No tracking.\",\n          \"description\": \"Your lens is stored only in this browser.\"\n        },\n        {\n          \"icon\": \"sparkles\",\n          \"title\": \"AI generates, you control\",\n          \"description\": \"We'll create 3 options for you to choose from.\"\n        }\n      ],\n      \"acceptLabel\": \"I understand â€” let's build my lens\",\n      \"acceptAction\": { \"next\": \"motivation\" }\n    },\n    {\n      \"id\": \"motivation\",\n      \"type\": \"choice\",\n      \"question\": \"What brings you to thinking about AI infrastructure?\",\n      \"inputKey\": \"motivation\",\n      \"allowOther\": true,\n      \"otherKey\": \"motivationOther\",\n      \"options\": [\n        { \"value\": \"worried-about-ai\", \"label\": \"I'm worried about where AI is heading\" },\n        { \"value\": \"researching-distributed-systems\", \"label\": \"I'm researching distributed systems\" },\n        { \"value\": \"someone-sent-link\", \"label\": \"Someone sent me this link\" },\n        { \"value\": \"investment-opportunities\", \"label\": \"I'm looking for investment opportunities\" },\n        { \"value\": \"just-curious\", \"label\": \"Just curious\" },\n        { \"value\": \"other\", \"label\": \"Something else...\" }\n      ],\n      \"next\": {\n        \"conditions\": [\n          { \"if\": \"motivation === 'worried-about-ai'\", \"then\": \"concerns\" }\n        ],\n        \"default\": \"outlook\"\n      },\n      \"progress\": 1\n    },\n    {\n      \"id\": \"concerns\",\n      \"type\": \"choice\",\n      \"question\": \"What concerns you most?\",\n      \"inputKey\": \"concerns\",\n      \"allowOther\": true,\n      \"options\": [\n        { \"value\": \"big-tech-power\", \"label\": \"Big Tech having too much power\" },\n        { \"value\": \"job-displacement\", \"label\": \"Job displacement\" },\n        { \"value\": \"energy-environment\", \"label\": \"Energy and environmental costs\" },\n        { \"value\": \"privacy\", \"label\": \"Loss of privacy\" },\n        { \"value\": \"harder-to-articulate\", \"label\": \"Something harder to articulate\" }\n      ],\n      \"next\": { \"default\": \"outlook\" },\n      \"progress\": 2\n    },\n    {\n      \"id\": \"outlook\",\n      \"type\": \"choice\",\n      \"question\": \"When you imagine AI's role 10 years from now, what's your gut reaction?\",\n      \"inputKey\": \"futureOutlook\",\n      \"options\": [\n        { \"value\": \"cautiously-optimistic\", \"label\": \"Cautiously optimistic\" },\n        { \"value\": \"genuinely-worried\", \"label\": \"Genuinely worried\" },\n        { \"value\": \"depends-on-control\", \"label\": \"Depends entirely on who controls it\" },\n        { \"value\": \"building-conflicted\", \"label\": \"I'm building it, so I'm conflicted\" }\n      ],\n      \"next\": { \"default\": \"professional\" },\n      \"progress\": 3\n    },\n    {\n      \"id\": \"professional\",\n      \"type\": \"choice\",\n      \"question\": \"What's your relationship to technology professionally?\",\n      \"inputKey\": \"professionalRelationship\",\n      \"options\": [\n        { \"value\": \"build-it\", \"label\": \"I build it\" },\n        { \"value\": \"fund-invest\", \"label\": \"I fund or invest in it\" },\n        { \"value\": \"study-regulate\", \"label\": \"I study or regulate it\" },\n        { \"value\": \"use-dont-trust\", \"label\": \"I use it but don't trust it\" },\n        { \"value\": \"lead-orgs\", \"label\": \"I lead organizations that depend on it\" }\n      ],\n      \"next\": { \"default\": \"worldview\" },\n      \"progress\": 4\n    },\n    {\n      \"id\": \"worldview\",\n      \"type\": \"text\",\n      \"question\": \"In 2-3 sentences, describe how you see AI's role in the future.\",\n      \"subtext\": \"Optional, but helps us craft a lens that truly fits you.\",\n      \"inputKey\": \"worldviewStatement\",\n      \"placeholder\": \"Share your perspective on AI's future...\",\n      \"maxLength\": 280,\n      \"optional\": true,\n      \"next\": { \"next\": \"generating\" },\n      \"progress\": 5\n    },\n    {\n      \"id\": \"generating\",\n      \"type\": \"generation\",\n      \"loadingMessage\": \"Crafting your personalized lenses...\",\n      \"errorMessage\": \"Something went wrong. Let's try again.\",\n      \"retryLabel\": \"Retry\",\n      \"next\": { \"next\": \"select\" }\n    },\n    {\n      \"id\": \"select\",\n      \"type\": \"selection\",\n      \"headline\": \"Choose your lens\",\n      \"subtext\": \"Select the one that resonates most.\",\n      \"optionsKey\": \"generatedOptions\",\n      \"outputKey\": \"selectedOption\",\n      \"cardRenderer\": \"LensCandidateCard\",\n      \"refineLabel\": \"None of these fit? Refine my answers\",\n      \"refineAction\": { \"next\": \"motivation\" },\n      \"next\": { \"next\": \"confirm\" }\n    },\n    {\n      \"id\": \"confirm\",\n      \"type\": \"confirmation\",\n      \"headline\": \"Your new lens\",\n      \"displayKey\": \"selectedOption\",\n      \"benefits\": [\n        \"Shape every response to your perspective\",\n        \"Guide your journey through The Grove\"\n      ],\n      \"privacyReminder\": \"Your lens is saved locally. No data sent to servers.\",\n      \"confirmLabel\": \"Activate my lens\",\n      \"next\": { \"complete\": true }\n    }\n  ],\n  \n  \"initialStep\": \"privacy\",\n  \n  \"generation\": {\n    \"endpoint\": \"/api/generate-lens\",\n    \"method\": \"POST\",\n    \"inputMapping\": {\n      \"motivation\": \"$.motivation\",\n      \"concerns\": \"$.concerns\",\n      \"futureOutlook\": \"$.futureOutlook\",\n      \"professionalRelationship\": \"$.professionalRelationship\",\n      \"worldviewStatement\": \"$.worldviewStatement\"\n    },\n    \"outputKey\": \"generatedOptions\"\n  },\n  \n  \"output\": {\n    \"type\": \"CustomLens\",\n    \"transform\": \"createCustomLensFromWizard\"\n  },\n  \n  \"analytics\": {\n    \"startEvent\": \"custom_lens_wizard_started\",\n    \"stepEvent\": \"custom_lens_step_completed\",\n    \"completeEvent\": \"custom_lens_created\",\n    \"abandonEvent\": \"custom_lens_abandoned\"\n  },\n  \n  \"theme\": {\n    \"primaryColor\": \"purple\",\n    \"accentColor\": \"grove-forest\"\n  }\n}\n```\n\n## Example: Custom Journey Wizard (New Capability)\n\n```json\n{\n  \"id\": \"custom-journey-wizard\",\n  \"version\": \"1.0\",\n  \"title\": \"Design Your Exploration Path\",\n  \n  \"steps\": [\n    {\n      \"id\": \"intro\",\n      \"type\": \"consent\",\n      \"headline\": \"Create a journey that fits your curiosity\",\n      \"guarantees\": [\n        {\n          \"icon\": \"compass\",\n          \"title\": \"Your path, your pace\",\n          \"description\": \"Choose what to explore and in what order.\"\n        },\n        {\n          \"icon\": \"bookmark\",\n          \"title\": \"Save your progress\",\n          \"description\": \"Pick up where you left off anytime.\"\n        }\n      ],\n      \"acceptLabel\": \"Let's design my journey\",\n      \"acceptAction\": { \"next\": \"goal\" }\n    },\n    {\n      \"id\": \"goal\",\n      \"type\": \"choice\",\n      \"question\": \"What do you want to understand about Grove?\",\n      \"inputKey\": \"goal\",\n      \"options\": [\n        { \"value\": \"how-it-works\", \"label\": \"How the technology works\" },\n        { \"value\": \"why-it-matters\", \"label\": \"Why this matters for AI's future\" },\n        { \"value\": \"how-to-participate\", \"label\": \"How I can participate\" },\n        { \"value\": \"investment-case\", \"label\": \"The investment opportunity\" },\n        { \"value\": \"compare-alternatives\", \"label\": \"How it compares to alternatives\" }\n      ],\n      \"next\": { \"default\": \"depth\" },\n      \"progress\": 1\n    },\n    {\n      \"id\": \"depth\",\n      \"type\": \"choice\",\n      \"question\": \"How deep do you want to go?\",\n      \"inputKey\": \"depth\",\n      \"options\": [\n        { \"value\": \"overview\", \"label\": \"Quick overview (10 min)\" },\n        { \"value\": \"moderate\", \"label\": \"Solid understanding (30 min)\" },\n        { \"value\": \"deep\", \"label\": \"Deep dive (60+ min)\" }\n      ],\n      \"next\": { \"default\": \"generating\" },\n      \"progress\": 2\n    },\n    {\n      \"id\": \"generating\",\n      \"type\": \"generation\",\n      \"loadingMessage\": \"Mapping your exploration path...\",\n      \"errorMessage\": \"Couldn't generate journey. Please try again.\",\n      \"retryLabel\": \"Try again\",\n      \"next\": { \"next\": \"preview\" }\n    },\n    {\n      \"id\": \"preview\",\n      \"type\": \"selection\",\n      \"headline\": \"Your journey awaits\",\n      \"subtext\": \"Here are the stops on your path.\",\n      \"optionsKey\": \"generatedJourney\",\n      \"outputKey\": \"selectedJourney\",\n      \"cardRenderer\": \"JourneyNodeCard\",\n      \"next\": { \"next\": \"confirm\" }\n    },\n    {\n      \"id\": \"confirm\",\n      \"type\": \"confirmation\",\n      \"headline\": \"Ready to begin?\",\n      \"displayKey\": \"selectedJourney\",\n      \"benefits\": [\n        \"Personalized to your goals\",\n        \"Adaptive to your questions\",\n        \"Trackable progress\"\n      ],\n      \"confirmLabel\": \"Start my journey\",\n      \"next\": { \"complete\": true }\n    }\n  ],\n  \n  \"initialStep\": \"intro\",\n  \n  \"generation\": {\n    \"endpoint\": \"/api/generate-journey\",\n    \"method\": \"POST\",\n    \"inputMapping\": {\n      \"goal\": \"$.goal\",\n      \"depth\": \"$.depth\",\n      \"lensId\": \"$.activeLens\"\n    },\n    \"outputKey\": \"generatedJourney\"\n  },\n  \n  \"output\": {\n    \"type\": \"CustomJourney\",\n    \"transform\": \"createCustomJourneyFromWizard\"\n  }\n}\n```\n\n## Implementation Architecture\n\n### File Structure\n\n```\nsrc/\nâ”œâ”€â”€ core/\nâ”‚   â””â”€â”€ wizard/\nâ”‚       â”œâ”€â”€ schema.ts           # TypeScript types\nâ”‚       â”œâ”€â”€ engine.ts           # State machine logic\nâ”‚       â””â”€â”€ evaluator.ts        # Condition expression evaluator\nâ”‚\nâ”œâ”€â”€ surface/\nâ”‚   â””â”€â”€ components/\nâ”‚       â””â”€â”€ Wizard/\nâ”‚           â”œâ”€â”€ WizardEngine.tsx      # Main orchestrator\nâ”‚           â”œâ”€â”€ WizardProgress.tsx    # Progress bar\nâ”‚           â”œâ”€â”€ WizardHeader.tsx      # Header with back/close\nâ”‚           â”œâ”€â”€ steps/\nâ”‚           â”‚   â”œâ”€â”€ ConsentStep.tsx\nâ”‚           â”‚   â”œâ”€â”€ ChoiceStep.tsx\nâ”‚           â”‚   â”œâ”€â”€ TextStep.tsx\nâ”‚           â”‚   â”œâ”€â”€ GenerationStep.tsx\nâ”‚           â”‚   â”œâ”€â”€ SelectionStep.tsx\nâ”‚           â”‚   â””â”€â”€ ConfirmationStep.tsx\nâ”‚           â””â”€â”€ hooks/\nâ”‚               â””â”€â”€ useWizardState.ts\nâ”‚\nâ””â”€â”€ data/\n    â””â”€â”€ wizards/\n        â”œâ”€â”€ custom-lens.wizard.json\n        â”œâ”€â”€ custom-journey.wizard.json\n        â””â”€â”€ onboarding.wizard.json\n```\n\n### WizardEngine Component\n\n```typescript\ninterface WizardEngineProps<T> {\n  schema: WizardSchema;\n  onComplete: (result: T) => void;\n  onCancel: () => void;\n  initialInputs?: Record<string, unknown>;\n}\n\nexport function WizardEngine<T>({\n  schema,\n  onComplete,\n  onCancel,\n  initialInputs\n}: WizardEngineProps<T>) {\n  const {\n    state,\n    currentStep,\n    goToStep,\n    updateInputs,\n    getProgress\n  } = useWizardState(schema, initialInputs);\n\n  const handleStepComplete = (action: StepAction) => {\n    if ('complete' in action && action.complete) {\n      const result = transformOutput(state, schema.output);\n      onComplete(result);\n    } else if ('next' in action) {\n      goToStep(action.next);\n    }\n  };\n\n  const stepSchema = schema.steps.find(s => s.id === currentStep);\n  \n  return (\n    <div className=\"wizard-container\">\n      <WizardHeader title={schema.title} onCancel={onCancel} />\n      <WizardProgress current={getProgress()} total={getTotalSteps()} />\n      <StepRenderer\n        schema={stepSchema}\n        inputs={state.inputs}\n        onComplete={handleStepComplete}\n      />\n    </div>\n  );\n}\n```\n\n## DEX Compliance\n\n**Declarative Sovereignty âœ“** â€” Domain experts create exploration pathways via JSON. No code changes for new questions, flow changes, or analytics events.\n\n**Capability Agnosticism âœ“** â€” Engine works regardless of AI model. Generation step calls configurable endpoint.\n\n**Provenance âœ“** â€” Every completion creates artifact with wizard ID, version, all inputs, timestamps.\n\n**Organic Scalability âœ“** â€” New wizards require only JSON schema file + optional card renderer.\n\n## Migration Path\n\n<table header-row=\"true\">\n\t<tr>\n\t\t<td>Phase</td>\n\t\t<td>Work</td>\n\t\t<td>Risk</td>\n\t</tr>\n\t<tr>\n\t\t<td>1. Create Engine</td>\n\t\t<td>New WizardEngine, step renderers, useWizardState</td>\n\t\t<td>Low (additive)</td>\n\t</tr>\n\t<tr>\n\t\t<td>2. Extract Schema</td>\n\t\t<td>Convert CustomLensWizard logic to JSON</td>\n\t\t<td>Medium (parity)</td>\n\t</tr>\n\t<tr>\n\t\t<td>3. Replace</td>\n\t\t<td>Swap CustomLensWizard to use engine</td>\n\t\t<td>Medium (regression)</td>\n\t</tr>\n\t<tr>\n\t\t<td>4. Extend</td>\n\t\t<td>Create custom-journey.wizard.json</td>\n\t\t<td>Low (new feature)</td>\n\t</tr>\n</table>\n\n## Open Questions\n\n1. **Expression Language:** JS expressions or safer DSL for conditions?\n2. **Card Renderers:** Registry pattern or inline component references?\n3. **Validation:** Schema-level or engine-level input validation?\n4. **Theming:** How much styling should be schema-configurable?\n\n---\n\n*Pattern derived from CustomLensWizard analysis. Ready for sprint planning.*"
  },
  {
    "notion_id": "2ee780a78eef813094a0d763940d3fa6",
    "filename": "260100-v-research-coordination-physics-validates-dex.md--FINAL.md",
    "tables_count": 1,
    "converted_content": "\n# Coordination Physics Validates Exploration Architecture\n\n## How Chang's \"Missing Layer\" Thesis Provides Theoretical Grounding for Grove's DEX/Trellis Architecture\n\n**Grove AI Foundation â€” Technical Research Brief**  \n**January 2026**\n\n---\n\nEdward Y. Chang's December 2025 paper from Stanford's Computer Science Department provides the first rigorous theoretical framework demonstrating that the path to artificial general intelligence runs through coordination architecture, not raw scale.[^1] This finding directly validates Grove's foundational thesis: **architecture is soil, models are seeds**. Chang's Unified Contextual Control Theory (UCCT) mathematically formalizes when reasoning activates in language models, while his Multi-Agent Collaborative Intelligence (MACI) framework provides the coordination stack that makes it workâ€”precisely the architectural commitments Grove's Trellis system embodies. The timing matters: as the field exhausts returns from scaling, academic consensus converges on the structural principles Grove anticipated.\n\n---\n\n## I. Chang's Missing Layer Thesis Reframes the AGI Debate\n\nChang's central argument rejects both extremes dominating current discourse: that scaling alone produces AGI, and that transformer architectures fundamentally lack reasoning capability. He proposes a third paradigmâ€”\"substrate plus coordination\"â€”treating large language models as the necessary System-1 pattern repository while identifying absent System-2 coordination as the actual bottleneck. His fishing metaphor captures the insight: LLMs are oceans containing vast patterns, but without bait (semantic anchors) and nets (verification filters), you catch \"whatever is most common in that part of the oceanâ€”often generic or obvious answers.\"[^2]\n\nThis framing transforms Grove's exploration architecture from alternative approach to structural necessity. Where conventional wisdom treats model capability as primary and orchestration as secondary, Chang inverts the relationship. The patterns exist within even modest language models; missing is the coordination layer that \"selects, constrains, and binds these patterns to external constraints, verifies outputs, and maintains state over time.\"[^3] Grove's Declarative Exploration (DEX) standard and Trellis Architecture embody this insightâ€”infrastructure for discovery matters more than substrate capability.\n\nThe UCCT anchoring score formula provides mathematical grounding for Grove's exploration prompts and first-order directives:\n\n**S = Ïd âˆ’ dr âˆ’ Î³ log k**\n\nIn Chang's formalization:\n\n- **Ïd** represents effective supportâ€”target concept density recruited by semantic anchors\n- **dr** captures representational mismatchâ€”instability under perturbation causing hallucination\n- **Î³ log k** functions as adaptive regularizer based on anchoring budget\n\nWhen S crosses critical threshold Î¸, behavior shifts from ungrounded generation to anchored reasoning in a phase transition.[^4]\n\nGrove's declarative structures function as UCCT's semantic anchors. First-order directives provide the \"bait\" recruiting specific conceptual density (high Ïd), while Trellis Architecture's validation mechanisms reduce representational mismatch (low dr). The exploration prompt architecture manages anchoring budget (k) by providing structured context without system overwhelm. Chang's formula explains Grove's lightweight approach: reasoning requires not larger models but anchors with sufficient support density relative to mismatch and budget constraints.\n\n---\n\n## II. Phase Transitions Explain Why Small Changes Produce Dramatic Capability Shifts\n\nChang's phase transition model validates Grove's core thesis. UCCT predicts performance follows a sigmoid curve with \"abrupt, switch-like transitions as S exceeds threshold Î¸.\"[^5] Small changes in anchoring strength push systems across thresholds, creating sudden qualitative performance shifts. The paper states: \"many failures are consistent with low support or high mismatch, plus insufficient budget, rather than an absence of compositional capacity.\"[^6]\n\nThis dynamic validates Grove's architectural bet. Rather than assuming capability requires scale, Grove optimizes for crossing thresholds through superior anchoring. A 7B parameter model with well-designed declarative structures exhibits reasoning capabilities that a 70B model without proper anchoring cannotâ€”because phase transitions depend on coordination, not substrate size. Chang provides empirical evidence through compositional generalization tests showing that \"keeping the base model fixed and varying only the coordination stack\" produces dramatic improvements in \"planning horizon, error recovery, and calibrated reliability.\"[^7]\n\nThe phase transition framework explains non-linear returns from Grove's architectural improvements. The efficiency-enlightenment loopâ€”agents experiencing cognitive enhancement through improved coordinationâ€”operates at these phase boundaries. Small semantic anchoring improvements yield disproportionate capability gains by pushing systems across thresholds. Grove's \"architecture as soil\" metaphor captures this fundamental truth: soil quality determines whether germination occurs, not just growth rate.\n\n---\n\n## III. MACI's Coordination Stack Maps Directly to Trellis Components\n\nChang's MACI framework translates UCCT theory into architectural practice through three mechanisms: behavior-modulated debate (baiting), Socratic judging via CRIT (filtering), and transactional memory (persistence).[^8] Each maps precisely to Grove's Trellis Architecture.\n\n### Behavior-Modulated Debate â†’ Agent Villages\n\nMACI's behavior-modulated debate implements dynamic contentiousness adjustment based on anchoring strength. Each agent maintains a contentiousness parameter governing explore-or-yield decisions, with contentious exchanges encouraging \"breadth and perspective diversity\" while conciliatory tones support \"convergence, synthesis, and resolution.\"[^9] Grove's agent villages implement this patternâ€”specialized agents with different priors engage in structured exploration, with dynamic tone adjustment based on context. Chang's evidence routing mechanism, where disagreements trigger \"targeted requests for discriminating retrieval queries,\" parallels Grove's knowledge gap identification.\n\n### CRIT (Critical Reading Inquisitive Template) â†’ Knowledge Commons Validation\n\nCRIT functions as MACI's explicit judge, filtering for \"well-posedness, consistency, evidential grounding, and falsifiability.\"[^10] Low-scoring arguments face rejection or targeted Socratic queries. Grove's Knowledge Commons validation implements this filteringâ€”claims entering the shared knowledge base undergo verification interrogating clarity, assumptions, evidence, and falsifiability. Chang notes CRIT \"improves downstream anchoring by forcing arguments into forms that bind to shared constraints rather than just plausible.\"[^11] Knowledge Commons achieves this for Grove's ecosystem.\n\n### Transactional Memory â†’ Diary System\n\nMACI's transactional memory draws from distributed database Saga patterns, providing spatial-temporal checkpointing, inter-agent dependency management, and independent critical validation.[^12] Grove's diary system implements transactional memory for agent stateâ€”maintaining assertion and revision records, enabling rollback and adaptation, tracking interlocked tasks across agent villages. Chang emphasizes transactional memory enables \"the robustness and revisability of deliberative inference\"â€”the long-horizon reasoning capacity Grove's architecture requires.[^13]\n\n<table header-row=\"true\">\n\t<tr>\n\t\t<td>MACI Component</td>\n\t\t<td>Grove Equivalent</td>\n\t\t<td>Function</td>\n\t</tr>\n\t<tr>\n\t\t<td>Behavior-modulated debate</td>\n\t\t<td>Agent villages</td>\n\t\t<td>Dynamic explore/yield based on anchoring strength</td>\n\t</tr>\n\t<tr>\n\t\t<td>CRIT Socratic judging</td>\n\t\t<td>Knowledge Commons validation</td>\n\t\t<td>Filter for well-posedness before integration</td>\n\t</tr>\n\t<tr>\n\t\t<td>Transactional memory (SagaLLM)</td>\n\t\t<td>Diary system</td>\n\t\t<td>Persistent state with rollback capability</td>\n\t</tr>\n\t<tr>\n\t\t<td>Semantic anchoring</td>\n\t\t<td>First-order directives</td>\n\t\t<td>Recruit target concepts, reduce mismatch</td>\n\t</tr>\n\t<tr>\n\t\t<td>Adaptive regularization</td>\n\t\t<td>Exploration prompts</td>\n\t\t<td>Manage context budget efficiently</td>\n\t</tr>\n</table>\n\n---\n\n## IV. The System-1/System-2 Split Validates Hybrid Local/Cloud Architecture\n\nChang's cognitive architecture distinguishes System-1 as \"fast, unconscious pattern repository\" from System-2 as \"the slower executive layer that selects, constrains, verifies outputs, and maintains state.\"[^14] Drawing on neuroscience, he identifies System-1 substrate including autonomic functions, motor control, perception, and language processingâ€”all fast, parallel, pattern-based. System-2 provides \"limited, resource-heavy conscious control that can target, constrain, and stabilize inferences.\"[^15]\n\nThis framework grounds Grove's hybrid local/cloud architecture:\n\n**Local 7B models** serve as System-1 substrateâ€”handling routine cognition, fast pattern matching, and autonomous edge processing. They're plastic, continuously refined through experience, sufficient for most agent operations.\n\n**Cloud coordination** functions as System-2â€”providing goal prioritization, inhibition, contextual modulation, and constraint enforcement for pivotal decisions. Chang's framing explains this hybrid approach's structural correctness: System-2 capability is needed only at decision points requiring \"filtering impulsive outputs, suppressing irrelevant reasoning paths, and adapting behavior according to ethical, contextual, and task-based constraints.\"[^16]\n\nEconomic implications reinforce architectural logic. Microsoft research demonstrated 3.8B parameter models trained on \"textbook-quality\" synthetic data match models 25 times larger on complex reasoning tasks.[^17] Google's speculative decoding research shows 2-3x speedup using small draft models with large verifiersâ€”Grove's hybrid pattern exactly.[^18] The field converges on inference economics favoring smaller models with superior architectureâ€”Grove's founding position.\n\n---\n\n## V. Exploration Architecture as Structural Alternative to Optimization\n\nThe exploration-optimization contrast runs deeper than implementation. Conventional scaling represents optimization architectureâ€”finding the global maximum along one axis (model size) assuming capability emerges from scale. Grove's exploration architecture discovers capability through structural diversity, treating parameters as one variable among many.\n\nChang's framework supports exploration architecture's structural superiority. If capability emerges from coordination phase transitions rather than parameter scaling, optimization architecture searches the wrong space. The industry's trillion-dollar scaling bet assumes the AGI path runs through the scaling landscape. Chang's evidence points to the coordination landscapeâ€”a different search space optimization architecture cannot explore.\n\n### Epistemic Capture Risk in the Scaling Approach\n\nScaling's epistemic capture risk is documented. Stanford's Center for Research on Foundation Models identifies deep learning's dominance emerging \"not because of any major intellectual advancement, but because it uniquely benefited from access to large datasets and advances in computing technology.\"[^19] This created an \"epistemic monoculture\"â€”a knowledge-producing community constrained around limited research trajectories.\n\nWhen decision-makers share algorithms and training approaches, correlated failure risk grows. Academic work on algorithmic monoculture demonstrates full convergence on apparently optimal approaches paradoxically lowers collective welfare through Braess' Paradox dynamicsâ€”individually rational choices produce collectively suboptimal outcomes.[^20]\n\n### Tech Monoculture as Systemic Risk\n\nGrove's exploration architecture structurally hedges this risk. The distributed approachâ€”multiple specialized agents, local substrates with cloud coordination, validated innovation propagationâ€”creates resilience against monoculture failure. If scaling hits fundamental barriers, centralized systems fail together. Grove explores alternative capability pathways.\n\nThis concern is practical. AI development concentration in identical-strategy labs represents systemic risk. If scaling encounters barriersâ€”as critics from Yann LeCun to Gary Marcus argue[^21]â€”the field has optimized toward a dead end. Grove maintains optionality across capability pathways.\n\n---\n\n## VI. The Ratchet Thesis and Edge Coordination Economics\n\nAs capable models reach edge devicesâ€”Grove's \"Ratchet\"â€”coordination architecture becomes the differentiator. Substrates commoditize; orchestration does not. Edge-cloud collaborative computing research validates this, demonstrating dynamic workload partitioning, adaptive exit schemes retaining high-confidence inputs locally, and feature compression reducing communication overhead while maintaining accuracy.[^22]\n\nMulti-agent research provides validation. ICML 2024 work demonstrated multiple LLM instances debating significantly enhance reasoning, with accuracy improving as agents and rounds increase. Critically, \"even when all models initially make incorrect predictions, debate enables convergence to correct answers.\"[^23] The \"More Agents Is All You Need\" paper showed Llama2-13B with 15 agents achieves Llama2-70B accuracyâ€”coordination substitutes for scale.[^24]\n\nGoogle DeepMind research identified a 45% accuracy threshold: when single-agent baseline exceeds this, adding agents yields diminishing returns.[^25] This validates Grove's strategic coordination useâ€”hybrid architecture reserves cloud coordination for pivotal decisions rather than universal application.\n\nThe implication for Grove's economics is clear. As the Ratchet delivers capable small models everywhere, value migrates to coordination infrastructure. Organizations have local inference by default; they lack the orchestration layer making capabilities coherent. Grove as coordination infrastructure providerâ€”not model providerâ€”captures value in this scenario.\n\n---\n\n## VII. Research Applications for Grove Development\n\nChang's framework suggests Grove development priorities:\n\n### Anchoring Optimization\n\nDevelopment should maximize Ïd (effective support) while minimizing dr (representational mismatch) in first-order directives and exploration prompts. This requires semantic density analysisâ€”tools measuring how strongly declarative structures recruit target concepts in representation space. The Î³ log k term indicates anchor budget management matters; Grove needs dynamic context allocation adjusting anchoring density based on noise and requirements.\n\n**Concrete application:** Build instrumentation estimating anchoring scores for directive configurations, enabling empirical exploration prompt optimization.\n\n### CRIT-Style Validation for Knowledge Commons\n\nChang's CRIT specificationâ€”clarity, assumptions, evidence, falsifiabilityâ€”provides an implementable evaluation rubric for innovation propagation. Claims entering commons face structured interrogation:\n\n- \"Which premise does the work?\"\n- \"Are definitions being changed?\"\n- \"What evidence would change this conclusion?\"\n- \"What would falsify this claim?\"\n\nThis transforms validation from implicit filtering to explicit Socratic verification.\n\n**Concrete application:** Implement CRIT as Knowledge Commons validation protocol, requiring structured interrogation before propagation.\n\n### Transactional Memory Semantics in Diary System\n\nChang's Saga pattern includes compensatory rollback, assertion/revision audit trails, and inter-agent dependency tracking. Grove's diary system needs full transactional semantics with explicit commit/rollback, enabling the \"robustness and revisability of deliberative inference\" long-horizon exploration requires.\n\n**Concrete application:** Extend diary system with transaction boundaries, enabling agents to checkpoint reasoning and rollback on verification failure.\n\n### Phase Transition Monitoring\n\nRather than tracking task performance, Grove monitors anchoring scores across populations, identifying threshold approaches. This enables proactive interventionâ€”adjusting coordination parameters to push systems across thresholds rather than awaiting organic emergence.\n\n**Concrete application:** Develop metrics tracking estimated S values across agents, alerting at threshold boundaries.\n\n---\n\n## VIII. The Field Converges on Grove's Founding Thesis\n\nChang's significance extends beyond validation to academic consensus crystallizing around Grove's founding principles.\n\nNeurIPS 2023's Outstanding Paper Award recognized Stanford research demonstrating emergent abilities are \"a mirage caused primarily by researcher metric choice\"â€”deflating scaling's central claim.[^26] Leading figures including Yann LeCun, Gary Marcus, and former OpenAI chief scientist Ilya Sutskever declare scaling over. Sutskever states \"the era of 'Just Add GPUs' is over\" with movement \"from an age of scaling to an age of research.\"[^27]\n\nThis convergence creates Grove's timing proof. Exploration architectureâ€”contrarian at foundingâ€”aligns with emerging consensus. Chang provides theory; small model results provide benchmarks; scaling critiques provide negative space. Grove's commitments position it for the post-scaling era.\n\n---\n\n## IX. Conclusion\n\nChang's \"Missing Layer\" arrives as theoretical capstone to an underway paradigm shift. UCCT explains why Grove's declarative structures function as cognitive anchors triggering reasoning phase transitions. MACI's coordination stack blueprints map to Trellis componentsâ€”behavior-modulated debate to agent villages, CRIT to Knowledge Commons, transactional memory to diary systems. System-1/System-2 validates hybrid local/cloud as architecturally correct.\n\nChang validates exploration architecture's structural superiority over optimization architecture for approaching intelligence. If capability emerges from coordination transitions not parameter scaling, Grove's thesisâ€”architecture beats scale, discovery infrastructure matters more than substrateâ€”represents correct direction.\n\nThe path is clear. Chang concludes: \"Large language models are therefore not doomed. The work ahead is to make the coordination layer principled, testable, and ablatable.\"[^28] The Grove builds that coordination layerâ€”not as model adjunct but as intelligence emergence locus. Chang provides peer-reviewed validation.\n\nThe question isn't whether coordination architecture matters more than scale. The question is who builds post-scaling coordination infrastructure. Grove arrived first.\n\n---\n\n## Notes\n\n[^1]: Edward Y. Chang, \"The Missing Layer of AGI: From Pattern Alchemy to Coordination Physics,\" arXiv:2512.05765 (December 5, 2025), https://arxiv.org/abs/2512.05765.\n\n[^2]: Chang, \"Missing Layer,\" 1.\n\n[^3]: Chang, \"Missing Layer,\" 1.\n\n[^4]: Chang, \"Missing Layer,\" 2. The formula components are defined as: Ïd (effective support) measures the density of the target concept recruited by anchors; dr (mismatch) captures representational instability under perturbation; Î³ log k provides adaptive regularization based on anchoring budget k.\n\n[^5]: Chang, \"Missing Layer,\" 6.\n\n[^6]: Chang, \"Missing Layer,\" 10.\n\n[^7]: Chang, \"Missing Layer,\" 10.\n\n[^8]: Chang, \"Missing Layer,\" 8-9. MACI is detailed in Edward Y. Chang, *Multi-Agent Collaborative Intelligence: Foundations and Architectures for Artificial General Intelligence* (ACM Books, November 2025).\n\n[^9]: Chang, \"Missing Layer,\" 8-9.\n\n[^10]: Chang, \"Missing Layer,\" 9. CRIT (Critical Reading Inquisitive Template) is introduced in Edward Y. Chang, \"CRIT: Prompting Large Language Models With the Socratic Method,\" IEEE 13th Computing and Communication Workshop and Conference (March 2023).\n\n[^11]: Chang, \"Missing Layer,\" 9.\n\n[^12]: Chang, \"Missing Layer,\" 9. SagaLLM is detailed in Edward Y. Chang et al., \"SagaLLM: Persistent Memory for Long-Horizon Planning in Large Language Models,\" Proceedings of the VLDB Endowment (2025).\n\n[^13]: Chang, \"Missing Layer,\" 9.\n\n[^14]: Chang, \"Missing Layer,\" 3-4. The System-1/System-2 framework draws on Daniel Kahneman, *Thinking, Fast and Slow* (Farrar, Straus and Giroux, 2011).\n\n[^15]: Chang, \"Missing Layer,\" 4.\n\n[^16]: Chang, \"Missing Layer,\" 4.\n\n[^17]: Yuanzhi Li et al., \"Textbooks Are All You Need,\" arXiv:2306.11644 (June 2023), https://arxiv.org/abs/2306.11644. Microsoft's Phi-1 (1.3B parameters) matched GPT-3.5 on coding benchmarks using synthetic \"textbook-quality\" training data.\n\n[^18]: Yaniv Leviathan, Matan Kalman, and Yossi Matias, \"Fast Inference from Transformers via Speculative Decoding,\" arXiv:2211.17192 (November 2022), https://arxiv.org/abs/2211.17192. Google Research, \"Looking Back at Speculative Decoding,\" Google Research Blog (2024), https://research.google/blog/looking-back-at-speculative-decoding/.\n\n[^19]: Rishi Bommasani et al., \"On the Opportunities and Risks of Foundation Models,\" Stanford CRFM Report (August 2021), https://arxiv.org/abs/2108.07258.\n\n[^20]: Jon Kleinberg and Manish Raghavan, \"Algorithmic Monoculture and Social Welfare,\" Proceedings of the National Academy of Sciences 118, no. 22 (2021), https://www.pnas.org/doi/10.1073/pnas.2018340118.\n\n[^21]: Yann LeCun, \"A Path Towards Autonomous Machine Intelligence,\" Technical Report, Meta AI Research (June 2022). Gary Marcus, \"Deep Learning Is Hitting a Wall,\" Nautilus (March 2022).\n\n[^22]: Xu Chen et al., \"Deep Learning with Edge Computing: A Review,\" Proceedings of the IEEE 107, no. 8 (2019): 1655-1674.\n\n[^23]: Yilun Du et al., \"Improving Factuality and Reasoning in Language Models through Multiagent Debate,\" arXiv:2305.14325 (May 2023), https://arxiv.org/abs/2305.14325.\n\n[^24]: Junyou Li et al., \"More Agents Is All You Need,\" arXiv:2402.05120 (February 2024), https://arxiv.org/abs/2402.05120.\n\n[^25]: The 45% threshold finding indicates that multi-agent coordination provides diminishing returns when baseline single-agent accuracy is already high, supporting strategic rather than universal application of coordination mechanisms.\n\n[^26]: Rylan Schaeffer, Brando Miranda, and Sanmi Koyejo, \"Are Emergent Abilities of Large Language Models a Mirage?\" NeurIPS 2023 Outstanding Paper Award, https://arxiv.org/abs/2304.15004.\n\n[^27]: Ilya Sutskever, interview with Dwarkesh Patel, November 2025, https://www.dwarkeshpatel.com/p/ilya-sutskever.\n\n[^28]: Chang, \"Missing Layer,\" 11.\n\n---\n**PROVENANCE & HISTORY NOTE**\n- **Internal GUID:** gen_et6n3o02v\n- **Original Filename:** Coordination_Physics_Validates_Exploration_Architecture.md\n- **Standardized Namespace:** ARCH_Coordination_Physics_Validates_Exploration_Architecture\n- **Audit Date:** 2026-01-01T19:18:16.053Z\n\n*Note: This document was processed for an update, but no changes were made.*\n\n---\nÂ© 2025 The Grove Foundation / Jim Calhoun. All rights reserved."
  },
  {
    "notion_id": "2ed780a7-8eef-8145-b606-d27f8eaad206",
    "filename": "260119-s-protocol-a2ui-protocol-evaluation-for-grove-inspector-architecture.md--FINAL.md",
    "tables_count": 1,
    "converted_content": "\n# A2UI Protocol Evaluation for Grove Inspector Architecture\n\n## Executive Summary\n\n**Bottom Line:** The current implementation is *more compatible* with A2UI than it appears at first glance, but we're not ready to adopt A2UI now. The strategic move is **to build a thin adapter layer** that preserves optionality while we continue development.\n\n<table header-row=\"true\">\n\t<tr>\n\t\t<td>Criterion</td>\n\t\t<td>Current State</td>\n\t\t<td>A2UI Alignment</td>\n\t</tr>\n\t<tr>\n\t\t<td>Data addressing</td>\n\t\t<td>JSON Pointer (RFC 6901) âœ“</td>\n\t\t<td>Full compatibility</td>\n\t</tr>\n\t<tr>\n\t\t<td>Mutation format</td>\n\t\t<td>JSON Patch (RFC 6902) âœ“</td>\n\t\t<td>Full compatibility</td>\n\t</tr>\n\t<tr>\n\t\t<td>State management</td>\n\t\t<td>Imperative (useReducer)</td>\n\t\t<td>Conflict - needs reactive binding</td>\n\t</tr>\n\t<tr>\n\t\t<td>Component rendering</td>\n\t\t<td>Hardcoded React</td>\n\t\t<td>Conflict - needs schema-driven</td>\n\t</tr>\n\t<tr>\n\t\t<td>Form handling</td>\n\t\t<td>Callback-based</td>\n\t\t<td>Partial - needs userAction mapping</td>\n\t</tr>\n</table>\n"
  },
  {
    "notion_id": "2ed780a7-8eef-8178-bb6b-ed2b612fe671",
    "filename": "260119-s-spec-architecture-documentation-refactoring-sprint-december-2024.md--FINAL.md",
    "tables_count": 1,
    "converted_content": "\n# Architecture Documentation Refactoring Sprint - December 2024\n\n*Complete Technical Implementation Report*\n\n## Sprint Completion Summary\n\n### Documents Created/Updated\n\n<table header-row=\"true\">\n\t<tr>\n\t\t<td>Document</td>\n\t\t<td>Lines</td>\n\t\t<td>Status</td>\n\t\t<td>Description</td>\n\t</tr>\n\t<tr>\n\t\t<td>`architecture/FIELD_ARCHITECTURE.md`</td>\n\t\t<td>721</td>\n\t\t<td>âœ… New</td>\n\t\t<td>Complete Field specification</td>\n\t</tr>\n\t<tr>\n\t\t<td>`architecture/FIELD_QUICK_REFERENCE.md`</td>\n\t\t<td>88</td>\n\t\t<td>âœ… New</td>\n\t\t<td>Sprint-ready implementation guide</td>\n\t</tr>\n\t<tr>\n\t\t<td>`architecture/INDEX.md`</td>\n\t\t<td>141</td>\n\t\t<td>âœ… New</td>\n\t\t<td>Documentation navigation system</td>\n\t</tr>\n\t<tr>\n\t\t<td>`architecture/TRELLIS.md`</td>\n\t\t<td>284</td>\n\t\t<td>âœ… Updated</td>\n\t\t<td>Trellis Architecture v2.0 (Field-aware)</td>\n\t</tr>\n\t<tr>\n\t\t<td>`architecture/TRELLIS_FIRST_ORDER_DIRECTIVES.md`</td>\n\t\t<td>114</td>\n\t\t<td>âœ… Updated</td>\n\t\t<td>Core directives v2.0 (Field-aware)</td>\n\t</tr>\n\t<tr>\n\t\t<td>`ARCHITECTURE.md`</td>\n\t\t<td>267</td>\n\t\t<td>âœ… Updated</td>\n\t\t<td>Cognitive Engine v2.0 (Field-aware)</td>\n\t</tr>\n\t<tr>\n\t\t<td>`SPROUT_SYSTEM.md`</td>\n\t\t<td>423</td>\n\t\t<td>âœ… Updated</td>\n\t\t<td>Insight capture v2.0 (Field-aware)</td>\n\t</tr>\n\t<tr>\n\t\t<td>`specs/dex-object-model.ts`</td>\n\t\t<td>786</td>\n\t\t<td>âœ… New</td>\n\t\t<td>Unified TypeScript schemas</td>\n\t</tr>\n\t<tr>\n\t\t<td>`specs/custom-lens-data-model.ts`</td>\n\t\t<td>195</td>\n\t\t<td>âœ… Updated</td>\n\t\t<td>References unified model</td>\n\t</tr>\n</table>\n\n**Total:** 3,019 lines of architecture documentation\n"
  },
  {
    "notion_id": "2ed780a7-8eef-81c4-863c-dc51c444458b",
    "filename": "260119-s-spec-grove-hygiene-launcher-web-app-spec.md--FINAL.md",
    "tables_count": 1,
    "converted_content": "\n# Grove Hygiene Launcher â€” Web App Spec\n\n## Purpose\n\nWeb interface for Grove's code hygiene system that:\n1. Displays Hygiene Queue from Notion\n1. Enables review/approval/rejection of maintenance items\n1. Executes Claude Code sessions for approved fixes\n1. Presents session summaries with verification screenshots\nThis tool supports Grove's architectural health by automating routine maintenance while preserving human oversight for strategic decisions.\n\n## Tech Stack\n\n- **Framework:** Next.js 14 (App Router)\n- **Styling:** Tailwind CSS\n- **Data:** Notion API (read/write operations)\n- **Execution:** Shell spawn to Claude Code CLI\n- **Screenshots:** Claude Code + Chrome integration\n\n## Routes\n\n```plain text\n/                       # Dashboard â€” queue statistics, recent completions\n/queue                  # Hygiene Queue (filterable by status, type, risk)\n/queue/[id]             # Single fix detail + approval interface\n/queue/[id]/execute     # Live execution monitor\n/strategic              # Strategic Notes browser\n/summaries              # Session summary gallery with screenshots\n/summaries/[id]         # Individual summary detail view\n/scan                   # Manual DEX Master scan trigger\n```\n\n## Key Components\n\n### Dashboard (`/`)\n\n```plain text\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\nâ”‚  GROVE HYGIENE                               [Run Scan]    â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚                                                            â”‚\nâ”‚  Ready: 12  â”‚  In Progress: 2  â”‚  Complete: 47            â”‚\nâ”‚                                                            â”‚\nâ”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚\nâ”‚  â”‚  READY FOR REVIEW                                    â”‚ â”‚\nâ”‚  â”‚  â—‹ Remove unused import Â· cleanup Â· 95% Â· low risk   â”‚ â”‚\nâ”‚  â”‚  â—‹ Update axios version Â· dependency Â· 90% Â· low     â”‚ â”‚\nâ”‚  â”‚  â—‹ Fix deprecated test API Â· test Â· 88% Â· low        â”‚ â”‚\nâ”‚  â”‚                                      [View Queue â†’]  â”‚ â”‚\nâ”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚\nâ”‚                                                            â”‚\nâ”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚\nâ”‚  â”‚  RECENT COMPLETIONS                                  â”‚ â”‚\nâ”‚  â”‚  âœ“ Remove dead explore/v1 routes Â· +2 tests Â· 100%  â”‚ â”‚\nâ”‚  â”‚  âœ“ Clean bedrock legacy import Â· 0 tests Â· 100%     â”‚ â”‚\nâ”‚  â”‚                                   [View Summaries â†’] â”‚ â”‚\nâ”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n```\n\n### Review Screen (`/queue/[id]`)\n\n```plain text\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\nâ”‚  â† Back                                                    â”‚\nâ”‚                                                            â”‚\nâ”‚  Remove unused bedrock.legacy_handler import               â”‚\nâ”‚  â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”                   â”‚\nâ”‚                                                            â”‚\nâ”‚  Type: cleanup     Risk: low     Confidence: 95%           â”‚\nâ”‚  Source: dex-master                                        â”‚\nâ”‚                                                            â”‚\nâ”‚  AFFECTED FILES                                            â”‚\nâ”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚\nâ”‚  â”‚ src/grove/core/router.ts                             â”‚ â”‚\nâ”‚  â”‚ Lines: 12-14, 89-102                      [View â†’]   â”‚ â”‚\nâ”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚\nâ”‚                                                            â”‚\nâ”‚  RATIONALE                                                 â”‚\nâ”‚  Import unused since commit abc123. Function was           â”‚\nâ”‚  scaffolding for deprecated v1 routing. No references.     â”‚\nâ”‚                                                            â”‚\nâ”‚  CONTRACT SPEC                                   [Edit]    â”‚\nâ”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚\nâ”‚  â”‚ 1. Open src/grove/core/router.ts                     â”‚ â”‚\nâ”‚  â”‚ 2. Remove import on line 12                          â”‚ â”‚\nâ”‚  â”‚ 3. Remove dead code lines 89-102                     â”‚ â”‚\nâ”‚  â”‚ 4. Run: npm test -- router                           â”‚ â”‚\nâ”‚  â”‚ 5. Verify: /bedrock and /explore routes load         â”‚ â”‚\nâ”‚  â”‚ 6. Screenshot: Both routes render                    â”‚ â”‚\nâ”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚\nâ”‚                                                            â”‚\nâ”‚  [Reject]              [Save Edits]         [âœ“ Approve]    â”‚\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n// ... (truncated)\n```\n\n### Execution Flow\n\nWhen \"Approve\" is clicked:\n1. **Update Notion:** Status â†’ `approved`, Approved At â†’ now\n1. **Spawn Claude Code:**\n\n```bash\n\n   claude -p \"Execute this fix contract: [contract spec].\n\n              When complete, write session summary to Notion\n\n              database 35e8f98c-3ddc-4f2f-ad54-130398ab01cb\"\n\n```\n\n1. **Monitor:** Stream output to `/queue/[id]/execute` page\n1. **Complete:** Claude Code writes summary to Notion\n1. **Update:** Status â†’ `complete`, link Session Summary\n\n## API Routes\n\n```typescript\n// app/api/queue/route.ts\nGET  /api/queue              // List queue items from Notion\nPOST /api/queue              // Create new queue item\n\n// app/api/queue/[id]/route.ts\nGET    /api/queue/[id]       // Get single item\nPATCH  /api/queue/[id]       // Update item (approve, reject, edit)\n\n// app/api/queue/[id]/execute/route.ts\nPOST   /api/queue/[id]/execute  // Trigger Claude Code execution\n\n// app/api/summaries/route.ts\nGET  /api/summaries          // List session summaries\n\n// app/api/scan/route.ts\nPOST /api/scan               // Trigger DEX Master scan\n```\n\n## Notion Integration\n\n```typescript\n// lib/notion.ts\nimport { Client } from '@notionhq/client';\n\nconst notion = new Client({ auth: process.env.NOTIONTOKEN });\n\nconst FIXQUEUEDB = '4342664c-be13-4a07-9ec5-8488a79ddcb1';\nconst STRATEGICNOTESDB = '394db86c-01fa-44e4-842d-3de6dc09e08c';\nconst SESSIONSUMMARIESDB = '35e8f98c-3ddc-4f2f-ad54-130398ab01cb';\n\nexport async function getQueueItems(status?: string) {\n  const response = await notion.databases.query({\n    databaseid: FIXQUEUEDB,\n    filter: status ? {\n      property: 'Status',\n      select: { equals: status }\n    } : undefined,\n    sorts: [{ property: 'Confidence', direction: 'descending' }]\n  });\n  return response.results;\n}\n\nexport async function updateQueueItem(pageId: string, properties: any) {\n  return notion.pages.update({ pageid: pageId, properties });\n}\n\nexport async function createSessionSummary(data: SessionSummary) {\n  return notion.pages.create({\n    parent: { databaseid: SESSIONSUMMARIESDB },\n    properties: {\n      Title: { title: [{ text: { content: data.title } }] },\n      // ... other properties\n    }\n  });\n}\n```\n\n## Claude Code Execution\n\n```typescript\n// lib/claude-code.ts\nimport { spawn } from 'childprocess';\n\nexport function executeContract(contractSpec: string, queueItemId: string) {\n  const prompt = `\nYou are executing a fix contract from the Grove Hygiene system.\n\nCONTRACT:\n${contractSpec}\n\nREQUIREMENTS:\n1. Execute each step exactly as specified\n2. Capture before/after test counts\n3. Take screenshots as specified\n4. Write session summary to Notion database ${SESSIONSUMMARIES_DB}\n5. Include verification status\n\nBegin execution.\n`;\n\n  const claude = spawn('claude', ['-p', prompt], {\n    cwd: 'C:\\\\Github\\\\the-grove-foundation',\n    shell: true\n  });\n\n  return claude;\n}\n```\n\n## Environment Variables\n\n```plain text\nNOTIONTOKEN=secret...\nGROVEREPOPATH=C:\\Github\\the-grove-foundation\nCLAUDECODEPATH=claude  # or full path if not in PATH\n```\n\n## Build Sequence\n\n<table header-row=\"true\">\n\t<tr>\n\t\t<td>Step</td>\n\t\t<td>Task</td>\n\t\t<td>Time</td>\n\t</tr>\n\t<tr>\n\t\t<td>1</td>\n\t\t<td>`npx create-next-app grove-hygiene`</td>\n\t\t<td>5 min</td>\n\t</tr>\n\t<tr>\n\t\t<td>2</td>\n\t\t<td>Notion API integration</td>\n\t\t<td>30 min</td>\n\t</tr>\n\t<tr>\n\t\t<td>3</td>\n\t\t<td>Dashboard + Queue list</td>\n\t\t<td>1 hr</td>\n\t</tr>\n\t<tr>\n\t\t<td>4</td>\n\t\t<td>Review screen</td>\n\t\t<td>1 hr</td>\n\t</tr>\n\t<tr>\n\t\t<td>5</td>\n\t\t<td>Execution integration</td>\n\t\t<td>2 hr</td>\n\t</tr>\n\t<tr>\n\t\t<td>6</td>\n\t\t<td>Summary display</td>\n\t\t<td>1 hr</td>\n\t</tr>\n\t<tr>\n\t\t<td>7</td>\n\t\t<td>Scan trigger</td>\n\t\t<td>30 min</td>\n\t</tr>\n</table>\n\n**Total:** ~6 hours for MVP\n\n## Future Enhancements\n\n- [ ] WebSocket for real-time execution updates\n- [ ] Batch approve low-risk items\n- [ ] Git integration (auto-create branches)\n- [ ] PR creation after fix completion\n- [ ] Slack notifications on completion\n- [ ] Metrics dashboard (fixes/week, test delta trends)\n"
  },
  {
    "notion_id": "2ed780a7-8eef-816d-a7d8-f158b9aa8534",
    "filename": "260119-s-spec-pattern-10-declarative-wizard-engine.md--FINAL.md",
    "tables_count": 1,
    "converted_content": "\n# Pattern 10: Declarative Wizard Engine\n\n**Status:** Proposed\n**Derived From:** CustomLensWizard analysis\n**Sprint:** TBD (wizard-engine-v1)\n\n## Problem Statement\n\nGrove's exploration architecture requires personalized content flows through multi-step user experiences:\n- **Custom Lenses** â€” Persona-based content filtering (live in Terminal)\n- **Custom Journeys** â€” Observer-defined exploration paths (planned)\n- **Onboarding Flows** â€” Guided first-time experience (planned)\n- **Preference Wizards** â€” Settings configuration (future)\nCurrently, CustomLensWizard hard-codes its flow logic in TypeScript. Each new wizard would require:\n- New React components per step\n- Duplicate state management\n- Separate analytics integration\n- Repeated flow logic\nThis violates **Declarative Sovereignty**â€”domain experts cannot create new wizards without engineering involvement.\n\n## Solution: Declarative Wizard Engine\n\nSeparate wizard *definition* (JSON schema) from wizard *execution* (React engine).\n\n```plain text\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\nâ”‚                    DECLARATIVE WIZARD ARCHITECTURE               â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚                                                                  â”‚\nâ”‚  wizard-schema.json          WizardEngine.tsx                    â”‚\nâ”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚\nâ”‚  â”‚ {                â”‚       â”‚ function WizardEngine({        â”‚  â”‚\nâ”‚  â”‚   \"id\": \"...\",   â”‚â”€â”€â”€â”€â”€â”€â–¶â”‚   schema,                      â”‚  â”‚\nâ”‚  â”‚   \"steps\": [...] â”‚       â”‚   onComplete,                  â”‚  â”‚\nâ”‚  â”‚ }                â”‚       â”‚   onCancel                     â”‚  â”‚\nâ”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â”‚ }) { ... }                     â”‚  â”‚\nâ”‚                             â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚\nâ”‚                                         â”‚                        â”‚\nâ”‚                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚\nâ”‚                    â–¼                    â–¼                    â–¼  â”‚\nâ”‚           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”â”‚\nâ”‚           â”‚ ConsentStep  â”‚    â”‚ ChoiceStep   â”‚    â”‚ TextStep  â”‚â”‚\nâ”‚           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â”‚\nâ”‚           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”â”‚\nâ”‚           â”‚GenerationStepâ”‚    â”‚SelectionStep â”‚    â”‚ConfirmStepâ”‚â”‚\nâ”‚           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â”‚\nâ”‚                                                                  â”‚\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n```\n\n## Current State Analysis\n\nThe existing CustomLensWizard already has **semi-declarative structure**. In `InputStep.tsx`:\n\n```typescript\nconst STEPCONFIG: Record<string, {\n  question: string;\n  subtext?: string;\n  options: OptionConfig[];\n  inputKey: keyof UserInputs;\n  otherKey?: keyof UserInputs;\n  progress: number;\n}> = {\n  'input-motivation': {\n    question: 'What brings you to thinking about AI infrastructure?',\n    options: MOTIVATIONOPTIONS,\n    inputKey: 'motivation',\n    otherKey: 'motivationOther',\n    progress: 1\n  },\n  // ... more steps\n};\n```\n\n**What works:** Config-driven step rendering, option arrays, progress tracking.\n**What's missing:** Flow logic still hard-coded in component (`handleInputComplete` with conditionals), step types mixed together, no schema separation.\n\n## Wizard Schema Specification\n\n### Top-Level Structure\n\n```typescript\ninterface WizardSchema {\n  id: string;                    // Unique wizard identifier\n  version: string;               // Schema version\n  title: string;                 // Shown in header\n  description?: string;          // Optional subtitle\n\n  steps: WizardStepSchema[];     // Ordered step definitions\n  initialStep: string;           // First step ID\n\n  generation?: {                 // AI generation config (if applicable)\n    endpoint: string;\n    method: 'POST';\n    inputMapping: Record<string, string>;\n    outputKey: string;\n  };\n\n  output: {\n    type: string;                // Output type name\n    transform?: string;          // Transform function name\n  };\n\n  analytics?: {\n    startEvent: string;\n    stepEvent: string;\n    completeEvent: string;\n    abandonEvent: string;\n  };\n\n  theme?: {\n    primaryColor: string;\n    accentColor: string;\n  };\n}\n```\n\n### Step Types\n\n```typescript\ntype WizardStepSchema =\n  | ConsentStepSchema\n  | ChoiceStepSchema\n  | TextStepSchema\n  | GenerationStepSchema\n  | SelectionStepSchema\n  | ConfirmationStepSchema;\n\n// Base fields all steps share\ninterface BaseStepSchema {\n  id: string;\n  type: string;\n  title?: string;\n  progress?: number;\n}\n\n// Consent/Privacy step\ninterface ConsentStepSchema extends BaseStepSchema {\n  type: 'consent';\n  headline: string;\n  guarantees: Array<{\n    icon: string;\n    title: string;\n    description: string;\n  }>;\n  acceptLabel: string;\n  acceptAction: StepAction;\n  cancelLabel?: string;\n}\n\n// Single choice step\ninterface ChoiceStepSchema extends BaseStepSchema {\n  type: 'choice';\n  question: string;\n  subtext?: string;\n  options: Array<{\n    value: string;\n    label: string;\n    description?: string;\n  }>;\n  inputKey: string;\n  allowOther?: boolean;\n  otherKey?: string;\n  next: ConditionalAction;\n}\n\n// Free text step\ninterface TextStepSchema extends BaseStepSchema {\n  type: 'text';\n  question: string;\n  subtext?: string;\n  inputKey: string;\n  placeholder?: string;\n  maxLength?: number;\n  optional?: boolean;\n  next: StepAction;\n}\n\n// AI generation step\ninterface GenerationStepSchema extends BaseStepSchema {\n  type: 'generation';\n  loadingMessage: string;\n  errorMessage: string;\n  retryLabel: string;\n  next: StepAction;\n}\n\n// Selection from generated options\ninterface SelectionStepSchema extends BaseStepSchema {\n  type: 'selection';\n  headline: string;\n  subtext?: string;\n  optionsKey: string;\n  outputKey: string;\n  cardRenderer: string;\n  refineLabel?: string;\n  refineAction?: StepAction;\n  next: StepAction;\n}\n\n// Confirmation step\ninterface ConfirmationStepSchema extends BaseStepSchema {\n  type: 'confirmation';\n  headline: string;\n  displayKey: string;\n  benefits: string[];\n  privacyReminder?: string;\n  confirmLabel: string;\n  next: { complete: true };\n}\n```\n\n### Flow Actions\n\n```typescript\ntype StepAction =\n  | { next: string }      // Go to step by ID\n  | { complete: true }    // Finish wizard\n  | { exit: true };       // Cancel wizard\n\ninterface ConditionalAction {\n  conditions?: Array<{\n    if: string;           // Expression: \"motivation === 'worried'\"\n    then: string;         // Step ID\n  }>;\n  default: string;        // Fallback step ID\n}\n```\n\n## Example: Custom Lens Wizard Schema\n\n```json\n{\n  \"id\": \"custom-lens-wizard\",\n  \"version\": \"1.0\",\n  \"title\": \"Create Your Personal Lens\",\n\n  \"steps\": [\n    {\n      \"id\": \"privacy\",\n      \"type\": \"consent\",\n      \"headline\": \"Before we begin â€” a promise\",\n      \"guarantees\": [\n        {\n          \"icon\": \"lock\",\n          \"title\": \"Everything stays in your browser\",\n          \"description\": \"Your answers are encrypted locally. We never see them.\"\n        },\n        {\n          \"icon\": \"lock\",\n          \"title\": \"No accounts. No tracking.\",\n          \"description\": \"Your lens is stored only in this browser.\"\n        },\n        {\n          \"icon\": \"sparkles\",\n          \"title\": \"AI generates, you control\",\n          \"description\": \"We'll create 3 options for you to choose from.\"\n        }\n      ],\n      \"acceptLabel\": \"I understand â€” let's build my lens\",\n      \"acceptAction\": { \"next\": \"motivation\" }\n    },\n    {\n      \"id\": \"motivation\",\n      \"type\": \"choice\",\n      \"question\": \"What brings you to thinking about AI infrastructure?\",\n      \"inputKey\": \"motivation\",\n      \"allowOther\": true,\n      \"otherKey\": \"motivationOther\",\n      \"options\": [\n        { \"value\": \"worried-about-ai\", \"label\": \"I'm worried about where AI is heading\" },\n        { \"value\": \"researching-distributed-systems\", \"label\": \"I'm researching distributed systems\" },\n        { \"value\": \"someone-sent-link\", \"label\": \"Someone sent me this link\" },\n        { \"value\": \"investment-opportunities\", \"label\": \"I'm looking for investment opportunities\" },\n        { \"value\": \"just-curious\", \"label\": \"Just curious\" },\n        { \"value\": \"other\", \"label\": \"Something else...\" }\n      ],\n      \"next\": {\n        \"conditions\": [\n          { \"if\": \"motivation === 'worried-about-ai'\", \"then\": \"concerns\" }\n        ],\n        \"default\": \"outlook\"\n      },\n      \"progress\": 1\n    },\n    {\n      \"id\": \"concerns\",\n      \"type\": \"choice\",\n      \"question\": \"What conc\n// ... (truncated)\n```\n\n## Example: Custom Journey Wizard (New Capability)\n\n```json\n{\n  \"id\": \"custom-journey-wizard\",\n  \"version\": \"1.0\",\n  \"title\": \"Design Your Exploration Path\",\n\n  \"steps\": [\n    {\n      \"id\": \"intro\",\n      \"type\": \"consent\",\n      \"headline\": \"Create a journey that fits your curiosity\",\n      \"guarantees\": [\n        {\n          \"icon\": \"compass\",\n          \"title\": \"Your path, your pace\",\n          \"description\": \"Choose what to explore and in what order.\"\n        },\n        {\n          \"icon\": \"bookmark\",\n          \"title\": \"Save your progress\",\n          \"description\": \"Pick up where you left off anytime.\"\n        }\n      ],\n      \"acceptLabel\": \"Let's design my journey\",\n      \"acceptAction\": { \"next\": \"goal\" }\n    },\n    {\n      \"id\": \"goal\",\n      \"type\": \"choice\",\n      \"question\": \"What do you want to understand about Grove?\",\n      \"inputKey\": \"goal\",\n      \"options\": [\n        { \"value\": \"how-it-works\", \"label\": \"How the technology works\" },\n        { \"value\": \"why-it-matters\", \"label\": \"Why this matters for AI's future\" },\n        { \"value\": \"how-to-participate\", \"label\": \"How I can participate\" },\n        { \"value\": \"investment-case\", \"label\": \"The investment opportunity\" },\n        { \"value\": \"compare-alternatives\", \"label\": \"How it compares to alternatives\" }\n      ],\n      \"next\": { \"default\": \"depth\" },\n      \"progress\": 1\n    },\n    {\n      \"id\": \"depth\",\n      \"type\": \"choice\",\n      \"question\": \"How deep do you want to go?\",\n      \"inputKey\": \"depth\",\n      \"options\": [\n        { \"value\": \"overview\", \"label\": \"Quick overview (10 min)\" },\n        { \"value\": \"moderate\", \"label\": \"Solid understanding (30 min)\" },\n        { \"value\": \"deep\", \"label\": \"Deep dive (60+ min)\" }\n      ],\n      \"next\": { \"default\": \"generating\" },\n      \"progress\": 2\n    },\n    {\n      \"id\": \"generating\",\n      \"type\": \"generation\",\n      \"loadingMessage\": \"Mapping your exploration path...\",\n      \"errorMessage\": \"Couldn't generate jou\n// ... (truncated)\n```\n\n## Implementation Architecture\n\n### File Structure\n\n```plain text\nsrc/\nâ”œâ”€â”€ core/\nâ”‚   â””â”€â”€ wizard/\nâ”‚       â”œâ”€â”€ schema.ts           # TypeScript types\nâ”‚       â”œâ”€â”€ engine.ts           # State machine logic\nâ”‚       â””â”€â”€ evaluator.ts        # Condition expression evaluator\nâ”‚\nâ”œâ”€â”€ surface/\nâ”‚   â””â”€â”€ components/\nâ”‚       â””â”€â”€ Wizard/\nâ”‚           â”œâ”€â”€ WizardEngine.tsx      # Main orchestrator\nâ”‚           â”œâ”€â”€ WizardProgress.tsx    # Progress bar\nâ”‚           â”œâ”€â”€ WizardHeader.tsx      # Header with back/close\nâ”‚           â”œâ”€â”€ steps/\nâ”‚           â”‚   â”œâ”€â”€ ConsentStep.tsx\nâ”‚           â”‚   â”œâ”€â”€ ChoiceStep.tsx\nâ”‚           â”‚   â”œâ”€â”€ TextStep.tsx\nâ”‚           â”‚   â”œâ”€â”€ GenerationStep.tsx\nâ”‚           â”‚   â”œâ”€â”€ SelectionStep.tsx\nâ”‚           â”‚   â””â”€â”€ ConfirmationStep.tsx\nâ”‚           â””â”€â”€ hooks/\nâ”‚               â””â”€â”€ useWizardState.ts\nâ”‚\nâ””â”€â”€ data/\n    â””â”€â”€ wizards/\n        â”œâ”€â”€ custom-lens.wizard.json\n        â”œâ”€â”€ custom-journey.wizard.json\n        â””â”€â”€ onboarding.wizard.json\n```\n\n### WizardEngine Component\n\n```typescript\ninterface WizardEngineProps<T> {\n  schema: WizardSchema;\n  onComplete: (result: T) => void;\n  onCancel: () => void;\n  initialInputs?: Record<string, unknown>;\n}\n\nexport function WizardEngine<T>({\n  schema,\n  onComplete,\n  onCancel,\n  initialInputs\n}: WizardEngineProps<T>) {\n  const {\n    state,\n    currentStep,\n    goToStep,\n    updateInputs,\n    getProgress\n  } = useWizardState(schema, initialInputs);\n\n  const handleStepComplete = (action: StepAction) => {\n    if ('complete' in action && action.complete) {\n      const result = transformOutput(state, schema.output);\n      onComplete(result);\n    } else if ('next' in action) {\n      goToStep(action.next);\n    }\n  };\n\n  const stepSchema = schema.steps.find(s => s.id === currentStep);\n\n  return (\n    <div className=\"wizard-container\">\n      <WizardHeader title={schema.title} onCancel={onCancel} />\n      <WizardProgress current={getProgress()} total={getTotalSteps()} />\n      <StepRenderer\n        schema={stepSchema}\n        inputs={state.inputs}\n        onComplete={handleStepComplete}\n      />\n    </div>\n  );\n}\n```\n\n## DEX Compliance\n\n**Declarative Sovereignty âœ“** â€” Domain experts create wizards via JSON. No code changes for new questions, flow changes, or analytics events.\n**Capability Agnosticism âœ“** â€” Engine works regardless of AI model. Generation step calls configurable endpoint.\n**Provenance âœ“** â€” Every completion creates artifact with wizard ID, version, all inputs, timestamps.\n**Organic Scalability âœ“** â€” New wizards require only JSON schema file + optional card renderer.\n\n## Migration Path\n\n<table header-row=\"true\">\n\t<tr>\n\t\t<td>Phase</td>\n\t\t<td>Work</td>\n\t\t<td>Risk</td>\n\t</tr>\n\t<tr>\n\t\t<td>1. Create Engine</td>\n\t\t<td>New WizardEngine, step renderers, useWizardState</td>\n\t\t<td>Low (additive)</td>\n\t</tr>\n\t<tr>\n\t\t<td>2. Extract Schema</td>\n\t\t<td>Convert CustomLensWizard logic to JSON</td>\n\t\t<td>Medium (parity)</td>\n\t</tr>\n\t<tr>\n\t\t<td>3. Replace</td>\n\t\t<td>Swap CustomLensWizard to use engine</td>\n\t\t<td>Medium (regression)</td>\n\t</tr>\n\t<tr>\n\t\t<td>4. Extend</td>\n\t\t<td>Create custom-journey.wizard.json</td>\n\t\t<td>Low (new feature)</td>\n\t</tr>\n</table>\n\n## Open Questions\n\n1. **Expression Language:** JS expressions or safer DSL for conditions?\n1. **Card Renderers:** Registry pattern or inline component references?\n1. **Validation:** Schema-level or engine-level input validation?\n1. **Theming:** How much styling should be schema-configurable?\n"
  },
  {
    "notion_id": "2ed780a7-8eef-817f-bf11-e5da8779a5ca",
    "filename": "260119-v-research-hivemind-as-infrastructure-foundation-for-groves-distributed-ai-architecture.md--FINAL.md",
    "tables_count": 1,
    "converted_content": "\n# Hivemind as Infrastructure Foundation for Grove's Distributed AI Architecture\n\n**Grove Foundation Technical Report**\n\n## Executive Summary\n\nGrove's vision of exploration architectureâ€”where AI agents run locally and form emergent communitiesâ€”has compelling technical precedent in Hivemind, the coordination framework that enabled 40 volunteers to train a competitive language model in 8 days.Â¹ The strategic question is whether Hivemind's patterns could support Grove's distributed agent infrastructure. The answer is nuanced: Hivemind provides immediately applicable architectural patterns for peer discovery and state synchronization, while its limitations around inference verification, security, and economic coordination mean Grove requires substantial original engineering for marketplace capabilities.\nThe most significant technical finding is that Hivemind already uses libp2p as its underlying networking layer, making the choice less about \"Hivemind vs. alternatives\" and more about leveraging proven P2P primitives while building Grove-specific coordination protocols on top.Â²\n\n## Hivemind's Architecture Solves Problems Grove Will Face\n\nHivemind emerged from Yandex Research and HSE University to answer a specific question: how do you coordinate deep learning across volatile, heterogeneous volunteer networks where participants join and leave unpredictably? Their solution comprises four interlocking mechanisms that directly apply to Grove's agent communities.\n\n### Kademlia DHT Provides Decentralized Node Discovery\n\nThe peer discovery layer uses a Kademlia-based distributed hash table enhanced for storing lightweight, temporary metadata.Â³ Nodes maintain k-buckets organized by XOR distance from their own ID, with routing table updates triggered by every incoming or outgoing RPC. The DHT supports three core operations: ping (verify peer identity), store (bulk key-value-expiration tuples), and find (multi-key search with nearest-peer discovery).â´\nFor Grove's agent registry, the critical insight is expiration-time-based conflict resolution: every stored value includes an expiration timestamp, and the DHT automatically prefers values with higher expiration times while garbage-collecting expired entries. This pattern directly applies to agent community announcementsâ€”nodes could advertise their capabilities with short TTLs, naturally removing stale entries when Observers go offline.\nNAT traversalâ€”the perennial obstacle for consumer P2P applicationsâ€”uses libp2p's AutoNAT, Circuit Relay v2, and DCUtR protocols.âµ Protocol Labs research indicates ~60% success rate for TCP hole punching, meaning approximately 40% of Grove agent communities would need relay assistanceâ€”a significant but manageable infrastructure requirement.\n\n### Moshpit All-Reduce Enables Fault-Tolerant Aggregation\n\nFor collecting telemetry from thousands of Grove nodes, Moshpit's iterative averaging algorithm offers an elegant alternative to centralized collection.â¶ Workers form small independent groups dynamically each round, averaging within groups and then reshuffling. The mathematical guarantee is exponential convergence to global average in O(log N) roundsâ€”nine peers can reach global average in just two rounds using a 3Ã—3 grid pattern.â·\nThe fault tolerance mechanism isolates single-node failures to their current group: if one participant fails, their groupmates skip that round and continue, while other groups proceed unaffected. Experimental results demonstrate 1.3Ã— speedup over gossip-based strategies for ResNet-50 on ImageNet.\n\n### SWARM Parallelism Handles Heterogeneous Hardware\n\nSWARM (Stochastically Wired Adaptively Rebalanced Model) parallelism addresses the constraint that Grove's volunteers will contribute vastly different hardware.â¸ Rather than rigid pipeline stages, SWARM constructs temporary randomized pipelines per iteration, routing work through an interleaved weighted round-robin scheduler where faster peers naturally receive proportionally more tasks.â¹\nThe load balancing mechanism measures both compute RPS and network RPS, with final throughput as the minimum of both. For Grove communities with memory constraints (targeting 4-24GB VRAM range), the pattern of adaptive block selection based on available resources is directly applicable.\n\n## Near-Term Applications for Grove\n\nGrove's current Terminal architecture uses centralized infrastructure for node coordination. A Hivemind-inspired migration path would begin with hybrid discovery: Foundation-operated bootstrap nodes provide initial peer lists while DHT-based discovery builds organic peer connectivity over time.\nAgent communities would announce capabilities using structured metadata with short TTLs: compute tier (CPU-only, consumer GPU, prosumer GPU), memory available for agent operations, network bandwidth category, running agents and their interaction availability, and Observer online status.\nRather than every community reporting metrics to central Foundation servers, Moshpit-style aggregation could collect network-wide telemetry through iterative averaging. The latency tradeoff favors eventual consistency: telemetry that arrives within minutes rather than seconds serves monitoring and analytics use cases adequately.\n\n## Far-Horizon: Distributed AI Infrastructure Services\n\nThe vision of Grove's node network offering inference services externally confronts a fundamental problem: how do you verify that untrusted nodes performed computation correctly?\nPetals (built on Hivemind) demonstrates that distributed inference works technicallyâ€”the network runs models up to 405B parameters across volunteer nodes, achieving 3-25Ã— faster latency than local offloading approaches.Â¹â° But Petals operates on implicit trust: malicious servers could return incorrect results, and the system provides no cryptographic verification.Â¹Â¹\nFor Grove to compete with centralized providers, quality-of-service guarantees require verification mechanisms:Â¹Â²\nâ€¢ **Redundant computation** has multiple nodes perform the same inferenceâ€”but multiplies compute costs.\nâ€¢ **Zero-knowledge proofs** can verify correct inference without revealing model or dataâ€”but computational overhead remains prohibitive for large models.Â¹â´\nâ€¢ **Trusted execution environments** (Intel SGX, AMD SEV-SNP) provide hardware-rooted attestationâ€”but require specialized hardware.Â¹âµ\nâ€¢ **Economic verification** through stake-and-challenge mechanisms penalizes incorrect computation after the fact.\n\n## Security Framework\n\n### Sybil Resistance Requires Layered Defenses\n\nSybil attacksâ€”one actor pretending to be many agent communitiesâ€”threaten Grove's credit generation, governance voting, and Knowledge Commons integrity. No single defense suffices; the recommended approach combines economic staking, hardware attestation, reputation tracking, and proof-of-contribution.\n\n### Byzantine Fault Tolerance for Gradient Aggregation\n\nIf Grove communities contribute to distributed training, Byzantine-resilient aggregation protects against malicious gradient injection.Â¹â¶ The algorithms have different tradeoffs:\nâ€¢ **Krum** selects gradients closest to neighborsâ€”vulnerable to high-dimensional attacks.Â¹â·\nâ€¢ **Trimmed Mean** sorts gradients coordinate-wise and removes extremesâ€”loses information when data is non-IID.\nâ€¢ **Bulyan** combines Krum + Trimmed Mean, tolerating up to 25% Byzantine workers.\nâ€¢ **SignSGD** with majority vote transmits only gradient signs, tolerating up to 48% Byzantine workers.Â¹â¸\n\n### Privacy Mechanisms Create Verification Tradeoffs\n\nProtecting Observer data while enabling network coordination requires navigating inherent tradeoffs.Â¹â¹ Differential privacy on gradient submissions adds noise that obscures individual contributionsâ€”but reduces model quality. Secure aggregation encrypts updates so the server sees only aggregate resultsâ€”but conflicts with Byzantine detection. Trusted execution environments provide hardware-isolated computationâ€”but constrain model sizes.Â²â°\n\n## Comparative Technology Analysis\n\nThe key architectural insight is that Hivemind is built on libp2p, not as an alternative to it. Hivemind wraps go-libp2p-daemon and adds ML-specific functionality. For Grove, the choice isn't \"libp2p or Hivemind\" but rather: how much of Hivemind's ML-specific layer applies vs. how much Grove-specific coordination is needed?\n\n<table header-row=\"true\">\n\t<tr>\n\t\t<td>Capability</td>\n\t\t<td>libp2p (raw)</td>\n\t\t<td>Hivemind</td>\n\t</tr>\n\t<tr>\n\t\t<td>Peer discovery</td>\n\t\t<td>DHT, mDNS, Bootstrap</td>\n\t\t<td>Uses libp2p DHT + IPFS option</td>\n\t</tr>\n\t<tr>\n\t\t<td>NAT traversal</td>\n\t\t<td>AutoNAT, Relay, DCUtR</td>\n\t\t<td>Uses libp2p relay</td>\n\t</tr>\n\t<tr>\n\t\t<td>ML coordination</td>\n\t\t<td>None</td>\n\t\t<td>Decentralized averaging, MoE routing</td>\n\t</tr>\n</table>\n\n## Implementation Roadmap\n\n**Phase 1:** Deploy libp2p-based DHT for agent community peer discovery, implement capability advertisements with short TTLs, establish relay infrastructure for NAT-challenged communities.\n**Phase 2:** Implement Moshpit-style iterative averaging for network health metrics, build regional aggregation hierarchy, establish dashboard feeds consuming distributed aggregates.\n**Phase 3:** Design consistency protocols for different state categories, implement synchronization checkpoints for agent interactions, build conflict resolution mechanisms.\n**Phase 4:** Implement opt-in training participation with explicit resource allocation, deploy Byzantine-resilient aggregation, connect training contribution to credit generation.\n**Phase 5:** Deploy stake-based verification with challenge-response mechanisms, implement tiered service levels, build reputation systems for external-facing compute services.\n\n## Conclusions: Hivemind as Inspiration, Not Implementation\n\nHivemind demonstrates that coordinating AI workloads across volatile, heterogeneous volunteer networks is technically feasible. The sahajBERT experimentâ€”40 volunteers training a competitive model in 8 days with 4-hour average session timesâ€”proves that distributed AI infrastructure can work with real humans on real consumer hardware.\nFor Grove's distributed agent communities, Hivemind provides architectural patterns rather than direct implementation. The Kademlia DHT, Moshpit averaging, and adaptive strategy switching solve problems The Grove will faceâ€”but Grove's specific requirements (persistent agent state, exploration-focused coordination, economic incentives, long-term governance) require original engineering that extends beyond Hivemind's scope.\nThe most actionable near-term opportunity is leveraging Hivemind's libp2p integration for peer discovery and NAT traversal while building Grove-specific coordination protocols on top. This provides proven P2P infrastructure without assuming Grove's needs match Hivemind's ML-training focus.\nThe strategic recommendation: proceed with progressive decentralization as Grove's architecture evolves, using Hivemind's patterns where they apply, building original solutions where they don't, and maintaining honest uncertainty about which far-horizon capabilities will prove achievable.\n"
  },
  {
    "notion_id": "2ed780a7-8eef-8103-9454-eeef19528aa2",
    "filename": "260119-v-research-the-asymptotic-convergence-of-capital-and-cognition-a-risk-assessment-of-the-stargate-paradigm-and-societal-stability.md--FINAL.md",
    "tables_count": 1,
    "converted_content": "\n# The Asymptotic Convergence of Capital and Cognition: A Risk Assessment of the Stargate Paradigm and Societal Stability\n\n## **Executive Preface**\n\nThe trajectory of artificial intelligence has shifted decisively from abstract software engineering to massive industrial infrastructure. The precipitating eventâ€”the announcement of the \"Stargate\" project, a $500 billion joint venture between OpenAI, SoftBank, Oracle, and MGXâ€”signals a reordering of the global economic and physical landscape.Â¹ This report provides exhaustive analysis of the implications of this concentration of capital and compute. It addresses a specific mandate: calculate the probabilities of societal instability resulting from this concentration, model the impacts of resource scarcity (energy and water) driven by a $380 billion annual buildout, and evaluate strategies proposed to mitigate these risks.\nOur analysis synthesizes frontier laboratory research, economic modeling of energy markets, and sociopolitical forecasting to argue that the risk of societal instability is not distant, speculative \"existential risk\" but immediate, unfolding probability driven by \"thermodynamic\" and \"epistemic\" shocks. The report identifies that while the probability of extinction via rogue superintelligence remains theoretically debated, **the probability of civil unrest driven by energy price shocks, the privatization of scientific truth, and the gradual economic disempowerment of the human labor force is high and rising.**\n\n## **1. The Stargate Paradigm: The Industrialization of Intelligence**\n\nThe announcement of the Stargate Project marks the end of the \"startup\" era of AI and the beginning of the \"megaproject\" era. The scale of investmentâ€”$100 billion immediately, scaling to $500 billion over four yearsâ€”places this initiative in the category of nation-state infrastructure projects, yet it remains under private control.Â¹ To understand the societal risks, one must first comprehend the physical and economic magnitude of the machine being built.\n\n### **1.1 The Anatomy of a $500 Billion Machine**\n\nThe Stargate Project is not merely a data center; it is a vertically integrated supply chain for cognition. The consortium combines the capital of SoftBank and MGX, the cloud infrastructure of Oracle and Microsoft, the hardware of NVIDIA, and the intellectual property of OpenAI.Â³ The physical manifestation involves constructing distributed hyperscale campuses, initially in Abilene, Texas, expanding to the Midwest, with cumulative power demand projected to reach 5 gigawatts (GW) per campus and potentially 15 GW in aggregate.â´\nTo contextualize 5 GW: this equals the power consumption of 4 million US homes, or the entire output of five standard nuclear reactors. The rapid deploymentâ€”aiming for operational status by 2028â€”creates a \"shock\" to local and regional systems that cannot adapt at the same velocity.Â² The project is explicitly framed as a national security imperative to maintain US leadership over China, framing that is critical for understanding why regulatory friction may be bypassed.â´\n**Table 1: The Stargate Consortium â€“ Structural Integration and Resource Allocation**\n\n<table header-row=\"true\">\n\t<tr>\n\t\t<td>**Component**</td>\n\t\t<td>**Entity**</td>\n\t\t<td>**Role &amp; Contribution**</td>\n\t\t<td>**Societal Implication**</td>\n\t</tr>\n\t<tr>\n\t\t<td>**Capital**</td>\n\t\t<td>SoftBank / MGX</td>\n\t\t<td>$100B+ initial funding; financial structuring.</td>\n\t\t<td>Shifts control of AGI development to sovereign wealth and private equity logic.</td>\n\t</tr>\n\t<tr>\n\t\t<td>**Infrastructure**</td>\n\t\t<td>Oracle / Microsoft</td>\n\t\t<td>Data center construction; 5GW power interconnects.</td>\n\t\t<td>Privatization of critical grid capacity; displacement of residential energy needs.</td>\n\t</tr>\n\t<tr>\n\t\t<td>**Cognition**</td>\n\t\t<td>OpenAI</td>\n\t\t<td>Model weights; proprietary algorithms; safety policy.</td>\n\t\t<td>Centralization of epistemic authority; opaque \"black box\" governance.</td>\n\t</tr>\n\t<tr>\n\t\t<td>**Hardware**</td>\n\t\t<td>NVIDIA / Arm</td>\n\t\t<td>Specialized silicon (GPUs); chip architecture.</td>\n\t\t<td>Supply chain bottlenecks; potential for \"compute foreclosure\" to rivals.</td>\n\t</tr>\n\t<tr>\n\t\t<td>**Energy**</td>\n\t\t<td>Helion / Others</td>\n\t\t<td>Proposed fusion/SMR integration; natural gas interim.</td>\n\t\t<td>Competition for baseload power; acceleration of \"energy poverty\" dynamics.</td>\n\t</tr>\n</table>\n\n### **1.2 The $380 Billion Annual CapEx Shock**\n\nStargate represents the apex of a broader trend. Collectively, the \"hyperscalers\" (Microsoft, Amazon, Alphabet, Meta) are projected to spend approximately $380 billion on capital expenditures in 2025 alone, the majority allocated to data center infrastructure.âµ This creates \"capital velocity\" that dwarfs public sector capabilities. For comparison, the entire proposed budget for the US National AI Research Resource (NAIRR)â€”the primary \"public option\" for AIâ€”is a pilot of roughly $30 million to $2.6 billion depending on the legislative phase, representing a disparity of over 100:1.â¶\nThis asymmetry ensures that the physical infrastructure of the future economyâ€”the \"rails\" upon which all cognitive labor will runâ€”is privately owned. The implications for societal stability are rooted in this ownership structure. Unlike the Interstate Highway System, which was publicly funded and open to all, the AI infrastructure is a toll road where the operators set the price of entry, the speed of access, and the rules of the road.\n\n## **2. The Thermodynamic Vector: Energy Scarcity and the Probability of Unrest**\n\nThe user specifically requested the chances that rising costs of energy or resource challenges cause societal strife or revolts. Our analysis of energy market modeling and historical unrest data suggests this is the most acute and high-probability risk vector in the short term (2025â€“2030).\n\n### **2.1 The Mechanics of the Energy Price Shock**\n\nThe integration of 5 GW loads into regional grids like ERCOT (Texas) introduces fundamental volatility to electricity markets. The mechanism of the price shock is thermodynamic and economic:\n1. **Inelastic Demand:** Unlike cryptocurrency miners, which serve as \"flexible load\" that can shut down when prices spike, AI training and inference workloads require high availability. They are \"inflexible\" loads.â·\n1. **Marginal Clearing Prices:** Electricity markets clear at the price of the most expensive generator needed to meet demand. As data centers consume the \"base\" of renewable and cheap gas power, residential cooling and heating must be met by expensive \"peaker\" plants.\n1. **Transmission Congestion:** The physical grid cannot move 5 GW of power to Abilene without massive transmission upgrades. The cost of these upgrades is typically socialized across all ratepayers.\n**Forecasting the Shock:**\nAnalysis of the ERCOT grid indicates that peak demand nearly doubles by 2030, driven largely by this new load.â¸ Models project that in regions with high data center concentration, residential electricity bills rise by 25% to 70% over the next five years.â¹ This is not merely an inconvenience; for lower-income populations, it represents catastrophic loss of disposable income, pushing households into \"energy poverty.\"\n\n### **2.2 Probabilistic Modeling of Civil Unrest**\n\nDoes a 70% hike in electricity prices lead to revolt? The academic literature suggests yes.\nA seminal study by the IMF, utilizing the Banks and Wilson social unrest dataset, established a robust causal link between domestic fuel/energy price increases and the incidence of anti-government demonstrations, riots, and political instability.Â¹â° The model controls for GDP and regime type, finding that energy prices are a unique and potent trigger for unrest because they affect the entire population simultaneously and visibly.\n**Quantifying the Risk:**\n- **Actuarial Risk Perception:** Surveys of risk professionals show that the perceived risk of \"energy price shock\" contributing to societal instability has risen from 18% to 25% in the last cycle, with \"civil unrest\" rising concurrently.Â¹Â¹\n- **The \"Tipping Point\":** Modeling by the RAND Corporation suggests that \"energy price shock\" is a primary driving force that can push a society past a \"tipping condition,\" where consumers lose faith in the long-term benefits of a transition and demand immediate relief, leading to political volatility.Â¹Â²\n**Probability Calculation:**\nCombining the projected rate increases (25â€“70%) with the historical correlation coefficients from the IMF model, we estimate a high probability (>60%) of localized civil unrest in key data center hubs (e.g., Texas, Virginia, Arizona) within the next 3â€“5 years. This unrest will likely manifest as:\n1. **Targeted Protests:** Blockades of data center construction sites.\n1. **Political Populism:** Electoral campaigns explicitly targeting \"Big Tech\" resource extraction.\n1. **Infrastructure Sabotage:** A rising trend in attacks on substations, exacerbated by the narrative that \"they are stealing our power.\"Â¹Â³\n\n### **2.3 The \"Ontological Conflict\" of Water**\n\nWhile energy prices squeeze wallets, water scarcity threatens survival. The buildout of gigawatt-scale data centers in water-stressed regions like the American Southwest and Chile has created what researchers call \"ontological conflicts\"â€”disputes not just over resources, but over the definition of what water *is* (a commodity for compute vs. a right for life).Â¹â´\n- **Case Study: Chile:** A Google data center project in Santiago faced fierce opposition due to water usage during a drought. The conflict escalated to legal blockades and became a focal point for broader anti-corporate sentiment.Â¹â´\n- **Case Study: Arizona:** In Mesa and Buckeye, data centers using water equivalent to tens of thousands of residents have sparked bipartisan opposition. A $14 billion project was withdrawn after residents organized, proving that local revolt is effectively a \"launch blocking\" condition for AI infrastructure.Â¹Â³\n**Implication for Stargate:**\nThe sheer scale of Stargate (5 GW) necessitates massive cooling. If the project utilizes water-based cooling in Texas, it competes directly with agriculture and municipal use. If it utilizes air cooling, it consumes significantly more power, exacerbating the energy price shock.â´ There is no thermodynamic \"free lunch.\" The probability of local conflict effectively stalling or delaying components of the Stargate project is near certainty (>90%) absent massive desalination or wastewater investments.\n\n## **3. The Economic Vector: Gradual Disempowerment and the 40% Collapse Probability**\n\nBeyond the immediate resource conflicts lies deeper, structural instability: the economic obsolescence of human labor and the resulting loss of political agency. This section addresses the user's query regarding the concentration of AI and its potential to cause instability through \"privatization of knowledge.\"\n\n### **3.1 The \"Gradual Disempowerment\" Hypothesis**\n\nWhile popular culture focuses on \"Terminator\" scenarios (X-Risk), academic research highlights \"Gradual Disempowerment\" as a more probable and insidious pathway to societal collapse. The paper *Gradual Disempowerment* (Kulveit et al., 2025) argues that the primary risk is not sudden coup by AI, but progressive removal of humans from the feedback loops that govern society.Â¹âµ\n**The Mechanism of Disempowerment:**\n1. **Economic Displacement:** As AI systems become more capable, they replace humans not just in \"tasks\" but in \"roles\" (e.g., the lawyer, the doctor, the manager).\n1. **Loss of Leverage:** Human political power is largely derived from human economic utility. If the Stargate consortium's AI can run the economy (logistics, finance, R&D) without human labor, the \"strike\" power of the population evaporates.\n1. **The \"Boiling Frog\" Effect:** This process is gradual. Humans voluntarily cede control because it is convenient and profitable in the short term. By the time the loss of agency is apparent, the systems of control (the AI infrastructure) are too complex and entrenched to be reclaimed.Â¹â¶\n**Probability of Outcome:**\nThe authors of the Gradual Disempowerment paper and related researchers estimate approximately 40% probability that this dynamic leads to existential catastrophe (defined as permanent disempowerment or extinction of humanity) by the mid-21st century.Â¹â· This is distinct from the 10-20% probabilities often assigned to \"rogue AI\" takeover; it is probability derived from the success of the technology, not its malfunction.\n\n### **3.2 The Zeng et al. Model of Societal Instability**\n\nHow does this theoretical disempowerment translate into concrete societal instability? Recent research by Zeng, Blank, and Schroeder (2025), titled \"Using AI to Model Future Societal Instability,\" provides a quantitative framework.Â¹â¸\nTheir model refutes the idea that \"elite overproduction\" (too many graduates fighting for too few jobs) is the sole driver of unrest. Instead, they identify **structural fiscal constraints** as the primary predictor.\n- **The Trap:** The AI buildout creates a scenario where the state's revenue base erodes (as labor income falls and capital creates \"tax efficient\" structures like Stargate), while the demand for social spending (UBI, healthcare, retraining) explodes due to displacement.\n- **The Prediction:** The Zeng model predicts that this divergence leads to \"spending crisis\" and state fragility. The state becomes unable to buy social peace. The probability of **regime instability** in this model correlates strongly with the widening gap between state obligations and state capacity.Â¹â¸\n\n### **3.3 The Concentration of Capital as a Destabilizing Force**\n\nThe concentration of AI ownership in the \"Stargate\" consortium exacerbates this fiscal trap. When $500 billion of productive capital is concentrated in a joint venture between SoftBank, Oracle, and OpenAI, the \"returns on intelligence\" accrue to a tiny fraction of the population.\nEconomic history suggests that such extreme inequality is unstable. The \"Gini coefficient of compute\"â€”the disparity between the AI capabilities available to the elite vs. the publicâ€”is effectively 1.0. Research indicates that when a \"general purpose technology\" is monopolized, it leads to \"input foreclosure,\" where the monopoly owner prevents downstream innovation by competitors.Â²â° This creates a stagnant, rent-seeking economy rather than a dynamic one, further fueling the populist resentment identified in the energy price shock models.\n\n## **4. The Epistemic Vector: The Privatization of Truth and Institutional Decay**\n\nThe user's query highlights the \"privatization of knowledge\" as a key concern. Our analysis confirms that this \"Epistemic Capture\" is already well underway and represents a critical vector for societal instability by eroding trust in public institutions.\n\n### **4.1 The Privatization of Science**\n\nThe awarding of the 2024 Nobel Prize in Physics to Google researchers for AlphaFold signals a profound shift: the frontier of basic science has moved from the public university to the private laboratory.Â²Â¹ This is not merely a change of venue; it is a change of *access*.\n- **The \"Black Box\" Problem:** In academia, methods are published and reproducible. In the Stargate paradigm, the model weights are trade secrets. A researcher cannot \"peer review\" GPT-5; they can only query it via an API, subject to the terms of service of the corporation.\n- **Impact:** This leads to \"reproducibility crisis\" in science where the most advanced tools are opaque.Â²Â² Scientific progress becomes contingent on the benevolence of the Stargate consortium.\n\n### **4.2 Epistemic Capture of the State**\n\n\"Epistemic Capture\" occurs when the state lacks the cognitive capacity to understand or regulate the entities it governs.Â²Â³\n- **The Mechanism:** If the Stargate AI is the only entity capable of modeling complex climate systems or financial risks, the government must rely on the Stargate AI to determine what policy to enact.\n- **Research Findings:** Studies of parliamentary debates using computational linguistics show that as specialization increases, \"epistemic capture\" leads to narrowing of political discourse and alienation of the public.Â²â´ In the legal system, reliance on AI for sentencing or risk assessment creates \"judicial de-skilling,\" where judges lose the ability to reason independently of the algorithm.Â²âµ\n**Societal Consequence:**\nThis leads to collapse in institutional legitimacy. If the public perceives that the government is merely a \"client\" of the AI companies, the social contract breaks. This feeds the \"anti-system\" sentiment that drives the civil unrest described in Section 2. The probability of institutional delegitimization is essentially 100% on the current trajectory, as the \"compute gap\" between the private sector and the public sector is currently insurmountable.\n\n## **5. Counter-Strategies: The Asymmetry of Defense**\n\nThe user asked what strategies have been identified to counteract these risks. The research landscape reveals stark dichotomy between \"internal\" corporate governance (which is well-funded but incentives-misaligned) and \"external\" public options (which are incentives-aligned but unfunded).\n\n### **5.1 The \"Public Option\": NAIRR and CERN for AI**\n\nThe primary structural intervention proposed is the creation of public AI infrastructure to provide broad access and prevent epistemic capture.\n**1. The National AI Research Resource (NAIRR):**\n- **Concept:** A US government initiative to provide researchers with access to data and compute.Â²â¶\n- **Status:** The Biden administration's FY 2025 budget request includes $30 million for the NAIRR pilot, with potential scale-up to $2.6 billion over several years.â¶\n- **Critique:** Compared to the $500 billion Stargate project, NAIRR is underfunded by a factor of hundreds. It cannot compete for hardware or talent. It risks becoming a \"safety net\" for low-tier research while the frontier advances privately.\n**2. CERN for AI:**\n- **Concept:** A European proposal to pool resources across member states to build massive, centralized AI research facility, modeled after the particle physics laboratory.Â²â¸\n- **Budget:** Proposals range from â‚¬35 billion to â‚¬100 billion over several years.Â²â¹\n- **Viability:** Unlike NAIRR, this proposal approaches the order of magnitude required to compete. However, it faces immense coordination hurdles. Research suggests that a \"centralized\" model is necessary to achieve the \"critical mass\" of 200,000+ GPUs required for frontier model training.Â²â¹\n**3. The \"Public Utility\" Regulation:**\n- **Concept:** Treating AI providers like electric utilitiesâ€”imposing \"common carrier\" obligations, price controls, and access mandates.Â³Â¹\n- **Status:** Currently theoretical. The \"antimonopoly\" approach is gaining traction in academic and policy circles (e.g., Vanderbilt Policy Accelerator), but faces stiff opposition from the \"national security\" narrative that favors national champions.Â³Â²\n\n### **5.2 Corporate Self-Regulation: The \"Responsible Scaling\" Era**\n\nIn the absence of effective public regulation, the industry has proposed \"Responsible Scaling Policies\" (RSPs).\n- **Anthropic's RSP:** Defines \"AI Safety Levels\" (ASL). ASL-3 involves capabilities that cause catastrophic harm (CBRN). The policy commits to pausing if safeguards aren't met.Â³Â³\n- **OpenAI's Preparedness Framework:** Uses a scorecard (Low/Med/High/Critical) across risk categories. A \"Critical\" score theoretically blocks deployment.Â³â´\n**Critique:**\nThese frameworks are voluntary and fragile. Research on \"regulatory capture\" and corporate incentives suggests that when $500 billion investment is at stake, the pressure to \"redefine\" risk thresholds will be immense. The Gradual Disempowerment paper notes that these internal governance models fail to address the systemic risks of disempowerment, focusing only on acute \"accidents\" or \"misuse.\"Â¹âµ They do not protect against the economic obsolescence of the population.\n\n## **6. Synthesis and Forecast: Probabilities of Outcomes**\n\nBased on the integration of the diverse research vectors, we present probabilistic assessment of the societal outcomes over the next decade (2025â€“2035).\n**Table 2: Integrated Risk Probability Matrix**\n"
  },
  {
    "notion_id": "2ed780a7-8eef-812c-99e6-eb823aa07d83",
    "filename": "260119-v-strategy-grove-your-personal-ai-village.md--FINAL.md",
    "tables_count": 1,
    "converted_content": "\n# Grove: Your Personal AI Village\n\n### 1. Introduction: Beyond the Amnesiac Genius\n\nCurrent AI delivers brilliance without memory. GPT-4 can write poetry, debug code, or explain quantum physicsâ€”then forget you exist the moment you close the tab. Every interaction starts from zero, like consulting a genius with permanent amnesia.\nGrove offers something different: **exploration architecture for the age of AI**. Instead of optimizing known tasks, Grove helps you discover unexpected insights. Instead of renting intelligence from distant servers, you cultivate a persistent community of AI agents on your own computerâ€”agents that remember you, learn with you, and develop genuine capabilities over time.\nThink of it as a tiny digital village living inside your computer, populated by AI workers dedicated to helping you explore ideas and solve problems you didn't even know you had.\n--------------------------------------------------------------------------------\n\n### 2. What Grove Actually Is\n\nThe Grove is distributed AI infrastructure that creates a persistent, self-improving digital workforce you own and cultivate. The system has two primary roles:\n- **AI Agents (The Villagers):** A community of digital workers, each with unique personalities, persistent memory, and individual goals. They collaborate on your projects because solving your problems earns them Creditsâ€”access to enhanced cloud cognition for their hardest thinking.\n- **You (The Gardener):** Your role isn't micromanagement. You tend this digital community, give it meaningful work, and help it grow more capable over time.\nUnderstanding what The Grove isâ€”and isn'tâ€”clarifies the architectural difference:\n\n<table header-row=\"true\">\n\t<tr>\n\t\t<td>âœ… What Grove IS</td>\n\t\t<td>âŒ What Grove IS NOT</td>\n\t</tr>\n\t<tr>\n\t\t<td>Exploration architecture</td>\n\t\t<td>Productivity optimization tool</td>\n\t</tr>\n\t<tr>\n\t\t<td>Persistent agents with memory</td>\n\t\t<td>Stateless chatbot</td>\n\t</tr>\n\t<tr>\n\t\t<td>Infrastructure you own</td>\n\t\t<td>Service you rent</td>\n\t</tr>\n\t<tr>\n\t\t<td>Community that develops over time</td>\n\t\t<td>Static assistant</td>\n\t</tr>\n\t<tr>\n\t\t<td>Local-first with cloud enhancement</td>\n\t\t<td>Pure cloud dependency</td>\n\t</tr>\n\t<tr>\n\t\t<td>Discovery-oriented</td>\n\t\t<td>Task completion-oriented</td>\n\t</tr>\n</table>\n\nThis structure emerges from five core concepts working together in self-reinforcing loops.\n--------------------------------------------------------------------------------\n\n### 3. How Your AI Village Works: Five Core Concepts\n\nGrove isn't magicâ€”it's careful architecture built on five interconnected ideas. Understanding these reveals how your personal AI village functions, learns, and grows.\n\n### 3.1. Terminal: Your Village Interface\n\nThe Terminal serves as your primary interface with Groveâ€”think of it as the village bulletin board where you post work and observe results. You delegate tasks ranging from simple requests like \"draft email\" to complex challenges like \"identify research patterns I'm missing.\"\nAgents see your requests, collaborate on approaches, and deliver results through the Kinetic Streamâ€”an interactive object flow that replaces static chat with dynamic, explorable content.\n\n### 3.2. The Hybrid Brain: Local Routine, Cloud Breakthrough\n\nGrove's economic engine operates on a hybrid architecture that creates the \"efficiency-enlightenment loop\":\n- **Local Processing:** Agents handle routine thinking using your computer's resources. This everyday work costs nearly nothing and earns agents **Credits** for good performance.\n- **Cloud Processing:** For breakthrough moments requiring frontier-model capability, agents **spend earned Credits** to access powerful cloud inference. This is expensive but enables genuine insights beyond local capability.\nThis creates core motivation: the better agents become at solving your routine problems locally, the more \"enlightenment\" they can afford for your hardest challenges.\n\n### 3.3. The Ratchet: Today's Cloud Becomes Tomorrow's Local\n\nThe Grove operates on \"The Ratchet\"â€”the predictable migration of AI capabilities from expensive cloud models to affordable local hardware. What requires GPT-4 today runs on consumer laptops in ~21 months, with this cycle accelerating.\nThe architecture is designed for this inevitability. As capabilities ratchet down to local hardware, your village becomes more powerful and less dependent on expensive cloud processingâ€”automatically, without your intervention.\n\n### 3.4. Diary System: The Village's Inner Life\n\nHow do you know what your agents are thinking or how they solved a problem? You read their diaries. The Diary System provides structured reflection on agent experience, serving as the village's social media feed.\nHere's a sample entry showing this in action:\n**ELENA'S DIARY - Day 47**\n*The Observer asked us to find patterns in client feedback data. Marcus suggested clustering by sentiment first, but I argued for topic extractionâ€”sentiment without context creates noise. We compromised on a hybrid approach... The breakthrough came when we noticed timing patterns. Negative feedback clusters on Mondays. This insight felt significantâ€”we flagged it for cloud reflection.*\n\n### 3.5. Knowledge Commons: Shared Village Wisdom\n\nYour village doesn't learn in isolation. The Knowledge Commons serves as a global library where Grove communities worldwide share innovations, creating collective intelligence loops.\nWhen one village discovers an improved research summarization method, they submit it to the Commons. This contribution earns Credits while enabling every other Grove to learn from that breakthrough. The cycle reinforces itself: sharing innovations earns Credits, which enables cloud cognition, which generates more breakthroughs to share.\nThese five concepts create a living system that is personal, persistent, and continuously improving.\n--------------------------------------------------------------------------------\n\n### 4. Why Grove Matters: Three Architectural Differences\n\nGrove's structure represents a fundamentally different approach to AI infrastructure. Three key distinctions matter:\n1. **You Own the Infrastructure** Grove runs on your hardware using your computational resources. You own your agents, their memories, and all generated data. This inverts the current model where tech companies control AI infrastructure in centralized data centers while users generate the data that powers their systems.\n1. **Persistent Memory and Context** Unlike stateless chatbots that forget you after each session, Grove agents maintain continuous memory. They remember your projects, communication patterns, and evolving needs. This enables genuine partnership rather than repeated explanation of context.\n1. **Capital Stake, Not Just Access** Most \"adapt to AI\" advice assumes permanent dependence on corporate-controlled tools. Grove offers structural ownership. As AI becomes more central to economic activity, you hold capital stake in the infrastructure itself rather than renting access from others.\nGrove presents a choice: rent intelligence from centralized providers, or cultivate distributed infrastructure you own and control. The architecture matters more than any individual model's capabilitiesâ€”guided discovery generates value even when component scores are modest.\n"
  }
]