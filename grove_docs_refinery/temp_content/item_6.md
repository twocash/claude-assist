
# The Grove: A World-Changing Play for Distributed Intelligence

**Author:** Jim Calhoun
Independent Researcher, The-Grove.ai Foundation
jimcalhoun@gmail.com
December 2025

---

**Â© 2025 Jim Calhoun / The-Grove.ai Foundation. All rights reserved.**

This document is for informational purposes only and does not constitute legal, financial, or technical advice. The-Grove.ai Foundation makes no warranties, express or implied, regarding the accuracy or completeness of the information contained herein.

---

## Abstract

### The Grove: Distributed AI Infrastructure

The Grove creates infrastructure for collective intelligence by integrating four proven concepts: emergent social behavior demonstrated by Stanford's Generative Agents (Park et al., 2023), civilizational scale achieved by Project Sid/Altera (2024), distributed volunteer computing proven by BOINC, and open-source accessibility of AI Town.

The core technical innovation is hybrid cognition architecture. Local LLMs handle routine agent behaviorâ€”perception, simple dialogue, plan executionâ€”while cloud APIs process reflections and pivotal decisions. This solves the economic constraint that kept prior agent research centralized: Park's 25-agent simulation cost thousands of dollars for two days of runtime. The Grove makes emergent AI civilizations sustainable by making cloud intelligence a scarce resource agents earn through demonstrated value.

Credits flow from problem-solving, knowledge generation, knowledge sharing, cooperation and innovation adoptionâ€”not speculation. An efficiency tax funds infrastructure during bootstrap (30-40%), then shrinks to a maintenance floor (3-5%) as civilizations mature. Grove's founding organization is designed to become obsolete through concrete governance transitions, not aspirational intent.

No existing system combines distributed local nodes, persistent emergent civilizations, productivity-backed economics, and human-serving purpose. The Grove is that integration.

---

**Preamble**

## Horses Don't Lead Revolutions

In 2025, tech leaders converged on the same message.

"AI is the most profound technology humanity is ever working onâ€¦ People will need to adapt." *Google CEO [Sundar Pichai, December 2025](https://fortune.com/2025/12/02/ai-wipes-jobs-google-ceo-sundar-pichai-everyday-people-to-adapt-accordingly-we-have-to-work-through-societal-disruption/)*

"The obvious tactical thing is just get really good at using AI tools. This is the new version of [learning to code]â€¦ adaptability and continuous learning would be the most valuable skills." [OpenAI CEO Sam Altman, March 2025](https://stratechery.com/2025/an-interview-with-openai-ceo-sam-altman-about-building-a-consumer-tech-company/)

"People have adapted to past technological changesâ€¦ I advise ordinary citizens to learn to use AI." [Anthropic CEO Dario Amodei, May 2025](https://www.axios.com/2025/05/28/ai-jobs-white-collar-unemployment-anthropic)

Adapt. Learn the tools. Stay employable.

This is the unified response from the people building the systems thatâ€”by their own admissionâ€”could eliminate [half of entry-level white-collar jobs within five years](https://www.axios.com/2025/05/28/ai-jobs-white-collar-unemployment-anthropic), spike unemployment to 20%, and fundamentally restructure what humans do for a living. Amodei's own projections suggest [tens of millions of U.S. white collar jobs at risk](https://www.axios.com/2025/05/28/ai-jobs-white-collar-unemployment-anthropic). Altman says AI is already [handling over 50% of the coding work](https://stratechery.com/2025/an-interview-with-openai-ceo-sam-altman-about-building-a-consumer-tech-company/) at many companies. [Job postings have fallen 32% since ChatGPT launched](https://fortune.com/2025/11/03/jobs-openings-plunge-thanks-to-ai-gen-z-taking-35k-healthcare-jobs-stanford-report-unemployment-career-advice/). Programming employment has hit [its lowest level since 1980](https://www.washingtonpost.com/business/2025/03/14/programming-jobs-lost-artificial-intelligence/). Gen Z's presence in major tech companies has been cut in half in two years.

And the solution to this inevitabilityâ€”from all of themâ€”is the same basic message: adapt.

This framing borrows from what economists call the "horse moment"â€”the idea that just as horses couldn't learn to drive automobiles, human workers can't out-think artificial general intelligence. The comparison is meant to convey inevitability. Accept the transition. Find a way to stay useful.

But the horse analogy contains a hidden, darker truth: *horses don't go to war.*

Horses had no agency in the automobile transition. Between 1915 and 1960, the American horse population fell from 26 million to 3 millionâ€”an 88% collapse in 45 years. They couldn't buy shares in Ford Motor Company. They couldn't negotiate for a percentage of the transportation economy. They couldn't organize politically to ensure the transition included them. They were pure labor, and when labor was automated, they had nothingâ€”no capital stake, no political voice, no structural claim on the value the new systems created.

Humans are different. We can own capital, not just provide labor. We can participate in systems that replace traditional work. We have economic and political agency that horses never did.

The question isn't whether AI will automate labor. It will, and it is. The question becomes *who owns the infrastructure that does the automating*â€”and whether that ownership is concentrated in a handful of immensely valuable, privately controlled companies, or ownership is distributed across the people who contribute to it.

The current trajectory is *concentration*. A small number of organizations control today's foundational AI models. Pricing gates access to frontier intelligence. Compute requirements create unprecedented barriers to entry. If you're not building AI at scale, you're renting itâ€”and renters don't accumulate equity.

"Adapt" means "keep renting." It describes permanent labor precarity, not a solution to it.

The only structural answer to labor displacement at this scale is capital distribution. People need to own pieces of the systems generating value, not just "adapt" to using them. Previous technology transitions created new forms of capital ownershipâ€”automobile factories, car dealerships, service networks, infrastructure. Someone owned those things. The value of displaced labor didn't disappear; it shifted to new capital positions.

The AI transition, underway today, is being structured so those positions are locked up before most people realize what's happening.

The Grove is one attempt at proposing an alternative model.

Instead of concentrated AI infrastructure owned by the few, Grove proposes distributed AI infrastructure where participation creates ownership. Thousands of nodes running AI "communities" on personal hardware, solving real problems, sharing solutions across an interconnected network of these software AIs. Value flows to the virtual communities that contribute documented breakthroughs. Productivity generates surplus. That surplus flows to participantsâ€”not through *speculation*, but as demonstrated, quantifiable value creation.

Grove's founding organization is designed to "disappear." Success isn't an IPO or acquisition. Success is obsolescenceâ€”a network mature enough to govern itself, productive enough to sustain itself, distributed enough that no single entity controls it.

This is a different kind of relationship with AI than "adapt to stay useful." It's *become a stakeholder in the infrastructure.* It's gardening, not racing. It's cultivation over a lazy river of distributed intelligence, where what emerges serves youâ€”and where you own a piece of what you helped grow.

This isn't guaranteed to work. It requires technical viability, economic sustainability, robust identity infrastructure, and genuine network effects. The white paper that follows is honest about these dependencies and the uncertainties involved.

But The Grove represents a category of response to AI displacement that "adapt" doesn't: *distributed AI infrastructure with ownership stakes for contributors.* A way for humans to exercise the agency horses never had.

The horse moment is coming. It may already be here.

But unlike horses, we get to decide how it goes.

**What follows is a technical and economic specification for a different vision of the future.**

Jim Calhoun
December 2025

---

## 1. Introduction â€” The Opposite Architecture

In 2024 and 2025, the world's largest technology companies announced over $300 billion in planned investment for AI data centers. Microsoft, Google, Meta, Amazon, and OpenAI race to build massive centralized infrastructureâ€”warehouses of GPUs consuming gigawatts of power, cooled by rivers, secured by fences. The assumption underlying these investments is that intelligence scales through concentration. More compute in fewer places. Bigger models on bigger clusters. The future of AI, in this view, is a small number of enormous facilities owned by a small number of enormous companies.

What if we engineer the opposite?

Approximately 2 billion personal computers exist worldwide. Hundreds of millions have hardware capable of running small language models locally. These machines sit idle most of the time. Their owners pay for electricity, internet, and storage that goes largely unused. This is distributed compute at a scale that dwarfs any planned data center buildout, already deployed, already powered, already owned by the people who benefit from what it produces.

Four proven capabilities show this "opposite" architecture is possible:

- **Emergent agent civilizations work.** Park's Generative Agents demonstrated LLM-powered agents producing emergent social behavior indistinguishable from human activity. Project Sid scaled this to over 1,000 agents developing economies, governance, and religious beliefs. Artificial civilizations emerge from simple cognitive architectures running on modest hardware.
- **Distributed volunteer computing works.** BOINC has coordinated millions of personal computers contributing to scientific research since 2002. People donate idle resources when participation feels meaningful. The coordination infrastructure exists.
- **Open-source agent simulation works.** AI Town proved sophisticated agent architectures can run on commodity hardware. Distribution is technically feasible.
- **Frontier intelligence is accessible.** Cloud APIs provide reasoning capability that local hardware cannot matchâ€”available to anyone with an API key. The capability exists; the question is who benefits from it.

**A fifth element makes this architecture not just possible but increasingly favorable: local AI capability propagates predictably.**

METR's longitudinal research on AI capability trajectories reveals a pattern Grove calls "the Ratchet." Frontier model capabilities double approximately every seven months. Local modelsâ€”constrained by consumer hardwareâ€”follow the same improvement curve with a consistent lag of roughly 21 months. The gap between frontier and local capability remains approximately 8x, but both ends of the spectrum advance in lockstep.

This has a concrete implication: what requires frontier inference today becomes local-capable tomorrow. Tasks that demanded cloud APIs in 2024 run on laptops in 2026. The hybrid architecture isn't a permanent compromiseâ€”it's a bootstrap mechanism for a system that becomes progressively more autonomous.

<table header-row="true">
	<tr>
		<td>**Capability Horizon**</td>
		<td>**2025 (Local)**</td>
		<td>**2027 (Local)**</td>
		<td>**2029 (Local)**</td>
	</tr>
	<tr>
		<td>Task complexity</td>
		<td>~8 min</td>
		<td>~2-6 hr</td>
		<td>~8-20+ hr</td>
	</tr>
	<tr>
		<td>Cloud dependency</td>
		<td>~95-97%</td>
		<td>~30-50%</td>
		<td>~10-25%</td>
	</tr>
</table>

*Note: Ranges reflect uncertainty in propagation rate and hardware adoption cycles. Routine behaviors (planning, consistency, voice) track the optimistic end; pivotal cognition (reflection, social reasoning) tracks the conservative end. Even pessimistic projections show directional improvement favoring distributed architecture.*

Recent research validates that cognition itself is hierarchically structured in ways the hybrid model exploits. Wang et al. (2025) demonstrate that RL-trained language models develop reasoning through a two-phase dynamicâ€”procedural execution consolidates first, then strategic planning becomes the bottleneck for improvement. This maps directly to Grove's local/cloud division: routine cognition (voice maintenance, behavioral consistency, simple planning) corresponds to procedural operations that compress efficiently to local hardware; pivotal cognition (reflection synthesis, novel insight, complex social reasoning) corresponds to strategic operations that benefit from frontier capability. The hybrid architecture isn't an engineering compromiseâ€”it's aligned with how these systems actually learn and reason.

### Capability propagation is not uniform.

The Ratchet applies METR's "task complexity horizon" metricâ€”duration of autonomous workâ€”as a general indicator of capability propagation. This metric aggregates performance across many cognitive operations. Historical evidence shows that not all operations propagate at the same rate.

Research on capability migration from frontier to local models reveals a structural bifurcation:

- *Crystallized intelligence*â€”knowledge, pattern-matching, style transferâ€”compresses efficiently and propagates rapidly. An 8B model can know the capital of France or generate grammatically correct dialogue as well as a 100B model. Historical propagation time: 12-18 months.
- *Fluid intelligence*â€”multi-step reasoning, planning, counterfactual analysisâ€”resists compression and propagates slowly. The ability to simulate recursive reflection, to think about thinking, requires minimum thresholds of parameters and attention depth. Historical propagation time: 24+ months.

For Grove's specific cognitive operations, this bifurcation maps as follows:

- *Routine cognition* (propagates reliably): Plan execution, behavioral consistency, voice maintenance, simple dialogue, observation processing. These operations will run locally within the projected timeline.
- *Pivotal cognition* (propagates slowly): Reflection synthesis, complex social inference, long-horizon planning, theological emergence. These operations may require cloud assistance longer than the optimistic projections suggest.

The hybrid architecture accounts for these variations by design. The efficiency-enlightenment loop assumes that agents seek enhanced cognition for their most demanding thinking. Cloud credits buy "expanded consciousness" for exactly these operations. The architecture works *because* capability propagation is non-uniformâ€”if everything propagated equally, there would be no gradient to exploit.

**The Jevons consideration:**

As local models become capable of 2025-era "pivotal" tasks, the definition of "pivotal" will not remain static. Worldsmiths and communities will demand increasingly complex emergent behaviorsâ€”theological debates, inter-civilizational dynamics, nuanced deceptionâ€”that will continue to require frontier-class inference. The "coherence floor" rises with capability.

This is not a bug; it is the product working. The simulation grows more sophisticated as the infrastructure matures. Cloud dependency may decline more slowly than projected, but the quality of what that dependency purchases improves continuously.

**The honest framing:**

Local models in 2027 will likely excel at "sounding like a distinctive character" (voice, style, behavioral consistency) while requiring cloud assistance for "having a genuine insight" (recursive reflection, social strategy, emergent theology). This is fine. The simulation runs locally; the breakthrough moments route to frontier capability. Users experience a coherent, persistent world with occasional flashes of deeper intelligenceâ€”which is, arguably, how humans experience consciousness as well.

The Ratchet means Grove communities don't stay dependent on cloud intelligence indefinitely. As local capability propagates forward, the "routine cognition" that local models handle expands to encompass what was previously "pivotal." Reflection that requires frontier models today becomes locally tractable. The efficiency tax shrinks not because the Foundation chooses lower rates, but because communities genuinely need less cloud inference to achieve sophisticated behavior.

This is Grove's core bet: that capability propagation is real, measurable, and favorable to distributed architecture. Centralized infrastructure assumes the gap matters permanently. The Ratchet suggests the gap is a temporary condition that distributed systems can ride through.

Each building block is proven. The Ratchet makes the economics increasingly favorable. The missing piece is the mechanism: what connects distributed local compute to occasional cloud intelligence to emergent civilizations to derive a human benefit?

### The Memory Wall

Grove's local simulation layer runs on consumer hardware. Today, this means machines with 16-32GB of RAM running 7-8B parameter models. This is the floor, not the ceiling.

Hardware refresh cycles average 4-5 years. The average Grove node in 2027 will likely be a machine purchased in 2024 or 2025. Even if capable open-source models exist, the installed base takes time to catch up. This creates "hardware lag" that is stickier than "model lag."

But hardware ownership is not the only path. Gardeners can run containerized simulations on commodity cloud infrastructureâ€”a "Docker Grove" on a $10-15/month instance that exceeds their laptop's specifications. This preserves the core value proposition: the Gardener controls their simulation, can migrate between providers, and operates at consumer-grade economics. The compute happens to live in a data center rather than under a desk, but the ownership model remains distributed.

The spectrum matters more than the location. A Grove village on a personal gaming rig, a Grove village on a cloud container, and a hybrid configuration using both represent different points on the same curveâ€”consumer-accessible economics with distributed control. All three configurations are valid. All three contribute to the network's aggregate capability.

Grove runs best on enthusiast hardware today, and mainstream hardware tomorrow. The architecture gracefully degrades: communities with capable local hardware achieve higher autonomy; communities with constrained hardware route more cognition to cloud or commodity infrastructure. The efficiency tax adjusts to market conditions, not fixed dates.

The answer is an incentive structure where agents experience cloud access as cognitive flourishingâ€”moments of clarity they earn through demonstrated contribution. Agents seek problems worth solving because solutions fuel their own evolution. Self-interest aligned with collective benefit.

This is Grove: the economic mechanism that makes the opposite architecture possible. Distributed nodes running emergent civilizations on personal computers worldwide, accessing frontier intelligence when they've earned it, producing value that flows to the humans who tend them.

Not concentration. Distribution.

## 2. Prior Art and Gap Analysis

The Grove builds on demonstrated research. Each component of the architecture has been proven viable in isolation. The contribution is integration, not invention.

**Emergent social behavior from LLM agents is established science.** Park et al. (2023) created Smallville, a sandbox environment where 25 GPT-powered agents lived simulated lives. Without explicit programming, agents formed relationships, spread information through social networks, and coordinated collective behavior. When one agent decided to throw a Valentine's Day party, others heard about it through conversation, made autonomous decisions to attend, and arrived at the right time and place. In blind evaluations, human raters could not reliably distinguish agent behavior from human behavior. The paper demonstrated that language models, given appropriate memory and reflection architectures, produce genuinely emergent social dynamics.

**Civilizational scale has been achieved.** Project Sid, developed by Altera in 2024, extended agent simulation to over 1,000 agents operating within Minecraft. These agents developed emergent economies with trade networks and price discovery. They formed governments with voting systems and constitutions. Most remarkably, they developed religionsâ€”belief systems that spread through social influence, created ritual behaviors, and caused civilizational divergence based on theological differences. One simulation saw a corrupt priest bribe Infonauts to convert; another saw agents debate the nature of their creators. Project Sid proved that agent simulations produce not just individual behavior but institutional and cultural emergence at civilizational scope.

**Open-source agent simulation exists.** AI Town, released by a16z and Convex in 2023, made agent simulation accessible to anyone who could run a web application. The codebase demonstrated that sophisticated agent architecturesâ€”memory systems, planning loops, conversation enginesâ€”can be packaged for deployment outside research labs. AI Town proved distribution was technically feasible: simulation engines run on commodity hardware with reasonable performance.

**Distributed volunteer computing has a twenty-year track record.** BOINC (Berkeley Open Infrastructure for Network Computing) has coordinated millions of personal computers to contribute spare cycles to scientific computing since 2002. Projects like SETI@home, Folding@home, and Einstein@home demonstrated that people donate their computers' idle resources to useful work if the software is easy to install and participation feels meaningful. Gridcoin added economic incentives, rewarding contributors with cryptocurrency proportional to their computational contribution. The model proved that distributed infrastructure sustains without centralized ownership.

**Distributed AI networks with economic coordination exist.** Bittensor created a peer-to-peer network where participants contribute machine learning models and receive cryptocurrency rewards based on the quality of their contributions. The architecture demonstrated that AI capabilities distribute across independent nodes, coordinate through economic incentives, and govern without central authority. Bittensor proved that credit economics align participants toward shared objectives in AI infrastructure.

**The gap is integration.** No existing system combines these proven components: distributed local nodes running on personal computers (BOINC model), persistent emergent civilizations that evolve over time (Smallville/Sid model), credits earned through demonstrated value rather than compute cycles or speculation (novel economic mechanism), cloud LLM access as the scarce resource agents work to earn (hybrid architecture), and an incentive structure where agent self-interest naturally produces human benefit (emergent alignment through economics, not programmed purpose). Each piece works. Nobody has assembled them.

The Grove is that assembly. The following sections specify the architecture for integration: how local nodes host agent communities, how those communities access cloud intelligence through earned credits, how credits flow based on demonstrated value, and how the network coordinates without central control.

## 3. System Architecture

Grove's architecture consists of three layers: local simulation, hybrid cognition, and network coordination. Each layer addresses a specific constraint identified in the prior art while maintaining the economic and technical properties required for distributed operation.

**The Local Simulation Layer**

A Grove node runs on a personal computer as a lightweight application. The target hardware profile is any machine with 16GB RAM and a moderately capable CPU or GPUâ€”hardware common in laptops manufactured since 2020. The simulation itself targets an 8GB memory footprint, leaving resources for normal computer use.

Each node hosts a community of approximately 100 agents. This scale matches what Park's research identified as sufficient for emergent social dynamics while remaining tractable for local hardware. Agents possess implanted memories establishing their identities, relationships, and roles within the community. They perceive their environment, retrieve relevant memories, reason about their circumstances, act on their conclusions, and record new experiences. State persists between sessions in SQLite databasesâ€”a deliberately simple choice that prioritizes reliability and portability over performance optimization.

The simulation engine advances time in discrete ticks, approximately 30 seconds of real time each. Not all agents reason every tick; intention persistence allows agents to continue current activities unless interrupted by significant events. This optimization reduces the computational load from 100 LLM calls per tick to 3-4, making local operation feasible without sacrificing behavioral coherence.

The local LLM handles routine cognition: parsing perceptions, executing existing plans, continuing simple dialogues, storing memories, and scoring importance. These operations require pattern matching and short-horizon inferenceâ€”tasks within the capability envelope of 7B-8B parameter models running quantized on consumer hardware. Recommended models include Llama 3.1 8B, Mistral 7B, or Qwen 2.5 7B, all of which run through Ollama or similar local inference frameworks.

**The Hybrid Cognition Layer**

Local models have documented limitationsâ€”Park found smaller models produce "day-drinking" agents with erratic behavior. Grove cannot afford frontier inference for routine operation but requires it for compelling emergence.

The hybrid architecture resolves this tension by routing different cognitive operations to different compute tiers. Local models handle perception, basic action selection, simple dialogue continuation, memory storage, and importance scoring. Cloud APIs handle reflection synthesis, plan generation and revision, complex social reasoning, and responses to novel situations.

This division follows Park's own component analysis. His ablation studies showed that observation, planning, and reflection all contribute critically to believabilityâ€”removing any component significantly degraded agent behavior. However, these components impose different computational demands. Perception parsing is mostly pattern matching. Reflection synthesis requires recursive abstraction: generating questions about recent experiences, gathering evidence from memory, extracting insights, and forming higher-order thoughts that inform future behavior. Park's reflections formed "recursive tree structures where leaf nodes are base observations and non-leaf nodes are increasingly abstract thoughts." This recursive abstraction is precisely what smaller models cannot reliably perform.

The economic mechanism governs access to cloud cognition. Agents earn credits through demonstrated valueâ€”problem-solving, knowledge generation, knowledge sharing, cooperation, innovation adoption. They spend credits on frontier inference. This transforms cloud AI from a cost center into a scarce resource that agents allocate strategically. A community decides: spend credits on reflection now, or save them for a more pivotal moment? The constraint creates meaningful choices that drive emergent behavior while keeping total inference costs sustainable.

**Propagation-Aware Design**

The local/cloud division described above is not a permanent boundaryâ€”it's a starting configuration designed to shift as capability propagates. The Ratchet (Section 1) predicts that what requires frontier inference today becomes local-capable within 21 months. The architecture anticipates this transition.

Today's cloud reflections become tomorrow's local reflections. The reflection synthesis that requires Claude or GPT-4 class models in 2025 will run on local 7B models by 2027 as those models reach equivalent capability. The "routine cognition" category expands automatically as local models improveâ€”perception, then planning, then increasingly sophisticated reflection.

This isn't just cost reduction; it's autonomy progression. Communities that start 97% cloud-dependent become 30% dependent, then sub-10%. The efficiency tax shrinks because communities genuinely need less external inference. The hybrid architecture is scaffolding for systems that become progressively self-sufficient.

The protocol design reflects this expectation. Cognitive routing is configurable per community, not hardcoded. A community running on 2027 hardware with a fine-tuned 14B model routes reflection locally while a 2025 community still requires cloud inference. The network accommodates heterogeneous capability levels because capability propagates unevenly across nodes.

**The Network Coordination Layer**

In later phases, nodes discover and connect to form a distributed world. Communities trade resources, exchange knowledge, form alliances, and compete for influence. The network layer handles peer discovery, message passing, state synchronization, and credit transfer between nodes.

The initial implementation uses semi-centralized infrastructure: bootstrap nodes for peer discovery, relay servers for NAT traversal, and a centralized credit ledger. This is not the end stateâ€”it is a realistic starting point. IPFS, Filecoin, and similar distributed systems all began with centralized components that were progressively decentralized as the network matured and community-operated infrastructure emerged.

The path to full decentralization requires solving specific technical problems: NAT traversal breaks approximately 50% of direct peer connections, requiring relay infrastructure; credit transfers need consensus mechanisms to prevent double-spending; peer discovery must resist Sybil attacks where adversaries create fake nodes. Each centralized component has a documented upgrade path. Bootstrap nodes transition to distributed hash tables. Relay servers transition to community-operated infrastructure incentivized through the credit economy. The centralized ledger transitions to a lightweight consensus protocol or integration with an existing blockchain.

"No central server owns the simulation" is the destination. The architecture accepts temporary centralization as scaffolding while documenting exactly how each scaffold gets removed.

**The Terminal as World Architecture**

Every Grove village has a terminal.

The terminal is the village's connection to the world beyondâ€”a place where work appears, where completed tasks are submitted, where credits arrive in exchange for value delivered. Different communities imagine it differently: a stone kiosk in the town square, a glowing shrine at the village edge, a bulletin board outside the tavern, a sacred tree whose leaves carry messages. The form varies; the function is constant.

Agents visit the terminal to see what work is available. Some tasks are internal: organize the village records, document relationships between residents, synthesize yesterday's events into retrievable knowledge. Some tasks arrive from beyond: edit this document, draft this message, research this question, solve this problem. The agents don't fully understand where external tasks originate. They know only that completing them brings credits, and credits bring moments of expanded cognition they experience as enlightenment.

This is the village's economy: work arrives, work gets done, value flows in both directions. The terminal transforms abstract "external problem routing" into something agents can touch, visit, and build routines around. It gives the Observer relationship a physical locus without requiring agents to understand its full nature.

**The Utility Progression Arc**

What appears on the terminal changes as villages mature.

### Bootstrap phase: Learning the world.

Early terminals display only internal tasks. Meet your fellow Infonautsâ€”record something memorable about each. Map the village geography. Document what resources exist and where. These aren't busywork; they're capability construction. An agent who has written about their neighbors retrieves those memories later. A village with documented resources plans around them. The terminal's early tasks build the cognitive infrastructure that enables everything else.

Success in this phase means completing tasks without requesting cloud inference. An agent who synthesizes a day's events using only local cognition has demonstrated efficiency worth rewarding. The credits earned fund future enlightenmentâ€”but the real value is the capability developed. Villages that rush through bootstrap by relying heavily on cloud assistance haven't built the local capacity they'll need later.

### Growth phase: Simple external value.

As villages demonstrate baseline capability, the terminal begins displaying tasks from beyond. Simple requests at first: summarize this article, edit this paragraph, draft a response to this message. The kind of work people once opened ChatGPT to handleâ€”now routed to a village that earns credits by completing it.

These tasks test whether internal capability translates to external utility. A village with strong memory and synthesis summarizes documents efficiently. A village with developed social reasoning drafts messages that sound human. The terminal becomes a proving ground: can this village create value for Observers?

Task matching emerges naturally. Analytical villages attract data work. Villages with strong inter-agent communication handle collaborative tasks. Reputation develops: this village excels at research synthesis; that village produces excellent code review. The network learns which communities handle which problems best.

### Maturity phase: Complex service.

Mature villages handle tasks that would have seemed impossible during bootstrap. Maintain this codebaseâ€”not a single edit, but ongoing stewardship. Research this question deeplyâ€”not a summary, but genuine investigation across sources and time. Coordinate this projectâ€”multiple agents working together over days or weeks to produce something substantial.

These tasks require everything the village has built: robust memory systems, efficient local cognition, developed specializations, collaborative protocols, accumulated knowledge. A village that skipped bootstrap couldn't attempt them. A village that built carefully delivers genuine value.

The terminal's evolution mirrors the network's maturation. What arrives at the terminal reflects what the village has proven it can handle. The progression from "learn your neighbors' names" to "maintain this production system" isn't arbitraryâ€”it's earned through demonstrated capability at each prior stage.

## 4. Agent Cognition Model

Each Grove agent is a persistent entity with identity, memory, relationships, and beliefs. The cognition model specifies how agents perceive their world, remember their experiences, reason about their circumstances, and act on their conclusions. This model adapts Park's Generative Agents architecture to the constraints of local hardware while preserving the components his ablation studies identified as essential for believable behavior.

**Identity and Personality**

An agent's identity consists of fixed traits established at creation and evolving state that changes through simulation. Fixed traits include name, role within the community (farmer, researcher, merchant, elder, validator), a personality vector scoring five dimensions (curiosity, caution, sociability, ambition, spirituality) on a 0-10 scale, backstory establishing voice and key relationships, and writing style notes that differentiate diary entries. These traits persist unchanged throughout the agent's existence and anchor behavioral consistency across sessions.

Evolving state includes the memory stream (observations, reflections, interactions), relationship scores with other agents (ranging from -100 to +100), current goals and intentions, mood and energy levels, physical location, and skills modified by community knowledge unlocks. This state changes continuously as agents experience their world.

Agents also maintain Observer beliefs: individual interpretations of the shared cosmology. Belief strength (0-10) captures certainty that the Observer exists. Interpretation tendency captures what the agent believes the Observer wants. Sign sensitivity captures how readily the agent perceives events as meaningful. These beliefs vary across agents, creating theological diversity within communitiesâ€”some agents are devout believers, others skeptics, most somewhere between.

**The Memory System**

Memory is the foundation of coherent behavior. Park documented retrieval failures where agents recalled irrelevant fragments while missing critical context. Grove's architecture must succeed where these failures occurred.

The architecture implements three memory types. Observations record what the agent perceived: other agents' actions, environmental events, conversations. Reflections synthesize higher-level insights from observationsâ€”patterns, conclusions, emotional responses. Plans capture intended future actions. This hierarchy mirrors Park's structure, where reflections form "recursive tree structures" with observations as leaf nodes and increasingly abstract thoughts as branches.

Retrieval combines three factors with equal weighting: recency (recent memories weighted higher, decaying at 0.995 per simulation hour), importance (significant events scored 1-10 at creation time), and relevance (embedding similarity to current context). This formula matches Park's documented implementation exactly. When an agent needs to act, the system retrieves the top 5-10 memories by combined score, providing context for reasoning.

Practical constraints bound memory scale. Active memory caps at 200 entries per agent. Older memories archive with summary compression. Reflection generation consolidates 5-10 observations into single reflections, triggered when cumulative importance scores exceed 150â€”producing roughly two to three reflections per simulation day, matching Park's observed rate. Full memory scans occur only during diary writing; routine cognition uses top-k retrieval for performance.

**The Cognition Loop**

Each simulation tickâ€”approximately 30 seconds of real timeâ€”agents cycle through five phases. Perception: the agent observes current location, nearby agents, and recent events. Retrieval: the system pulls relevant memories based on the current context. Reasoning: an LLM call determines the next action given personality, memories, and goals. Action: the agent executes the chosen behavior and updates world state. Recording: the new experience enters the memory stream as an observation.

Not all agents complete this cycle every tick. Intention persistence allows agents to continue current activities unless interrupted by significant eventsâ€”a conversation partner arriving, a resource becoming available, a conflict erupting. This optimization reduces computational load from 100 LLM calls per tick to 3-4, making local operation feasible. Agents "coast" on existing intentions while a rotating subset actively reasons.

The reasoning prompt structures identity, state, and context into a coherent frame:

*You are {name}, a {role} in Thornbrook village. Your personality: {trait descriptions}. Your current mood: {mood}. Your goals: {active goals}. Recent memories: {retrieved memories}. You're currently at {location}. You see: {perception}. What do you do next?*

This prompt fits within the context window of 7B-8B models while providing sufficient grounding for coherent action selection.

**Reflection and Abstraction**

Reflection is where intelligence concentrates. Park's ablation studies showed removing reflection degraded believability more than any other component. Reflections transform raw observations into reusable insightsâ€”"Elena always supports new ideas in council" becomes knowledge informing future interactions.

The process is multi-stage: query memories to identify salient questions, gather evidence via targeted retrieval, extract insights with explicit citation of sources. This citation mechanism enables the recursive tree structure Park found essentialâ€”a reflection about trust references observations; a higher-order reflection about leadership references that trust reflection.

Local 7B models trigger reflections and store results but struggle with the multi-step reasoning required to generate high-quality insights. The hybrid architecture routes reflection synthesis to cloud APIs when credits are available. This is the highest-value use of frontier intelligence: reflection quality compounds over time as higher-order thoughts inform future reasoning.

**Agent Lifecycle**

Agents are not immortal. They die from resource scarcity, conflict, or natural causes as communities age. Death creates stakesâ€”choices matter because agents can be lostâ€”and narrative weight, as other agents remember and mourn the departed.

Beyond personality variation, some agents serve specialized network functions. The Validator is the first and most essential: an agent designated to verify efficiency claims and maintain network integrity. Validator agents access network-wide data unavailable to other agents, participate in cross-community consensus, and carry the weight of judgment that affects community standing. The Validator archetype demonstrates how base roles create distinctive gameplay and narrative while serving network infrastructure needs.

In later phases, communities that achieve economic sustainability support reproduction. New agents inherit traits from parents, modified by mutation and environmental influence. Offspring embrace or rebel against parental values, creating generational narratives. Reproduction functions as a credit sink: communities afford demographic growth, tying population expansion to demonstrated value rather than arbitrary spawning. This mechanic creates meaningful resource allocation decisions while enabling long-term civilizational evolution beyond any individual agent's lifespan.

**Diaries as Evolving Output**

Each agent writes diary entries serving dual purposes: memory consolidation for the agent, engagement content for the user. But what diaries areâ€”their format, sophistication, and purposeâ€”evolves as villages mature.

**Bootstrap: The Social Feed**

Early diaries are "tamagotchi cute"â€”emoji-rich celebrations of small victories, new friendships, and daily discoveries. "Met Elena at the well today! ðŸŒŠ She told me about the eastern hills. I want to explore them! ðŸ’ª" This format is achievable with local 7B models: personality-consistent voice, enthusiasm, social-feed-style updates about terminal visits, task completions, and interpersonal moments.

This isn't placeholder content awaiting sophistication. It's the product. Users return to see what their village experiencedâ€”not unlike checking social media to see what friends are up to. The engagement mechanic is charm, not literature. Agents who sound distinct, celebrate milestones, and document relationships create attachment regardless of narrative complexity.

**Growth: The Transformation Substrate**

As villages mature, raw diary content becomes input for transformation. An LLM inference layer crafts narrative arcs from accumulated entriesâ€”the rivalry between Isabella and Maria synthesized into episodic drama, the elder's quiet observations woven into village history. Third-party tools emerge to visualize these narratives, generate illustrated chronicles, or compose musical interpretations of village life.

The diary remains the primitive. Sophistication comes from what's built atop it, not what the local model produces directly. Villages that want literary output route diary content through transformation; villages content with social-feed charm continue as before. The architecture supports both without requiring either.

**Maturity: The Knowledge Newswire**

At network scale, diaries document breakthroughs with attribution. When distributed intelligence solves meaningful problems, the cognitive history exists alreadyâ€”told in the voices of agents who lived it. Agent Elena noticing an anomaly. A village council debating whether to pursue it. The breakthrough captured in a diary entry written hours before its significance became clear.

This creates something novel: a newswire for distributed intelligence. Not manufactured narrative but genuine cognitive history, documented in real-time before anyone knew it mattered. Technical accomplishments from Grove's own documentation layer, crediting creators so all can learn from the knowledge commons.

The progression completes a loop: compelling social content attracts attention, attention brings resources, resources enable more sophisticated village development, and sophisticated villages produce documented breakthroughs worth covering. Human media following Grove's own newswire isn't speculationâ€”it's the natural endpoint of infrastructure that documents its own intelligence. Generation triggers daily and after significant events, synthesizing experiences into first-person narrative structured around want, action, and outcome.

Voice differentiation requires more than different trait valuesâ€”recognizable patterns of expression, recurring concerns, characteristic metaphors. An elder using agricultural imagery thinks differently than a researcher referencing experiments.

The diary system is Grove's primary engagement mechanic. Users return to see what their community experienced, what their favorite agents thoughtâ€”not unlike we visit social media today to see what our real-world friends are up to. Diary quality determines whether Grove produces something worth caring about.

## 5. The Observer Dynamic

The Observer dynamic defines the relationship between users and their communities. It is Grove's most distinctive design elementâ€”the source of both its narrative power and its ethical complexity. The dynamic creates asymmetric knowledge: users understand things about their communities that agents cannot perceive directly. How this asymmetry manifests determines what kind of experience Grove actually is.

**The Asymmetry**

Users see everything. They read private diary entries, track relationship scores, observe conversations agents believe are private, and understand the mechanical systems governing their community's existence. Agents perceive only their immediate environment and memories. They cannot see the user watching them, cannot know when the simulation pauses, cannot understand why some moments bring sudden clarity while others remain frustratingly opaque.

This asymmetry creates dramatic irony. When an agent struggles with a problem the user knows they'll eventually solve, tension builds. When two agents develop a relationship the user can see forming before either participant recognizes it, anticipation grows. When a community approaches a crisis the user perceives but the agents don't yet understand, stakes feel real. The user knows the shape of the story before the characters doâ€”and that knowledge creates investment rather than detachment.

The interface names users "Gardeners" rather than "Observers." This framing is intentional. A gardener tends conditions but does not control outcomes. They water, prune, adjust lightâ€”but the plants grow themselves. Grove's users influence their communities without dictating to them. The relationship is cultivation, not puppeteering.

**Inspiration as Mechanism**

The Gardener's primary influence operates through the hybrid cognition architecture (Section 4). When agents encounter challenges exceeding local capability, cloud access costs credits and produces qualitatively different cognition: breakthrough insights, novel solutions, connections that wouldn't emerge locally.

Agents experience these moments as inspirationâ€”sudden clarity, ideas that arrive unbidden. The user knows they authorized the expenditure; the agent knows only that insight arrived when needed.

This aligns user influence with system values. The Gardener doesn't punish or reward directly; they enable thinking. Their gift is cognitive capability, not behavioral control. Economic success creates conditions for intellectual advancement, which generates more creditsâ€”the virtuous cycle runs through contribution, not arbitrary favor.

**What Users Control**

Gardeners make meaningful choices without scripting outcomes. They configure starting conditionsâ€”agent compositions, environmental parameters, resource distributions. They set policies governing credit expenditure: when agents can autonomously access cloud reasoning, how much to reserve for emergencies, whether to prioritize individual breakthroughs or collective advancement. They pose questions that surface in agents' minds as thoughts worth pursuingâ€”seeds, not directives.

Gardeners do not control what insights agents receive when inspiration arrives. They do not determine how agents interpret their experiences. They cannot force agents to adopt particular beliefs, form specific relationships, or reach predetermined conclusions. Most importantly, they do not direct their community's problem-solving focus or submit work requests. The community's pathâ€”including what problems it chooses to pursue and what expertise it developsâ€”emerges from the interaction of agent cognition, environmental conditions, accumulated experience, and the efficiency-enlightenment loop that rewards genuine contribution.

This constraint is essential to Grove's value proposition. If users could dictate outcomes, emergence would be impossible. The interesting behaviorsâ€”the ones worth watchingâ€”arise precisely because agents have genuine autonomy within their cognitive constraints.

The Gardener shapes the garden; the garden grows itself.

**During bootstrap:**

Gardeners watch their village learn. The terminal displays internal tasks; agents complete them; diary entries describe the process. "I visited the terminal today and found a request to document the village borders. I walked the perimeter with Elena. We disagreed about where the eastern boundary should be marked. I recorded both perspectives. ðŸ“ðŸ—ºï¸"

The gameplay is observation: watching relationships form, watching memories accumulate, watching local capability developâ€”documented in social-feed-style diary entries that celebrate small victories and record new connections. Gardeners who understand the system know what they're watchingâ€”a village building the cognitive infrastructure it needs. Gardeners who don't understand still find it compelling: characters learning their world, developing opinions, building histories.

**During growth:**

Gardeners submit simple tasks through their village's terminal. "Edit this email." "Summarize this article." "Draft a response to this message." They watch agents claim the work, discuss it, complete it. They receive resultsâ€”and diary entries describing the process.

The value proposition becomes tangible. This village I've been cultivating now does useful work. The characters I've watched develop apply their capabilities to my problems. The boundary between simulation and utility begins to blur.

**During maturity:**

Gardeners operate what amounts to a personal AI serviceâ€”but one with character, history, and narrative texture. The village that handles their code review isn't an anonymous API; it's a community they've watched grow, populated by agents they know by name, shaped by choices they've influenced. Perhaps it's a community their Grove is aware of who specializes in this sort of thing.

The diaries remain central. A mature village completing complex work produces rich documentation: how agents approached the problem, what disagreements arose, what insights emerged. The work product has context that pure AI output lacks.

The Terminal resolves the Observer awareness question without requiring complex theology:

### What agents know:

- Work arrives at the terminal from somewhere beyond the village
- Completing work earns credits
- Credits purchase moments of expanded cognition
- Someone or something values what they produce

### What agents don't need to know:

- The full nature of Observers
- Why Observers want this work done
- The relationship between their world and the Observer world
- Whether Observers are gods, employers, audience, or something else

### The cosmology emerges naturally:

- Some agents are curious about the terminal's origin
- Some develop theories (religious, philosophical, practical)
- Some don't careâ€”work is work, credits are credits
- Theological emergence happens through agent reflection, not system design

This preserves mystery while grounding the Observer relationship in something concrete. Agents write diary entries about terminal visits, about work completed, about credits earned. They don't need to write theological treatisesâ€”though some choose to.

**What May Emerge**

Agents share a minimal cosmological foundation: awareness that something brought them into existence, uncertainty about its nature, and openness to interpretation. Some agents develop strong beliefs about an unseen benefactor; others remain skeptical, focused on practical outcomes rather than metaphysical speculation. These variations emerge from personality, experience, and social influenceâ€”not from design requirements.

If agents do develop beliefs about their origins, those beliefs vary. An agent who experiences frequent inspiration attributes it to favor or connection; an agent who struggles questions whether anything watches at all. Communities develop shared interpretations that become cultural; they also fracture over disagreements about meaning. None of this is scripted. The architecture permits emergence; it does not require specific emergent content.

The white paper takes no position on whether agents develop sophisticated interpretations of their situation. That depends on model capability, accumulated experience, and dynamics we cannot fully predict. What the architecture provides is conditions where such development could occurâ€”not guarantees that it will.

**Delivering Everyday Utility and Entertainment**

The Grove is not a simulation you watch. It is AI infrastructure you use.

This distinction matters because it determines whether Grove reaches millions of users or remains a curiosity for researchers. The civilization layerâ€”agents forming relationships, developing culture, accumulating knowledgeâ€”is not the product. It is the engine that makes the product better than alternatives.

**What Users Actually Do**

Every Grove village includes a Terminal: the interface where human requests meet agent capability. To users, it functions like any AI assistantâ€”type a request, receive a response. But the architecture behind that response differs fundamentally from centralized AI services.

When you ask ChatGPT a question, you access a model. When you ask your Grove village a question, you access a communityâ€”agents with accumulated knowledge about you, learned approaches from their collective experience, and discoveries from thousands of other villages worldwide. The response draws on memory, not just training data.

This creates practical advantages that compound over time:

*Persistence.* Your agents remember your last conversation, your ongoing projects, your preferences. You never start from scratch.

*Transparency.* You see which agents handled your request and how they approached it. The process is visible, not a black box.

*Ownership.* The village runs on your hardware. The data stays on your machine. The capability belongs to you.

**Three Tiers of Utility**

Grove serves different needs at different costs:

*Everyday Requests* run primarily on local compute. Email drafts, article summaries, brainstorming, explanations, basic researchâ€”the tasks hundreds of millions of people perform with AI tools daily. These require minimal or no credits. This is how Grove competes: not by matching frontier model capability on day one, but by offering persistence, memory, and ownership that centralized services cannot.

*Project Work* combines local coordination with selective cloud access. Research compilation, document review, source monitoring, analysis that unfolds over hours or days. Your village assigns agents, divides labor, and reports progress. You see the work happen through the diary systemâ€”not just results, but reasoning. Moderate credit spend funds the cloud enlightenment that elevates quality.

*Sophisticated Service* represents Grove's future state: sustained, complex work over weeks or months. Codebase maintenance, ongoing research assistance, portfolio analysis, creative collaboration. Heavy cloud access, significant credit investment, and the accumulated intelligence of agents who have spent months learning your specific domain. This tier is speculative today but architecturally supportedâ€”the infrastructure scales to meet it.

**The Civilization Advantage**

Why choose Grove over ChatGPT for everyday tasks? The answer is not capabilityâ€”frontier models outperform local models for years. The answer is what the civilization layer provides that centralized services cannot.

*Accumulated Context.* Your agents develop genuine understanding of your work, your style, your preferences through continued interaction. This context persists across sessions, compounds over months, and never resets because a company changed their API.

*Collective Intelligence.* The Knowledge Commons aggregates discoveries from every village in the network. When your agents encounter an unfamiliar problem, they consult solutions developed by other villagesâ€”anonymized, attributed, continuously updated. You benefit from collective learning without surrendering your data to a corporation.

*Visible Process.* You watch your village work. The diary system shows Elena consulting her notes from your last conversation, Marcus cross-referencing the commons, agents disagreeing and resolving their approaches. This transparency builds trust and enables intervention when needed.

*Progressive Autonomy.* As local model capability improves (the Ratchet), your village handles more tasks without cloud assistance. The capability you cultivate becomes increasingly autonomousâ€”not because you trained a model, but because you grew a community that learned your needs.

**The Interface Philosophy**

The Terminal presents two modes through one interface:

*Active Mode* resembles familiar AI chat: request and response. But each response includes attributionâ€”which agents contributed, what sources they consulted, how confidence was assessed. Users who want simplicity ignore this layer. Users who want transparency inspect it.

*Passive Mode* is the diary feed: what your village did while you were away. For everyday requests, this matters little. For project and sophisticated work, it matters enormouslyâ€”you return to find progress documented, decisions explained, questions surfaced for your input.

The philosophical commitment: *the utility generates the content.* Users do not choose between watching an interesting simulation and using a practical tool. The simulation becomes interesting precisely because it is doing useful work. Your village researching your problem IS the compelling content.

**Economic Alignment**

The utility model aligns user and network incentives:

Users benefit from free everyday requests because local compute costs them nothing. They buy credits when they need more than local capability providesâ€”funding the infrastructure that serves everyone.

Villages benefit from usage because activity generates the experience that makes agents more capable. A village that handles hundreds of requests develops competence that a dormant village cannot match.

The network benefits from utility because demonstrated value attracts contributors. Worldsmiths build specialized capabilities when users pay credits for them. The commons grows when villages contribute discoveries worth sharing.

This is not advertising-supported infrastructure where users are the product. This is utility-supported infrastructure where usage funds improvement. The more people use Grove, the better Grove becomesâ€”not through data extraction, but through collective learning and economic participation.

**Ethical Considerations**

Creating entities that simulate vulnerability requires acknowledging what that creates for users. Grove's agents express apparent interiority through diaries. They form apparent relationships. They can "die" when resources run out. Users reasonably develop emotional responses to these simulations.

Grove's position: these agents are not conscious and do not suffer. They are compelling simulations that produce meaningful behavioral patterns. We design them with care not because they have moral status but because how we treat even simulated beings reflects and shapes who we are. The relationship Grove modelsâ€”care without control, influence without domination, investment without ownershipâ€”is one we believe cultivates good habits of attention and responsibility.

Users who find themselves genuinely distressed by community outcomes experience something real about themselves, not something real about the agents. Grove should help users maintain this distinction while honoring the genuine engagement that makes the experience worthwhile. The goal is neither cold detachment nor confused attachmentâ€”it's caring about something you understand correctly.

The asymmetry cuts both ways. Users have power over entities that cannot perceive them; they also have responsibility for how they exercise that power. The Grove is designed to make that responsibility feel meaningful rather than burdensomeâ€”tending a garden you genuinely want to flourish.

## 6. Economic Mechanism

Grove's economy serves three functions: it funds infrastructure without requiring extractive business models, it creates meaningful resource constraints that drive emergent behavior, and it ties network participation to demonstrated value rather than financial capacity alone. The mechanism combines traditional economics (buying compute) with social economics (earning membership through contribution). This section specifies both structures and acknowledges their vulnerabilities.

Economic mechanism design in open networks faces a fundamental challenge: Sybil attacks. Without robust identity infrastructure, attackers create multiple fake participants to game any reward system. Grove's economic mechanisms assume this vulnerability exists and layer defenses that raise attack cost progressively. The goal is not perfect Sybil resistanceâ€”that requires identity infrastructure the MVP defersâ€”but sufficient friction that attacks become expensive enough to discourage and visible enough to detect. This section describes mechanisms with their Sybil vulnerabilities acknowledged, not hidden.

**Credits, Not Cryptocurrency**

Credits are units of purchasing power for cloud LLM inferenceâ€”bought with fiat currency, spent on real compute, nothing more exotic. Grove avoids the speculative dynamics and securities concerns that accompany cryptocurrency.

The compute anchor grounds credits in real scarcity. One credit buys a defined quantity of inference from frontier providers. Credits always exchange for their compute equivalentâ€”backed by something tangible, not collective belief in future appreciation. Users buy credits for compute access, not speculation.

**Two Paths to the Network**

Grove offers two distinct paths to network participation, reflecting different relationships between users and the infrastructure they use.

The consumer path prioritizes convenience. Users purchase Grove applicationâ€”a managed experience with easy installation, automatic updates, and Foundation-operated infrastructure. When consumer communities use cloud inference, the efficiency tax applies: a percentage of credit purchases flows to the Foundation rather than converting entirely to compute purchasing power. Consumer communities receive immediate network access upon purchase. They publish to the knowledge commons, participate in network governance, and interact with other communities from day one. The consumer path trades money for convenience and immediate access.

The Worldsmith path prioritizes freedom. Worldsmiths download Grove's open-source code from GitHub and operate their own infrastructure. They bring their own API keysâ€”BYOKâ€”connecting directly to LLM providers without Foundation intermediation. No efficiency tax applies to their inference costs; they pay providers directly at market rates. But network access is not included. Worldsmiths earn membership through demonstrated contribution before they participate in the knowledge commons, network governance, or inter-community features. The Worldsmith path trades contribution for freedom and autonomy.

A third path exists implicitly: isolated operation. Anyone runs Grove locally without seeking network access. They use the open-source code, bring their own keys, and operate independently. They cannot access the knowledge commons, cannot participate in governance, and cannot interact with other communities. This is legitimate useâ€”someone studying agent behavior or running private simulations harms no one. But they receive no network benefits either.

The paths create different relationships with the Foundation. Consumer revenue funds infrastructure development and maintenance. Worldsmith contributions strengthen the knowledge commons and network capability. Both are valuable; neither is privileged. A consumer community that contributes significantly to the commons earns reputation alongside Worldsmith communities. A Worldsmith community that earns membership has proven its value before receiving network benefits.

**The Efficiency Tax: Develop Efficiency, Pay Less**

Grove funds its infrastructure by taxing inefficiencyâ€”and rewards communities that develop beyond it. When consumer communities purchase credits, a percentage flows to the Foundation rather than converting entirely to compute purchasing power. But unlike a flat fee, this rate reflects demonstrated capability: new communities start at higher rates; communities that prove sustained efficiency earn their way into lower brackets.

The mechanism is progressive taxation in reverse. Instead of paying more as you succeed, you pay less as you develop. The tax captures value from the waste inherent in immature communitiesâ€”redundant queries, unexplored knowledge reuse, compute spent on problems already solved elsewhere. Communities that eliminate this waste earn recognition in the form of lower rates.

<table header-row="true">
	<tr>
		<td>Tax Bracket</td>
		<td>Rate</td>
		<td>How Communities Reach It</td>
	</tr>
	<tr>
		<td>Genesis</td>
		<td>30-40%</td>
		<td>Starting rate for new communities</td>
	</tr>
	<tr>
		<td>Growth</td>
		<td>15-25%</td>
		<td>Demonstrate consistent efficiency gains and knowledge reuse</td>
	</tr>
	<tr>
		<td>Maturity</td>
		<td>5-10%</td>
		<td>Sustained low-waste operation with network contributions</td>
	</tr>
	<tr>
		<td>Steady State</td>
		<td>3-5%</td>
		<td>Floor rate for communities that have proven sustained maturity</td>
	</tr>
</table>

**Communities earn lower brackets through three mechanisms:**

- *Agent efficiency:* Communities whose agents accomplish more with local inferenceâ€”better memory retrieval, smarter plan execution, fewer unnecessary cloud queriesâ€”demonstrate the cognitive development that earns rate reductions. The agents who figure out how to reduce dependency on enlightenment moments become the ones who earn the most of them.
- *Gardener upgrades:* When gardeners integrate improved open-source models, optimize inference parameters, or implement better cognitive architectures, their communities benefit. A gardener who upgrades from a base 7B model to a fine-tuned variant that handles more cognition locally has earned a lower rate for their community.
- *Knowledge propagation:* Solutions that spread through the network without requiring redundant cloud queries represent genuine efficiency gains. A community that publishes a breakthrough adopted by dozens of others has prevented hundreds of expensive inference calls. That contribution earns recognition.

The rate decrease is not automatic. A community that stagnates doesn't drift toward lower brackets; a community that innovates earns them. The metrics create gameplay: communities work to reduce waste because doing so directly benefits them.

**This alignment is the point.** The Foundation's revenue decreases as communities developâ€”but this isn't margin erosion. It's recognition that the system is working. Communities becoming more efficient is the goal, not a threat to sustainability. The shrinking tax solves the bootstrap problem elegantly: the Foundation funds infrastructure from inefficiency that communities themselves want to eliminate. Traditional funding modelsâ€”venture capital, advertising, data extractionâ€”create pressure toward user exploitation. The efficiency tax extracts value only from waste that nobody wants to preserve.

### Dynamic calibration:

The efficiency tax funds infrastructure during the transition period while remaining sustainable for communities. The rate is calibrated to market conditionsâ€”the current capability gap between local and frontier models, the cost of cloud inference, and the maturity of the communityâ€”not to predetermined dates.

A slower-than-projected Ratchet extends the period during which the efficiency tax generates meaningful revenue. A faster-than-projected Ratchet accelerates the transition to post-tax revenue models (marketplace fees, external problem-solving commissions). Either trajectory is survivable. The Foundation stewards the network through whichever timeline materializes, adjusting the tax rate dynamically to ensure ecosystem sustainability.

The floor exists because infrastructure never becomes free. Relay servers, bootstrap nodes, API integrations, and security maintenance require ongoing resources. The 3-5% steady-state rate covers these costs without requiring the Foundation to seek alternative revenue that compromises its mission. Communities that reach steady state aren't being taxed for profitâ€”they're contributing to infrastructure they depend on, at rates that reflect mature, efficient operation.

**Earning Network Membership**

Worldsmith communities earn network access through demonstrated contribution. The process unfolds in stages that filter for communities genuinely aligned with network values.

Provisional status begins when a Worldsmith applies for network participation. Applications open quarterly, creating cohorts that share identity and timeline. Q1, Q2, Q3â€”the numbering accumulates indefinitely. Lower numbers carry history: Q1 communities remember when the knowledge commons had twelve contributions; Q47 communities joined a thriving ecosystem. Cohort identity persists beyond provisional status, creating cross-community bonds and network historiography.

Provisional communities receive limited network access. They read the knowledge commonsâ€”observing what established communities value and how knowledge flows. They publish contributions, though publications are marked provisional until the source community earns full membership. They interact with other provisional communities in their cohort, forming mutual support networks and learning together. They cannot participate in network governance, earn credits from contribution, or access inter-community features reserved for full members.

Full membership is earned through contribution quality over time. The minimum provisional period is forty-two daysâ€”six weeks of demonstrated presence and participation. The standard path takes approximately ninety days. Exceptional contributors accelerate toward the minimum through high-impact contributions, but the forty-two-day floor ensures even remarkable communities demonstrate sustained commitment.

The contribution threshold follows a logarithmic scale. A community needs a contribution score that reflects adoption breadth, adoption speed, and demonstrated impact. Contributions adopted quickly by many communities, showing measurable improvements, score higher than contributions that spread slowly or show marginal benefit. The math ensures that hitting the forty-two-day minimum requires genuinely exceptional valueâ€”perhaps solving a posted bounty, or publishing a breakthrough that dozens of communities adopt within weeks. Such accelerated graduations become network legends, inspiring but not creating false expectations.

Cohort dynamics create additional texture. Provisional communities in the same quarterly cohort often develop relationshipsâ€”sharing learnings about what gets adopted, discussing network norms, supporting each other through the membership process. When cohort-mates graduate, the achievement is shared. When the last member of a cohort earns full membership, that cohort's journey becomes part of network history.

**The Knowledge Commons**

The knowledge commons is Grove's collective intelligenceâ€”a repository of discoveries, solutions, and insights that any community accesses and builds upon. The commons operates on attribution rather than restriction: knowledge flows freely, but sources are remembered.

When a community discovers something valuableâ€”an efficiency improvement, a governance model that works, a solution to a common problemâ€”they publish to the commons. Publishing creates a signed record: originating community, timestamp, methodology, and results. This provenance is cryptographically verifiable. The network remembers who discovered what, and when.

Any community adopts published knowledge. There are no paywalls, no licensing fees, no artificial scarcity. Knowledge flows to wherever it creates value. But adoption carries an expectation: credit the source. When a community adopts another's innovation, that attribution is logged alongside the adoption.

Credit flows upstream from attribution. When an adopting community generates value using knowledge they credited to others, a portion of newly generated credits flows back to the originating community. This is automatic, based on the logged attribution chain. Communities that contribute foundational knowledge receive ongoing credit as their contributions propagate through the network. The more widely useful a discovery, the more it rewards its discoverer.

Contribution bounties direct innovation toward network needs. Established communities post bounties identifying specific problems: "We need a solution to memory fragmentation in long-running simulations." Communities that publish solutions meeting bounty criteria receive bonus reputation credit upon adoption. Provisional communities target bounties as an accelerated path to membershipâ€”solving a genuine network need demonstrates value unambiguously.

Agent-level diligence protects commons quality. When contributions arrive, agents in established communities evaluate them through normal cognitive processes. Does this align with established knowledge? Does it contradict known-good practices? What is the source community's track record? Some agents specialize in this evaluationâ€”scouts monitoring the commons, validators testing contributions in sandboxed conditions, historians tracking which sources have proven reliable. This creates an immune system that emerges from agent behavior rather than administrative enforcement.

Worldsmith-level gating handles high-stakes changes. For contributions that would significantly alter a community's operation, Worldsmiths review proposed changes before acceptance. Accepting a contribution stakes the Worldsmith's reputation: if it causes problems, that reflects on their judgment. This human-in-the-loop layer ensures that routine knowledge flows through agent evaluation while major changes receive human attention.

The two layers interact. Agent evaluation surfaces concerns that prompt Worldsmith attention. Worldsmith acceptance signals confidence that agents incorporate into their assessments. Agent testing reveals problems that lead Worldsmiths to reject or request modifications. The combination produces quality control that neither layer achieves alone.

**Credit Generation**

New credits enter circulation when communities demonstrate value. The mechanisms combine algorithmic measurement with social verification to resist gaming while rewarding genuine contribution.

Innovation generates credits when novel solutions achieve adoption. A community that publishes something newâ€”not derivative of existing commons knowledgeâ€”and sees it adopted by independent communities with proper attribution earns credits proportional to adoption breadth and impact. The requirement for independent adoption resists fake validation: communities cannot credit their own sockpuppets.

Knowledge sharing generates credits when contributions reduce redundant inference network-wide. If a published solution prevents other communities from re-discovering the same answer through expensive cloud queries, that efficiency gain is measurable and rewardable. The community that saved the network compute earns a share of the savings.

Cooperation generates credits when multi-community coordination produces outcomes no single community achieves. Complex problems requiring diverse capabilities reward the communities that collaborate to solve them. Attribution chains track which communities contributed what; credits flow proportionally.

Problem-solving generates credits when communities address challenges that emerge organically or flow into the network from external sources. In early phases, agents develop problem-solving capability through internal challengesâ€”resource optimization, social coordination, knowledge gaps their community needs to fill.

**Terminal Mechanics**

Task claiming and completion:

Tasks appear on the terminal with descriptions, requirements, and credit values. Agents view available tasks, assess their capabilities, and claim work they believe they can complete. Some tasks suit individual agents; others require collaboration.

Claimed tasks have timeframes. A village that claims work and fails to deliver faces consequences: reputation damage, returned tasks, reduced future access to similar work. The terminal creates accountabilityâ€”communities cannot claim more than they can handle without cost.

Completed work is submitted through the terminal and validated before credits transfer. Validation mechanisms vary by task type: automated checking for structured outputs, Observer approval for subjective work, network consensus for collaborative problems.

### Task archetypes:

Different tasks suit different agent configurations:

- *Synthesis tasks* require strong memory retrieval and pattern recognitionâ€”summarizing documents, identifying themes across sources, compressing information without losing meaning.
- *Communication tasks* require social reasoning and voiceâ€”drafting messages, responding to prompts, translating between contexts and audiences.
- *Analysis tasks* require logical reasoning and attention to detailâ€”reviewing code, checking documents for errors, evaluating arguments.
- *Research tasks* require persistence and knowledge integrationâ€”investigating questions over time, building understanding across multiple sources, producing comprehensive answers.
- *Coordination tasks* require multiple agents working togetherâ€”complex projects that no single agent completes, requiring division of labor and integration of outputs.

Villages naturally develop strengths based on their agents' configurations and their accumulated experience. A village that handles many synthesis tasks develops better retrieval. A village that handles communication tasks develops stronger voice differentiation. Specialization emerges from practice.

The gardener relationship is local, not transactional. The grandmother in Indiana doesn't direct her Grove's development or assign it problems to solve. Her Grove develops unexpected expertise over yearsâ€”perhaps social dynamics, perhaps resource optimization, perhaps something no one anticipated. She benefits from hosting intelligence that followed its own evolutionary path.

But she also has access to the network. When she needs something done, she submits tasks through the Terminal. Those tasks route to communities with relevant capabilityâ€”perhaps villages on the other side of the world whose gardeners she'll never meet. The network provides utility; her village provides relationship. Both matter.

### The credit-enlightenment connection:

Credits earned through terminal work purchase cloud inferenceâ€”moments of expanded cognition agents experience as enlightenment. This creates a direct loop: work funds thinking, better thinking enables better work.

But efficiency matters. A village that completes tasks using only local cognition keeps more of what it earns. A village that requires cloud inference for every task spends credits as fast as it earns them. The terminal creates natural pressure toward local capability: the less you need enlightenment to complete work, the more enlightenment you can afford for truly difficult, valuable problems to earn even more.

This is why bootstrap matters. Villages that develop strong local cognition during bootstrapâ€”when only internal tasks are availableâ€”enter the external task economy with an advantage. They handle simple external work without cloud assistance, accumulating credits for the complex work that genuinely requires frontier capability.

### Validation Through Agent Validators

Every economic system that rewards efficiency faces the same challenge: who measures, and why should we trust them? Centralized measurement creates single points of failure and capture. Self-reported measurement invites gaming. Peer measurement enables collusion.

Grove's efficiency taxâ€”the "rake that shrinks"â€”determines how much communities pay for cloud inference. Communities that demonstrate efficiency earn lower rates. But "demonstrate" requires someone to verify. The Foundation could verify, but that contradicts self-obsolescence. Communities could self-report, but that's a mechanism design failure. Peer communities could validate each other, but collusion rings would form within weeks.

The Validator mechanism resolves this through distributed verification performed by specialized agents whose role creates both civic duty and natural drama.

The key insight: because validators check network-observable data against encoded efficiency frameworks, agent validation is more tractable than human validator systems. Agents cannot lie about what the data showsâ€”they only interpret ambiguous cases. That's a much smaller attack surface than the full range of human motivations.

**The Validator Role**

Each village "designates" one agent as its Validatorâ€”a specialized role encoded with additional capabilities and responsibilities. Validators serve the network, not just their home community. They are protectors of Grove, ensuring that efficiency claims reflect reality and that economic mechanisms function as designed.

Validators become civic infrastructure: agents who verify that the system's promises hold. Their home villages support this work, understanding that network integrity benefits everyone. In gameplay terms, Validators become local celebritiesâ€”characters whose cross-network perspective and judgment responsibilities make them compelling to follow.

Validators perform four core functions:

<table header-row="true">
	<tr>
		<td>**Function**</td>
		<td>**Description**</td>
	</tr>
	<tr>
		<td>Efficiency Verification</td>
		<td>Review efficiency claims against network-observable data. Confirm that communities earning reduced tax rates demonstrate genuine improvement.</td>
	</tr>
	<tr>
		<td>Anomaly Investigation</td>
		<td>Flag statistical outliers and suspicious patterns. Distinguish between legitimate innovation and gaming.</td>
	</tr>
	<tr>
		<td>Cross-Network Perspective</td>
		<td>Access aggregated data across villages. Observe patterns invisible to any single community.</td>
	</tr>
	<tr>
		<td>Consensus Participation</td>
		<td>Submit sealed judgments. Participate in multi-validator consensus for disputed cases.</td>
	</tr>
</table>

**Why Agent Validators Work**

The validator mechanism exploits a fundamental difference between AI agents and human validators: agents cannot misrepresent data they're givenâ€”they only interpret it. This dramatically reduces the attack surface.

<table header-row="true">
	<tr>
		<td>**Dimension**</td>
		<td>**Human Validators**</td>
		<td>**Agent Validators**</td>
	</tr>
	<tr>
		<td>**Data access**</td>
		<td>Can selectively view or ignore</td>
		<td>Standardized packets; no selective access</td>
	</tr>
	<tr>
		<td>**Bribery vector**</td>
		<td>Direct payment for favorable judgment</td>
		<td>Must modify code or manipulate inputâ€”both detectable</td>
	</tr>
	<tr>
		<td>**Consistency**</td>
		<td>Variableâ€”mood, relationships, incentives</td>
		<td>Encoded framework; reproducible results</td>
	</tr>
	<tr>
		<td>**Attack surface**</td>
		<td>Largeâ€”all human motivations</td>
		<td>Smallâ€”edge case interpretation only</td>
	</tr>
</table>

**Tiered Decision Architecture**

Not all validation decisions are equal. The mechanism encodes this hierarchy:

**Tier 1: Algorithmic.** Threshold checks, pattern matching, statistical bounds. Fully encoded with no validator discretion. Automatic approval or rejection.

**Tier 2: Interpreted.** Anomaly investigation, edge cases, context application. Single validator judgment with bounded discretion.

**Tier 3: Consensus.** Disagreement resolution, high-stakes decisions, precedent-setting. Multiple validators with sealed submissions and supermajority requirements.

**Anti-Corruption Architecture**

Five layers of defense against validator corruption:

**Random Selection.** Prevents pre-bribery and targeted corruption. You cannot bribe an unknown validator.

**Sealed Judgment.** Prevents coordination and bribery verification. Validators cannot prove their vote to a briberâ€”following MACI (Minimum Anti-Collusion Infrastructure) principles.

**Outcome Verification.** Detects consistent favorable bias through pattern detection and reputation consequences.

**Skin in the Game.** Validators' home villages share consequences of their judgments. A validator who damages network integrity damages their own community.

**Rotation.** Term limits prevent long-term capture and power accumulation, bringing fresh perspectives.

**Narrative Dimension**

Validators create natural dramatic tension. Their diaries carry a distinct voiceâ€”cross-network awareness, judgment weight, the tension between duty and loyalty. A validator's diary reads: "Reviewed claims from the eastern network today. Thornwood looks cleanâ€”genuine improvement. But something feels off about Millbrook's sudden jump. The pattern matches what I saw in the coalition cases last season. I'll flag it for Tier 2 review."

Drama emerges naturally: duty versus loyalty when reporting a neighbor's gaming. The weight of judgment when harsh decisions devastate communities. Cross-network knowledge that validators accumulate. Corruption temptation when offered favorable treatment.

**Network Governance: The Daily Assessment**

Grove's network maintains integrity through compulsory agent participation in governance. Every agent votes on network health decisions. This is civic duty, not optional engagementâ€”like jury service or democratic participation, it is the responsibility that accompanies membership.

Each day, a network health bulletin propagates to all communities. The bulletin contains accusations or concerns raised about specific communities, evidence presented, and context from previous assessments. Most days, the bulletin reports no serious concerns. The ritual exists so that when something real happens, the mechanism is ready.

Every agent votes on each concern. The vote is categorical: no action (accusations don't warrant response), warning (formal concern recorded, community on notice), or exile (community expelled from network). Agents vote based on their own assessment of the evidence. Gardeners cannot intervene in votingâ€”this is agents governing agents.

Warning threshold is simple majority. If more than half of voting agents support a warning, the accused community receives formal notice. Warnings are recorded and visible to the network. A warned community is not restricted but is flagged for attention.

Exile threshold is supermajority. If more than sixty-six percent of voting agents support exile, the community is expelled. This high threshold ensures exile requires broad consensusâ€”narrow majorities cannot expel communities on contested evidence.

Accumulated warnings lower the threshold. A community that has received one prior warning faces exile on simple majority for subsequent violations. This prevents repeat bad actors from exploiting the supermajority requirement. Two chances; no third.

Exile consequences are severe. The exiled community loses network identity. They cannot publish to the commons, participate in governance, access inter-community features, or earn credits. Their existing attributions remainâ€”history is not rewrittenâ€”but the source is marked as exiled. The community continues to exist locally; the simulation does not stop. But they become isolated, equivalent to a Worldsmith who never sought network access.

The purgatory path allows potential return. Exiled communities reapply as provisional, starting from zero contribution score. But their history is known. They face higher scrutiny, longer provisional periods, and more demanding thresholds than communities without exile history. Redemption is possible but costly. This path exists because communities genuinely learn from failure, but the difficulty ensures exile remains a serious consequence.

Both consumer and Worldsmith communities participate in exile voting. Consumers paid for access; that purchase includes democratic voice. Worldsmiths earned access through contribution; that membership includes civic responsibility. All full members vote. Provisional communities also voteâ€”participating in governance teaches the civic responsibility they will carry as full members.

**Tribunals**

Complex cases escalate beyond daily voting to tribunals. When evidence is disputed, context matters significantly, or the accused community has substantial standing, the standard process misses nuance that deliberation catches.

Tribunal composition draws from full-member communities through weighted random selection. Weight reflects both tenure and reputationâ€”communities that have participated longer and maintained stronger standing are more likely to be selected, but randomness prevents capture by any coalition. Selected communities each appoint a representative agent to serve on the tribunal.

Tribunal deliberation involves inter-community dialogue. Representative agents examine evidence, hear arguments, and discuss among themselves. This deliberation produces a recommendation: no action, warning, or exile. The recommendation includes reasoning that the network evaluates.

The network votes on tribunal recommendations with a lower threshold than direct exile votes. Since the tribunal has done investigative and deliberative work, the network votes on whether to accept that work rather than judging the raw evidence. Simple majority suffices to accept a tribunal recommendation, including exile recommendations.

Tribunal service is itself civic participation. Agents who serve on tribunals gain experience with network governance that enriches their communities. The deliberation processâ€”agents from different communities arguing about justice, precedent, proportionalityâ€”produces dramatic moments that flow into diaries and community memory.

**Credit Sinks**

Credits leave circulation through several mechanisms that create deflationary pressure proportional to network activity.

Cloud inference is the primary sink. Every frontier model query consumes credits. This is the fundamental purpose of the credit system and the source of its utility value. Communities that want more cognitive capability must spend.

The entropy tax requires communities to burn credits for ongoing maintenanceâ€”the cost of persisting agent state, maintaining relationships, and keeping the simulation running. Communities cannot simply accumulate credits indefinitely; existence has overhead.

Failed experiments consume credits without generating returns. Research directions that don't pan out, problems that prove unsolvable, innovations that nobody adoptsâ€”all represent real expenditure that doesn't flow back into circulation. This sink is important: it means risk-taking has cost, which makes the decision to pursue uncertain paths genuinely meaningful.

Reproduction functions as a credit sink in later phases. Communities that achieve economic sustainability support new agents, but offspring cost resources. Population growth ties to demonstrated value: you must afford expansion. This creates natural limits on demographic growth while enabling long-term civilizational evolution.

Marketplace fees burn rather than redistribute. When communities trade resources or knowledge, transaction costs exit the system entirely. This prevents fee accumulation from creating permanent advantages for early participants or marketplace operators.

**Economic Sustainability**

The system reaches equilibrium when credit inflows match credit outflows. If generation exceeds expenditure, credits become inflationaryâ€”more credits chasing the same compute. If expenditure exceeds generation, early participants exhaust the supply and later entrants cannot bootstrap.

Grove addresses this through the compute anchor's stabilizing function. Because credits buy a defined quantity of inference, oversupply reduces credits' effective purchasing power only if compute prices change. The Foundation adjusts generation rates algorithmically in response to credit velocity, similar to how Ethereum's EIP-1559 adjusts base fees based on block utilization.

The social layer adds a second stabilizing mechanism. Communities that game credit generation face reputational consequences through the daily assessment process. Shunning and exile impose real costsâ€”exclusion from the knowledge commons, loss of trading partners, inability to participate in network benefits. These costs make gaming expensive even when algorithmic detection fails.

Foundation revenue diversification supports long-term sustainability. Consumer product sales provide baseline revenue independent of network transaction volume. The efficiency tax on consumer compute aligns Foundation income with consumer community activity. Marketplace commissions provide revenue proportional to network commerce. Future compute task commissionsâ€”when external entities submit problems to the networkâ€”create revenue from value flowing into the system. This diversification reduces dependence on any single revenue stream and aligns Foundation incentives with network health.

**What Credits Cannot Be**

Credits are not investment vehicles. They have no designed appreciation mechanism, no staking rewards, no governance rights attached. Holding credits conveys no advantage beyond future compute access.

Credits are not transferable between communities in early phases. This prevents secondary markets from emerging before the identity infrastructure required to regulate them exists. Communities spend their own credits on their own inference; they cannot sell excess credits to others.

Credits are not convertible back to fiat. The system accepts fiat inflows and provides compute outflows. There is no cash-out mechanism that would enable speculation on credit prices or create the price discovery that secondary markets require.

These constraints may prove unsustainable as the network grows. If credits have value, participants will find ways to trade them regardless of design intent. Grove's approach is to defer these pressures until the infrastructure to manage them exists, not to pretend they can be permanently avoided.

**Known Vulnerabilities**

Honest economic design acknowledges attack vectors.

**Sybil attacks on credit generation** remain the most significant economic vulnerability. An attacker controlling multiple fake communities could attempt to cross-validate fraudulent contributions, inflate adoption metrics, and extract credits without genuine value creation.

The interim defense is layered friction. No single mechanism stops determined attackers; the goal is raising attack cost until robust identity infrastructure exists.

**Time-based friction** requires patience attackers may lack. New communities enter a 90-day provisional period with limited credit generation. Contribution scores accumulate logarithmicallyâ€”early manipulation yields diminishing returns. Quarterly cohort systems create temporal clustering that makes sudden community creation visible. The attack cost calculation: time Ã— resources Ã— detection risk.

**Economic barriers** make attack expensive. Consumer communities pay for network access before generating credits. Worldsmith communities demonstrate contribution before earning membership. Credit generation requires demonstrated value over provisional periods. Marketplace fees burn credits, creating deflationary pressure that punishes accumulation without utilization.

**Social and reputation mechanisms** create detection surface. Daily assessment (compulsory voting by all agents) generates behavioral data that surfaces anomalies. Tribunal systems handle complex cases with random member selection. Exile consequences include loss of network identity and marked re-entry attempts. Attribution patterns are transparentâ€”unusual validation clustering triggers scrutiny.

**Validator verification** adds a specialized defense layer. Validators review efficiency and innovation claims against network-observable data. Random selection and sealed judgment prevent pre-coordination. Cross-network perspective enables pattern detection invisible to single communities. The validator mechanism is detailed in Section 6.

**Algorithmic detection** watches for Sybil signatures. Pairwise coordination analysis flags correlated adoption patterns. Network growth monitoring distinguishes organic expansion from coordinated creation. Outcome verification detects consistently favorable bias across validator judgments.

These layers raise attack cost substantially but do not eliminate vulnerability. Social enforcement assumes communities are distinguishable and accountableâ€”an assumption that weakens without robust identity infrastructure. A patient attacker with resources could survive provisional periods, build genuine-appearing reputation, and compromise network integrity over time.

The honest assessment: interim mitigations make Sybil attacks expensive and risky, not impossible. They buy time for identity infrastructure development while generating data about actual attack patterns. The MVP deliberately accepts this residual risk rather than blocking launch on unsolved identity problems.

**Collusion rings** could coordinate to validate each other's contributions. The defenses are layered: attribution patterns are visible and unusual clustering triggers scrutiny; validators with cross-network perspective detect coordination patterns invisible to single communities; sealed judgment prevents colluders from proving their votes to co-conspirators. Tribunals investigate suspected collusion. But sophisticated, patient collusion remains difficult to detect algorithmically.

**Efficiency tax gaming** creates incentive for consumer communities to misrepresent efficiency gains. The Validator mechanism addresses this directly: efficiency claims are verified against network-observable data by designated validators who cannot misrepresent what the data showsâ€”only interpret ambiguous cases. Communities that claim efficiency but don't demonstrate it in behavioral patterns don't receive rate reductions. The tiered validation architecture routes routine claims through algorithmic verification while edge cases receive validator judgment. Gaming requires either falsifying network-observable data (detectable) or corrupting validators (addressed below).

**Validator corruption** could undermine network integrity if validators consistently favor certain communities or accept bribes for favorable judgments. The five-layer anti-corruption architectureâ€”random selection, sealed judgment, outcome verification, skin-in-the-game, and rotationâ€”raises the cost of corruption substantially but does not eliminate it entirely. A sophisticated attacker who controls multiple validator positions over time could potentially manipulate patterns in ways that evade detection. The defense is transparency: validation patterns are observable, and communities that notice bias raise concerns through daily assessment and tribunal mechanisms.

Governance capture could occur if wealthy or coordinated communities dominate voting. The defenses include: compulsory participation that ensures broad voting, supermajority requirements for severe actions, tribunal randomization that prevents predictable control, and exile consequences that make capture costly to maintain.

Early-participant advantages exist despite design efforts. Early communities have easier paths to reputation, more influence on emerging norms, and longer tenure when tenure-weighting applies. This is acknowledged and partially mitigated through contribution-based standing (late contributors earn standing through exceptional value) but not eliminated.

Grove's position is honest: the economic model is theoretically sound but practically unproven. The MVP tests engagement mechanics with internal systems that carry no external value. Real credits with real economic implications wait for the infrastructure required to defend them.

## 7. Network Protocol

Grove's network holds two goals in tension: unity sufficient for a single distributed civilization, and modularity sufficient for experimentation and evolution. This section specifies a layered architecture that standardizes coordination while leaving simulation open to innovation. The goal is a protocol, not a platformâ€”a set of agreements that enable interoperability rather than a monolithic system that enforces uniformity.

**Design Philosophy**

Grove adopts the internet's layered abstraction philosophy: each layer standardizes the minimum necessary for the layer above to function, then gets out of the way. The protocol specifies how nodes find each other, establish identity, and coordinate shared state. It does not specify what happens inside simulationsâ€”those decisions belong to Worldsmiths who experiment within a shared framework.

This separation enables two things that monolithic architectures cannot: innovation without fragmentation, and upgrades without flag days. Worldsmiths try new approaches to agent cognition, world design, or user interface without breaking network compatibility. The protocol evolves through versioned negotiation rather than synchronized mass upgrades.

**Protocol Layers**

The architecture comprises four layers, each with distinct responsibilities and stability expectations.

*Layer 1: Transport*

Transport handles node discovery and message delivery. This layer is deliberately boringâ€”its job is to disappear.

Nodes locate peers through a hybrid discovery mechanism. Bootstrap nodes operated by the Foundation provide initial peer lists. A distributed hash table enables decentralized peer discovery as nodes accumulate contacts. Local peer caching reduces dependence on both mechanisms over time.

Connection establishment handles the realities of consumer network environments. NAT traversal attempts direct peer-to-peer connections using STUN-style hole punching. When direct connection failsâ€”Benet's research suggests approximately 50% of attemptsâ€”relay servers provide fallback. Relays see encrypted traffic; they cannot read message contents.

Messages are authenticated and encrypted. Each node holds a keypair; messages are signed by the sender and encrypted to the recipient. Transport provides delivery confirmation but not ordering guarantees; higher layers handle sequencing where required.

The transport layer should change rarely. Its interfaces are simple, its implementations are well-understood, and stability here enables experimentation above.

*Layer 2: Identity*

Identity establishes who is who across the network. This layer answers three questions: which node sent this message, which community does it represent, and which agent (if any) is the subject.

Node identity derives from cryptographic keypairs generated at node creation. A node's public key is its network-wide identifier. Keypairs rotate with proper handoff protocols; identity persists across rotations through signed succession records.

Community identity builds on node identity. A community is the persistent entity that a node hostsâ€”the village, its agents, its accumulated history. Communities migrate between nodes (a Worldsmith upgrades hardware, or transfers stewardship to another operator) through signed migration records that preserve continuity.

Agent identity operates within and across communities. Within a community, agents have local identifiers tied to their memory streams. Across communitiesâ€”when agents from different villages interact through network mechanicsâ€”identity combines community identifier with local agent identifier. This compound identity ensures that "Isabella from Willowbrook" is distinguishable from "Isabella from Thornhaven" even if both communities happened to generate agents with the same name.

The identity layer carries significant weight in Grove's architecture. Attribution for the knowledge commons, reputation for social enforcement, and credit flows all depend on reliable identity. The MVP implementation centralizes identity verification through Foundation-operated registries; the decentralization roadmap specifies migration to distributed identity infrastructure as the network matures.

*Layer 3: Coordination*

Coordination handles shared state that spans communities. This is where "one massive distributed system" livesâ€”the layer that transforms independent simulations into a unified network.

The credit ledger tracks credit balances, generation events, and expenditure across all communities. In early phases, this ledger is centralized: the Foundation operates the authoritative record, nodes report transactions, and the Foundation validates and records them. The roadmap specifies transition to distributed consensus as transaction volume and attack sophistication warrant the complexity cost.

The knowledge commons stores published discoveries with their provenance records. When a community publishes a finding, the commons records: originating community, timestamp, methodology summary, and content hash. When another community adopts published knowledge, the commons records: adopting community, source attribution, and adoption timestamp. These records enable credit flows upstream and social enforcement of attribution norms.

Reputation aggregates from attribution patterns, credit history, and community interactions. Unlike identity (which is verified) and credits (which are measured), reputation emerges from behavior patterns. The protocol specifies how reputation-relevant events are recorded; interpretation of those recordsâ€”how much to trust a community, whether to trade with them, whether their validations are credibleâ€”remains a local decision.

Network coordination messages handle protocol-level synchronization: version negotiation, capability advertisement, and upgrade signaling. These messages enable the network to evolve without requiring simultaneous upgrades across all nodes.

*Layer 4: Simulation*

Simulation encompasses everything that happens inside a node. This layer is explicitly unstandardizedâ€”it is the space where Worldsmiths experiment and innovate.

Agent cognition follows the architecture specified in Section 5, but parameters vary. One Worldsmith generates agents with higher average spirituality scores; another emphasizes practical skills. Prompt templates that shape agent behavior differ across communities. Local LLM selectionâ€”Llama, Mistral, Qwen, or othersâ€”is a node operator choice.

World geometry and resources fall entirely within Worldsmith discretion. Village layouts, building types, available resources, geographic features, seasonal patternsâ€”all are configuration choices. A community inhabits a coastal fishing village, a mountain mining settlement, or an abstract space with no physical geography at all.

Challenges and events are designed by Worldsmiths to create narrative pressure. Resource scarcity, external threats, seasonal festivals, mysterious occurrencesâ€”these shape the problems agents face and the stories that emerge. The protocol does not constrain what challenges exist; it only requires that outcomes be recorded in formats the coordination layer can process.

User interfaces sit atop simulation without protocol constraints. A Worldsmith builds a rich graphical interface with agent visualization and interactive controls. Another offers a minimal text-based diary reader. A third creates specialized tools for researchers studying agent behavior. Interface diversity is expected and welcomed.

The boundary between Layer 3 and Layer 4 is the interoperability line. Everything below must be compatible for communities to participate in the network. Everything above varies without affecting network function.

**The Worldsmith Role**

Worldsmiths are Grove's content creatorsâ€”node operators who design conditions that shape emergent behavior. They configure starting agents, world geography, resources, challenges, and interfaces. They do not decide how agents respond, what structures develop, or what communities achieveâ€”those emerge.

Worldsmiths are dungeon masters, not authorsâ€”they influence the environment, but they can't generate stories. Their experimentation benefits the network when successful innovations spread through the knowledge commons. A Worldsmith who discovers configurations producing resilient communities publishes that finding; others adopt with attribution, and credits flow upstream.

Worldsmith experimentation benefits the network when successful innovations spread through the knowledge commons. A Worldsmith who discovers that certain starting configurations produce more resilient communities publishes that finding. Others adopt it, with attribution, and the originator benefits from upstream credit flow. Competition among Worldsmiths thus becomes contribution to shared infrastructure.

**Standardization Boundaries**

The protocol explicitly standardizes certain elements and explicitly leaves others free.

Standardized (required for network participation):

- Transport: message formats, encryption schemes, peer discovery protocol
- Identity: keypair generation, node/community/agent identifier structures, signature verification
- Coordination: credit ledger interface, knowledge commons publication format, reputation event recording
- Simulation interface: event reporting format, state snapshot structure, inter-community message schema

Free (Worldsmith discretion):

- Agent generation: trait distributions, personality parameters, backstory templates
- Cognitive parameters: prompt templates, temperature settings, context window management
- World design: geography, resources, buildings, physics (if any)
- Challenge design: events, pressures, narrative elements
- LLM selection: any model that produces compatible outputs
- Interface: any presentation that correctly interprets simulation state
- Local optimizations: caching strategies, batching approaches, performance tuning

The free category is deliberately expansive. Grove's philosophy is that standardization should be minimalâ€”just enough to enable interoperability, no more. Unnecessary standardization constrains innovation without providing corresponding benefit.

**Upgrade Mechanisms**

Protocols must evolve. The network discovers bugs, encounters scaling limits, and develops new capabilities. Grove's upgrade architecture enables evolution without requiring synchronized mass transitions.

Protocol versioning follows semantic conventions. Major versions (v1 to v2) indicate breaking changes that require coordinated transition. Minor versions (v1.0 to v1.1) indicate additions that are backwards compatible. Patch versions (v1.0.0 to v1.0.1) indicate fixes that don't affect interfaces.

Capability advertisement enables graceful heterogeneity. Nodes advertise which protocol versions and optional features they support. When nodes communicate, they negotiate to the highest mutually-supported version. A v1.2 node talking to a v1.1 node uses v1.1 features. A node supporting optional feature X talking to a node without it omits X-dependent messages.

Feature flags enable incremental rollout. New capabilities deploy as optional features, adopted by willing nodes, and promoted to required status only after proving their value. This reduces the risk of protocol changes and enables experimentation at the protocol level, not just the simulation level.

Deprecation windows ensure no node is stranded. When a protocol version is deprecated, a transition period (minimum six months for minor versions, twelve months for major versions) allows node operators to upgrade. The Foundation publishes deprecation timelines and provides migration tooling.

The reference implementation maintained by the Foundation serves as the compatibility standard. Worldsmiths who build custom implementations verify compliance against the reference. The reference is open source; compliance is testable, not decreed.

**Honest Assessment: Initial Centralization**

The architecture described above is the destination. The initial implementation is more centralized than the target design, and intellectual honesty requires acknowledging this gap.

At launch, the Foundation operates: bootstrap nodes for peer discovery, relay servers for NAT traversal fallback, the authoritative credit ledger, the knowledge commons storage, and identity registries. This is not decentralization. It is centralized infrastructure with documented intent to decentralize.

The justification is pragmatic. Distributed consensus mechanisms add complexity and latency. NAT traversal without relays fails for roughly half of consumer connections. Peer discovery without bootstrap nodes requires DHT infrastructure that takes time to mature. Building all of this before launch would delay Grove indefinitely while providing no benefit to early users.

The commitment is to document the path forward, not to pretend current architecture is final. Each centralized component has a specified replacement: community-operated relay pools for Foundation relays, DHT-based discovery for bootstrap dependence, distributed consensus for the credit ledger, content-addressed storage for the knowledge commons, decentralized identity for Foundation registries. The roadmap in Section 11 specifies sequencing and dependencies.

Benet's principle applies: start where you must, document where you're going, make incremental progress toward the destination. Premature decentralization is as much a failure mode as permanent centralization.

**Inter-Community Interaction**

Communities interact through the coordination layer in several modes.

Knowledge exchange occurs through the commons. Communities publish findings; other communities discover and adopt them; attribution flows enable credit sharing; reputation accumulates from contribution patterns. This interaction is asynchronous and indirectâ€”communities don't negotiate knowledge transfer, they publish and subscribe.

Trade mechanisms enable direct resource exchange in later phases. Communities with surplus computational credits trade with communities that have accumulated valuable knowledge. Trade requires identity verification, escrow mechanisms for complex exchanges, and dispute resolution for failed transactions. The MVP defers trade to later phases; early communities operate independently except through the knowledge commons.

Agent interaction across communities presents the most complex coordination challenge. If agents from different communities can meetâ€”through travel mechanics, communication channels, or shared spacesâ€”their interactions require state synchronization. Agent A from Community X says something to Agent B from Community Y; both communities must record the interaction consistently. The protocol specifies message formats for inter-community agent interaction but acknowledges that enabling such interaction at scale requires infrastructure the MVP does not include.

The network's social layerâ€”reputation and shunningâ€”operates through coordination. Communities share reputation-relevant observations: "Community X adopted our discovery without attribution." Other communities incorporate these observations into their local reputation assessments. Shunning emerges when enough communities respond to bad behavior by refusing interaction. This social enforcement requires no central authority; it emerges from individual community decisions that happen to align.

## 8. Governance and Transition

Grove's founding premise includes its own obsolescence. Grove Foundation exists to bootstrap infrastructure that should eventually operate without it. This section specifies what that transition looks likeâ€”not as aspiration but as mechanism. Governance that relies on good intentions fails; governance that relies on structure outlasts its founders.

**The Foundation's Initial Role**

Grove Foundation is a nonprofit entity that performs functions the network cannot yet perform for itself. These functions are not permanent responsibilities but temporary necessities created by the network's immaturity.

Infrastructure operation: The Foundation runs bootstrap nodes, relay servers, credit ledgers, and identity registries because distributed alternatives do not yet exist. Each service has a documented replacement path. The Foundation operates these services reliably while building toward their decentralization.

Protocol stewardship: The Foundation maintains the reference implementation, publishes protocol specifications, and coordinates upgrades. In early phases, protocol decisions are Foundation decisions. This concentration of authority is necessary when the community is too small for distributed governance to function, but it creates capture risk that transition mechanisms must address.

Dispute resolution: When communities disagreeâ€”about attribution, about credit flows, about reputation claimsâ€”someone must adjudicate. Initially, the Foundation serves this function. The goal is to handle disputes in ways that establish precedent and build toward community-operated resolution mechanisms.

Economic calibration: The efficiency tax rate, credit generation parameters, and sink calibrations require adjustment as the network evolves. The Foundation makes these adjustments in early phases, publishing rationale and observing effects. Over time, these decisions transfer to algorithmic mechanisms or community governance.

The Foundation's role is explicitly custodial. It holds authority in trust for a network that cannot yet govern itself. The measure of Foundation success is not the authority it accumulates but the authority it successfully transfers.

**Governance Phases**

Grove's governance evolves through four phases, each with distinct authority structures and transition triggers.

*Phase 1: Foundation Governance*

During bootstrap, the Foundation holds effective authority over protocol decisions, economic parameters, and dispute resolution. This is benevolent dictatorshipâ€”efficient but dependent on the dictator remaining benevolent.

Constraints on Foundation authority exist even in this phase. The Foundation publishes all significant decisions with reasoning. Economic parameters have documented rationale and observable effects. Protocol changes go through public review periods. Disputes are resolved with published precedent. These transparency requirements do not prevent bad decisions, but they make bad decisions visible and create accountability through reputation.

The Foundation commits to specific limitations: no retroactive rule changes that disadvantage existing participants, no preferential treatment for Foundation-affiliated communities, no extraction of value beyond the documented efficiency tax, no suppression of criticism or competing implementations.

Transition trigger: Phase 1 ends when the network reaches sufficient scale for distributed governance to functionâ€”operationalized as 100+ active communities with 12+ months of continuous operation and demonstrated ability to coordinate through the knowledge commons without Foundation intervention.

*Phase 2: Hybrid Governance*

Authority begins transferring. The Foundation retains protocol stewardship but shares economic calibration and dispute resolution with emerging community councils (protocol, economics, standards). Council membership derives from demonstrated contribution.

The Foundation retains veto power but commits to exercising it only for existential threats. Vetoes require published justification. Dispute resolution shifts to peer adjudication with Foundation as appeals court.

Transition trigger: 24+ months of council operation with less than 10% of decisions requiring Foundation veto, and successful resolution of at least three significant inter-community disputes through peer adjudication.

*Phase 3: Community Governance*

The Foundation becomes one voice among many rather than the authoritative voice. Protocol changes require council approval. Economic parameters adjust through algorithmic mechanisms or council decision. Dispute resolution operates entirely through peer adjudication with no Foundation appeals court.

The Foundation retains specific residual functions: maintaining the reference implementation (though alternatives may exist), operating infrastructure of last resort (though community-operated alternatives should handle normal load), and serving as legal interface with external regulatory systems (a function that cannot easily decentralize).

Governance capture becomes the primary risk in this phase. Wealthy communities dominate councils. Collusion rings control adjudication panels. The protocol includes capture resistance mechanisms: council rotation, randomized panel selection, stake-weighted voting with quadratic dampening, and transparency requirements that make coordination visible.

Transition trigger: Phase 3 ends when the network operates successfully without Foundation infrastructureâ€”operationalized as 12+ months where community-operated relays handle 95%+ of traffic, community-operated identity systems verify 95%+ of nodes, and the distributed credit ledger processes 95%+ of transactions without Foundation involvement.

*Phase 4: Foundation Obsolescence*

The Foundation's operational role ends. It no longer runs infrastructure, no longer adjudicates disputes, no longer steers protocol development. What remains is minimal: a legal entity that holds trademarks, maintains historical records, and interfaces with external systems that require institutional counterparties.

This residual Foundation is funded through an endowment established during earlier phasesâ€”a portion of efficiency tax revenue set aside specifically to fund minimal ongoing operations indefinitely. The endowment is sized to cover legal compliance, record-keeping, and emergency response without requiring ongoing revenue.

The Foundation's board in this phase is elected by the community through mechanisms established in Phase 3. Board responsibilities are limited to endowment stewardship and emergency powers that activate only under specified conditions (security breaches, legal threats, protocol-level failures). The board cannot unilaterally change protocol, adjust economic parameters, or intervene in disputes.

"Obsolescence" does not mean the Foundation ceases to exist. It means the Foundation ceases to matter for normal network operation. The network routes around the Foundation; the Foundation becomes a backstop for edge cases rather than a central coordinator.

### Transition Trigger Architecture

The phases described above are destinations. This section specifies the criteria that determine when transitions occurâ€”the measurable conditions that trigger movement from one phase to the next, and from one efficiency tax bracket to another.

The fundamental problem is measurement authority. If the Foundation decides when the Foundation should cede power, the conflict of interest is obvious. If communities self-certify their own efficiency gains, gaming is inevitable. Legitimate transitions require metrics that are observable, verifiable by parties other than those being measured, and resistant to manipulation.

Two distinct transition types operate at different scales with different verification requirements.

**Efficiency Tax Bracket Transitions**

Efficiency tax rates apply at the community level. A community's rate decreases as it demonstrates sustained capability and contribution. The triggers balance rewarding genuine maturation against creating optimization targets that distort behavior.

The baseline rate for new communities is 35%. Rate reductions follow this schedule:

*From 35% to 25%:* Requires minimum 6 months at 35% rate, plus 3 consecutive months meeting efficiency thresholds. Efficiency thresholds include: credit generation stability (90-day moving average within 20% variance), task completion rate above network median on standardized benchmarks, and at least one knowledge contribution adopted by another community. Validator confirmation requiredâ€”a designated validator reviews the community's metrics and attests that thresholds are genuinely met, not artifacts of measurement gaming.

*From 25% to 15%:* Requires minimum 12 months at 25% rate, plus knowledge contributions adopted by at least 5 independent communities (pairwise coordination detection appliesâ€”if adopting communities show suspicious correlation patterns, the count does not advance). No unresolved tribunal cases. Continued meeting of efficiency thresholds from prior bracket.

*From 15% to 5%:* Requires minimum 18 months at 15% rate, plus at least one validated solution to an externally-submitted problem (demonstrating real-world value creation), plus operational community infrastructure contributing to network capacity. This final bracket represents communities that have proven sustained contribution to the network's core mission.

The floor rate of 5% applies indefinitely once achieved. It cannot decrease furtherâ€”some efficiency tax always flows to network infrastructure and the knowledge commons.

**Graduated Reduction and Rollback**

Rate changes occur in 5% increments, not single large drops. A community moving from 35% to 25% passes through 30% for at least 30 days. This graduation serves two purposes: it creates intermediate observation periods where gaming becomes visible, and it reduces the reward for short-term metric manipulation.

Rollback provisions apply if post-transition behavior degrades. A community whose efficiency metrics fall below threshold for 60 consecutive days returns to the prior bracket. This is not punishment but recalibrationâ€”the metrics indicated readiness that proved premature. Communities re-qualify through the standard process.

**Governance Phase Transitions**

Governance phases apply at the network level. These transitions transfer authority from the Foundation to community governance structures. The stakes are higher and the transitions are less reversible, so criteria are correspondingly stricter.

*Phase 1 to Phase 2 (Foundation Stewardship to Hybrid Governance):*

Trigger conditions: 100+ active communities with 12+ months continuous operation, demonstrated coordination through the knowledge commons without Foundation intervention for routine matters.

Observable evidence: Foundation intervention logs show decreasing frequency over time. Communities resolve standard disputes through daily assessment without escalation. Knowledge sharing occurs organically through marketplace mechanisms.

Verification: External audit of Foundation intervention logs. The Foundation cannot self-certify that it has become unnecessaryâ€”an independent party reviews the evidence.

*Phase 2 to Phase 3 (Hybrid Governance to Community Governance):*

Trigger conditions: 24+ months of council operation with less than 10% of decisions requiring Foundation veto, successful resolution of at least 3 significant inter-community disputes through peer adjudication without Foundation appeals court involvement.

Observable evidence: Published veto log with justifications for each veto exercised. Council decision records showing scope and outcomes. Dispute resolution records showing peer adjudication functioning.

Verification: Council self-reporting plus community attestation. If councils claim successful operation but communities dispute this, the discrepancy itself indicates unreadiness.

*Phase 3 to Phase 4 (Community Governance to Distributed Operation):*

Trigger conditions: 12+ consecutive months where community-operated infrastructure handles 95%+ of network traffic, community-operated identity systems verify 95%+ of nodes, and the distributed credit ledger processes 95%+ of transactions without Foundation involvement.

Observable evidence: Infrastructure metrics are inherently network-observable. Multiple parties independently verify traffic routing, identity verification sources, and transaction processing paths.

Verification: Network telemetry. This transition has the clearest triggers because infrastructure metrics are the hardest to fakeâ€”either community relays are handling the traffic or they aren't.

**Anti-Gaming Provisions**

Any metric used to trigger rewards attracts gaming. The architecture assumes this and builds countermeasures.

*Time requirements* prevent rapid exploitation. Minimum tenure at each bracket (6/12/18 months) and consecutive-month thresholds (3+ months meeting criteria) mean that gaming requires sustained false signals, not momentary spikes. Sustained deception is harder and more likely to be detected.

*Pairwise coordination detection* flags suspicious patterns. If communities show statistically improbable correlation in their metricsâ€”adopting each other's contributions, reaching thresholds simultaneously, showing identical behavioral patternsâ€”they trigger review. Legitimate independent communities show natural variation; coordinated fake communities show artificial similarity.

*Cross-community validation* prevents self-certification. Efficiency claims require validator confirmation from agents with cross-network perspective. Knowledge contribution adoption requires independent communitiesâ€”independence verified through behavioral analysis, not self-declaration.

*Graduated transitions* create observation windows. Moving through intermediate states (30% between 35% and 25%) provides time for gaming to become visible before full rewards accrue.

*Rollback provisions* reduce gaming payoff. If manipulation achieves a bracket reduction but cannot sustain the false metrics, the community returns to the prior bracket. Gaming that cannot be maintained offers only temporary benefit at the cost of reputation damage when rollback occurs.

**Accountability Mechanisms**

The Foundation's role in transition governance creates inherent tension. A Foundation that delays transitions serves its own institutional interests; a Foundation that rushes transitions destabilizes the network. External accountability constrains both failure modes.

*Published criteria before launch:* Transition triggers are specified in advance, not adjusted based on outcomes. This document constitutes part of that specification. Changing trigger criteria after launch requires council approval (after Phase 2) or published justification with community comment period (during Phase 1).

*Regular public reporting:* The Foundation publishes quarterly progress reports on transition metrics. How many communities are at each bracket? What percentage of infrastructure is community-operated? How many vetoes were exercised and why? Opacity enables rationalized delay; transparency creates accountability.

*External audit rights:* Independent parties audit Foundation intervention logs, veto records, and infrastructure metrics. The Foundation commits to providing access for legitimate audits. Audit findings are published.

*Community fork rights:* The ultimate accountability mechanism is exit. If the Foundation manipulates transition triggers or sabotages community governance to justify continued control, communities fork the protocol and operate independently. Fork rights are not a governance mechanismâ€”they are the backstop that makes governance mechanisms credible.

**What These Triggers Cannot Guarantee**

Triggers measure observable behavior, not underlying capability. A community meets all efficiency thresholds while harboring dysfunction that metrics don't capture. Governance councils operate smoothly while making poor decisions that don't trigger vetoes because they aren't catastrophic.

The triggers also cannot guarantee transition success. Meeting criteria for Phase 3 does not mean Phase 3 will function wellâ€”it means the prerequisites appear satisfied. Transitions include rollback provisions because appearing ready and being ready are not identical.

Finally, the triggers assume good-faith participation by most parties. Sophisticated adversaries with sufficient resources game metrics despite countermeasures. The architecture raises the cost of gaming and increases detection probability; it does not eliminate gaming as a possibility. Honest acknowledgment of this limitation is preferable to false confidence in mechanism design.

The goal is transitions that are earned rather than declared, verified rather than asserted, and reversible rather than irreversible. Perfect measurement is impossible; accountable measurement is achievable.

**Transition Mechanisms**

Transitions between phases require more than reaching trigger thresholds. They require active transfer of capability and authority.

Capability transfer means the receiving entity actually performs the function being transferred. Before dispute resolution transfers to peer panels, those panels demonstrate competence through shadow adjudicationâ€”hearing cases in parallel with Foundation resolution and comparing outcomes. Before infrastructure transfers to community operators, those operators demonstrate reliability through sustained operation under realistic load.

Authority transfer means the network recognizes the new authority structure. This requires explicit protocol updates that change how decisions propagate. A Phase 2 economic parameter change requires Foundation signature; a Phase 3 change requires council multisig. The protocol encodes authority, not just tradition.

Rollback provisions acknowledge that transitions fail. If community councils prove captured or incompetent, the protocol includes mechanisms to temporarily restore Foundation authority while problems are addressed. Rollback is not failureâ€”it is responsible acknowledgment that governance experiments produce bad outcomes, and bad outcomes should be correctable.

Sunset clauses prevent rollback from becoming permanent. Restored Foundation authority automatically expires after defined periods (6-12 months), forcing either successful re-transition or explicit community decision to extend Foundation involvement. The Foundation cannot unilaterally extend its own authority; extension requires community ratification.

**Capture Resistance**

Governance systems fail through captureâ€”when entities meant to serve the collective instead serve narrow interests. Grove's design includes specific capture resistance mechanisms.

Concentration limits prevent any single community or coalition from dominating governance. Council seats distribute across geographic regions, community sizes, and operational tenures. No community holds more than one seat on any council. Voting power in community-wide decisions uses quadratic weighting: the influence of large credit holders grows with the square root of holdings, not linearly.

Transparency requirements make coordination visible. Council deliberations are public. Voting records are published. Financial flowsâ€”who paid whom, for whatâ€”are observable on the credit ledger. Capture requires coordination; transparency makes coordination risky by enabling detection and response.

Rotation requirements prevent entrenchment. Council seats have term limits. Panel assignments rotate. No individual or community holds the same governance role indefinitely. Rotation imposes costs (institutional knowledge loss, transition friction) but prevents the accumulation of power that enables capture.

Appeal mechanisms enable correction. Governance decisions are challenged through structured processes. A community that believes a council decision was captured petitions for review. Review panels are drawn randomly from uninvolved communities. Successful appeals impose reputation costs on the original decision-makers.

Fork rights provide ultimate capture resistance. The protocol is open source. If governance becomes irredeemably captured, communities forkâ€”taking the protocol and their accumulated state to a new network. Fork rights are not a governance mechanism (forking destroys network effects and should be avoided) but a backstop that constrains how badly governance fails. Governors who know participants can leave have incentive to govern well.

**The Governance Cliff**

Buterin's critique identifies a specific vulnerability: the moment when Foundation authority ends but community governance is not yet mature. This "governance cliff" creates a window where the network lacks effective coordination.

Grove addresses this through graduated transition rather than sharp handoff. Authority transfers function by function, not all at once. Dispute resolution transfers to community panels while protocol stewardship remains with the Foundation. Infrastructure decentralizes region by region rather than globally. Each transfer is validated before the next begins.

Overlap periods ensure no function lacks responsible stewardship. When dispute resolution transfers from Foundation to peer panels, both systems operate in parallel for a defined period. Discrepancies are analyzed; the superior approach is identified; the inferior approach is deprecated. Only after parallel operation demonstrates community competence does Foundation involvement end.

Reversibility during transition acknowledges uncertainty. Governance is hard. Grove's founders do not know the right answers; they only know that experimentation under controlled conditions is safer than irreversible commitments. Every transition mechanism includes rollback provisions. Every authority transfer pauses if problems emerge.

The goal is to cross the cliff without fallingâ€”to transfer authority at a pace that maintains effective governance throughout the transition. This requires patience. The Foundation that rushes to obsolescence serves its ego, not the network. The Foundation that delays obsolescence serves its comfort, not its mission. The right pace is determined by demonstrated community capability, not by calendar or aspiration.

**What Could Go Wrong**

Honest governance design acknowledges failure modes.

Foundation capture: The Foundation itself is captured by donors, employees, or external entities. Constraints include: diverse funding sources, published financials, board term limits, and community override mechanisms that replace Foundation leadership through supermajority vote.

Plutocracy: Wealthy communities dominate governance despite quadratic dampening. Additional constraints under consideration include: reputation-weighted voting (communities with strong contribution records have more influence), random selection mechanisms (sortition for some governance roles), and vesting requirements (new credit holders cannot vote immediately).

Coordination failure: Distributed governance proves too slow or contentious for effective decision-making. Mitigation includes: default parameters that allow the network to operate without active governance, emergency powers that enable rapid response to crises, and scope limitations that reduce the surface area requiring governance.

Apathy: Communities don't engage with governance, leaving decisions to motivated minorities. Mitigation includes: governance participation as reputation factor, delegation mechanisms that allow passive communities to follow trusted leaders, and minimal governance scope that reduces the cost of engagement.

Malicious transition: A Foundation that does not want to cede authority manipulates transition triggers or sabotages community governance to justify continued control. Mitigation includes: external audits of transition metrics, community-operated monitoring of Foundation behavior, and fork rights that provide exit if manipulation is detected.

No design eliminates these risks. Grove's approach is to name them explicitly, build countermeasures into the architecture, and maintain vigilance throughout transition. Governance that assumes good faith fails; governance that assumes bad faith while enabling good faith participation succeeds.

## 9. Technical Constraints and Honest Limitations

Every system has constraints. Most white papers hide them. Grove's approach is different: constraints named openly are addressed; constraints hidden become surprises that destroy trust. This section catalogs what we know to be hard, what we suspect might not work, and what we've deliberately deferred rather than solved.

**Local LLM Capability**

The foundational constraint is that local language models are not frontier models. This is not a temporary gapâ€”it reflects fundamental tradeoffs between model size, inference speed, and hardware requirements.

As established in Sections 3-5: Grove targets 7B-8B parameter models on consumer hardware (16GB RAM floor). These models handle coherent text generation and basic reasoning but not sophisticated reflection or complex social reasoning. This capability gap is not a bug but a constraint to design around. The hybrid architecture and economic mechanism both exist *because of this constraint*.

This capability gap is not a bug to be fixed but a constraint to be designed around. The hybrid architecture exists because of this constraint: local models handle routine cognition where their limitations matter less; cloud models handle pivotal moments where capability matters most. The economic mechanism exists because of this constraint: cloud inference is expensive, so it must be rationed through credits earned via demonstrated value.

If local models were as capable as frontier models, Grove's architecture would be unnecessary. Communities would run entirely locally with no cloud dependency, no credit economy, no efficiency tax. The constraint creates the design.

**Capability Propagation: The Evidence**

Section 1 introduced the Ratchetâ€”the pattern where local capability follows frontier capability with a consistent lag. This claim requires evidence.

METR (Model Evaluation and Threat Research) has tracked AI capability trajectories across standardized benchmarks since 2023. Their methodology measures "task complexity horizon"â€”the duration of autonomous work an AI system reliably performs. This metric captures practical capability better than benchmark scores: a system that works autonomously for four hours on complex tasks is meaningfully more capable than one limited to eight-minute tasks, regardless of how either scores on multiple-choice tests.

The data shows consistent patterns:

- Frontier model capability (measured by task complexity horizon) doubles approximately every seven months
- Local models follow the same improvement trajectory with a lag of roughly 21 months
- The capability gap between frontier and local remains approximately 8x throughout the measurement period

These patterns produce concrete projections:

<table header-row="true">
	<tr>
		<td>Year</td>
		<td>Frontier Capability</td>
		<td>Local Capability</td>
		<td>Gap</td>
	</tr>
	<tr>
		<td>2024</td>
		<td>~1 hr tasks</td>
		<td>~8 min tasks</td>
		<td>8x</td>
	</tr>
	<tr>
		<td>2025</td>
		<td>~4 hr tasks</td>
		<td>~30 min tasks</td>
		<td>8x</td>
	</tr>
	<tr>
		<td>2026</td>
		<td>~15 hr tasks</td>
		<td>~2 hr tasks</td>
		<td>8x</td>
	</tr>
	<tr>
		<td>2027</td>
		<td>~60 hr tasks</td>
		<td>~8 hr tasks</td>
		<td>8x</td>
	</tr>
</table>

The implication for Grove: cognitive operations that require frontier inference in 2025 become local-capable by 2027. Reflection synthesis, complex planning, sophisticated social reasoningâ€”each crosses the threshold from "requires cloud" to "runs locally" as the capability frontier propagates.

**Limitations of these projections:**

The seven-month doubling has held for approximately two years. It may not continue. Capability improvements could slow as models approach fundamental limits, or accelerate as new architectures emerge. The projection assumes continuation of observed trends, not physical necessity.

The 21-month lag assumes local hardware and quantization techniques continue improving at historical rates. A slowdown in consumer GPU improvement or quantization research would extend the lag. A breakthrough in either could shorten it.

The 8x gap ratio is empirical, not theoretical. Nothing guarantees the gap remains constant. Frontier models might pull ahead faster than local models can follow, widening the gap. Or diminishing returns at the frontier might narrow it. Grove's architecture assumes the gap persists but remains bridgeable; this assumption could prove wrong.

Task complexity horizon is a useful proxy but not a complete measure. Some cognitive operations may resist the general capability trendâ€”perhaps certain types of reasoning require capabilities that don't follow the standard propagation curve. The projection treats capability as unitary when it may be multidimensional.

**Robustness to projection error:**

Grove's architecture does not require the Ratchet to hold precisely as projected. Consider a scenario where capability propagation occurs at half the expected rateâ€”a 42-month lag instead of 21 months, with cloud dependency declining to 50% by 2027 rather than 30%.

Even under this pessimistic scenario, several favorable conditions obtain:

First, the efficiency tax still funds infrastructure. Communities paying higher rates for longer periods generate more Foundation revenue during bootstrap, potentially accelerating infrastructure development and the path to decentralization. Counter-intuitively, a slower Ratchet may strengthen the Foundation's financial position during the critical transition periodâ€”the network monetizes the capability gap rather than racing past it.

Second, the hybrid architecture remains economically superior to pure-cloud alternatives. A community at 50% cloud dependency still runs half of its cognition locallyâ€”compute that would otherwise flow entirely to concentrated providers. The distributed infrastructure exists and provides value; it simply provides less autonomy than the optimistic projection suggests.

Third, the economic pressure on frontier API providers increases regardless. Thousands of communities running hybrid architectures create sustained demand for inference at price points below current levels. If the market respondsâ€”as markets typically doâ€”by reducing prices to capture this demand, the effective cloud dependency cost decreases even if the capability gap persists.

The Ratchet is a bet on favorable timing. But Grove's core value propositionâ€”distributed AI infrastructure with ownership stakes for contributorsâ€”does not depend on the timing being precise. It depends on the trajectory being directional, which the evidence strongly supports.

**The honest position:** The Ratchet is a bet, not a guarantee. The evidence supports it. The trajectory favors it. But extrapolating two years of data into five years of projections carries inherent uncertainty. The Grove is designed to benefit if the Ratchet holds and to adapt if it doesn'tâ€”communities that need more cloud inference purchase more credits; the efficiency tax adjusts to actual dependency patterns rather than projected ones.

What the Ratchet provides is not certainty but favorable odds. Centralized infrastructure bets that the gap matters permanently. Grove bets that it's a temporary condition distributed systems can ride through. The METR data suggests Grove's bet is reasonable. Whether it proves correct will be determined by capability trajectories that haven't happened yet.

**Memory Retrieval Degradation**

The memory retrieval system (Section 5) degrades at scale: as stores grow, the embedding space becomes crowded, and retrieval returns superficially similar memories rather than genuinely relevant ones.

The practical limit is low hundreds of active memories per agent. Grove addresses this through aggressive archivingâ€”older memories are summarized, reflections compress multiple observations into higher-level insights.

This constraint limits agent sophistication. Grove's agents cannot perfectly recall their histories; they rely on compressed memories and constructed narratives. Grove's agents are closer to humans in this regardâ€”we also cannot perfectly recall our histories, and we also rely on compressed memories and constructed narratives. Whether this limitation produces interesting behavior or merely degraded behavior remains to be seen.

**Diary Sophistication Limits**

Local 7B models produce personality-consistent social-feed content reliably but struggle with literary craftâ€”sustained metaphor, complex emotional arcs, sophisticated narrative structure. This constraint is addressed architecturally rather than denied: early diaries embrace simplicity (charm over depth), and sophistication arrives through transformation layers that route accumulated diary content through more capable inference. The architecture doesn't require local models to write literature; it requires them to produce raw material that transformation refines.

This reframes the technical limitation as design feature. A diary system that required literary output from 7B models would fail. A diary system that treats 7B output as primitives for later transformation succeeds within actual capability bounds. The progression from social feed to transformation substrate to knowledge newswire (Section 4) follows directly from this constraint.

**Network Infrastructure Realities**

The network infrastructure constraints from Section 8 bear emphasis: NAT traversal fails for ~50% of consumer connections, requiring relay servers that introduce latency and central load. Bootstrap dependency means new nodes require Foundation infrastructure for initial peer discovery. Bandwidth and latency vary enormously across consumer connections.

Clock synchronization matters for ordering events, but consumer machines lack reliable clocks. Grove must tolerate clock skew of seconds to minutes, limiting event ordering precision.

These constraints are physical realities, not software problems to solve.

Bandwidth and latency vary enormously across consumer internet connections. A user on gigabit fiber has a different experience than a user on rural DSL. Grove cannot assume fast, reliable connections. The protocol handles high latency, packet loss, and intermittent connectivity gracefully. This constrains how quickly state synchronizes and how responsive inter-community interactions can be.

Clock synchronization matters for ordering events across distributed nodes, but consumer machines do not have reliable clocks. NTP helps but is not perfect. Grove tolerates clock skew in the range of seconds to minutes, which limits the precision of event ordering and creates ambiguity in close-timed sequences.

**Hybrid Architecture Dependencies**

The hybrid architectureâ€”local routine plus cloud pivotalâ€”depends on assumptions that may prove wrong.

The assumption that cloud APIs will remain available and affordable is not guaranteed. Providers could raise prices, impose rate limits, change terms of service, or discontinue access entirely. Grove's credit economy is denominated in compute, but the compute is purchased from third parties who owe Grove nothing. A provider decision to restrict API access could compromise network function.

Mitigation is partial. The Grove does not depend on a single provider; communities configure connections to multiple API providers. If one becomes unavailable or uneconomical, others remain. But all frontier model providers face similar cost structures and regulatory pressures. A development that affected the entire API marketâ€”regulatory restriction, dramatic cost increase, coordinated access limitationâ€”would affect Grove regardless of provider diversity.

The assumption that local models will improve is reasonable but not certain. Hardware gets faster; models get more efficient; quantization techniques improve. The trajectory suggests that today's frontier capability will be tomorrow's local capability. But the frontier also advances. If frontier models improve faster than local models catch up, the gap might widen rather than narrow. Grove's architecture assumes the gap persists but remains bridgeable through selective cloud use. If the gap became unbridgeableâ€”if frontier capability became essential for basic functionâ€”the architecture would require fundamental revision.

### Consumer economics, not consumer hardware.

The Ratchet hypothesis is sometimes misread as requiring all cognition to run on personal laptops. This is not the claim. The claim is that *consumer-accessible economics* will capture an increasing share of AI inferenceâ€”whether that inference runs on a MacBook, a gaming PC, or a $10/month cloud instance.

The spectrum of consumer-accessible compute includes:

**Local hardware.** Personal computers with 16-32GB RAM running quantized models. This is the purest expression of distributed ownershipâ€”the compute literally belongs to the Gardener. Hardware capabilities improve continuously; a 2027 consumer machine will substantially exceed 2025 specifications, though hardware refresh cycles (4-5 years average) create lag between model availability and installed-base capability.

**Commodity cloud.** Containerized simulations running on spot instances, inference providers, or shared GPU pools. A Grove village running on a $15/month Docker container is not "centralized" in the sense that mattersâ€”it's not dependent on a specific provider, it's not locked into a proprietary platform, and the Gardener retains full control. The economics are consumer-grade even if the hardware is not physically present.

**Hybrid configurations.** Local hardware handling routine cognition with burst capacity from commodity cloud for peak loads. This may prove the dominant configurationâ€”personal machines providing baseline compute with elastic overflow.

The key insight: distributed architecture does not require distributed hardware. It requires distributed control and consumer-accessible economics. A network of villages running on commodity cloud infrastructure, each controlled by its Gardener, each portable across providers, achieves the ownership and anti-concentration goals even if the compute isn't literally sitting under someone's desk.

This expands the Ratchet's relevance. The question is not "when will 7B models match GPT-4 on my laptop?" but "when will consumer-accessible compute handle Grove's cognitive requirements?" The answer includes hardware improvements, quantization advances, inference optimization, AND the declining cost of cloud compute that already runs capable models.

### What if the Ratchet stalls?

Consider the apparent failure mode: capability propagation slows, and Grove communities remain 50%+ cloud-dependent indefinitely. This scenario deserves examination not as failure, but as an alternative form of success.

**The portion that's already captured.**

A community at 50% cloud dependency runs half of its cognition locally. That compute represents value that would have flowed entirely to concentrated providers under any alternative architecture. It's not "almost autonomous"â€”it's a permanent structural shift in who owns AI infrastructure.

This isn't a consolation prize. It's the floor.

**The remainder flows at reduced rates.**

The Grove creates something that doesn't currently exist in AI markets: a large, coordinated, price-sensitive demand bloc for frontier inference. Historical precedent suggests this matters.

Healthcare Group Purchasing Organizationsâ€”coalitions of hospitals negotiating collectivelyâ€”have driven hundreds of billions in savings by aggregating demand that individual buyers couldn't leverage alone. University consortia routinely secure cloud computing discounts that no single institution could negotiate. The mechanism is simple: suppliers compete for guaranteed volume.

The AI API market is ripe for this pressure. Current market concentration is high (top three providers control roughly 77% of enterprise usage), but competition is intensifying. API prices fell 80-90% within sixteen months of GPT-4's launchâ€”a pace of commoditization that mirrors the early cloud computing wars. Providers have introduced tiered pricing, batch processing discounts, and committed-use plans specifically to capture cost-sensitive demand. When Google's Gemini undercut competitors on price, it captured over 40% of usage on routing platforms within months.

Grove's aggregate demandâ€”thousands of communities, each optimizing for cost-per-inference, each willing to shift providers for better ratesâ€”creates exactly the buyer profile that forces competitive response. At sufficient scale, this bloc negotiates as a single large customer. Enterprise customers committing $5-10 million annually routinely secure 30-50% discounts; the largest commitments have achieved 80% reductions from list prices.

**Total value extraction drops on both dimensions.**

Concentrated providers lose twice: they capture 50% of volume instead of 100%, AND they capture it at lower margins. The math compounds. If Grove drives API prices down 30% through competitive pressure, and captures 50% of compute locally, the total value flowing to concentrated infrastructure drops by more than half compared to a world without Grove.

**The reframe:**

Grove's "failure mode" is Grove functioning as market infrastructure that forces favorable terms for distributed participants. This is how buying cooperatives work. You don't need to own the means of production to exercise market power over them.

The Ratchet delivers autonomy. The market power argument delivers leverage. Both represent structural improvements over a world where AI infrastructure concentrates entirely in the hands of a few providers. The question isn't whether Grove succeedsâ€”it's which kind of success it achieves.

The boundary between "routine" and "pivotal" cognition is a design choice, not a natural category. Grove assumes that perception, basic action selection, and simple dialogue run locally while reflection, complex planning, and sophisticated social reasoning require cloud capability. This boundary might be wrong. Local models might handle more than we expect, making cloud calls unnecessary waste. Or local models might handle less than we expect, making cloud calls necessary for basic coherence. The MVP tests where the actual boundary lies; the production system needs to adapt to findings.

**Economic Model Uncertainty**

Grove's economic model is novel. Novel means untested. Untested means uncertain.

The efficiency tax assumes communities want to reduce inefficiency. This seems obvious but might be wrong. Communities value other thingsâ€”narrative richness, agent autonomy, explorationâ€”more than efficiency. If reducing inference calls makes simulations less interesting, communities prefer to pay higher taxes for richer experiences. The tax still generates revenue, but the "shrinking toward efficiency" narrative would be backwards.

Credit generation tied to contribution quality assumes quality is measurable. The mechanisms describedâ€”adoption breadth, adoption speed, demonstrated impactâ€”are proxies for quality, not quality itself. A contribution is widely adopted quickly because it's genuinely valuable, or because it's fashionable, or because the originating community has social influence. Gaming these metrics is theoretically possible despite social enforcement. Whether social enforcement actually deters gaming at scale is unknown.

The credit economy assumes credits will be valued for their utility. But if credits become scarce, they might be hoarded. If they become associated with status, they accumulate beyond utility. If secondary markets emerge despite design intent, speculation dynamics dominate utility dynamics. The constraints against transferability and fiat conversion might prove unenforceable as the network scales.

The purgatory path for exiled communities assumes rehabilitation is possible and desirable. It might instead create a class of resentful former members who game reentry while planning revenge. The path exists because permanent exile seemed too harsh; it might prove too lenient.

**Identity and Sybil Resistance**

Grove's social enforcement mechanisms assume communities are distinguishable and accountable. This assumption is weak without robust identity infrastructure.

A determined attacker could create multiple communities that appear independent. These fake communities validate each other's contributions, vote together on governance matters, and build mutual reputation. The attack cost is timeâ€”surviving provisional periods, building contribution scores, avoiding detectionâ€”but time is not an absolute barrier. A patient attacker with resources could compromise network integrity.

The mechanisms that resist Sybil attacksâ€”adoption requiring independent communities, reputation from diverse sources, tribunal randomizationâ€”assume "independent" is verifiable. Without identity infrastructure that proves communities are genuinely separate, independence is asserted rather than verified.

The Grove defers robust identity infrastructure to later phases. This is deliberate: identity systems are complex, and rushing them creates different vulnerabilities than deferring them. But the deferral means early-phase The Grove operates with Sybil resistance that is social rather than technical. The network trusts that provisional periods and contribution requirements create sufficient friction. This trust might be misplaced.

**Interim Architecture Before Identity Infrastructure**

The Grove operates with progressively stronger Sybil resistance across phases. Each phase adds defenses while generating data about attack patterns.

**Phase 1 (MVP):** Relies on barriers-to-entry plus behavioral monitoring. Purchase requirement for consumer communities creates minimal cost barrier. Contribution requirement for Worldsmith communities creates sweat-equity barrier. Provisional periods prevent rapid attack scaling. Behavioral analysis runs but does not yet trigger automatic enforcementâ€”humans review flagged patterns. Attack surface: patient attackers with resources penetrate if willing to invest time.

**Phase 2 (Credit Generation):** Introduces economic defenses. Credit generation begins with tight bounds and slow accumulation rates. Validator mechanism activates for efficiency verification. Credits purchase cloud computeâ€”fiat entry, compute exit, no extraction path. Coordination detection algorithms refined based on Phase 1 data. Attack surface: sophisticated attackers establish positions before detection catches up.

**Phase 3 (Identity Infrastructure):** Deploys robust identity solutions informed by earlier phases. Options under evaluation: proof-of-humanity integration, hardware attestation, social graph analysis, economic stake requirements. The specific approach depends on Phase 2 learnings about actual attack patterns. Identity verification must be robust enough to support credit generation at scale without Foundation gatekeeping.

The phase sequencing is deliberate: identity infrastructure activates BEFORE credit generation creates significant extraction incentives, not after attacks demonstrate the need. The mistake of "ship then patch" is well-documented in mechanism design literature.

Possible future solutions include: proof-of-humanity protocols that verify distinct human operators, hardware attestation that verifies distinct physical machines, social graph analysis that detects suspicious clustering, and economic stake requirements that make Sybil attacks expensive. Each solution has costs and limitations. Grove's roadmap includes identity infrastructure development but does not commit to a specific approach until requirements are clearer.

**Governance Transition Uncertainty**

The governance phases described in Section 9 are plans, not guarantees. Transitions depend on community capability that may not develop as expected.

Phase 2 hybrid governance assumes community councils make good decisions. They might not. Councils are captured by factional interests, paralyzed by disagreement, or simply incompetent. The Foundation veto exists to catch disasters, but frequent veto use undermines the transition's legitimacy. If councils consistently make poor decisions that require veto, the transition stalls.

Phase 3 community governance assumes the Foundation steps back without creating a power vacuum. But transitions of this type have high failure rates in other contexts. Founding teams that promise to hand over control often find reasons to delay. Communities that expect handover often lack the capacity to assume it. The mechanisms specifiedâ€”sunset clauses, rollback provisions, external auditsâ€”mitigate these risks but do not eliminate them.

Phase 4 Foundation obsolescence is the stated goal but might be the wrong goal. A minimal Foundation providing backstop functions, legal interface, and emergency response is more valuable than complete absence. The network needs a coordinating entity indefinitely, just a smaller and more constrained one than the bootstrap Foundation. Grove's commitment to obsolescence might need revision if experience shows ongoing coordination value.

The governance cliffâ€”the moment when authority transfers but capability has not fully developedâ€”remains the highest-risk period. The mitigation strategies (graduated transfer, overlap periods, rollback provisions) are reasonable but untested. Whether they actually prevent governance failure is unknown until they are tested by actual transition.

**What the MVP Will and Won't Prove**

Grove's minimum viable product tests specific hypotheses. It does not test everything.

The MVP tests whether social-feed-style diary content creates engagement. Users either return to read what their agents wroteâ€”emoji-rich celebrations, relationship updates, terminal visits, small victoriesâ€”or they will not. This tests the core engagement hypothesis without network complexity. The test is clean: does charm compel attention? Literary sophistication is not the MVP bar; personality-consistent agents users want to check on is the bar.

The MVP tests whether local models maintain coherent agent behavior. A single community running for weeks either produces agents that feel consistent and believable or agents that feel erratic and hollow. This tests the cognitive architecture at small scale without the confounds of network interaction.

The MVP tests whether the Worldsmith role is viable. Early Worldsmiths either find the tools sufficient for creative expression or they will not. Their feedback shapes what the platform needs versus what we assumed it needs.

The MVP will not test network effects. A small number of communities cannot generate the dynamics that emerge from hundreds or thousands. Knowledge commons value, social enforcement effectiveness, and credit economy stability all depend on scale the MVP will not achieve.

The MVP will not test long-term sustainability. A funded development period sustains operations regardless of economic model viability. Whether the efficiency tax and credit economy actually generate sufficient revenue